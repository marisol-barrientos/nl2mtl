@article{oda_viennadoc_2020,
	title = {{ViennaDoc}: {An} animatable and testable specification documentation tool},
	volume = {12233 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089717739&doi=10.1007%2f978-3-030-54997-8_19&partnerID=40&md5=dc364d12084ae68964ed98e902fe0063},
	doi = {10.1007/978-3-030-54997-8_19},
	abstract = {An obstacle to applying formal specification techniques to industrial projects is that stakeholders with little engineering background may experience difficulty comprehending the specification. Forming a common understanding of a specification is indeed essential in software development because a specification is consulted by many kinds of stakeholders, including those who do not necessarily have an engineering background. This paper introduces ViennaDoc, a specification documentation tool that interleaves animation of a formal specification into informal texts written using natural language. ViennaDoc helps readers to understand the behaviour of the specified system by providing opportunities to verify their understanding by executing the specification in the context of the informal explanation. ViennaDoc also helps maintainers of the specification by enabling unit testing that asserts equality between values embedded in the informal specification and formal expressions. © Springer Nature Switzerland AG 2020.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Oda, Tomohiro and Araki, Keijiro and Yamamoto, Yasuhiro and Nakakoji, Kumiyo and Sako, Hiroshi and Chang, Han-Myung and Larsen, Peter Gorm},
	editor = {E, Sekerinski and N, Moreira and J.N, Oliveira and D, Ratiu and R, Guidotti and M, Farrell and M, Luckcuck and D, Marmsoler and J, Campos and T, Astarte and L, Gonnord and A, Cerone and L, Couto and B, Dongol and M, Kutrib and P, Monteiro and D, Delmas},
	year = {2020},
	note = {ISBN: 978-303054996-1
Publisher: Springer
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Software design, Formal expressions, Documentation tools, Formal specification techniques, Industrial projects, Unit testing},
	pages = {289 -- 302},
	annote = {Cited by: 0; Conference name: 3rd World Congress on Formal Methods, FM 2019; Conference date: 7 October 2019 through 11 October 2019; Conference code: 243549; All Open Access, Green Open Access},
}


@inproceedings{dave_identifying_2022,
	title = {Identifying {Functional} and {Non}-functional {Software} {Requirements} from {User} {App} {Reviews}},
	isbn = {978-1-66548-684-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133840756&doi=10.1109%2fIEMTRONICS55184.2022.9795770&partnerID=40&md5=1c2a464458ba3d79df13b99c99127002},
	doi = {10.1109/IEMTRONICS55184.2022.9795770},
	abstract = {Mobile app developers are always looking for ways to use the reviews (provided by their app's users) to improve their application (e.g., adding a new functionality in the app that a user mentioned in their review). Usually, there are thousands of user reviews that are available for each mobile app and isolating software requirements manually from such as big dataset can be difficult and time-consuming. The primary objective of the current research is to automate the process of extracting functional requirements and filtering out non-requirements from user app reviews to help app developers better meet the wants and needs of their users. This paper proposes and evaluates machine learning based models to identify and classify software requirements from both, formal Software Requirements Specifications (SRS) documents and Mobile App Reviews (written by users) using machine learning (ML) algorithms combined with natural language processing (NLP) techniques. Initial evaluation of our ML-based models show that they can help classify user app reviews and software requirements as Functional Requirements (FR), Non-Functional Requirements (NFR), or Non-Requirements (NR). © 2022 IEEE.},
	language = {English},
	booktitle = {2022 {IEEE} {International} {IOT}, {Electronics} and {Mechatronics} {Conference}, {IEMTRONICS} 2022},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Dave, Dev and Anu, Vaibhav},
	editor = {S, Chakrabarti and R, Paul and B, Gill and M, Gangopadhyay and S, Poddar},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Software requirements, Machine learning, Learning algorithms, Classification (of information), Application programs, Language processing, Requirement, Machine-learning, Natural language processing, Functional requirement, Learning Based Models, Mobile app, Non-functional},
	annote = {Cited by: 1; Conference name: 2022 IEEE International IOT, Electronics and Mechatronics Conference, IEMTRONICS 2022; Conference date: 1 June 2022 through 4 June 2022; Conference code: 180242},
	annote = {Cited by: 3; Conference name: 2022 IEEE International IOT, Electronics and Mechatronics Conference, IEMTRONICS 2022; Conference date: 1 June 2022 through 4 June 2022; Conference code: 180242},
	annote = {RELEVANCE: MEDIUM
},
}


@article{da_silva_automatic_2022,
	title = {Automatic {Trajectory} {Synthesis} for {Real}-{Time} {Temporal} {Logic}},
	volume = {67},
	issn = {00189286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100831781&doi=10.1109%2fTAC.2021.3058068&partnerID=40&md5=8e7f616e9d43f5f4e08fde63c7980083},
	doi = {10.1109/TAC.2021.3058068},
	abstract = {Many safety-critical systems, such as autonomous vehicles and service robots, must achieve high-level task specifications with performance guarantees. Much recent progress toward this goal has been made through an automatic controller synthesis from temporal logic specifications. Existing approaches, however, have been limited to relatively short and simple specifications. Furthermore, existing methods either consider some prior discretization of the state space, deal only with a convex fragment of temporal logic, or are not provably complete. We propose a scalable, provably complete algorithm that synthesizes continuous trajectories to satisfy nonconvex temporal logic over reals (RTL) specifications. We separate discrete task planning and continuous motion planning on-the-fly and harness highly efficient Boolean satisfiability and linear programming solvers to find dynamically feasible trajectories that satisfy nonconvex RTL specifications for high-dimensional systems. The proposed design algorithms are proven sound and complete, and simulation results demonstrate our approach's scalability. © 1963-2012 IEEE.},
	language = {English},
	number = {2},
	journal = {IEEE Transactions on Automatic Control},
	author = {Da Silva, Rafael Rodrigues and Kurtz, Vince and Lin, Hai},
	year = {2022},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.
Type: Article},
	keywords = {Temporal logic, Specifications, Task specifications, Computer circuits, Safety engineering, Safety critical systems, Controller synthesis, High-dimensional systems, Linear programming, Real-time temporal logic, Satisfiability modulo Theories, Temporal logic specifications, Trajectories, Trajectory synthesis},
	pages = {780 -- 794},
	annote = {Cited by: 0; All Open Access, Green Open Access},
	annote = {Cited by: 2; All Open Access, Bronze Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{d_28th_2022,
	title = {28th {International} {Conference} on {Tools} and {Algorithms} for the {Construction} and {Analysis} of {Systems}, {TACAS} 2022 held as part of 25th {European} {Joint} {Conferences} on {Theory} and {Practice} of {Software}, {ETAPS} 2022},
	volume = {13244 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128704610&partnerID=40&md5=165ed285cbdf5cd3eec313b3824c770e},
	abstract = {The proceedings contain 67 papers. The special focus in this conference is on Tools and Algorithms for the Construction and Analysis of Systems. The topics include: A New Approach for Active Automata Learning Based on Apartness; learning Realtime One-Counter Automata; scalable Anytime Algorithms for Learning Fragments of Linear Temporal Logic; learning Model Checking and the Kernel Trick for Signal Temporal Logic on Stochastic Processes; inferring Interval-Valued Floating-Point Preconditions; neuReach: Learning Reachability Functions from Simulations; inferring Invariants with Quantifier Alternations: Taming the Search Space Explosion; linSyn: Synthesizing Tight Linear Bounds for Arbitrary Neural Network Activation Functions; The Complexity of LTL Rational Synthesis; Kmclib: Automated Inference and Verification of Session Types from OCaml Programs; automated Translation of Natural Language Requirements to Runtime Monitors; maskD: A Tool for Measuring Masking Fault-Tolerance; better Counterexamples for Dafny; cvc5: A Versatile and Industrial-Strength SMT Solver; clausal Proofs for Pseudo-Boolean Reasoning; moving Definition Variables in Quantified Boolean Formulas; a Sorted Datalog Hammer for Supervisor Verification Conditions Modulo Simple Linear Arithmetic; property Directed Reachability for Generalized Petri Nets; transition Power Abstractions for Deep Counterexample Detection; synthesis of Compact Strategies for Coordination Programs; searching for Ribbon-Shaped Paths in Fair Transition Systems; coVeriTeam: On-Demand Composition of Cooperative Verification Systems; ZDD Boolean Synthesis; comparative Verification of the Digital Library of Mathematical Functions and Computer Algebra Systems; Verifying Fortran Programs with CIVL; NORMA: a tool for the analysis of Relay-based Railway Interlocking Systems; efficient Neural Network Analysis with Sum-of-Infeasibilities; formal Verification of the Ethereum 2.0 Beacon Chain.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {D, Fisman and G, Rosu},
	year = {2022},
	note = {ISBN: 978-303099526-3
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: 28th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2022 held as part of 25th European Joint Conferences on Theory and Practice of Software, ETAPS 2022; Conference date: 2 April 2022 through 7 April 2022; Conference code: 276269},
	annote = {Cited by: 0; Conference name: 28th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2022 held as part of 25th European Joint Conferences on Theory and Practice of Software, ETAPS 2022; Conference date: 2 April 2022 through 7 April 2022; Conference code: 276269},
	annote = {Cited by: 0; Conference name: 28th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2022 held as part of 25th European Joint Conferences on Theory and Practice of Software, ETAPS 2022; Conference date: 2 April 2022 through 7 April 2022; Conference code: 276269},
	annote = {Cited by: 0; Conference name: 28th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2022 held as part of 25th European Joint Conferences on Theory and Practice of Software, ETAPS 2022; Conference date: 2 April 2022 through 7 April 2022; Conference code: 276269},
	annote = {Cited by: 0; Conference name: 28th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2022 held as part of 25th European Joint Conferences on Theory and Practice of Software, ETAPS 2022; Conference date: 2 April 2022 through 7 April 2022; Conference code: 276269},
	annote = {ISBN: 978-303099523-2 Publisher: Springer Science and Business Media Deutschland GmbH Type: Conference review},
	annote = {RELEVANCE: NULL - procedings
},
}


@inproceedings{conrad_compositional_2022,
	address = {New York, NY, USA},
	series = {{CPP} 2022},
	title = {A {Compositional} {Proof} {Framework} for {FRETish} {Requirements}},
	isbn = {978-1-4503-9182-5},
	url = {https://doi.org/10.1145/3497775.3503685},
	doi = {10.1145/3497775.3503685},
	abstract = {Structured natural languages provide a trade space between ambiguous natural languages that make up most written requirements, and mathematical formal specifications such as Linear Temporal Logic. FRETish is a structured natural language for the elicitation of system requirements developed at NASA. The related open-source tool Fret provides support for translating FRETish requirements into temporal logic formulas that can be input to several verification and analysis tools. In the context of safety-critical systems, it is crucial to ensure that a generated formula captures the semantics of the corresponding FRETish requirement precisely. This paper presents a rigorous formalization of the FRETish language including a new denotational semantics and a proof of semantic equivalence between FRETish specifications and their temporal logic counterparts computed by Fret. The complete formalization and the proof have been developed in the Prototype Verification System (PVS) theorem prover.},
	booktitle = {Proceedings of the 11th {ACM} {SIGPLAN} {International} {Conference} on {Certified} {Programs} and {Proofs}},
	publisher = {Association for Computing Machinery},
	author = {Conrad, Esther and Titolo, Laura and Giannakopoulou, Dimitra and Pressburger, Thomas and Dutle, Aaron},
	year = {2022},
	note = {event-place: Philadelphia, PA, USA},
	keywords = {Formal specification, Natural languages, Semantics, Temporal logic, Linear temporal logic, Model checking, Formal verification, Computer circuits, Safety engineering, Formalisation, NASA, Requirement, Formal proofs, Formal Proofs, Metric temporal logic, Metric Temporal Logic, Open systems, Prototype verification systems, PVS, Requirements, Space between, Structured natural language, Structured Natural Language, Trade space},
	pages = {68--81},
	annote = {Cited by: 4; Conference name: 11th ACM SIGPLAN International Conference on Certified Programs and Proofs, CPP 2022 - co-located with POPL 2022; Conference date: 17 January 2022 through 18 January 2022; Conference code: 176264; All Open Access, Green Open Access},
	annote = {Cited by: 6; Conference name: 11th ACM SIGPLAN International Conference on Certified Programs and Proofs, CPP 2022 - co-located with POPL 2022; Conference date: 17 January 2022 through 18 January 2022; Conference code: 176264; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{pei_can_2023,
	series = {{ICML}'23},
	title = {Can {Large} {Language} {Models} {Reason} about {Program} {Invariants}?},
	abstract = {Identifying invariants is an important program analysis task with applications towards program understanding, bug finding, vulnerability analysis, and formal verification. Existing tools for identifying program invariants rely on dynamic analysis, requiring traces collected from multiple executions in order to produce reliable invariants. We study the application of large language models to invariant prediction, finding that models trained on source code and fine-tuned for invariant generation can perform invariant prediction as static rather than dynamic analysis. Using a scratch-pad approach where invariants are predicted sequentially through a program gives the best performance, finding invariants statically of quality comparable to those obtained by a dynamic analysis tool with access to five program traces.},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Machine} {Learning}},
	publisher = {JMLR.org},
	author = {Pei, Kexin and Bieber, David and Shi, Kensen and Sutton, Charles and Yin, Pengcheng},
	year = {2023},
	note = {Place: Honolulu, Hawaii, USA},
	keywords = {Quality control, Machine learning, Application programs, Language model, Program understanding, ON dynamics, Computational linguistics, Bug finding, Dynamics analysis, Invariant generations, Program analysis, Program invariants, Source codes, Vulnerability analysis},
	annote = {Cited by: 0; Conference name: 40th International Conference on Machine Learning, ICML 2023; Conference date: 23 July 2023 through 29 July 2023; Conference code: 191855},
	annote = {Cited by: 0; Conference name: 40th International Conference on Machine Learning, ICML 2023; Conference date: 23 July 2023 through 29 July 2023; Conference code: 191855},
	annote = {ISSN: 26403498 Type: Conference paper},
	annote = {Place: Honolulu, Hawaii, USA},
	annote = {RELEVANCE: NULL
},
	annote = {RELEVANCE: NULL},
}


@article{maiko_onishishinpei_ogatakozo_okanodaisuke_bekki_method_2023,
	title = {A {Method} for {Matching} {Patterns} {Based} on {Event} {Semantics} with {Requirements}},
	url = {{http://link.springer.com/chapter/10.1007/978-3-031-17583-1_14}},
	doi = {10.1007/978-3-031-17583-1_14},
	journal = {Knowledge-Based Software Engineering: 2022},
	author = {{Maiko OnishiShinpei OgataKozo OkanoDaisuke Bekki}},
	year = {2023},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Semantics, Model checking, Pattern matching, Requirement engineering, Syntactics, Systems specification, Language processing, Natural language processing, Semantic parsing, Event semantics, Matching methods, Matching patterns, Pattern-matching},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Publisher: Springer Nature Type: Book chapter},
	annote = {RELEVANCE: LOW

},
}


@article{konstantinidis_enabling_2021,
	title = {Enabling {Personal} {Consent} in {Databases}},
	volume = {15},
	issn = {21508097},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126186395&doi=10.14778%2f3489496.3489516&partnerID=40&md5=81e38105eb6513fe65a9180ecd60a53e},
	doi = {10.14778/3489496.3489516},
	abstract = {Users have the right to consent to the use of their data, but current methods are limited to very coarse-grained expressions of consent, as “opt-in/opt-out” choices for certain uses. In this paper we identify the need for fine-grained consent management and formalize how to express and manage user consent and personal contracts of data usage in relational databases. Unlike privacy approaches, our focus is not on preserving confidentiality against an adversary, but rather cooperate with a trusted service provider to abide by user preferences in an algorithmic way. Our approach enables data owners to express the intended data usage in formal specifications, that we call consent constraints, and enables a service provider that wants to honor these constraints, to automatically do so by filtering query results that violate consent; rather than both sides relying on “terms of use” agreements written in natural language. We provide formal foundations (based on provenance), algorithms (based on unification and query rewriting), connections to data privacy, and complexity results for supporting consent in databases. We implement our framework in an open source RDBMS, and provide an evaluation against the most relevant privacy approach using the TPC-H benchmark, and on a real dataset of ICU data. © 2021, VLDB Endowment. All rights reserved.},
	language = {English},
	number = {2},
	journal = {Proceedings of the VLDB Endowment},
	author = {Konstantinidis, George and Holt, Jet and Chapman, Adriane},
	editor = {J, Freire and X, Lin},
	year = {2021},
	note = {Publisher: VLDB Endowment
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, 'current, Coarse-grained, Data privacy, Algorithmics, Service provider, Data usage, Fine-grained consent management, Query results, Relational Database, User's preferences},
	pages = {375 -- 387},
	annote = {Cited by: 3; Conference name: 48th International Conference on Very Large Data Bases, VLDB 2022; Conference date: 5 September 2022 through 9 September 2022; Conference code: 271259},
	annote = {Cited by: 3; Conference name: 48th International Conference on Very Large Data Bases, VLDB 2022; Conference date: 5 September 2022 through 9 September 2022; Conference code: 271259; All Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{alman_declo_2020,
	title = {Declo: {A} chatbot for user-friendly specification of declarative process models},
	volume = {2673},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092663333&partnerID=40&md5=706df84041da39d7d158d04cd9c176b8},
	abstract = {Proposed approaches for modeling knowledge-intensive pro- cesses include declarative, constraint-based solutions, which meet halfway between support and exibility. A noteworthy example is the Declare framework, which is equipped with a graphical declarative lan- guage whose semantics can be expressed with multiple logic-based for- malisms. So far, the practical use of Declare constraints has been mostly hampered by the difficulty of modeling them: the formal notation of De- clare represents a steep learning curve for users lacking an understanding of temporal logic, while the graphical notation has proven to be unin- tuitive. This work presents Declo, a chatbot that allows users to easily define declarative constraints using natural language statements provided in the form of vocal or textual input. The supported constraints cover the entire Multi-Perspective extension of Declare (MP-Declare), comple- menting control- ow constraints with data and temporal perspectives. Copyright © 2020 for this paper by its authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Alman, Anti and Balder, Karl Johannes and Maggi, Fabrizio Maria and Van Der Aa, Han},
	editor = {W.M.P, van der Aalst and J, vom Brocke and M, Comuzzi and C, Di Ciccio and F, Garcia and A, Kumar and J, Mendling and B, Pentland and L, Pufahl and M, Reichert and M, Weske},
	year = {2020},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural languages, Semantics, Computer circuits, Declarative process models, Graphical notation, Formal notations, Multi-perspective, Constraint-based, Declarative constraints, Steep learning curve},
	pages = {122 -- 126},
	annote = {Cited by: 3; Conference name: 2020 Best Dissertation Award, Doctoral Consortium, and Demonstration and Resources Track at BPM, BPM-D 2020; Conference date: 13 September 2020 through 18 September 2020; Conference code: 163020},
	annote = {Cited by: 4; Conference name: 2020 Best Dissertation Award, Doctoral Consortium, and Demonstration and Resources Track at BPM, BPM-D 2020; Conference date: 13 September 2020 through 18 September 2020; Conference code: 163020},
	annote = {RELEVANCE: HIGH
},
}


@article{wang_automatic_2021-1,
	title = {Automatic {Generation} of {Specification} from {Natural} {Language} {Based} on {Temporal} {Logic}},
	volume = {12723 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111149251&doi=10.1007%2f978-3-030-77474-5_11&partnerID=40&md5=a3ae38ee79be193921eff0b48fd59cfe},
	doi = {10.1007/978-3-030-77474-5_11},
	abstract = {Formal specifications are usually used for describing safety system properties and play an important role in formal verification. In order to improve the effectiveness of formal specification generation and formal verification, this paper proposes a framework for automatic conversion from natural language describing properties to temporal logic formulas, and implements a tool PPTLGenerator (Propositional Projection Temporal Logic formula Generator) for the conversion. First, PPTLGenerator is developed based on JavaCC for automatic conversion from natural language to PPTL. Then, the satisfiability of a PPTL formula generated by PPTLGenerator is checked by a tool PPTLSAT. Finally, to illustrate the principle and effectiveness of the framework, a case study of the safety property of Level 3 autonomous car is provided. © 2021, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Wang, Xiaobing and Li, Ge and Li, Chunyi and Zhao, Liang and Shu, Xinfeng},
	editor = {J, Xue and F, Nagoya and S, Liu and Z, Duan},
	year = {2021},
	note = {ISBN: 978-303077473-8
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Temporal logic, Formal languages, Formal verification, Computer circuits, Temporal logic formula, Automatic Generation, Automatic conversion, Safety property, Satisfiability, Specification generations, System property},
	pages = {154 -- 171},
	annote = {Cited by: 0; Conference name: International Workshop on Structured Object-Oriented Formal Language and Method, SOFL+MSVL 2020; Conference date: 1 March 2021 through 1 March 2021; Conference code: 260819},
}


@article{nguyen_automated_2020,
	title = {Automated {Test} {Input} {Generation} via {Model} {Inference} {Based} on {User} {Story} and {Acceptance} {Criteria} for {Mobile} {Application} {Development}},
	volume = {30},
	issn = {02181940},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084171125&doi=10.1142%2fS0218194020500163&partnerID=40&md5=0b1adee50062093e2c11eb329f08194b},
	doi = {10.1142/S0218194020500163},
	abstract = {There has been observed explosive growth in the development of mobile applications (apps) for Android and iOS operating systems, which has led to the direct impact towards mobile app development. In order to design and propose quality-oriented apps, it is the primary responsibility of developers to devote time and sufficient efforts towards testing to make the apps bug-free and operational in the hands of end-users without any hiccup. Manual testing procedures take a prolonged amount of time in writing test cases, and in some cases, the full testing requirements are not met. Besides, the insufficient knowledge of tester also impacts the overall quality and bug-free apps. To overcome the obstacles of testing, we propose a new testing methodology cum tool called "AgileUATM" which works primarily towards white-box and black-box testing. To evaluate the validity of the proposed tool, we put the tool in a real-time operational environment concerning mobile test apps. By using this tool, all the acceptance criteria are determined via user stories. The testers/developers specify requirements with formal specifications based on programs properties, predicates, invariants, and constraints. The results show that the proposed tool generated effective and accurate test cases, test input. Meanwhile, expected output was also generated in a unified fashion from the user stories to meet acceptance criteria. The proposed solution also reduced the development time to identify test data as compared to manual Behavior-Driven Development (BDD) methodologies. This tool can support the developers to get a better idea about the required tests and able to translate the customer's natural languages to computer languages as well. This paper fulfills an approach to suitably test mobile application development. © 2020 World Scientific Publishing Company.},
	language = {English},
	number = {3},
	journal = {International Journal of Software Engineering and Knowledge Engineering},
	author = {Nguyen, Duc-Man and Huynh, Quyet-Thang and Ha, Nhu-Hang and Nguyen, Thanh-Hung},
	year = {2020},
	note = {Publisher: World Scientific Publishing Co. Pte Ltd
Type: Review},
	keywords = {Natural languages, Acceptance tests, Mobile computing, Acceptance criteria, Black-box testing, Explosive growth, Mobile application development, Mobile applications, Operational environments, Testing methodology, Testing requirements},
	pages = {399 -- 425},
	annote = {Cited by: 2},
	annote = {Cited by: 3},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{soavi_legal_2021,
	title = {From {Legal} {Contracts} to {Formal} {Specifications}: {A} {Progress} {Report}},
	volume = {2857},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105560078&partnerID=40&md5=e7179eff8bdfebad88fcd92f4f311f86},
	abstract = {Smart contracts are software systems that partially automate, monitor and control the execution of legal contracts. The requirements of such systems consist of a formal specification of the legal contract whose execution is to be monitored and controlled. Legal contracts are always available as text expressed in natural language. We have been working on the translation of such text documents into formal specifications. Our translation process consists of four steps that (a) Semantic annotation of text identifying obligations, powers, contracting parties and assets, (b) Identification of relationships among the concepts identified in (a), (c) Generation of a domain model for terms used in the contract, as well as identification of parameters and local variables for the contract, (d) Generation of formal expressions that formalize the constituents of obligations and powers. This paper reports on the status of the project and the results that have been achieved. © 2021 CEUR-WS. All rights reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Soavi, Michele and Zeni, Nicola and Mylopoulos, John and Mich, Luisa},
	editor = {F.B, Aydemir and C, Gralha and M, Daneva and E.C, Groen and A, Herrmann and P, Mennig and S, Abualhaija and A, Ferrari and J, Guo and R, Guizzardi and J, Horkoff and A, Perini and A, Susi and T, Breaux and X, Franch and N, Ernst and E, Paja and N, Seyff},
	year = {2021},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Computer software selection and evaluation, Formal specification, Natural languages, Requirements engineering, Semantics, Software systems, Formal expressions, Local variables, Monitor and control, Progress report, Semantic annotations, Translation process},
	annote = {Cited by: 0; Conference name: Joint Workshops of the 27th International Conference on Requirements Engineering, REFSQ 2021 - OpenRE, Posters and Tools Track, and Doctoral Symposium; Conference date: 12 April 2021; Conference code: 168710},
	annote = {Cited by: 0; Conference name: Joint Workshops of the 27th International Conference on Requirements Engineering, REFSQ 2021 - OpenRE, Posters and Tools Track, and Doctoral Symposium; Conference date: 12 April 2021; Conference code: 168710},
	annote = {RELEVANCE: HIGH
},
}


@article{borisov_cross-world_2019,
	title = {{CROSS}-{WORLD} {PREDICATION} {IN} {BELIEF} {REPORTS}},
	volume = {3},
	issn = {25878719},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167922223&doi=10.17323%2f2587-8719-2019-3-201-217&partnerID=40&md5=61e10f479bb521b5c93914a25f7c8f33},
	doi = {10.17323/2587-8719-2019-3-201-217},
	abstract = {Some sentences of natural language, construed in terms of possible world semantics, describe cross-world relations. Among them are some belief reports like I thought your yacht was larger than it is, and prescriptions about beliefs like You should not underestimate people. Standard modal semantics cannot capture the truth conditions of such sentences because, in standard semantics, predicates can only have intra-world extensions. In order to be able to analyze sentences of this sort, we need a semantics providing a cross-world interpretation of predicates and capable of evaluating sentences at sequences of possible worlds rather than single possible worlds. Butterfield and Stirling offered a system of temporal logic of this sort. More recently, Wehmeier offered an alethic logic of this sort. However, the applicability of their systems to relevant types of discourse is substantially restricted. In the paper, a semantic system is developed that is applicable to doxastic and deontic-doxastic contexts without restriction. © Borisov, E. V. © Philosophy. Journal of the Higher School of Economics.},
	language = {Russian},
	number = {3},
	journal = {Filosofiya. Zhurnal Vysshey Shkoly Ekonomiki},
	author = {Borisov, Yevgeniy},
	year = {2019},
	note = {Publisher: National Research University, Higher School of Econoimics
Type: Article},
	pages = {201 -- 217},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{kaiser_ai4rfq_2021,
	title = {{AI4RFQ}: {Exploiting} {User} {Annotations} towards {Automating} the {Extraction} of {Information} and {Requirements} from {Specification} {Documents}},
	volume = {2905},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110416507&partnerID=40&md5=1a781dfa01e1ab3e8000a3372bd908ea},
	abstract = {A common task in business-to-business relationships is the analysis of specification documents within a request for quotation (RFQ) process. For non-standard products or services, one company with a need provides detailed specifications to potential suppliers and invites them to make an offer. In order to create an offer that fits with the specification, a supplier company needs to carefully inspect the documents to extract any requirements that are relevant for designing the contents of this offer and calculating its price. In a research effort focusing on HCI and natural language processing aspects, we seek methods and technology to support such RFQ processes. We have created a software tool that supports the reading and requirements identification process with a set of intelligent features that are expected to speed up the process significantly. Whenever users are extracting information, they are asked to annotate all text passages that contain relevant information. This annotation data is used to train machine learning models that provide suggestions in the future. The degree of automation increases continuously as more example data is collected. We strive to participate in the 'Automation Experience at the Workplace' workshop to discuss this change in work practice for our target users in terms of a technical as well as a user experience dimension. We would like to especially reflect on users' motivation to cooperate with the system and provide useful annotations (sharing their precious work expertise), the question of responsibility when dealing with automatic suggestions, as well as the fear of being replaced by 'an Artificial Intelligence' in the near future. Copyright © 2021 for this paper by its authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Kaiser, Rene and Stern, Hermann},
	editor = {M, Baldauf and P, Frohlich and S, Sadeghian and P, Palanque and V, Roto and W, Ju and L, Baillie and M, Tscheligi and M, Tscheligi},
	year = {2021},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Artificial intelligence, NAtural language processing, Specifications, Automation, Machine learning models, Identification process, Administrative data processing, User experience, Extracting information, Business to business, Degree of automation, Extraction of information, Request for quotations},
	annote = {Cited by: 0; Conference name: 2021 Workshop on Automation Experience at the Workplace, AutomationXP 2021; Conference date: 7 May 2021; Conference code: 170007},
	annote = {Cited by: 0; Conference name: 2021 Workshop on Automation Experience at the Workplace, AutomationXP 2021; Conference date: 7 May 2021; Conference code: 170007},
	annote = {RELEVANCE: MEDIUM
},
}


@article{toledo_method_2020,
	title = {A method for expressing integrity constraints in database conceptual modeling},
	volume = {24},
	issn = {14055546},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086658861&doi=10.13053%2fCyS-24-1-3217&partnerID=40&md5=ab13c544f462877e6a7b5448d3b9cd58},
	doi = {10.13053/CyS-24-1-3217},
	abstract = {Traditional methods lack the necessary or appropriate means for expressing the integrity constraints during the database conceptual modeling stage. At most, integrity constraints are informally documented and then, coded in the application. This leads to late error detection and database inconsistencies due to the incapacity of the domain expert to validate the program code. Thus, it is necessary to express such constraints in a natural and formal way in order to close the gap between modelers and domain experts, and to support the transformation to other languages and models. As a result, we propose a controlled natural language based on Semantics of Business Vocabulary and Business Rules (SBVR) to help modelers and domain experts in the process of writing and validating the constraints that cannot be represented in an Entity-Relationship schema; and the Alloy language to allow a formal specification. In addition, all the correspondences between the models and languages are described in order to consistently express the constraints and to lay the foundations of the automatic transformation. Finally, a case study and a usability survey show that the proposal is feasible, without abandoning a traditional and popular approach such as the Entity-Relationship model. © 2020 Instituto Politecnico Nacional. All rights reserved.},
	language = {English},
	number = {1},
	journal = {Computacion y Sistemas},
	author = {Toledo, Alain Pereira and Morffi, Abel Rodríguez and Alonso, Alain Pérez and Hernández, Andy Morfa and González González, Luisa M.},
	year = {2020},
	note = {Publisher: Instituto Politecnico Nacional
Type: Article},
	pages = {75 -- 95},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{patel_grounding_2020,
	title = {Grounding {Language} to {Non}-{Markovian} {Tasks} with {No} {Supervision} of {Task} {Specifications}},
	isbn = {978-0-9923747-6-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107830853&doi=10.15607%2fRSS.2020.XVI.016&partnerID=40&md5=129a91eb4ad786bb0270afd55d082b6e},
	doi = {10.15607/RSS.2020.XVI.016},
	abstract = {Natural language instructions often exhibit sequential constraints rather than being simply goal-oriented, for example “go around the lake and then travel north until the intersection”. Existing approaches map these kinds of natural language expressions to Linear Temporal Logic expressions but require an expensive dataset of LTL expressions paired with English sentences. We introduce an approach that can learn to map from English to LTL expressions given only pairs of English sentences and trajectories, enabling a robot to understand commands with sequential constraints. We use formal methods of LTL progression to reward the produced logical forms by progressing each LTL logical form against the ground-truth trajectory, represented as a sequence of states, so that no LTL expressions are needed during training. We evaluate in two ways: on the SAIL dataset, a benchmark artificial environment of 3,266 trajectories and language commands as well as on 10 newly-collected real-world environments of roughly the same size. We show that our model correctly interprets natural language commands with 76.9\% accuracy on average. We demonstrate the end-to-end process in real-time in simulation, starting with only a natural language instruction and an initial robot state, producing a logical form from the model trained with trajectories, and finding a trajectory that satisfies sequential constraints with an LTL planner in the environment. © 2020, MIT Press Journals. All rights reserved.},
	language = {English},
	booktitle = {Robotics: {Science} and {Systems}},
	publisher = {MIT Press Journals},
	author = {Patel, Roma and Pavlick, Ellie and Tellex, Stefanie},
	editor = {M, Toussaint and A, Bicchi and T, Hermans},
	year = {2020},
	note = {ISSN: 2330765X
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Temporal logic, Linear temporal logic, Markov processes, Non-Markovian, Task specifications, Formal methods, Trajectories, Goal-oriented, English sentences, Grounding language, Logical forms, Natural-language expressions, Sequential constraints},
	annote = {Cited by: 7; Conference name: 16th Robotics: Science and Systems, RSS 2020; Conference date: 12 July 2020 through 16 July 2020; Conference code: 275129; All Open Access, Bronze Open Access},
	annote = {Cited by: 10; Conference name: 16th Robotics: Science and Systems, RSS 2020; Conference date: 12 July 2020 through 16 July 2020; Conference code: 275129; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{mavridou_bridging_2020,
	title = {Bridging the gap between requirements and simulink model analysis},
	volume = {2584},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082724013&partnerID=40&md5=90b3f18854a506f2c2cb474dda41a812},
	abstract = {Formal verification and simulation are powerful tools for the verification of requirements against complex systems. Requirements are developed in early stages of the software lifecycle and are typically expressed in natural language. There is a gap between such requirements and their software implementation. We present a framework that bridges this gap by supporting a tight integration and feedback loop between high- level requirements and their analysis against software artifacts. Our framework implements an analysis portal within the fret requirements elicitation tool, thus forming an end-to-end, open-source environment where requirements are written in an intuitive, structured natural lan- guage, and are verified automatically against Simulink models. Copyright © 2020 for this paper by its authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Mavridou, Anastasia and Bourbouh, Hamza and Garoche, Pierre Loic and Giannakopoulou, Dimitra and Pressburger, Thomas and Schumann, Johann},
	editor = {M, Sabetzadeh and A, Vogelsang and S, Abualhaija and M, Borg and F, Dalpiaz and M, Daneva and N.C, Fernandez and X, Franch and D, Fucci and V, Gervasi and E, Groen and R, Guizzardi and A, Herrmann and J, Horkoff and L, Mich and A, Perini and A, Susi},
	year = {2020},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Computer software selection and evaluation, Natural languages, Requirements engineering, Requirements elicitation, Formal verification, Life cycle, Open source software, Simulink modeling, Simulink models, Software artifacts, Software implementation, Software life cycles, Tight integrations},
	annote = {Cited by: 4; Conference name: Joint 26th International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, Live Studies Track, and Poster Track, REFSQ-JP 2020; Conference date: 24 March 2020 through 27 March 2020; Conference code: 158674},
	annote = {Cited by: 4; Conference name: Joint 26th International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, Live Studies Track, and Poster Track, REFSQ-JP 2020; Conference date: 24 March 2020 through 27 March 2020; Conference code: 158674},
	annote = {RELEVANCE: LOW
},
}


@article{malik_automating_2021,
	title = {Automating test oracles from restricted natural language agile requirements},
	volume = {38},
	issn = {02664720},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088308770&doi=10.1111%2fexsy.12608&partnerID=40&md5=5f8455235608a804878d728fb0c4a66f},
	doi = {10.1111/exsy.12608},
	abstract = {Manual testing of software requirements written in natural language for agile or any other methodology requires more time and human resources. This leaves the testing process error prone and time consuming. For satisfied end users with bug-free software delivered on time, there is a need to automate the test oracle process for natural language or informal requirements. The automation of the test oracle is relatively easier with formal requirements, but this task is difficult to achieve with natural language requirements. This study proposes an approach called Restricted Natural Language Agile Requirements Testing (ReNaLART) to automate the test oracle from restricted natural language agile requirements. For this purpose, it uses an existing user story template with some modifications for writing user stories. This helps in identifying test input and expected output for a user story. For comparison of expected and observed outputs it makes use of a regex pattern and string distance functions. It is capable of assigning different types of verdicts automatically depending upon the similarity/dissimilarity between observed and expected outputs of user stories. ReNaLART is validated using several case studies of different domains, namely, OLX Pakistan, Mental Health Tests, McDelivery Pakistan, BlueStacks, Power Searching with Google, TensorFlow Playground, w3Schools 2018 offline and Touch'D. It revealed several faults in five of the above listed eight applications. Plus, the proposed test oracle on an average took 0.02 s for test data generation, expected output generation and verdict assignment. Both these facts show the fault revealing effectiveness and efficiency of ReNaLART. © 2020 John Wiley \& Sons, Ltd},
	language = {English},
	number = {1},
	journal = {Expert Systems},
	author = {Malik, Maryam Imtiaz and Sindhu, Muddassar Azam and Khattak, Akmal Saeed and Abbasi, Rabeeh Ayaz and Saleem, Khalid},
	year = {2021},
	note = {Publisher: Blackwell Publishing Ltd
Type: Article},
	keywords = {Testing, Natural language processing systems, Natural language requirements, Software requirements, Software testing, Effectiveness and efficiencies, Informal requirements, Agile requirements, Different domains, Distance functions, Test data generation},
	annote = {Cited by: 7},
	annote = {Cited by: 7},
	annote = {RELEVANCE: LOW
},
}


@article{ossoukine_ar2b_2020,
	title = {{AR2B}: {Formalization} of {Arabic} texts with event-{B}},
	volume = {6},
	issn = {24139351},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090744870&doi=10.5455%2fjjcit.71-1570002057&partnerID=40&md5=1d5cd06bb70cd608e726eb52dc07a9e2},
	doi = {10.5455/jjcit.71-1570002057},
	abstract = {Transforming natural software requirements into a more formal specification is difficult and may be an excellent application for natural language processing. This problem is not recent. It aroused and still arouses great interest, because it gives rise to many challenges in various scientific fields, such as automatic language processing, requirements engineering, knowledge representation and formal verification. This paper proposes a platform and a strategy to transform software requirements specified to formal specification with event-B. The texts used are those of Arabic language, which is really a challenge. The Ar2B system is built and the experiments showed good results with an accuracy of 70\%. © 2020, Scientific Research Support Fund of Jordan. All rights reserved.},
	language = {English},
	number = {2},
	journal = {Jordanian Journal of Computers and Information Technology},
	author = {Ossoukine, Kheira-Zineb Bousmaha and Hadrich, Lamia Belguith},
	year = {2020},
	note = {Publisher: Scientific Research Support Fund of Jordan
Type: Article},
	pages = {148 -- 164},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE:  LOW
},
}


@inproceedings{dutle_requirements_2020,
	title = {From requirements to autonomous flight: {An} overview of the monitoring {ICAROUS} project},
	volume = {329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101067660&doi=10.4204%2fEPTCS.329.3&partnerID=40&md5=40b509794247255a013c620bd4ee096e},
	doi = {10.4204/EPTCS.329.3},
	abstract = {The Independent Configurable Architecture for Reliable Operations of Unmanned Systems (ICAROUS) is a software architecture incorporating a set of algorithms to enable autonomous operations of unmanned aircraft applications. This paper provides an overview of Monitoring ICAROUS, a project whose objective is to provide a formal approach to generating runtime monitors for autonomous systems from requirements written in a structured natural language. This approach integrates FRET, a formal requirement elicitation and authoring tool, and Copilot, a runtime verification framework. FRET is used to specify formal requirements in structured natural language. These requirements are translated into temporal logic formulae. Copilot is then used to generate executable runtime monitors from these temporal logic specifications. The generated monitors are directly integrated into ICAROUS to perform runtime verification during flight. © 2020 Open Publishing Association. All rights reserved.},
	language = {English},
	booktitle = {Electronic {Proceedings} in {Theoretical} {Computer} {Science}, {EPTCS}},
	publisher = {Open Publishing Association},
	author = {Dutle, Aaron and Titolo, Laura and Giannakopoulou, Dimitra and Muñoz, César and Perez, Ivan and Mavridou, Anastasia and Conrad, Esther and Balachandran, Swee and Pressburger, Thomas and Goodloe, Alwyn},
	editor = {M, Luckcuck and M, Farrell},
	year = {2020},
	note = {ISSN: 20752180
Type: Conference paper},
	keywords = {Temporal logic, Requirement elicitation, Formal methods, Computer circuits, Application programs, Temporal logic specifications, Autonomous systems, Autonomous operations, Configurable architectures, Forster resonance energy transfer, Reliable operation, Run-time verification, Unmanned aircrafts},
	pages = {23 -- 30},
	annote = {Cited by: 8; Conference name: 2nd Workshop on Formal Methods for Autonomous Systems, FMAS 2020; Conference date: 7 December 2020; Conference code: 166772; All Open Access, Gold Open Access},
	annote = {Cited by: 10; Conference name: 2nd Workshop on Formal Methods for Autonomous Systems, FMAS 2020; Conference date: 7 December 2020; Conference code: 166772; All Open Access, Gold Open Access},
	annote = {RELEVANCE: MEDIUM
},
}


@article{giannakopoulou_generation_2020-1,
	title = {Generation of {Formal} {Requirements} from {Structured} {Natural} {Language}},
	volume = {12045 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083986430&doi=10.1007%2f978-3-030-44429-7_2&partnerID=40&md5=dea1255499debd812d6eb1daa54cd5cb},
	doi = {10.1007/978-3-030-44429-7_2},
	abstract = {[Motivation] The use of structured natural languages to capture requirements provides a reasonable trade-off between ambiguous natural language and unintuitive formal notations. [Problem] There are two major challenges in making structured natural language amenable to formal analysis: (1) associating requirements with formulas that can be processed by analysis tools and (2) ensuring that the formulas conform to the language semantics. [Results] FRETISH is a structured natural language that incorporates features from existing research and from NASA applications. Even though FRETISH is quite expressive, its underlying semantics is determined by the types of four fields: scope, condition, timing, and response. Each combination of field types defines a template with Real-Time Graphical Interval Logic (RTGIL) semantics. We present an approach that constructs future and past-time metric temporal logic formulas for each template compositionally, from its fields. To establish correctness of our approach we have developed a framework which, for each template: (1) extensively tests the generated formulas against the template semantics and (2) proves equivalence between its past-time and future-time formulas. Our approach has been used to capture and analyze requirements for a Lockheed Martin Cyber-Physical System challenge. [Contribution] To the best of our knowledge, this is the first approach to generate pure past-time and pure future-time formalizations to accommodate a variety of analysis tools. The compositional nature of our algorithms facilitates maintenance and extensibility, and our extensive verification framework establishes trust in the produced formalizations. Our approach is available through the open-source tool fret. © 2020, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Giannakopoulou, Dimitra and Pressburger, Thomas and Mavridou, Anastasia and Schumann, Johann},
	editor = {N, Madhavji and L, Pasquale},
	year = {2020},
	note = {ISBN: 978-303044428-0
Publisher: Springer
Type: Conference paper},
	keywords = {Computer software selection and evaluation, Natural languages, Requirements engineering, Semantics, Verification framework, Computer circuits, Embedded systems, NASA, Formal notations, Formal analysis, Metric temporal logic, Open source software, Economic and social effects, Language semantics, Open source tools, Template semantics},
	pages = {19 -- 35},
	annote = {Cited by: 22; Conference name: 26th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2020; Conference date: 24 March 2020 through 27 March 2020; Conference code: 239239},
}


@inproceedings{giannakopoulou_formal_2020,
	title = {Formal requirements elicitation with {FRET}},
	volume = {2584},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082697344&partnerID=40&md5=797f3992dc8554bb6bd14e731f5fcaf1},
	abstract = {Fret is a tool for writing, understanding, formalizing, and analyzing requirements. Users write requirements in an intuitive, restricted natural language, called fretish, with precise, unambiguous meaning. For a fretish requirement, fret: 1) produces natural language and diagrammatic explanations of its exact meaning, 2) formalizes the requirement in future-time and past-time temporal logic, and 3) supports interactive simulation of produced logic formulas to ensure that they capture user intentions. fret connects to analysis tools by facilitating the mapping between requirements and models/code, and by generating verification code. fret is available open source at https://github.com/NASA-SW-VnV/fret; a video can be accessed at: https://tinyurl.com/fretForREFSQ. Copyright © 2020 for this paper by its authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Giannakopoulou, Dimitra and Pressburger, Thomas and Mavridou, Anastasia and Rhein, Julian and Schumann, Johann and Shi, Nija},
	editor = {M, Sabetzadeh and A, Vogelsang and S, Abualhaija and M, Borg and F, Dalpiaz and M, Daneva and N.C, Fernandez and X, Franch and D, Fucci and V, Gervasi and E, Groen and R, Guizzardi and A, Herrmann and J, Horkoff and L, Mich and A, Perini and A, Susi},
	year = {2020},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Computer software selection and evaluation, Natural languages, Requirements engineering, Requirements elicitation, HTTP, Open source software, Open sources, Forster resonance energy transfer, Analysis tools, Interactive simulations, Logic formulas, Past-time temporal logic, User intention},
	annote = {Cited by: 8; Conference name: Joint 26th International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, Live Studies Track, and Poster Track, REFSQ-JP 2020; Conference date: 24 March 2020 through 27 March 2020; Conference code: 158674},
	annote = {Cited by: 8; Conference name: Joint 26th International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, Live Studies Track, and Poster Track, REFSQ-JP 2020; Conference date: 24 March 2020 through 27 March 2020; Conference code: 158674},
	annote = {RELEVANCE: LOW
},
}


@article{uz_zaman_formalizing_2020,
	title = {Formalizing the use case model: {A} model-based approach},
	volume = {15},
	issn = {19326203},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083487474&doi=10.1371%2fjournal.pone.0231534&partnerID=40&md5=46f8e9fde541a31acaae44e8b2dc9448},
	doi = {10.1371/journal.pone.0231534},
	abstract = {In general, requirements expressed in natural language are the first step in the software development process and are documented in the form of use cases. These requirements can be specified formally using some precise mathematical notation (e.g. Linear Temporal Logic (LTL), Computational Tree Logic (CTL) etc.) or using some modeling formalism (e.g. a Kripke structure). The rigor involved in writing formal requirements requires extra time and effort, which is not feasible in several software development scenarios. A number of existing approaches are able to transform informal software requirements to formal specifications. However, most of these approaches require additional skills like understanding of specification languages additional artifacts, or services of domain expert(s). Consequently, an automated approach is required to reduce the overhead of effort for converting informal requirements to formal specifications. This work introduces an approach that takes a use case model as input in the proposed template and produces a Kripke structure and LTL specifications as output. The proposed approach also considers the common use case relationships (i.e., include and extend). The generated Kripke structure model of the software allows analysis of software behavior early at the requirements specification stage which otherwise would not be possible before the design stage of the software development process. The generated LTL formal specifications can be used against a formal model like a Kripke structure generated during the software development process for verification purpose. We demonstrate the working of the proposed approach by a SIM vending machine example, where the use cases of this system are inputs in the proposed template and the corresponding Kripke structure and LTL formal specifications are produced as final output. Additionally, we use the NuSMV tool to verify the generated LTL specifications against the Kripke structure model of the software, which reports no counterexamples thus validating the proposed approach. © 2020 Zaman et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	language = {English},
	number = {4},
	journal = {PLoS ONE},
	author = {uz Zaman, Qamar and Nadeem, Aamer and Sindhu, Muddassar Azam},
	year = {2020},
	pmid = {32310952},
	note = {Publisher: Public Library of Science
Type: Article},
	keywords = {Humans, Algorithms, Software, human, Models, article, Commerce, algorithm, software, human experiment, language, theoretical model, artifact, Cell Phone, commercial phenomena, mobile phone, skill, structural model, Theoretical},
	annote = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{carver_blockchain_2020,
	title = {Blockchain and {Smart} {Contract} {Engineering}},
	volume = {37},
	issn = {07407459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096073080&doi=10.1109%2fMS.2020.2999995&partnerID=40&md5=9b18262fd5f40b5246cd365c7b77f1e9},
	doi = {10.1109/MS.2020.2999995},
	abstract = {This article reports on papers about blockchain and smart contract engineering from the 42nd International Conference on Software Engineering and the 2020 IEEE International Conference on Blockchain and Cryptocurrency. A paper entitled ‘Understanding the Motivations, Challenges, and Needs of Blockchain Software Developers: A Survey’ reports the results from a survey of 156 active blockchain developers from multiple blockchain software (BCS) projects. Blockchain solutions use decentralized, peer-to-peer, transparent, immutable, and append-only data storage. Potential external rewards include monetary compensation, benefits from software usage, the prospect of career growth, and the increased value of project-issued digital currencies. Another paper entitled ‘From Legal Agreements to Blockchain Smart Contracts’ describes a framework to allow lawyers to write legal agreements that can undergo formal verification and be deployed on the Ethereum blockchain platform. Smart contracts are immutable, deterministic, decentralized programs. This framework defines legal terms in both natural language and machine-readable combination logic to create a formal representation of legal agreements.},
	language = {English},
	number = {5},
	journal = {IEEE Software},
	author = {Carver, Jeffrey C. and Staron, Miroslaw},
	year = {2020},
	note = {Publisher: IEEE Computer Society
Type: Article},
	keywords = {Natural languages, Formal representations, Software engineering, Digital storage, Data storage, Blockchain, Laws and legislation, Surveys, Combination logic, Electronic money, Peer to peer, Software developer},
	pages = {94 -- 96},
	annote = {Cited by: 6; All Open Access, Bronze Open Access},
	annote = {Cited by: 6; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{akay_automating_2021,
	title = {Automating design requirement extraction from text with deep learning},
	volume = {3B-2021},
	isbn = {978-0-7918-8539-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119990263&doi=10.1115%2fDETC2021-66898&partnerID=40&md5=c108ba8c28e160e51f1d4daccc741eaf},
	doi = {10.1115/DETC2021-66898},
	abstract = {Nearly every artifact of the modern engineering design process is digitally recorded and stored, resulting in an overwhelming amount of raw data detailing past designs. Analyzing this design knowledge and extracting functional information from sets of digital documents is a difficult and time-consuming task for human designers. For the case of textual documentation, poorly written superfluous descriptions filled with jargon are especially challenging for junior designers with less domain expertise to read. If the task of reading documents to extract functional requirements could be automated, designers could actually benefit from the distillation of massive digital repositories of design documentation into valuable information that can inform engineering design. This paper presents a system for automating the extraction of structured functional requirements from textual design documents by applying state of the art Natural Language Processing (NLP) models. A recursive method utilizing Machine Learning-based question-answering is developed to process design texts by initially identifying the highest-level functional requirement, and subsequently extracting additional requirements contained in the text passage. The efficacy of this system is evaluated by comparing the Machine Learning-based results with a study of 75 human designers performing the same design document analysis task on technical texts from the field of Microelectromechanical Systems (MEMS). The prospect of deploying such a system on the sum of all digital engineering documents suggests a future where design failures are less likely to be repeated and past successes may be consistently used to forward innovation. © 2021 by ASME},
	language = {English},
	booktitle = {Proceedings of the {ASME} {Design} {Engineering} {Technical} {Conference}},
	publisher = {American Society of Mechanical Engineers (ASME)},
	author = {Akay, Haluk and Yang, Maria and Kim, Sang-Gook},
	year = {2021},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Product design, Extraction, Design documents, Learning algorithms, Machine-learning, Functional requirement, Neural-networks, Deep learning, Computer aided design, Design automations, Design knowledge, Design representation, Distillation, Electromechanical devices, Engineering design process, Functional reasoning, MEMS, Modern engineering},
	annote = {Cited by: 2; Conference name: 47th Design Automation Conference, DAC 2021, Held as Part of the ASME 2021 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, IDETC-CIE 2021; Conference date: 17 August 2021 through 19 August 2021; Conference code: 174204},
	annote = {Cited by: 2; Conference name: 47th Design Automation Conference, DAC 2021, Held as Part of the ASME 2021 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, IDETC-CIE 2021; Conference date: 17 August 2021 through 19 August 2021; Conference code: 174204},
	annote = {RELEVANCE: LOW
},
}


@article{hu_formal_2019,
	title = {A formal approach to candlestick pattern classification in financial time series},
	volume = {84},
	issn = {15684946},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071045524&doi=10.1016%2fj.asoc.2019.105700&partnerID=40&md5=f4d7539cbe1cd1d1454fcfb0c11ceab2},
	doi = {10.1016/j.asoc.2019.105700},
	abstract = {Patterns with varying numbers of candlestick-shaped features are commonly used by analysts to predict future price trends in financial markets. Although general descriptions of candlestick patterns have been reported in literature, they are usually described in natural languages. Such descriptions are prone to ambiguity and misinterpretation by users. Hence, these descriptions written in natural language cannot be easily adopted for use in computational technical analysis. Since there is also no agreed-upon standard on describing the definitions of these patterns, inconsistencies can easily occur during the applications of these patterns. To alleviate these problems, we propose a comprehensive formal specifications of 103 known candlestick patterns. Our goal is to establish an unambiguous reference model which can be used in future pattern classification research without significant modifications. The formal specifications of these patterns are formulated in the form of the first-order logic, which is comprehensive, extensible, and reusable. To evaluate the proposed specifications, extensive experiments are performed for classifying candlestick patterns from synthetic and real datasets. The experimental results show that the proposed specifications can be used to effectively generate synthetic datasets for selecting best classifiers for candlestick pattern identification. © 2019 Elsevier B.V.},
	language = {English},
	journal = {Applied Soft Computing Journal},
	author = {Hu, Weilong and Si, Yain-Whar and Fong, Simon and Lau, Raymond Yiu Keung},
	year = {2019},
	note = {Publisher: Elsevier Ltd
Type: Article},
	keywords = {Formal specification, Pattern matching, Classification (of information), Formal logic, Time series, Commerce, Financial data processing, Synthetic datasets, Reference modeling, Candlestick chart, Financial markets, Financial time series, First order logic, General description, Pattern identification, Technical analysis},
	annote = {Cited by: 17},
	annote = {Cited by: 18},
	annote = {RELEVANCE: LOW
},
}


@article{snook_domain-specific_2021,
	title = {Domain-specific scenarios for refinement-based methods},
	volume = {112},
	issn = {13837621},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091503874&doi=10.1016%2fj.sysarc.2020.101833&partnerID=40&md5=5948e42604f56aeb800ddeb45bbb5a99},
	doi = {10.1016/j.sysarc.2020.101833},
	abstract = {Formal methods use abstraction and rigorously verified refinement to manage the design of complex systems, ensuring that they satisfy important invariant properties. However, formal verification is not sufficient: models must also be tested to ensure that they behave according to the informal requirements and validated by domain experts who may not be expert in formal modelling. This can be satisfied by scenarios that complement the requirements specification. The model can be animated to check whether the scenario is feasible in the model and that the model reaches the states expected in the scenario. However, there are two problems with this approach. 1) The natural language used to describe the scenarios is often verbose, ambiguous and therefore difficult to understand; especially if the modeller is not a domain expert. 2) Provided scenarios are typically at the most concrete level corresponding to the full requirements and cannot be used until all the refinements have been completed in the model. We show by example how a precise and concise domain specific language can be used for writing these abstract scenarios in a style that can be easily understood by the domain expert (for validation purposes) as well as the modeller (for behavioural verification) and can be used as the persistence for automated tool support. We propose two alternative approaches to using scenarios during formal modelling: A method of refining scenarios before the model is refined so that the scenarios guide the modelling, and a method of abstracting scenarios from provided concrete ones so that they can be used to test early refinements of the model. We illustrate the two approaches on the ‘Tokeneer’ secure enclave example and the ERTMS/ETCS Hybrid Level 3 specification for railway controls. We base our approach on the Cucumber framework for scenarios and the Event-B modelling language and tool set. We have developed a new ‘Scenario Checker’ plugin to manage the animation of scenarios.1 © 2020},
	language = {English},
	journal = {Journal of Systems Architecture},
	author = {Snook, Colin and Hoang, Thai Son and Dghaym, Dana and Fathabadi, Asieh Salehi and Butler, Michael},
	year = {2021},
	note = {Publisher: Elsevier B.V.
Type: Article},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Modeling languages, Domain specific languages, Problem oriented languages, Formal verification, Requirements specifications, Informal requirements, Invariant properties, Automated tool support, Domain specific, Formal modelling},
	annote = {Cited by: 8; All Open Access, Green Open Access},
	annote = {Cited by: 9; All Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{shaaban_automated_2019,
	title = {An automated tool for detection and tutoring of sources of ambiguities in requirements documents},
	volume = {8},
	issn = {22773878},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073561031&doi=10.35940%2fijrte.C4660.098319&partnerID=40&md5=0cf76d058ee0e642105db1d8806e373e},
	doi = {10.35940/ijrte.C4660.098319},
	abstract = {Software Engineering (SE) is the application of essentials to deal with the analysis, design, development, testing, deployment and management-Software Development Life Cycle (SDLC)-of software systems. Requirements Engineering (RE) is responsible for the most critical task in the SDLC; which is transforming the requirements and wishes of the software users into complete, accurate and formal specifications. One of the main responsibilities of RE is the creation of a software requirements document that exactly, reliably, and totally defines the functional and non-functional properties of the system to be developed. At some point through the RE process, the requirements are written using a Natural Language (NL). On one hand, NLs are flexible, common, and popular. On the other hand, NLs are recognized widely as inherently ambiguous. Ambiguity is noticed in a requirement document when a piece of text is interpreted in distinct ways. This may lead to erroneous software that is too expensive to correct in later phases of the SDLC. Many tools have been developed in the literature to detect ambiguities in requirements documents. Best practices for writing requirements have also been proposed to help avoid ambiguities in the first place. The goal of this paper is to combine features from both approaches by developing the Ambiguity Checker Tutor (ACTutor), which not only detects ambiguities, but also aids in tutoring requirements engineers to apply best practices while writing requirements (rather than merely listing them). The paper is mainly concerned with proving the tutoring effectiveness of ACTutor through empirical evaluation. © BEIESP.},
	language = {English},
	number = {3},
	journal = {International Journal of Recent Technology and Engineering},
	author = {Shaaban, Ayat and Elazhary, Hanan and Hassanein, Ehab},
	year = {2019},
	note = {Publisher: Blue Eyes Intelligence Engineering and Sciences Publication
Type: Article},
	pages = {2371 -- 2375},
	annote = {Cited by: 0; All Open Access, Bronze Open Access},
	annote = {Cited by: 0; All Open Access, Bronze Open Access},
	annote = {RELEVANCE:  MEDIUM
},
}


@article{filonov_question-answering_2019,
	title = {A {Question}-{Answering} {System} for {Applicant} {Support} {Using} {Modern} {Messaging} {Apps}},
	volume = {53},
	issn = {01464116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080942736&doi=10.3103%2fS0146411619070046&partnerID=40&md5=77f66c6f83d3e2dbadf19e1214193df8},
	doi = {10.3103/S0146411619070046},
	abstract = {Abstract: There is an increasing user interest in instant messaging applications. These applications allow us to interact with other users and include a functionality that can help us to implement bots that automate various business processes or provide information services. This paper considers a specialized question answering system that employs today’s messaging services infrastructure to support university applicants. Over two years, we gathered a corpus of typical questions of applicants and developed an information retrieval model for finding similar questions in this corpus. Applicants can type their questions using natural language without any formal requirements to phrase construction or using special templates. If the system is unable to find a relevant answer, the user can directly address the question to representatives of the university. The system was implemented using modern cloud services provided by Amazon. We used serverless computations and NoSQL databases, so we had to develop an appropriate architecture of the service. Since the system operates sensitive personal data and provides personalized service, we analyzed methods of ensuring system security and approaches to user authorization. We are currently testing our system and estimating its information retrieval quality. © 2019, Allerton Press, Inc.},
	language = {English},
	number = {7},
	journal = {Automatic Control and Computer Sciences},
	author = {Filonov, D.R. and Chalyy, D. Ju. and Murin, D.M. and Durnev, V.G. and Sokolov, V.A.},
	year = {2019},
	note = {Publisher: Pleiades Publishing
Type: Article},
	keywords = {Natural language processing systems, Natural languages, Artificial intelligence, Information retrieval, Search engines, security, Information services, Cloud systems, Information retrieval models, Messaging services, messenger, Personalized service, Question answering systems},
	pages = {699 -- 704},
	annote = {Cited by: 1},
	annote = {Cited by: 1},
	annote = {RELEVANCE: LOW
},
}


@article{n_26th_2020,
	title = {26th {International} {Working} {Conference} on {Requirements} {Engineering}: {Foundation} for {Software} {Quality}, {REFSQ} 2020},
	volume = {12045 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084001280&partnerID=40&md5=1659f22bb84f820d7064c0194c7f9da7},
	abstract = {The proceedings contain 21 papers. The special focus in this conference is on Requirements Engineering. The topics include: Identifying and Classifying User Requirements in Online Feedback via Crowdsourcing; designing a Virtual Client for Requirements Elicitation Interviews; explicit Alignment of Requirements and Architecture in Agile Development; applying Distributed Cognition Theory to Agile Requirements Engineering; automatic Word Embeddings-Based Glossary Term Extraction from Large-Sized Software Requirements; conceptualizing Requirements Using User Stories and Use Cases: A Controlled Experiment; a Semi-automated Approach to Generate an Adaptive Quality Attribute Relationship Matrix; evaluating the Effects of Different Requirements Representations on Writing Test Cases; vision Meets Visualization: Are Animated Videos an Alternative?; generation of Formal Requirements from Structured Natural Language; requirements Assessment in Smart City Districts: A Motivation Concept for Citizens; visualizing Feature-Level Evolution in Product Lines: A Research Preview; using Eye Tracking Data to Improve Requirements Specification Use; hearing the Voice of Software Practitioners on Causes, Effects, and Practices to Deal with Documentation Debt; innovation Workshop Documentation for Following Software Engineering Activities; industrial Practices on Requirements Reuse: An Interview-Based Study; disambiguating Requirements Through Syntax-Driven Semantic Analysis of Information Types; on Understanding How Developers Perceive and Interpret Privacy Requirements Research Preview; A Methodology for Implementing the Formal Legal-GRL Framework: A Research Preview.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {N, Madhavji and L, Pasquale},
	year = {2020},
	note = {ISBN: 978-303044428-0
Publisher: Springer
Type: Conference review},
	annote = {Cited by: 0; Conference name: 26th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2020; Conference date: 24 March 2020 through 27 March 2020; Conference code: 239239},
	annote = {Cited by: 0; Conference name: 26th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2020; Conference date: 24 March 2020 through 27 March 2020; Conference code: 239239},
	annote = {RELEVANCE: NULL - procedings
},
}


@article{j_international_2021,
	title = {International {Workshop} on {Structured} {Object}-{Oriented} {Formal} {Language} and {Method}, {SOFL}+{MSVL} 2020},
	volume = {12723 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111080666&partnerID=40&md5=a688cd60b4413b2eb755b3bdd7266474},
	abstract = {The proceedings contain 13 papers. The special focus in this conference is on Structured Object-Oriented Formal Language and Method. The topics include: Automatic Generation of Specification from Natural Language Based on Temporal Logic; software Testing with Statistical Partial Oracles: - Application to Neural Networks Software -; Formalizing Spark Applications with MSVL; A Case Study on Combining Agile Requirements Development and SOFL; formal Modeling and Verification of Microservice-Based Cyber-Physical System; Design and Implementation of Virtual Reality Geometric Modeling in Apla+VR ; An Unified Model Checking Approach of APTL; Model Checking Multi-interruption Concurrent Programs with TMSVL; An MSVL Based Model Checking Method for Multi-threaded C Programs; A Formal Approach to Secure Design of RESTful Web APIs Using SOFL; pointer Program Synthesis as Non-deterministic Planning.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {J, Xue and F, Nagoya and S, Liu and Z, Duan},
	year = {2021},
	note = {ISBN: 978-303077473-8
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: International Workshop on Structured Object-Oriented Formal Language and Method, SOFL+MSVL 2020; Conference date: 1 March 2021 through 1 March 2021; Conference code: 260819},
	annote = {Cited by: 0; Conference name: International Workshop on Structured Object-Oriented Formal Language and Method, SOFL+MSVL 2020; Conference date: 1 March 2021 through 1 March 2021; Conference code: 260819},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{haris_automated_2020,
	title = {Automated requirement sentences extraction from software requirement specification document},
	isbn = {978-1-4503-7605-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099014527&doi=10.1145%2f3427423.3427450&partnerID=40&md5=6124c65a2d66449817de3958512a1dbf},
	doi = {10.1145/3427423.3427450},
	abstract = {In the requirement reuse and natural language document-based Software Product Line (SPL) domain analysis, requirement sentences of the requirement document are the primary concern. Most studies conducted in this research area have document preprocessing stage in their methods that is a manual process to separate requirement sentences and non-requirement sentences from the document. This manual labor process might be tedious and error-prone since it will need much time and expert intervention to make this process completely done. In this paper, we present a method to automate requirement sentence extraction from the Software Requirement Specification (SRS) document by leveraging Natural Language Processing (NLP) approach and requirement boilerplate sentence patterns. Conducted experiments in this research show this method has such accuracy from 64\% to 100\% on precision value and recall value in the range of 64\% to 89\%. © 2020 ACM.},
	language = {English},
	booktitle = {{ACM} {International} {Conference} {Proceeding} {Series}},
	publisher = {Association for Computing Machinery},
	author = {Haris, M Syauqi and Kurniawan, Tri Astoto},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Extraction, NAtural language processing, Software requirement specification, Sentence extraction, Computer software reusability, Document pre-processing, Domain analysis, Manual process, Software product lines},
	pages = {142 -- 147},
	annote = {Cited by: 2; Conference name: 5th International Conference on Sustainable Information Engineering and Technology, SIET 2020; Conference date: 16 November 2020 through 17 November 2020; Conference code: 166157},
	annote = {Cited by: 4; Conference name: 5th International Conference on Sustainable Information Engineering and Technology, SIET 2020; Conference date: 16 November 2020 through 17 November 2020; Conference code: 166157},
	annote = {RELEVANCE: MEDIUM
},
}


@article{cherukuri_towards_2022-1,
	title = {Towards {Explainable} {Formal} {Methods}: {From} {LTL} to {Natural} {Language} with {Neural} {Machine} {Translation}},
	volume = {13216 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127071136&doi=10.1007%2f978-3-030-98464-9_7&partnerID=40&md5=ba5bdc952cd20a8ad2688192f2dc504c},
	doi = {10.1007/978-3-030-98464-9_7},
	abstract = {[Context and motivation] Requirements formalisation facilitates reasoning about inconsistencies, detection of ambiguities, and identification critical issues in system models. Temporal logic formulae are the natural choice when it comes to formalise requirements associated to desired system behaviours. [Question/problem] Understanding and mastering temporal logic requires a formal background. Means are therefore needed to make temporal logic formulae interpretable by engineers, domain experts and other stakeholders involved in the development process. [Principal ideas/results] In this paper, we propose to use a neural machine translation tool, named OpenNMT, to translate Linear Temporal Logic (LTL) formulae into corresponding natural language descriptions. Our results show that the translation system achieves an average BLEU (BiLingual Evaluation Understudy) score of 93.53\%, which corresponds to high-quality translations. [Contribution] Our neural model can be applied to assess if requirements have been correctly formalised. This can be useful to requirements analysts, who may have limited confidence with LTL, and to other stakeholders involved in the requirements verification process. Overall, our research preview contributes to bridging the gap between formal methods and requirements engineering, and opens to further research in explainable formal methods. © 2022, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Cherukuri, Himaja and Ferrari, Alessio and Spoletini, Paola},
	editor = {V, Gervasi and A, Vogelsang},
	year = {2022},
	note = {ISBN: 978-303098463-2
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Temporal logic, Linear temporal logic, Computer circuits, Requirements formalizations, Requirement engineering, Temporal logic formula, Neural-networks, System models, Computational linguistics, Computer aided language translation, Critical issues, Inconsistency detection, Machine translation, System behaviors},
	pages = {79 -- 86},
	annote = {Cited by: 4; Conference name: 28th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2022; Conference date: 21 March 2022 through 24 March 2022; Conference code: 274709},
}


@article{shi_coq_2022,
	title = {Coq {Formalization} of {Propulsion} {Subsystem} of {Flight} {Control} {System} for {Multicopter}; [多旋翼飞控推进子系统的{Coq形式化验证}]},
	volume = {33},
	issn = {10009825},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131525193&doi=10.13328%2fj.cnki.jos.006575&partnerID=40&md5=94bd29b12fd809bf2007abcddc906e3e},
	doi = {10.13328/j.cnki.jos.006575},
	abstract = {A highly reliable flight control system (FCS) is a necessary prerequisite for the reliable operation of an aircraft. Under the traditional development approach, the domain knowledge is first modeled by the human in the form of natural language, and then code is written by humans according to the model, and finally, the software defects are eliminated by using testing technology. The approach fails to build reliable FCS, because of human error, natural language ambiguity, and incompleteness of test techniques. A novel development approach based on formal verification technology could improve the reliability of FCS from many aspects. This paper presents a formal design and verification method for multicopter propulsion subsystem based on Coq and generated a usable and highly reliable functional software library. The main work of this study includes: the domain knowledge is organized into a hierarchical document suitable for formal verification, the basic functions, and composite functions are separated, and the concept of the simplest form of function (SFF) is proposed; formalize the system in Coq according to this document, defining constants, variables, basic functions, composite functions, SFF, axioms, etc.; the correctness of the derivation of all kinds of composite functions is expressed as lemmas and be proved; the algorithm for solving practical problems such as the longest hover time of multicopter is given; and a functional software library is generated using OCaml language by COQ program extraction ability. In the future, more subsystems of FCS will be developed based on formal verification, and finally, a complete and highly reliable FCS with formal verification will be established. © Copyright 2022, Institute of Software, the Chinese Academy of Sciences. All rights reserved.},
	language = {Chinese},
	number = {6},
	journal = {Ruan Jian Xue Bao/Journal of Software},
	author = {Shi, Zheng-Pu and Cui, Min and Xie, Guo-Jun and Chen, Gang},
	year = {2022},
	note = {Publisher: Chinese Academy of Sciences
Type: Article},
	keywords = {Testing, Natural languages, Software testing, Formal verification, Coq, Theorem proving, Domain knowledge, Development approach, Composite functions, Domain Knowledge, Flight control systems, Flight-control systems, Functions, Multicopter, Ocaml, Propulsion, Propulsion subsystems, Propulsion system},
	pages = {2150 -- 2171},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: LOW
},
}


@article{intana_approach_2023,
	title = {An {Approach} of {Test} {Case} {Generation} with {Software} {Requirement} {Ontology}},
	volume = {14},
	issn = {2158107X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170648166&doi=10.14569%2fIJACSA.2023.01408109&partnerID=40&md5=199921af68a630c5390f0f7a4c32238e},
	doi = {10.14569/IJACSA.2023.01408109},
	abstract = {Software testing plays an essential role in software development process since it helps to ensure that the developed software product is free from errors and meets the defined specifications before the delivery. As the software specification is mostly written in the form of natural language, this may lead to the ambiguity and misunderstanding by software developers and results in the incorrect test cases to be generated from this unclear specification. Therefore, to solve this problem, this paper presents a novel hybrid approach, Software Requirement Ontologies based Test Case Generation (ReqOntoTestGen) to enhance the reliability of existing software testing techniques. This approach enables a framework that combines ontology engineering with the software test case generation approaches. Controlled Natural Language (CNL) provided by the ROO (Rabbit to OWL Ontologies Authoring) tools is used by the framework to build the software requirement ontology from unstructured functional requirements. This eliminates the inconsistency and ambiguity of requirements before test case generation. The OWL ontology resulted from ontology engineering is then transformed into the XML file of data dictionary. Combination of Equivalence and Classification Tree Method (CCTM) is used to generate test cases from this XML file with the decision tree. This allows us to reduce redundancy of test cases and increase testing coverage. The proposed approach is demonstrated with the developed prototype tool. The contribution of the tool is confirmed by the validation and evaluation result with two real case studies, Library Management System (LMS) and Kidney Failure Diagnosis (KFD) Subsystem, as we expected. © (2023), (Science and Information Organization). All Rights Reserved.},
	language = {English},
	number = {8},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {Intana, Adisak and Tantayakul, Kuljaree and Laosen, Kanjana and Charoenreh, Suraiya},
	year = {2023},
	note = {Publisher: Science and Information Organization
Type: Article},
	keywords = {Formal specification, Requirements engineering, Software design, Software requirements specifications, Ontology, Software reliability, Birds, Software requirements, Software testing, XML, Test case generation, Decision trees, Test case, Ontology's, Requirements ontology, Classification tree method, Equivalence, Ontology engineering, Software testings},
	pages = {1005 -- 1014},
	annote = {Cited by: 0; All Open Access, Gold Open Access},
	annote = {Cited by: 0; All Open Access, Gold Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{mustroph_verifying_2023-1,
	title = {Verifying {Resource} {Compliance} {Requirements} from {Natural} {Language} {Text} over {Event} {Logs}},
	volume = {14159 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172192425&doi=10.1007%2f978-3-031-41620-0_15&partnerID=40&md5=73b277bcc783f7c96eb873c5325927b2},
	doi = {10.1007/978-3-031-41620-0_15},
	abstract = {Process compliance aims to ensure that processes adhere to requirements imposed by natural language texts such as regulatory documents. Existing approaches assume that requirements are available in a formalized manner using, e.g., linear temporal logic, leaving the question open of how to automatically extract and formalize them for verification. Especially with the constantly growing amount of regulatory documents and their frequent updates, it can be preferable to provide an approach that enables the verification of processes with requirements in natural language text instead of formalized requirements. To this end, this paper presents an approach that copes with the verification of resource compliance requirements, e.g., which resource shall perform which activity, in natural language over event logs. The approach relies on a comprehensive literature analysis to identify resource compliance patterns. It then contrasts these patterns with resource patterns reflecting the process perspective, while considering the natural language perspective. We combine the state-of-the-art GPT-4 technology for pre-processing the natural language text with a customized compliance verification component to identify and verify resource compliance requirements. Thereby, the approach distinguishes different resource patterns including multiple organizational perspectives. The approach is evaluated based on a set of well-established process descriptions and synthesized event logs generated by a process execution engine as well as the BPIC 2020 dataset. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Mustroph, Henryk and Barrientos, Marisol and Winter, Karolin and Rinderle-Ma, Stefanie},
	editor = {C, Di Francescomarino and A, Burattin and C, Janiesch and S, Sadiq},
	year = {2023},
	note = {ISBN: 978-303141619-4
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Event logs, Natural languages, Requirements engineering, Regulatory compliance, Regulatory documents, Temporal logic, Linear temporal logic, Compliance control, Requirement verifications, Compliance requirement verification, Literature analysis, Natural languages texts, Process descriptions, Resources minings},
	pages = {249 -- 265},
	annote = {Cited by: 1; Conference name: Proceedings of the 21st International Conference on Business Process Management , BPM 2023; Conference date: 11 September 2023 through 15 September 2023; Conference code: 300169},
}


@book{devi_automated_2021,
	title = {Automated verification and validation of {IoRT} systems},
	isbn = {978-1-119-75216-5 978-1-119-75059-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148409140&doi=10.1002%2f9781119752165.ch3&partnerID=40&md5=0cdb2928ee512a53cb9395f316c81b6d},
	abstract = {The Internet of Robotic Things (IoRT), an evolving standard draws together autonomous Robotic systems with the Internet of Things (IoT) revelation of linked sensors and smart objects extensively rooted in everyday environments. Some of the concerns in Verification and Validation of IoRT systems involve dynamic environments with multiple sensors and devices in conjunction with robotic things unlike Application testing performed in an established environment, complex real-time Test scenarios, conceiving a Test environment to verify and validate functionality along with scalability, reliability and safety issues. Ensuring the safety and functional integrity of IORT systems calls for stringent verification and validation. The Formal methods apprehend the intended system behaviour in a formal specification using Mathematical reasoning and facilitate Verification, Synthesis and Validation. Effective validation enfolds automated approach to generating Test cases, Test suite reduction, Test case prioritization and Test execution scheduling in combination with appropriate program verification techniques such as SMT and constraint solvers. The unified modelling language is used to depict the system requirements and to put forward a base for test case generation. For the test cases to be automatically extracted, the test scenarios are automatically determined using Natural language processing and formal constraints are acquired for the test data to be generated. The formal constraints hence obtain the contexts triggering the execution of test scenarios. This way test cases are generated considering both test scenarios addressed by manually implemented test suites and the vital scenarios identifying critical bugs. Constraint programming and global constraints can be utilized to reduce Test suites through constraint optimization models to identify a subset of test cases that encompass all the test requirements and hence optimize the cost of selected test cases as a whole. Constraint model-based test case execution scheduling is performed by assigning Test cases with obvious characteristics to Test agents - Robots with limited time and/or resources capacity. The allocated test cases are the ones that are consistent with the capacity constraints of the Test agents and having optimized time cost functions. Test cases can be prioritized automatically by observing failing test cases, test results, their actions and effects during run time and thereby adapting the prioritization methods for the test cases continually since the pointers for the failing test cases vary over time according to modifications in the test suite. Evident memory models and reward functions are used for the process. The magnitudes of IORT systems software failures can be possibly intense. Hence making use of suites formal verification and validation at various levels of abstraction and coverage to help secure certainty of the systems' safety, reliability and functional exactness. © 2022 Scrivener Publishing LLC. All rights reserved.},
	language = {English},
	publisher = {wiley},
	author = {Devi, S.V. Gayetri and Nalini, C.},
	year = {2021},
	doi = {10.1002/9781119752165.ch3},
	note = {Publication Title: Human Communication Technology: Internet-of-Robotic-Things and Ubiquitous Computing
Type: Book chapter},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{gropler_automated_2022,
	title = {Automated {Requirement} {Formalization} {Using} {Product} {Design} {Specifications}},
	volume = {3122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128715774&partnerID=40&md5=6e87b52c6b3aaa7186831eb9b0d81717},
	abstract = {Assuring the quality of complex and highly configurable software systems is a demanding and time-consuming process. Especially for safety-critical systems, extensive testing based on requirements is necessary. Methods for model-based test automation in agile software development offer the possibility to overcome these difficulties. However, it is still a major effort to create formal models from functional requirements in natural language on a large scale. In this paper, we present and evaluate automated support for the requirements formalization process to reduce cost and effort. We present a new approach based on Natural Language Processing (NLP) and textual similarity using requirements and product design specifications to generate human- and machine-readable models. The method is evaluated on an industrial use case from the railway domain. The recommended requirement models for the considered propulsion system show an average accuracy of more than 90\% and an exact match of the entire models of about 55\%. These results show that our approach can support the requirements formalization process, which can be further used for test case generation and execution, as well as for requirements and design verification. © 2022 Copyright for this paper by its authors},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Gröpler, Robin and Kutty, Libin and Sudhi, Viju and Smalley, Daran},
	editor = {J, Fischbach and N, Condori-Fernandez and N, Condori-Fernandez and J, Doerr and M, Ruiz and J.-P, Steghofer and L, Pasquale and A, Zisman and R, Guizzardi and J, Horkoff and A, Perini and A, Susi and M, Daneva and A, Herrmann and K, Schneider and P, Mennig and F, Dalpiaz and D, Dell�Anna and S, Kopczynska and L, Montgomery and A.G, Darby and P, Sawyer},
	year = {2022},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Product design, Requirements engineering, Software design, Model checking, Specifications, Software testing, Modeling languages, Requirements formalizations, Automation, Safety engineering, Safety testing, Requirement engineering, Software-systems, Safety critical systems, Propulsion, Requirements modeling, Design specification, Extensive testing, Model-based test, Test Automation, Textual similarities},
	annote = {Cited by: 0; Conference name: Joint REFSQ-2022 Workshops, Doctoral Symposium, and Posters and Tools Track, REFSQ-JP 2022; Conference date: 21 March 2022; Conference code: 178725},
	annote = {Cited by: 0; Conference name: Joint REFSQ-2022 Workshops, Doctoral Symposium, and Posters and Tools Track, REFSQ-JP 2022; Conference date: 21 March 2022; Conference code: 178725},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{puccetti_combining_2021,
	title = {Combining formal and machine learning techniques for the generation of {JML} specifications},
	isbn = {978-1-4503-8543-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113218961&doi=10.1145%2f3464971.3468425&partnerID=40&md5=d233d895c08afc45ad0c9966e3e04af6},
	doi = {10.1145/3464971.3468425},
	abstract = {Producing maintainable programs is a big challenge for the software industry as it requires solid Engineering skills and efficient CASE tools. Often, industrial programs are of a very large size (more than 1M SLOC), use high-level programming languages to their full extent (e.g. C++20, Ada 2005 or Java 16), are provided with scarce and often outdated documentation partially written in natural language. Maintenance engineers are therefore in need to understand the application at hand starting from the material left behind by the developers. The European H2020 Project DECODER (https://www.decoder-project.eu) addresses this problem by proposing to combine Natural Language Processing techniques and Formal Methods to turn as best as possible code artifacts into formal data allowing to reduce the maintenance costs and thus the total costs of ownership. In this context, we will show how to generate JML annotations using a combination of 1) automatic generation of minimal predicates, 2) Natural Language Processing (NLP) based predicates generator, and 3) manual refinement and correction, to instrument and enhance code and documentation. We will illustrate it on code samples from the MyThaiStar (https://github.com/devonfw/my-thai-star) application developed with the CASE tool devonfw by CAP GEMINI, and the Joram JMS implementation (https://gitlab.ow2.org/joram/joram) from OW2 code base. © 2021 ACM.},
	language = {English},
	booktitle = {{FTfJP} 2021 - {Proceedings} of the 23rd {ACM} {International} {Workshop} on {Formal} {Techniques} for {Java}-{Like} {Programs}, co-located with {ECOOP}/{ISSTA} 2021},
	publisher = {Association for Computing Machinery, Inc},
	author = {Puccetti, Armand and De Chalendar, Gaël and Gibello, Pierre-Yves},
	editor = {D.R, Cok},
	year = {2021},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, NAtural language processing, Computer software, Object oriented programming, Machine learning, Codes (symbols), Java programming language, Computer aided software engineering, Automatic Generation, HTTP, Machine learning techniques, Automatic programming, Ada (programming language), Engineering skills, High-level programming language, Industrial programs, Maintenance engineers, Software industry},
	pages = {59 -- 64},
	annote = {Cited by: 0; Conference name: 23rd ACM International Workshop on Formal Techniques for Java-Like Programs, FTfJP 2021, co-located with ECOOP/ISSTA 2021; Conference date: 13 July 2021; Conference code: 170196},
	annote = {Cited by: 1; Conference name: 23rd ACM International Workshop on Formal Techniques for Java-Like Programs, FTfJP 2021, co-located with ECOOP/ISSTA 2021; Conference date: 13 July 2021; Conference code: 170196},
	annote = {RELEVANCE: LOW
},
}


@article{sierra_bdi_2021,
	title = {{BDI} logic applied to a dialogical interpretation of human-machine cooperative dialogues},
	volume = {29},
	issn = {13670751},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127008953&doi=10.1093%2fjigpal%2fjzz039&partnerID=40&md5=5562e2eee154abcc19751f5f79a642cc},
	doi = {10.1093/jigpal/jzz039},
	abstract = {We first define a language for the dialogical logic and the models that the language generates. This language is thought to capture the structure of the dialogues captured by Lekta - a software framework oriented to the design and implementation of natural language processing-related applications - and its users. These dialogues are defined as cooperative dialogues in which the dialogical logic perspective of a dialogue seen as a competition is shifted into a perspective in which both agents cooperate towards a common goal. Later we define a BDI temporal logic based on a modal framework that we will use to study the beliefs, desires and intentions of both agents based on the model generated by the dialogical logic. © The Author(s) 2020.},
	language = {English},
	number = {4},
	journal = {Logic Journal of the IGPL},
	author = {Sierra, Pablo},
	year = {2021},
	note = {Publisher: Oxford University Press
Type: Article},
	keywords = {Natural language processing systems, Computer circuits, Design and implementations, Application programs, Computer programming, Agent based, Software frameworks, BDI logic, Belief revision, Cooperative dialog, Dialogical logic, Human-machine},
	pages = {536 -- 548},
	annote = {Cited by: 1},
	annote = {Cited by: 1},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{wu_autoformalization_2022,
	title = {Autoformalization with {Large} {Language} {Models}},
	volume = {35},
	isbn = {978-1-71387-108-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144992805&partnerID=40&md5=6ef93aef894d2abaf7d32df8436b037b},
	abstract = {Autoformalization is the process of automatically translating from natural language mathematics to formal specifications and proofs. A successful autoformalization system could advance the fields of formal verification, program synthesis, and artificial intelligence. While the long-term goal of autoformalization seemed elusive for a long time, we show large language models provide new prospects towards this goal. We make the surprising observation that LLMs can correctly translate a significant portion (25.3\%) of mathematical competition problems perfectly to formal specifications in Isabelle/HOL. We demonstrate the usefulness of this process by improving a previously introduced neural theorem prover via training on these autoformalized theorems. Our methodology results in a new state-of-the-art result on the MiniF2F theorem proving benchmark, improving the proof rate from 29.6\% to 35.2\%. © 2022 Neural information processing systems foundation. All rights reserved.},
	language = {English},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Neural information processing systems foundation},
	author = {Wu, Yuhuai and Jiang, Albert Q. and Li, Wenda and Rabe, Markus N. and Staats, Charles and Jamnik, Mateja and Szegedy, Christian},
	editor = {S, Koyejo and S, Mohamed and A, Agarwal and D, Belgrave and K, Cho and A, Oh},
	year = {2022},
	note = {ISSN: 10495258
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Translation (languages), Language model, Theorem proving, Computational linguistics, State of the art, Program synthesis, Isabelle, Long-term goals, Theorem provers, Verification programs},
	annote = {Cited by: 4; Conference name: 36th Conference on Neural Information Processing Systems, NeurIPS 2022; Conference date: 28 November 2022 through 9 December 2022; Conference code: 189185},
	annote = {Cited by: 11; Conference name: 36th Conference on Neural Information Processing Systems, NeurIPS 2022; Conference date: 28 November 2022 through 9 December 2022; Conference code: 189185},
	annote = {RELEVANCE: HIGH
},
}


@article{pressburger_authoring_2023-1,
	title = {Authoring, {Analyzing}, and {Monitoring} {Requirements} for a {Lift}-{Plus}-{Cruise} {Aircraft}},
	volume = {13975 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152554680&doi=10.1007%2f978-3-031-29786-1_21&partnerID=40&md5=3f6680d09bdbcf7a09754a56038b6520},
	doi = {10.1007/978-3-031-29786-1_21},
	abstract = {[Context \& Motivation] Requirements specification and analysis is widely applied to ensure the correctness of industrial systems in safety critical domains. Requirements are often initially written in natural language, which is highly ambiguous, and as a second step transformed into a language with rigorous semantics for formal analysis. [Question/problem] In this paper, we report on our experience in requirements creation and analysis, as well as run-time monitor generation using the Formal Requirement Elicitation Tool (FRET), on an industrial case study for a Lift-Plus-Cruise concept aircraft. [Principal ideas/results] We study the creation of requirements directly in the structured language of FRET without a prior definition of the same requirements in natural language. We focus on requirements describing state machines and discuss the challenges that we faced, in terms of creating requirements and generating monitors. We demonstrate how realizability, i.e., checking whether a requirements specification can be implemented, is crucial for understanding temporal interdependencies among requirements. [Contribution] Our study is the first complete attempt at using FRET to create industrial, realizable requirements and generate run-time monitors. Insight from lessons learned was materialized into new features in the FRET and JKind analysis frameworks. © 2023, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Pressburger, Tom and Katis, Andreas and Dutle, Aaron and Mavridou, Anastasia},
	editor = {A, Ferrari and B, Penzenstadler},
	year = {2023},
	note = {ISBN: 978-303129785-4
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural languages, Requirements engineering, Semantics, Requirements elicitation, Specifications, Industrial case study, Requirements specifications, Safety-critical domain, Requirement analysis, Accident prevention, Formal analysis, Runtimes, Industrial systems, Aircraft, Analysis time},
	pages = {295 -- 308},
	annote = {Cited by: 0; Conference name: 29th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2023; Conference date: 17 April 2023 through 20 April 2023; Conference code: 293059},
}


@article{de_nicola_intuitive_2023-1,
	title = {Intuitive {Modelling} and {Formal} {Analysis} of {Collective} {Behaviour} in {Foraging} {Ants}},
	volume = {14137 LNBI},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172137244&doi=10.1007%2f978-3-031-42697-1_4&partnerID=40&md5=a0f93e9f4c1577dd416eb1b154eba18d},
	doi = {10.1007/978-3-031-42697-1_4},
	abstract = {We demonstrate a novel methodology that integrates intuitive modelling, simulation, and formal verification of collective behaviour in biological systems. To that end, we consider the case of a colony of foraging ants, where, for the combined effect of known biological mechanisms such as stigmergic interaction, pheromone release, and path integration, the ants will progressively work out the shortest path to move back and forth between their nest and a hypothetical food repository. Starting from an informal description in natural language, we show how to devise intuitive specifications for such scenario in a formal language. We then make use of a prototype software tool to formally assess whether such specifications would indeed replicate the expected collective behaviour of the colony as a whole. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {De Nicola, Rocco and Di Stefano, Luca and Inverso, Omar and Valiani, Serenella},
	editor = {J, Pang and J, Niehren},
	year = {2023},
	note = {ISBN: 978-303142696-4
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Simulation, Formal languages, Specifications, Formal verification, Autonomous agents, Computer aided software engineering, Formal analysis, Computational methods, Bioinformatics, Software prototyping, Simulation platform, Novel methodology, Agent-based model, Ant colonies, Collective behaviour, Foraging, Intuitive modeling, Modeling analyzes, Modeling simulation},
	pages = {44 -- 61},
	annote = {Cited by: 0; Conference name: Proceedings of the 21st International Conference on Computational Methods in Systems Biology, CMSB 2023; Conference date: 13 September 2023 through 15 September 2023; Conference code: 300549},
}


@article{giannakopoulou_automated_2021,
	title = {Automated formalization of structured natural language requirements},
	volume = {137},
	issn = {09505849},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110475677&doi=10.1016%2fj.infsof.2021.106590&partnerID=40&md5=026ddfe572f5a6ad835456a709fe95f0},
	doi = {10.1016/j.infsof.2021.106590},
	abstract = {The use of structured natural languages to capture requirements provides a reasonable trade-off between ambiguous natural language and unintuitive formal notations. There are two major challenges in making structured natural language amenable to formal analysis: (1) formalizing requirements as formulas that can be processed by analysis tools and (2) ensuring that the formulas conform to the semantics of the structured natural language. FRETISH is a structured natural language that incorporates features from existing research and from NASA applications. Even though FRETISH is quite expressive, its underlying semantics is determined by the types of four fields: scope, condition, timing, and response. Each combination of field types defines a template with Real-Time Graphical Interval Logic (RTGIL) semantics. We have developed a framework that constructs temporal logic formulas for each template compositionally, from its fields. The compositional nature of our algorithms facilitates maintenance and extensibility. Our goal is to be inclusive not only in terms of language expressivity, but also in terms of requirements analysis tools that we can interface with. For this reason we generate metric-temporal logic formulas with (1) exclusively future-time operators, over both finite and infinite traces, and (2) exclusively past-time operators. To establish trust in the produced formalizations for each template, our framework: (1) extensively tests the generated formulas against the template semantics and (2) proves equivalence between its past-time and future-time formulas. Our approach is available through the open-source tool FRET and has been used to capture and analyze requirements for a Lockheed Martin Cyber–Physical System challenge. © 2021},
	language = {English},
	journal = {Information and Software Technology},
	author = {Giannakopoulou, Dimitra and Pressburger, Thomas and Mavridou, Anastasia and Schumann, Johann},
	year = {2021},
	note = {Publisher: Elsevier B.V.
Type: Article},
	keywords = {Natural language processing systems, Natural languages, Semantics, Temporal logic, Natural language requirements, Computer circuits, NASA, Formal notations, Temporal logic formula, Metric temporal logic, Open systems, Economic and social effects, Open source tools, Template semantics, Requirements analysis tools},
	annote = {Cited by: 19; All Open Access, Bronze Open Access},
	annote = {Cited by: 20; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: MEDIUM
},
}


@article{v_28th_2022,
	title = {28th {International} {Working} {Conference} on {Requirements} {Engineering}: {Foundation} for {Software} {Quality}, {REFSQ} 2022},
	volume = {13216 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127026212&partnerID=40&md5=8adb2d92230dc66159b18e58330447c4},
	abstract = {The proceedings contain 19 papers. The special focus in this conference is on Requirements Engineering: Foundation for Software Quality. The topics include: Vision Video Making with Novices: A Research Preview; a Study on the Mental Models of Users Concerning Existing Software; requirements Engineering for Software-Enabled Art: Challenges and Guidelines; Setting AI in Context: A Case Study on Defining the Context and Operational Design Domain for Automated Driving; on Testing Security Requirements in Industry – A Survey Study; a Business Model Construction Kit for Platform Business Models - Research Preview; requirements Engineering in the Market Dialogue Phase of Public Procurement: A Case Study of an Innovation Partnership for Medical Technology; from User Stories to Data Flow Diagrams for Privacy Awareness: A Research Preview; guided Derivation of Conceptual Models from User Stories: A Controlled Experiment; invest in Splitting: User Story Splitting Within the Software Industry; Transparency and Explainability of AI Systems: Ethical Guidelines in Practice; preface; FRETting About Requirements: Formalised Requirements for an Aircraft Engine Controller; req2Spec: Transforming Software Requirements into Formal Specifications Using Natural Language Processing; Towards Explainable Formal Methods: From LTL to Natural Language with Neural Machine Translation; abbreviation-Expansion Pair Detection for Glossary Term Extraction; a Zero-Shot Learning Approach to Classifying Requirements: A Preliminary Study.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {V, Gervasi and A, Vogelsang},
	year = {2022},
	note = {ISBN: 978-303098463-2
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: 28th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2022; Conference date: 21 March 2022 through 24 March 2022; Conference code: 274709},
	annote = {Cited by: 0; Conference name: 28th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2022; Conference date: 21 March 2022 through 24 March 2022; Conference code: 274709},
	annote = {RELEVANCE: NULL - procedings
},
}


@article{barrientos_verification_2023,
	title = {Verification of {Quantitative} {Temporal} {Compliance} {Requirements} in {Process} {Descriptions} {Over} {Event} {Logs}},
	volume = {13901 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163923412&doi=10.1007%2f978-3-031-34560-9_25&partnerID=40&md5=353e9e058a5ab256b57b8f55ddc0861b},
	doi = {10.1007/978-3-031-34560-9_25},
	abstract = {Process compliance verification ensures that processes adhere to a set of given regulatory requirements which are typically assumed to be available in a formalized way using, e.g., LTL. However, formalized requirements are rarely available in practice, but rather embedded in regulatory documents such as the GDPR, requiring extraction and formalization by experts. Due to the vast amount and frequent changes in regulatory documents, it is almost impossible to keep formalized requirements up to date in a manual way. Therefore, this paper presents an approach towards compliance verification between natural language text and event logs without the need for requirements formalization. This enables humans to cope with an increasingly complex environment. The approach focuses on quantitative temporal requirements (QTCR) and consists of multiple steps. First, we identify clauses with temporal expressions from process descriptions. Second, we generate a set of QTCR by mapping the retrieved clauses to event log activities. Finally, in the third step, we verify that the event log is compliant with the QTCR. The approach is evaluated based on process descriptions and synthesized event logs. For the latter, we implement time shifting as a concept for simulating real-life logs with varying temporal challenges. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Barrientos, Marisol and Winter, Karolin and Mangler, Juergen and Rinderle-Ma, Stefanie},
	editor = {M, Indulska and I, Reinhartz-Berger and C, Cetina and O, Pastor},
	year = {2023},
	note = {ISBN: 978-303134559-3
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Event logs, Regulatory compliance, Regulatory documents, Compliance control, Requirements formalizations, Compliance verification, Formalisation, In-process, Natural languages texts, Process descriptions, Regulatory requirements, Temporal compliance requirement},
	pages = {417 -- 433},
	annote = {Cited by: 1; Conference name: 35th International Conference on Advanced Information Systems Engineering, CAiSE 2023; Conference date: 12 June 2023 through 16 June 2023; Conference code: 296279},
	annote = {RELEVANCE: HIGH
},
}


@article{adam_natural_2023-1,
	title = {From {Natural} {Language} {Requirements} to the {Verification} of {Programmable} {Logic} {Controllers}: {Integrating} {FRET} into {PLCverif}},
	volume = {13903 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163948676&doi=10.1007%2f978-3-031-33170-1_21&partnerID=40&md5=207888e33fec3c7c7a700b62dcc3a711},
	doi = {10.1007/978-3-031-33170-1_21},
	abstract = {PLCverif is an actively developed project at CERN, enabling the formal verification of Programmable Logic Controller (PLC) programs in critical systems. In this paper, we present our work on improving the formal requirements specification experience in PLCverif through the use of natural language. To this end, we integrate NASA’s FRET, a formal requirement elicitation and authoring tool, into PLCverif. FRET is used to specify formal requirements in structured natural language, which automatically translates into temporal logic formulae. FRET’s output is then directly used by PLCverif for verification purposes. We discuss practical challenges that PLCverif users face when authoring requirements and the FRET features that help alleviate these problems. We present the new requirement formalization workflow and report our experience using it on two critical CERN case studies. © 2023, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Ádám, Zsófia and Lopez-Miguel, Ignacio D. and Mavridou, Anastasia and Pressburger, Thomas and Bęś, Marcin and Blanco Viñuela, Enrique and Katis, Andreas and Tournier, Jean-Charles and Trinh, Khanh V. and Fernández Adiego, Borja},
	editor = {K.Y, Rozier and S, Chaudhuri},
	year = {2023},
	note = {ISBN: 978-303133169-5
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Natural language requirements, Requirements elicitation, Formal verification, Computer circuits, Requirements formalizations, NASA, Controllers, Temporal logic formula, Programmable logic controllers, Formal requirement specifications, Work-flows, Critical systems, Forster resonance energy transfer, Authoring tool, Controller programs},
	pages = {353 -- 360},
	annote = {Cited by: 0; Conference name: 15th International Symposium on NASA Formal Methods, NFM 2023; Conference date: 16 May 2023 through 18 May 2023; Conference code: 296139},
}


@article{yang_deepocl_2023,
	title = {{DeepOCL}: {A} deep natural network for {Object} {Constraint} {Language} generation from unrestricted nature language},
	issn = {24686557},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150591548&doi=10.1049%2fcit2.12207&partnerID=40&md5=e8b24d4352b7c763959bacabdd407258},
	doi = {10.1049/cit2.12207},
	abstract = {Object Constraint Language (OCL) is one kind of lightweight formal specification, which is widely used for software verification and validation in NASA and Object Management Group projects. Although OCL provides a simple expressive syntax, it is hard for the developers to write correctly due to lacking knowledge of the mathematical foundations of the first-order logic, which is approximately half accurate at the first stage of development. A deep natural network named DeepOCL is proposed, which takes the unrestricted natural language as inputs and automatically outputs the best-scored OCL candidates without requiring a domain conceptual model that is compulsively required in existing rule-based generation approaches. To demonstrate the validity of our proposed approach, ablation experiments were conducted on a new sentence-aligned dataset named OCLPairs. The experiments show that the proposed DeepOCL can achieve state of the art for OCL statement generation, scored 74.30 on BLEU, and greatly outperformed experienced developers by 35.19\%. The proposed approach is the first deep learning approach to generate the OCL expression from the natural language. It can be further developed as a CASE tool for the software industry. © 2023 The Authors. CAAI Transactions on Intelligence Technology published by John Wiley \& Sons Ltd on behalf of The Institution of Engineering and Technology and Chongqing University of Technology.},
	language = {English},
	journal = {CAAI Transactions on Intelligence Technology},
	author = {Yang, Yilong and Liu, Yibo and Bao, Tianshu and Wang, Weiru and Niu, Nan and Yin, Yongfeng},
	year = {2023},
	note = {Publisher: John Wiley and Sons Inc
Type: Article},
	keywords = {Natural languages, Verification, NASA, Formal logic, deep learning, Deep learning, software engineering, OCL, Group projects, Language generation, Mathematical foundations, Natural networks, Object Constraint Language, Object management, Simple++, Software verification and validation},
	annote = {Cited by: 0; All Open Access, Gold Open Access},
	annote = {Cited by: 1; All Open Access, Gold Open Access},
	annote = {Cited by: 1; All Open Access, Gold Open Access},
	annote = {Place: USA Publisher: John Wiley \&amp; Sons, Inc.},
	annote = {Place: USA Publisher: John Wiley \&amp; Sons, Inc.},
	annote = {RELEVANCE: LOW
},
}


@article{wang_compliance_2022,
	title = {Compliance {Validation} of {Traffic} {Rules} for {Automated} {Driving} {System}; [自动驾驶系统交通规则符合性仿真验证方法]},
	volume = {35},
	issn = {10017372},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140895380&doi=10.19721%2fj.cnki.1001-7372.2022.09.002&partnerID=40&md5=bf0c5bb6f73473b0ac28abeecc0068b6},
	doi = {10.19721/j.cnki.1001-7372.2022.09.002},
	abstract = {With the development of automated driving, road tests have gradually been conducted for high-level automated driving vehicles in limited areas. Assuring and improving the safe driving capability of self-driving systems is a popular topic in current research, testing, and development. To reduce the traffic safety risk under mixed traffic conditions, a method of verifying and testing the compliance of automated driving vehicles with the same traffic rules is proposed. Aiming at the technical bottleneck of automatic semantic analysis of various traffic laws and rules, this paper proposes a two-stage digital model of normalization-logic traffic rules based on improved predicate metric temporal logic (MTL). Natural language traffic rules were transformed into logical codes constituting propositions, logical connectives, and time-series operators. In addition, digital traffic rules that can be understood, executed, and verified in automated driving systems were generated. A classification and grading system for traffic rule propositions was constructed. Furthermore, a set of traffic rule compliance verification algorithms based on high-precision trajectories of automated driving vehicles were proposed, a simulation test platform was built, and verification was performed in a highway traffic scenario. Theoretical analysis and test results show that improvements such as simplifying the proposition space, adding time series operators, and predicate logic words effectively improve the time representation ability of the original MTL framework, solve the problem of time series logic, and greatly improve the efficiency of the digital transformation of traffic rules. Additionally, the method is compatible with local traffic laws and future traffic law revisions. The proposed traffic rule compliance verification method and test platform can effectively test the ability of an automated driving system to comply with the existing traffic rules. These results are significant for improving the safety performance of automated driving systems and the level of hybrid traffic safety control in the future. © 2022 Xi'an Highway University. All rights reserved.},
	language = {Chinese},
	number = {9},
	journal = {Zhongguo Gonglu Xuebao/China Journal of Highway and Transport},
	author = {Wang, Chang-Jun and Hu, Wei-Chao and Yu, Peng-Cheng and Zhou, Wen-Hui and Song, Si-Da},
	year = {2022},
	note = {Publisher: Chang'an University
Type: Article},
	keywords = {Semantics, Temporal logic, Compliance control, Computer circuits, Automation, Safety testing, Automated driving systems, Time series, Accident prevention, Traffic laws, Traffic rules, Metric temporal logic, Time series analysis, Vehicles, Traffic control, Time domain analysis, Automated driving, Grading, Mixed traffic, Simulation tests, Times series, Traffic Engineering, Traffic safety},
	pages = {13 -- 25},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{masmoudi_adopting_2022,
	title = {Adopting formal methods on requirements verification and validation for cyber-physical systems: {A} systematic literature review},
	volume = {55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144507475&doi=10.1016%2fj.ifacol.2022.10.131&partnerID=40&md5=42604e9eea9d6342c2ce87407e970246},
	doi = {10.1016/j.ifacol.2022.10.131},
	abstract = {Requirements engineering is a critical activity in developing complex cyber-physical systems. Requirements are usually expressed using natural language, which may be ambiguous, inconsistent, or incomplete. These issues in requirements qualities may introduce errors in system design that lead to high project cost overruns. Hence it is essential to verify the qualities of requirements early. Since formal methods have demonstrated their ability to verify system designs and are increasingly adopted to support requirements engineering for software systems, a question arises about adapting formal methods to account for specific properties of cyber-physical systems. Even if there are many literature reviews concerning requirements engineering, there is a lack of a global view on the reviews that specifically address the issues related to validation and verification (V\&V) of requirements. This paper aims to provide an overview of literature reviews related to requirements V\&V and mainly investigates the use of formal approaches and models for preventing, detecting, or correcting errors occurring in requirements and identifies the main challenges of adopting formal methods on requirements engineering for cyber-physical systems. Copyright © 2022 The Authors. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0/)},
	language = {English},
	booktitle = {{IFAC}-{PapersOnLine}},
	publisher = {Elsevier B.V.},
	author = {Masmoudi, Chedhli and Marange, Pascale and Bonjour, Eric and Levrat, Eric and Kerbrat, Alain},
	editor = {A, Bernard and A, Dolgui and H.H, Benderbal and D, Ivanov and D, Lemoine and F, Sgarbossa},
	year = {2022},
	note = {ISSN: 24058963
Issue: 10
Type: Conference paper},
	keywords = {Requirements engineering, Formal verification, Cyber Physical System, Embedded systems, Requirement engineering, Requirements validation, Verification-and-validation, Cybe-physical systems, Cyber-physical systems, Requirement verifications, Systematic literature review, Literature reviews, Systems analysis, Critical activities, Validation and verification},
	pages = {3274 -- 3279},
	annote = {Cited by: 0; Conference name: 10th IFAC Conference on Manufacturing Modelling, Management and Control, MIM 2022; Conference date: 22 June 2022 through 24 June 2022; Conference code: 148818; All Open Access, Bronze Open Access},
	annote = {Cited by: 0; Conference name: 10th IFAC Conference on Manufacturing Modelling, Management and Control, MIM 2022; Conference date: 22 June 2022 through 24 June 2022; Conference code: 148818; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: MEDIUM check
},
}


@article{pandey_conceptual_2022,
	title = {A {Conceptual} {Framework} to {Predict} {Mental} {Health} {Patients}' {Zoning} {Classification}},
	volume = {289},
	issn = {09269630},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123211848&doi=10.3233%2fSHTI210924&partnerID=40&md5=4ceb05cf1521d75d2503aa909035a50c},
	doi = {10.3233/SHTI210924},
	abstract = {Zoning classification is a rating mechanism, which uses a three-tier color coding to indicate perceived risk from the patients' conditions. It is a widely adopted manual system used across mental health settings, however it is time consuming and costly. We propose to automate classification, by adopting a hybrid approach, which combines Temporal Abstraction to capture the temporal relationship between symptoms and patients' behaviors, Natural Language Processing to quantify statistical information from patient notes, and Supervised Machine Learning Models to make a final prediction of zoning classification for mental health patients. © 2022 The authors and IOS Press.},
	language = {English},
	journal = {Studies in Health Technology and Informatics},
	author = {Pandey, Sanjib Raj and Smith, Alan and Gall, Edmund Nigel and Bhatnagar, Ajay and Chaussalet, Thierry},
	editor = {J, Mantas and A, Hasman and M.S, Househ and P, Gallos and E, Zoulias and J, Liasko},
	year = {2022},
	pmid = {35062157},
	note = {ISBN: 978-164368250-1
Publisher: IOS Press BV
Type: Conference paper},
	keywords = {natural language processing, Natural language processing systems, Learning algorithms, Classification (of information), Natural Language Processing, Humans, Machine Learning, Health, machine learning, prediction, Medical informatics, electronic health record, Electronic Health Records, human, Supervised learning, adult, controlled study, risk assessment, conceptual framework, Conceptual frameworks, Colour coding, conference paper, Hybrid approach, logic, mental health, Mental health, Mental Health, Patients' conditions, Perceived risk, quantitative analysis, Statistical information, supervised machine learning, Supervised machine learning, Supervised Machine Learning, Temporal abstraction, Temporal relationships, Zoning},
	pages = {321 -- 324},
	annote = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{ghosh_specnfs_2022,
	title = {{SpecNFS}: {A} {Challenge} {Dataset} {Towards} {Extracting} {Formal} {Models} from {Natural} {Language} {Specifications}},
	isbn = {979-10-95546-72-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144467883&partnerID=40&md5=35a4545cd8f0c8214404491a13793849},
	abstract = {Can NLP assist in building formal models for verifying complex systems? We study this challenge in the context of parsing Network File System (NFS) specifications. We define a semantic-dependency problem over SpecIR, a representation language we introduce to model sentences appearing in NFS specification documents (RFCs) as semantic dependency structures, and present an annotated dataset of 1,198 sentences. We develop and evaluate semantic-dependency parsing systems for this problem. Evaluations show that even when using a state-of-the-art language model, there is significant room for improvement, with the best models achieving an F1 score of only 60.5 and 33.3 in the named-entity-recognition and dependency-link-prediction sub-tasks, respectively. We also release additional unlabeled data and other domain-related texts. Experiments show that these additional resources increase the F1 measure when used for simple domain-adaption and transfer-learning-based approaches, suggesting fruitful directions for further research. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.},
	language = {English},
	booktitle = {2022 {Language} {Resources} and {Evaluation} {Conference}, {LREC} 2022},
	publisher = {European Language Resources Association (ELRA)},
	author = {Ghosh, Sayontan and Singh, Amanpreet and Merenstein, Alex and Su, Wei and Smolka, Scott A. and Zadok, Erez and Balasubramanian, Niranjan},
	editor = {N, Calzolari and F, Bechet and P, Blache and K, Choukri and C, Cieri and T, Declerck and S, Goggi and H, Isahara and B, Maegaard and J, Mariani and H, Mazo and J, Odijk and S, Piperidis},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Semantics, Specifications, Formal verification, Syntactics, Natural language specifications, Systems specification, Formal modeling, Dependency parsing, In-buildings, Network file system, Representation languages, Semantic dependency, Semantic dependency parsing, Specification dataset},
	pages = {2166 -- 2176},
	annote = {Cited by: 0; Conference name: 13th International Conference on Language Resources and Evaluation Conference, LREC 2022; Conference date: 20 June 2022 through 25 June 2022; Conference code: 184830},
	annote = {Cited by: 0; Conference name: 13th International Conference on Language Resources and Evaluation Conference, LREC 2022; Conference date: 20 June 2022 through 25 June 2022; Conference code: 184830},
	annote = {RELEVANCE: HIGH
},
}


@article{caserio_formal_2022,
	title = {A {Formal} {Validation} {Approach} for {XACML} 3.0 {Access} {Control} {Policy}},
	volume = {22},
	issn = {14248220},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128219116&doi=10.3390%2fs22082984&partnerID=40&md5=20c4ed4408aa42f81b6dfc17a1cb7786},
	doi = {10.3390/s22082984},
	abstract = {Access control systems represent a security mechanism to regulate the access to system resources, and XACML is the standard language for specifying, storing and deploying access control policies. The verbosity and complexity of XACML syntax as well as the natural language semantics provided by the standard make the verification and testing of these policies difficult and error-prone. In the literature, analysis techniques and access control languages formalizations are provided for verifiability and testability purposes. This paper provides three contributions: it provides a comprehensive formal specification of XACML 3.0 policy elements; it leverages the existing policy coverage criteria to be suitable for XACML 3.0; and it introduces a new set of coverage criteria to better focus the testing activities on the peculiarities of XACML 3.0. The application of the proposed coverage criteria to a policy example is described, and hints for future research directions are discussed. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	language = {English},
	number = {8},
	journal = {Sensors},
	author = {Caserio, Carmine and Lonetti, Francesca and Marchetti, Eda},
	year = {2022},
	pmid = {35458969},
	note = {Publisher: MDPI
Type: Article},
	keywords = {Semantics, Access control, Formalisation, Well testing, Policy, Access control policies, semantics, language, Access control systems, Coverage criteria, Formal validation, Language, policy, Policy testing, Security mechanism, System resources, Validation approach, XACML 3.0 formalization},
	annote = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{cosler_nl2spec_2023-1,
	title = {nl2spec: {Interactively} {Translating} {Unstructured} {Natural} {Language} to {Temporal} {Logics} with {Large} {Language} {Models}},
	volume = {13965 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172279049&doi=10.1007%2f978-3-031-37703-7_18&partnerID=40&md5=da4ca72272ab67781d4b7a02d3bf8273},
	doi = {10.1007/978-3-031-37703-7_18},
	abstract = {A rigorous formalization of desired system requirements is indispensable when performing any verification task. This often limits the application of verification techniques, as writing formal specifications is an error-prone and time-consuming manual task. To facilitate this, we present nl2spec, a framework for applying Large Language Models (LLMs) to derive formal specifications (in temporal logics) from unstructured natural language. In particular, we introduce a new methodology to detect and resolve the inherent ambiguity of system requirements in natural language: we utilize LLMs to map subformulas of the formalization back to the corresponding natural language fragments of the input. Users iteratively add, delete, and edit these sub-translations to amend erroneous formalizations, which is easier than manually redrafting the entire formalization. The framework is agnostic to specific application domains and can be extended to similar specification languages and new neural models. We perform a user study to obtain a challenging dataset, which we use to run experiments on the quality of translations. We provide an open-source implementation, including a web-based frontend. © 2023, The Author(s).},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Cosler, Matthias and Hahn, Christopher and Mendoza, Daniel and Schmitt, Frederik and Trippel, Caroline},
	editor = {C, Enea and A, Lal},
	year = {2023},
	note = {ISBN: 978-303137702-0
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Temporal logic, Specification languages, System requirements, Translation (languages), Formalisation, Verification techniques, Iterative methods, Language model, Error prones, Applications domains, Subformulas, Unstructured natural language, Verification task},
	pages = {383 -- 396},
	annote = {Cited by: 4; Conference name: Proceedings of the 35th International Conference on Computer Aided Verification, CAV 2023; Conference date: 17 July 2023 through 22 July 2023; Conference code: 298359; All Open Access, Green Open Access, Hybrid Gold Open Access},
}


@article{moketar_extraction_2018,
	title = {Extraction of essential requirements from natural language requirements},
	volume = {10},
	issn = {21801843},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048814265&partnerID=40&md5=1cc4bac17deabfd88015aa8a945a71d1},
	abstract = {Requirement is a formal expression of user's need. It is the main foundation of any software development project. Natural language (NL) is often used to express and write system requirements specifications as well as user requirements. However, there is a very high probability that more than half natural language requirements can be ambiguous, incomplete and inaccurate. A software engineer can miss-interpret the natural language requirements and can generate an erroneous software model, which finally will lead to project failure. Earlier, we have introduced a prototype tool that provides natural language requirements authoring facilities and consistency checking to assist requirement engineers when working with informal and semi-formal requirements. However, the tool has pattern limitation to support the extraction of the essential requirements from the NL requirements. Therefore this study is aimed to enhance the accuracy and scalability of the tool to capture the essential requirements from the NL requirements. Our approach is to implement lexical analysis and embed an English lexical database where it will serve as a thesaurus in the tool. This tool is expected to be able to find the synonym of the extracted phrases (essential requirements) in the database to match it to the essential interaction pattern (phrases and expressions) in the library. Our future work will focus on the next phase of requirements engineering, which is requirements validation. © 2018 Universiti Teknikal Malaysia Melaka. All Rights Reserved.},
	language = {English},
	number = {2-2},
	journal = {Journal of Telecommunication, Electronic and Computer Engineering},
	author = {Moketar, N.A. and Kamalrudin, M.},
	year = {2018},
	note = {Publisher: Universiti Teknikal Malaysia Melaka
Type: Article},
	pages = {35 -- 38},
	annote = {Cited by: 1},
	annote = {Cited by: 1},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{chhabra_formalizing_2018,
	title = {Formalizing and verifying natural language system requirements using petri nets and context based reasoning},
	volume = {2134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050472945&partnerID=40&md5=64df7203c36657fbf8bb9d210f284593},
	abstract = {Natural language descriptions are generally used to describe requirements in reactive systems. Translating the natural language requirements to a more formal specification is a challenging task. One possible approach to handle complex natural language requirements is to convert them to an intermediary formal representation. This intermediate representation is further converted into a more formal representation such as EDT (Expressive Decision Tables). In this paper, we use Petri nets in combination with domain based context reasoning as a tool to model natural language requirements. We have also built a tool, NatEDT, to generate EDT specifications. In a case study, consisting of natural language requirements across three domains, our experimental results show that Petri nets provide an efficient way of formalizing natural language requirements. © 2018 CEUR-WS. All Rights Reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Chhabra, Aishwarya and Sangroya, Amit and Anantaram, C.},
	editor = {J, Cassens and A, Kofod-Petersen and R, Wegener and A, Kofod-Petersen and R, Wegener},
	year = {2018},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Petri nets, Natural language processing systems, Formal specification, Natural languages, Artificial intelligence, Context reasoning, Context-based reasoning, Decision tables, Formal representations, Intermediate representations, Natural language requirements, Natural language systems, Reactive system},
	pages = {64 -- 71},
	annote = {Cited by: 4; Conference name: 10th International Workshop Modelling and Reasoning in Context, MRC 2018; Conference date: 13 July 2018; Conference code: 137772},
	annote = {Cited by: 5; Conference name: 10th International Workshop Modelling and Reasoning in Context, MRC 2018; Conference date: 13 July 2018; Conference code: 137772},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{friesen_cordula_2018,
	title = {{CORDULA}: {Software} requirements extraction utilizing chatbot as communication interface},
	volume = {2075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045428517&partnerID=40&md5=d4b4abace7d7289b989dbb84feab5d57},
	abstract = {Natural language requirement descriptions are often unstructured, contradictory and incomplete and are therefore challenging for automatic processing. Although many of these deficits can be compensated by means of natural language processing, there still remain cases where interaction with end-users is necessary for clarification. In this vision paper, we present CORDULA, a system using chatbot technology to establish end-user communication in order to support the requirement elicitation and partial compensation of deficits in user requirements. Copyright c 2018 by the paper's authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Friesen, Edwin and Bäumer, Frederik S. and Geierhos, Michaela},
	editor = {F, Dalpiaz and X, Franch and M, Kirikova and J, Ralyte and P, Spoletini and Y, Chisik and A, Ferrari and N, Madhavji and C, Palomares and M, Sabetzadeh and D, van der Linden and K, Schmid and E.B, Charrada and P, Sawyer and P, Forbrig and A, Zamansky},
	year = {2018},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Computer software selection and evaluation, Requirements engineering, Natural language requirements, Automatic processing, Communication interface, End users, Partial compensation, Requirement elicitation, Software requirements, User requirements},
	annote = {Cited by: 7; Conference name: 24th Joint International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, REFSQ-JP 2018; Conference date: 19 March 2018; Conference code: 135277},
	annote = {Cited by: 7; Conference name: 24th Joint International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, REFSQ-JP 2018; Conference date: 19 March 2018; Conference code: 135277},
	annote = {RELEVANCE: HIGH
},
}


@article{mokammel_automatic_2018,
	title = {Automatic requirements extraction, analysis, and graph representation using an approach derived from computational linguistics},
	volume = {21},
	issn = {10981241},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051070662&doi=10.1002%2fsys.21461&partnerID=40&md5=3eda877d27e29b86325972739debf3d8},
	doi = {10.1002/sys.21461},
	abstract = {The quality of requirements is fundamental in engineering projects. Requirements are usually expressed partly or totally in a natural language (NL) format and come from different documents. Their qualities are difficult to analyze manually, especially when hundreds of thousands of them have to be considered. The assistance of software tools is becoming a necessity. In this article, the goal was to develop a set of metrics supported by NL processing (NLP) methods supporting different types of analysis of requirements and especially the dependencies between requirements. An NLP approach is used to extract requirements from text; to analyze their quality, links, similarities, and contradictions; and to cluster them automatically. The analysis framework includes different combinations of methods such as cosine similarity, singular value decomposition, and K-means clustering. One objective is to assess the possible combinations and their impacts on detections to establish optimal metrics. Three case studies exemplify and support the validation of the work. Graphs are used to represent the automatically clustered requirements, as well as similarities and contradictions. A new contradiction analysis process that includes a rules-based approach is proposed. Finally, the combined results are presented as graphs, which unveil the semantic relationships between requirements. Subsection 4.8 compares the results provided by the tool and the results obtained from experts. The proposed methodology and network presentation not only support the understanding of the semantics of the requirements but also help requirements engineers to review the interconnections and consistency of requirements systems and manage traceability. The approach is valuable during the early phases of projects when requirements are evolving dynamically and rapidly. © 2018 Wiley Periodicals, Inc.},
	language = {English},
	number = {6},
	journal = {Systems Engineering},
	author = {Mokammel, Faisal and Coatanéa, Eric and Coatanéa, Joonas and Nenchev, Vladislav and Blanco, Eric and Pietola, Matti},
	year = {2018},
	note = {Publisher: John Wiley and Sons Inc.
Type: Article},
	keywords = {Natural language processing systems, Requirements engineering, Semantics, Contradiction analysis, Contradictions analysis, Graph representation, Network representation, Requirements management, Rules-based approaches, Semantic relationships, Similarity, Singular value decomposition},
	pages = {555 -- 575},
	annote = {Cited by: 8},
	annote = {Cited by: 11},
	annote = {RELEVANCE: MEDIUM
},
}


@article{garanina_ontology_2018,
	title = {An ontology of specification patterns for verification of concurrent systems},
	volume = {303},
	issn = {09226389},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063411082&doi=10.3233%2f978-1-61499-900-3-515&partnerID=40&md5=993078141732674c3c5e810677d38938},
	doi = {10.3233/978-1-61499-900-3-515},
	abstract = {Verifying the reliability of software systems formally is difficult due to the complexity of system correctness requirements. Specification patterns allow us to describe typical requirements in a natural language, while their formal semantics enable expressing these requirements in the input language of some verification tool. In this paper, we propose an ontology of specification patterns that combines patterns from existing requirement classifications with new patterns. Our ontology can be used to express combinations of requirements of the following types: qualitative, real and branching time, with combined events, quantitative characteristics of events, and simple statements about data. The advantage of our approach is the ability to formally verify the compatibility of multiple requirements. As an illustrating use case, we describe the requirements for the real-world vacuum control system of the Large Solar Vacuum Telescope. © 2018 The authors and IOS Press. All rights reserved.},
	language = {English},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Garanina, Natalia and Zubin, Vladimir and Lyakh, Tatiana and Gorlatch, Sergei},
	editor = {H, Fujita and E, Herrera-Viedma},
	year = {2018},
	note = {ISBN: 978-161499899-0
Publisher: IOS Press
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Semantics, Concurrent systems, Formal Semantics, Ontology, Quantitative characteristics, Requirement engeneering, Software reliability, Software systems, Specification patterns, Temporal logic, Verification tools, Software-systems, Real- time, Ontology's, Requirements classifications},
	pages = {515 -- 528},
	annote = {Cited by: 9; Conference name: 17th International Conference on New Trends in Intelligent Software Methodology Tools and Techniques, SoMeT 2018; Conference date: 26 September 2018 through 28 September 2018; Conference code: 146073},
	annote = {Cited by: 9; Conference name: 17th International Conference on New Trends in Intelligent Software Methodology Tools and Techniques, SoMeT 2018; Conference date: 26 September 2018 through 28 September 2018; Conference code: 146073},
	annote = {RELEVANCE: LOW
},
}


@article{liu_safety_2018,
	title = {A safety requirements analysis approach for level crossing based on {STPA}; [基于{STPA} 方法的平交道口安全需求分析]},
	volume = {42},
	issn = {16730291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055940165&doi=10.11860%2fj.issn.1673-0291.2018.02.012&partnerID=40&md5=c9b31c7f769df506fbc8651fa2a0a333},
	doi = {10.11860/j.issn.1673-0291.2018.02.012},
	abstract = {Modern level crossing control systems are mostly computer-based and communication-based control systems. The causal factors in this type of system are mostly due to the fact that the complex interaction scenarios between system components have not been fully identified and controlled. In order to avoid the occurrence of level crossing accidents, this paper proposes a set of safety analysis methods for railway signal systems based on System Theory Process Analysis (STPA). With the improvement of the traditional STPA and the XSTAMPP, this paper takes the level crossing control system as a case for safety analysis. The results achieve the automatic generation of safety requirements based on the hazards analysis results and solved the problem that the traditional STPA process is too dependent on labor. Meanwhile, the safety requirements of the level crossing control system are automatically converted into a formal specification of the Linear Temporal Logic (LTL) language description, which avoids the possible ambiguity in the natural language description of the traditional STPA analysis results. It provides references for a model-based system design, testing and verification. © 2018, Editorial Department of Journal of Beijing Jiaotong University. All right reserved.},
	language = {Chinese},
	number = {2},
	journal = {Beijing Jiaotong Daxue Xuebao/Journal of Beijing Jiaotong University},
	author = {Liu, Hongjie and Tang, Tao and Jin, Xiayao and Du, Heng},
	year = {2018},
	note = {Publisher: Journal Northern Jiaotong University
Type: Article},
	pages = {84 -- 90},
	annote = {Cited by: 4},
	annote = {Cited by: 4},
	annote = {RELEVANCE: LOW
},
}


@article{murugesh_exploiting_2018,
	title = {Exploiting ontology to map requirements derived from informal descriptions},
	volume = {10},
	issn = {17550556},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057826047&doi=10.1504%2fIJRIS.2018.096195&partnerID=40&md5=b4192b5f36ff222bdaead090b5540a4d},
	doi = {10.1504/IJRIS.2018.096195},
	abstract = {Requirements are narration of the services which a software system should make available along with the constraints that should be satisfied when the system operates. Software requirements have to be arrived from descriptions that are often incomplete, inconsistent, informal and ambiguous. Such informal descriptions have to be pre-processed and information constructs have to be extracted. This article deals with use of an ontology specific to automatic teller machine (ATM) operations domain that contains the concepts, the relationships that exists among the concepts and the focus is to decide on the feasibility of the requirement by mapping the extracted requirement with the requirement defined in the background ontology. The developed ontology is queried using simple protocol and RDF query language (SPARQL), if the derived requirement is present in the ontology it is said to be feasible; else decision may be taken to eliminate the requirements that are invalid and infeasible. Ontology is a formal specification of concepts with their attributes and relationship in a selected domain. As standard description formalism, the web ontology language (OWL) derived from resource description framework (RDF) is used. Copyright © 2018 Inderscience Enterprises Ltd.},
	language = {English},
	number = {3-4},
	journal = {International Journal of Reasoning-based Intelligent Systems},
	author = {Murugesh, S. and Jaya, A.},
	year = {2018},
	note = {Publisher: Inderscience Enterprises Ltd.
Type: Article},
	keywords = {Natural language processing systems, Requirements engineering, Ontology, Birds, NAtural language processing, Query languages, RDF query language, Requirements elicitation, Resource description framework, SIMPLE protocol, SPARQL, Unstructured documents, Web ontology language},
	pages = {169 -- 173},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: LOW
},
}


@article{ozkaya_informal_2018,
	title = {Do the informal \& formal software modeling notations satisfy practitioners for software architecture modeling?},
	volume = {95},
	issn = {09505849},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034616789&doi=10.1016%2fj.infsof.2017.10.008&partnerID=40&md5=d2baf9748ca8ef802b79d0c5ca344cf5},
	doi = {10.1016/j.infsof.2017.10.008},
	abstract = {Context: Software architectures can be modeled using semantically informal (i.e., ambiguous) or formal (i.e., mathematically precise) software modeling notations. Objective: In this paper, 115 different practitioners from 28 different countries who work in companies that perform software development have been surveyed. The goal is to understand practitioners’ knowledge and experience about informal and formal modeling notations in specifying software architectures. Method: The survey consists of 35 different questions, divided into three parts, i.e., the participant profile, the informal modeling, and formal modeling. The results of the survey lead to many interesting findings: Results: (1) Informal software modeling notations (especially UML) are practitioners’ top choice in specifying software architectures (94\%). (2) Despite many informal languages, some practitioners (40\%) insist using informal ad-hoc techniques (i.e., simple boxes/lines and natural languages) to specify complex design decisions (e.g., structure, behaviour, and interaction). (3) Practitioners using informal notations are impressed by their low learning-curve (79\%), visuality (62\%), and general-purpose scope (66\%). (4) Practitioners still criticise informal notations too, essentially for the lack of support for complex design decisions and their exhaustive analysis. (5) While formal modeling notations bridge this gap mentioned in step-4, many practitioners (70\%) rarely use formal notations due essentially to the high-learning curve, the lack of knowledge among stakeholders, and the lack of popularity in industry. (6) Among the considered formal notations (i.e., process algebras, high-level formal specification languages, and architecture description languages (ADLs)), process algebras are never used and ADLs are the least used formal languages are ADLs (i.e., 12\% frequently use ADLs). (7) Practitioners complain about ADLs’ weak tool support (38\%) and their lack of tutorials/guidance/etc (33\%). Conclusion: The survey results will let the community realise the advantages and disadvantages of informal and formal modeling notations for software architecture modeling from practitioners’ viewpoint. © 2017 Elsevier B.V.},
	language = {English},
	journal = {Information and Software Technology},
	author = {Ozkaya, Mert},
	year = {2018},
	note = {Publisher: Elsevier B.V.
Type: Article},
	keywords = {Formal specification, Natural languages, Software design, Semantics, Formal languages, Specification languages, Specifications, Algebra, High level languages, Software architecture, Design, Surveys, Ad-hoc techniques, ADLs, Architecture description languages, Complex design decisions, Knowledge and experience, Process algebras, Software architecture model},
	pages = {15 -- 33},
	annote = {Cited by: 25},
	annote = {Cited by: 26},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{e_cicm-ws_2019,
	title = {{CICM}-{WS} 2019 - {Joint} {Proceedings} of the {FMM} and {LML} {Workshops}, {Doctoral} {Program} and {Work} in {Progress} at the {Conference} on {Intelligent} {Computer} {Mathematics} 2019, co-located with the 12th {Conference} on {Intelligent} {Computer} {Mathematics}, {CICM} 2019},
	volume = {2634},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099337207&partnerID=40&md5=22e05f8016dfa109637434c7f707f09b},
	abstract = {The proceedings contain 20 papers. The topics discussed include: testing Mizar user interactivity in a university-level introductory course on foundations of mathematics; textbook mathematics in the Naproche-SAD system; formal verification of the correctness of chosen algorithms in Mizar; constructing examples of fuzzy implications within the Mizar mathematical library; isabelle technology for the archive of formal proofs with application to MMT; understanding scientific documents with synthetic analysis on mathematical expressions and natural language; definedness reasoning in formal mathematics and theorem proving; a unifying framework for managing conflict-laden content; leveraging information contained in theory presentations; and automating formalization of mathematics with machine learning and data mining.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	editor = {E, Brady and J, Davenport and W.M, Farmer and C, Kaliszyk and A, Kohlhase and M, Kohlhase and D, Muller and K, Pak and C.S, Coen},
	year = {2019},
	note = {ISSN: 16130073
Type: Conference review},
	annote = {Cited by: 0; Conference name: Joint 4th Workshop on Formal Mathematics for Mathematicians, FMM 2019 and Workshop on Large Mathematics Libraries, LML 2019, Doctoral Program and Work in Progress at the 12th Conference on Intelligent Computer Mathematics, CICM-WS 2019; Conference date: 8 July 2019 through 12 July 2019; Conference code: 165986},
	annote = {Cited by: 0; Conference name: Joint 4th Workshop on Formal Mathematics for Mathematicians, FMM 2019 and Workshop on Large Mathematics Libraries, LML 2019, Doctoral Program and Work in Progress at the 12th Conference on Intelligent Computer Mathematics, CICM-WS 2019; Conference date: 8 July 2019 through 12 July 2019; Conference code: 165986},
	annote = {RELEVANCE: LOW
},
}


@article{dos_santos_automated_2018,
	title = {Automated acceptance tests as software requirements: {An} experiment to compare the applicability of fit tables and {Gherkin} language},
	volume = {314},
	issn = {18651348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048046567&doi=10.1007%2f978-3-319-91602-6_7&partnerID=40&md5=ecdaf99e33f1954a2bbda73d278ae507},
	doi = {10.1007/978-3-319-91602-6_7},
	abstract = {It is estimated that 85\% of the defects in the developed software are originated from ambiguous, incomplete and wishful thinking software requirements. Natural language is often used to write software requirements specifications as well as user requirements. However, natural language specifications can be confusing and hard to understand. Some agile methodologists consider that acceptance tests are more precise and accurate sources of information about the customer’s needs than descriptions in natural language. Several studies have addressed the use of acceptance tests as software requirements specification. Therefore, none of the previous studies has performed experiments to compare the applicability of different acceptance testing techniques in order to support an organization in the selection of one technique over another. This paper addresses this problem reporting an experiment conducted with undergraduate students in Computer Science. This experiment compares the applicability of two acceptance testing techniques (Fit tables and Gherkin language) as software requirements specification. This research tries to answer three questions: (a) Which technique is the easiest to learn in order to specify acceptance test scenarios? (b) Which technique requires less effort to specify acceptance tests? (c) Which technique is the best one to communicate software requirements? The results show that there is no sufficient evidence to affirm that one technique is easier to specify test scenarios or better to communicate software requirements. Whereas, the comparison of effort in terms of time to specify acceptance testing shows that the mean time to specify test scenarios using Gherkin language is lower than Fit tables. © The Author(s) 2018.},
	language = {English},
	journal = {Lecture Notes in Business Information Processing},
	author = {dos Santos, Ernani César and Vilain, Patrícia},
	editor = {A, Aguiar and X, Wang and J, Garbajosa},
	year = {2018},
	note = {ISBN: 978-331991601-9
Publisher: Springer Verlag
Type: Conference paper},
	keywords = {Formal specification, Requirements engineering, Software design, Software requirements, Acceptance testing, Acceptance tests, ATDD, C (programming language), Cucumber, Fit tables, FitNesse, Gherkin language, Software testing, Students},
	pages = {104 -- 119},
	annote = {Cited by: 10; Conference name: 19th International Conference on Agile Software Development, XP 2018; Conference date: 21 May 2018 through 25 May 2018; Conference code: 213699; All Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 10; Conference name: 19th International Conference on Agile Software Development, XP 2018; Conference date: 21 May 2018 through 25 May 2018; Conference code: 213699; All Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE:  LOW
},
}


@inproceedings{atoum_scalable_2019,
	title = {A {Scalable} {Operational} {Framework} for {Requirements} {Validation} {Using} {Semantic} and {Functional} {Models}},
	isbn = {978-1-4503-6642-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063592239&doi=10.1145%2f3305160.3305166&partnerID=40&md5=93b00d04edf5aadaac6c5e63b15c0c44},
	doi = {10.1145/3305160.3305166},
	abstract = {A successful operational software depends on adequacy and degrees of freedom in requirements definitions. The software developer in conjunction with the customer validates requirements to ensure the completion of the intended use and the capability of the target application. Notwithstanding, requirements validation is time-consuming, effortless and expensive, and many times involves error-prone manual activities. The difficulty of the problem increases with an increase in the application size, the application domain, and inherit textual requirements constructs. Current approaches to the problem are considered as passive-defect aggregations, domain- specific, or rather fine-grained with formal specifications. We propose a scalable operational framework to learn, predict, and recognize requirements defects using semantic similarity models and the Integration Functional Definition methods. The proposed framework automates the validation process and increases the productivity of software engineers online with customer needs. A proof of concept shows the applicability of our solution to requirements inconsistency defects. © 2019 Association for Computing Machinery.},
	language = {English},
	booktitle = {{ACM} {International} {Conference} {Proceeding} {Series}},
	publisher = {Association for Computing Machinery},
	author = {Atoum, Issa},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Defects, Requirements engineering, Semantics, Software requirements, Big data, Requirements validation, Application programs, Semantic similarity, Deep learning, Information management, Degrees of freedom (mechanics), Functional model, Iso 29148},
	pages = {1 -- 6},
	annote = {Cited by: 8; Conference name: 2nd International Conference on Software Engineering and Information Management, ICSIM 2019 - and its Workshop 2019 2nd International Conference on Big Data and Smart Computing, ICBDSC 2019; Conference date: 10 January 2019 through 13 January 2019; Conference code: 146327},
	annote = {Cited by: 9; Conference name: 2nd International Conference on Software Engineering and Information Management, ICSIM 2019 - and its Workshop 2019 2nd International Conference on Big Data and Smart Computing, ICBDSC 2019; Conference date: 10 January 2019 through 13 January 2019; Conference code: 146327},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{ozkaya_towards_2018,
	title = {Towards understanding practitioners' knowledge and experiences on the software architecture viewpoints: {A} survey; [{Pratisyenlerin} yazılım mimarisi bakış açıları üzerine bilgi ve tecrübelerini anlamaya yönelik bir anket çalışması]},
	volume = {2291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060192003&partnerID=40&md5=088afb7e7b8e119442fb9fa407ceabf9},
	abstract = {Architecture viewpoints promote separating software architectures into different viewpoints that each address the particular aspect of a software system. This paper discusses a survey conducted among 56 practitioners from 20 different countries who are involved in software development and aims at understanding their knowledge and experience about five important architectural viewpoints - i.e., logical, behaviour, concurrency, physical, and deployment. Some of the interesting survey results are as follows: (i) while the logical, behaviour, physical, and deployment viewpoints are widely used, the concurrency viewpoint is not so; (ii) the top-preferred structural unit for a logical component is the external interfaces and the least-preferred is the internal computation unit. (iii) the top-preferred simple connector type is the asynchronous events; (iv) the complex connectors (e.g., adaptor and arbitrator) are not as popular as simple connectors; (v) boxes and lines diagram and natural languages (e.g., English) are the top-preferred software modelling notations for each viewpoint considered, while architectural languages, and formal specification languages are never used by many; (vi) documenting design decisions and their communication is the main source of motivation for each viewpoint; (vii) the specifications of the interaction behaviours of components are highly desired by practitioners; (viii) mapping between different viewpoints cannot always be achieved due to the inadequate software modelling notations; and (ix) scalability, performance, and security are the top-considered quality properties for the behaviour viewpoint, while scalability and availability are the top-considered ones for the deployment viewpoint. © 2019 CEUR Workshop Proceedings.All Rights Reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Ozkaya, Mert},
	editor = {B, Tekinerdogan and A.H, Dogru},
	year = {2018},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Software design, Specification languages, Modeling languages, Scalability, Software architecture, Surveys, Knowledge and experience, Architectural languages, Architectural viewpoints, Asynchronous event, Practitioners, Quality properties, Software modelling, Surveying},
	pages = {44 -- 58},
	annote = {Cited by: 0; Conference name: 7th Turkish National Software Architecture Conference, UYMK 2018; Conference date: 29 November 2018 through 30 November 2018; Conference code: 143577},
	annote = {Cited by: 0; Conference name: 7th Turkish National Software Architecture Conference, UYMK 2018; Conference date: 29 November 2018 through 30 November 2018; Conference code: 143577},
	annote = {RELEVANCE: NULL - not in english

},
}


@article{zaker_object-z_2018,
	title = {From object-{Z} specification to groovy implementation},
	volume = {25},
	issn = {10263098},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059161562&doi=10.24200%2fsci.2018.20798&partnerID=40&md5=c869531edd3a085b99e371b38a98a82f},
	doi = {10.24200/sci.2018.20798},
	abstract = {So far, valuable research studies have been conducted on mapping notations of object-oriented specification, such as Object-Z, in different object-oriented programming languages, such as C++. However, the results of selecting JVM-based programming languages for mapping have not covered most of basic Object-Z structures. In this paper, the Groovy language, as a dynamic JVM-based language, is selected to overcome some of the existing limitations. As the main contribution, the rules required for mapping Object-Z specifications to execute Groovy code are introduced. The proposed rules cover notions such as multiple inheritance, inverse specification of functions, functions defined on generic definitions, and free-type constructors. Previous methods have not covered these notions for the formal development of program from object-oriented specifications, regardless of the selected formal specification language and target programming language. In addition, in this paper, the parallel composition construct is mapped to a parallel, executable code to improve the faithfulness of the final code to the initial specification. A mapping rule for the class union construct is introduced, which has not yet been provided for any JVMbased language. Unlike previous works, instead of presenting the mapping rules in terms of natural languages, they are presented in terms of some formal mapping rules. © 2018 Sharif University of Technology. All rights reserved.},
	language = {English},
	number = {6D},
	journal = {Scientia Iranica},
	author = {Zaker, F. and Haghighi, H. and Nazemi, E.},
	year = {2018},
	note = {Publisher: Sharif University of Technology
Type: Article},
	keywords = {Formal specification, Mapping, Specification languages, Object oriented programming, C++ (programming language), Codes (symbols), software, computer simulation, Animation, Formal programdevelopment, Groovy, Inverse problems, mapping, Multiple inheritance, Object Z, Object-oriented specifications, Object-Z specification, Parallel composition, research, Target programming language},
	pages = {3415 -- 3441},
	annote = {Cited by: 0; All Open Access, Bronze Open Access},
	annote = {Cited by: 0; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{jilek_inflection-tolerant_2019,
	title = {Inflection-tolerant ontology-based named entity recognition for real-time applications},
	volume = {70},
	isbn = {978-3-95977-105-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068035432&doi=10.4230%2fOASIcs.LDK.2019.11&partnerID=40&md5=536904d913823ac752a0c332623e1805},
	doi = {10.4230/OASIcs.LDK.2019.11},
	abstract = {A growing number of applications users daily interact with have to operate in (near) real-time: chatbots, digital companions, knowledge work support systems – just to name a few. To perform the services desired by the user, these systems have to analyze user activity logs or explicit user input extremely fast. In particular, text content (e.g. in form of text snippets) needs to be processed in an information extraction task. Regarding the aforementioned temporal requirements, this has to be accomplished in just a few milliseconds, which limits the number of methods that can be applied. Practically, only very fast methods remain, which on the other hand deliver worse results than slower but more sophisticated Natural Language Processing (NLP) pipelines. In this paper, we investigate and propose methods for real-time capable Named Entity Recognition (NER). As a first improvement step, we address word variations induced by inflection, for example present in the German language. Our approach is ontology-based and makes use of several language information sources like Wiktionary. We evaluated it using the German Wikipedia (about 9.4B characters), for which the whole NER process took considerably less than an hour. Since precision and recall are higher than with comparably fast methods, we conclude that the quality gap between high speed methods and sophisticated NLP pipelines can be narrowed a bit more without losing real-time capable runtime performance. © Christian Jilek, Markus Schröder, Rudolf Novik, Sven Schwarz, Heiko Maus, and Andreas Dengel.},
	language = {English},
	booktitle = {{OpenAccess} {Series} in {Informatics}},
	publisher = {Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing},
	author = {Jilek, Christian and Schröder, Markus and Novik, Rudolf and Schwarz, Sven and Maus, Heiko and Dengel, Andreas},
	editor = {M, Eskevich and G, de Melo and C, Fath and J.P, McCrae and P, Buitelaar and C, Chiarcos and B, Klimek and M, Dojchinovski},
	year = {2019},
	note = {ISSN: 21906807
Type: Conference paper},
	keywords = {Natural language processing systems, Ontology, Artificial intelligence, NAtural language processing, Information retrieval, Real time systems, Interactive computer systems, Pipelines, Run-time performance, Language informations, Named entity recognition, Number of methods, Ontology-based information extraction, Precision and recall, Real-time application},
	annote = {Cited by: 4; Conference name: 2nd Conference on Language, Data and Knowledge, LDK 2019; Conference date: 20 May 2019 through 23 May 2019; Conference code: 148857},
	annote = {Cited by: 4; Conference name: 2nd Conference on Language, Data and Knowledge, LDK 2019; Conference date: 20 May 2019 through 23 May 2019; Conference code: 148857},
	annote = {RELEVANCE: LOW
},
}


@article{cuer_formal_2018,
	title = {A formal framework for the safe design of the {Autonomous} {Driving} supervision},
	volume = {174},
	issn = {09518320},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041704275&doi=10.1016%2fj.ress.2018.01.014&partnerID=40&md5=8b41980bf2b2692580c20e7c53f4c14b},
	doi = {10.1016/j.ress.2018.01.014},
	abstract = {The autonomous vehicle is meant to drive by itself, without any driver intervention (for the levels 4 and 5 of automated driving, according to the National Highway Traffic Safety Administration(NHTSA)). This car includes a new function, called Autonomous Driving (AD) function, in charge of driving the vehicle when it is authorized. This function may be in different states (basically active or inactive), that shall be managed by a sub-function, named supervision. The main focus of this work is to ensure that the supervision of a function, performed by a safety critical embedded automotive control system (controlled systems are not considered), respects functional and safety requirements. Usually two processes are involved in the system design: the systems engineering process and the safety one. The first process defines the functional requirements on the function while the safety one specifies redundant sub-functions (realizing together the function) allowing to ensure a continuous service under failure. Since two different aspects of the system are specified, it is a major challenge to make all requirements consistent, from the outset of the design process. In this paper, a method is precisely proposed to address this issue. A progressive reinforcement of the treated requirements is achieved by means of formal state models. In fact, the proposed approach permits to build state models from requirements initially expressed in natural language. Potential ambiguities, incompletenesses or undertones in requirements are in this way gradually deleted. The enrichment of conventional formal verification of control properties with safety requirements constitutes the main originality of the deployed method and contributes to solve inconsistencies between functional and safety verification processes. In addition, the application of the method to the design of AD function supervision highlights its efficiency in an industrial context. © 2018 Elsevier Ltd},
	language = {English},
	journal = {Reliability Engineering and System Safety},
	author = {Cuer, Romain and Piétrac, Laurent and Niel, Eric and Diallo, Saidou and Minoiu-Enache, Nicoleta and Dang-Van-Nhan, Christophe},
	year = {2018},
	note = {Publisher: Elsevier Ltd
Type: Article},
	keywords = {Requirements analysis, Systems engineering, Formal verification, Safety engineering, Embedded systems, Safety analysis, Vehicles, Design, Autonomous Vehicles, Design systems, Discrete event dynamic systems, Highway accidents, Redundancy control},
	pages = {29 -- 40},
	annote = {Cited by: 14},
	annote = {Cited by: 14},
	annote = {RELEVANCE: LOW
},
}


@article{naumchev_vercors_2019-1,
	title = {{VERCORS}: {Hardware} and {Software} {Complex} for {Intelligent} {Round}-{Trip} {Formalized} {Verification} of {Dependable} {Cyber}-{Physical} {Systems} in a {Digital} {Twin} {Environment} ({Position} {Paper})},
	volume = {11771 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075682305&doi=10.1007%2f978-3-030-29852-4_30&partnerID=40&md5=ddfd9800bc60ff99a1848056e7a50e0b},
	doi = {10.1007/978-3-030-29852-4_30},
	abstract = {Formal specification, model checking and model-based testing are recommended techniques for engineering of mission-critical systems. In the meantime, those techniques struggle to obtain wide adoption due to inherent learning barrier, i.e. it is considered difficult to use those methods. There is also a common difficulty in translating the specifications in natural language, a common practice nowadays, to formal specifications. In this position paper we discuss the concept of an end-to-end methodology that helps identify specifications from various sources, automatically create formal specifications and apply them to verification of cyber-physical systems. Thus, we intent to address the challenges of creation of formal specifications in an efficient automated and tool-supported manner. The novelty of the approach is analyzed through a survey of state of the art. It is currently planned to implement this concept and evaluate it with industrial case studies. © 2019, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Naumchev, Alexandr and Sadovykh, Andrey and Ivanov, Vladimir},
	editor = {M, Mazzara and B, Meyer and J.-M, Bruel and A, Petrenko},
	year = {2019},
	note = {ISBN: 978-303029851-7
Publisher: Springer
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Model checking, Modeling languages, Verification, Cyber Physical System, Embedded systems, Language processing, Computer simulation languages, Cyber-physical systems (CPS), Traceability, Digital twin, Multi-modelling, Cosimulation, Model based testing, Natural},
	pages = {351 -- 363},
	annote = {Cited by: 4; Conference name: 51st International Conference on Software Technology: Methods and Tools, TOOLS 2019; Conference date: 15 October 2019 through 17 October 2019; Conference code: 233059},
}


@inproceedings{hovorushchenko_intelligent_2019,
	title = {Intelligent system for determining the sufficiency of metric information in the software requirements specifications},
	volume = {2353},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065475950&partnerID=40&md5=83e434de705726bc6396fd7e41e8190c},
	abstract = {The paper is devoted to the developing the intelligent system for determining the sufficiency of metric information in the software requirements specifications (SRS), which provides on the basis of the natural language processing of SRS: conclusion about the sufficiency of metric information (indicators for metrics calculation) in SRS, numerical assessment of the sufficiency level of metric information in the SRS, visualization of missing indicators for metrics calculation. The developed intelligent system provides an increase in the sufficiency of information by 12.71-50.28\% for the SRS of the information and analytical system for the accounting of therapeutic and diagnostic activities provided to the wounded during transportation. In general, the developed system provides an increase in the sufficiency of metric information in the SRS to 100\% - if it's necessary (for critical software) or at the customer's request. The developed intelligent system for determining the sufficiency of metric information in the SRS can be used during the software development for government agencies, military formations and law enforcement agencies, commercial organizations (both for organizationsdevelopers of software and for organizations-customers of software). © 2019 CEUR-WS. All rights reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Hovorushchenko, Tetiana and Pavlova, Olga},
	editor = {Y, Bodyanskiy and K, Henke and V, Lytvynenko and D, Luengo and A, Parkhomenko and E, Zaitseva and N, Shakhovska and H.-D, Wuttke and I, Izonin and S, Subbotin and A, Sharpanskykh and A, Pester and P, Arras and G, Tabunshchyk and V, Levashenko and C, Wolff},
	year = {2019},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Software design, Software metrics, Software requirements specifications, NAtural language processing, Intelligent systems, Software agents, Government agencies, Information and analytical systems, Law-enforcement agencies, Metric information, Military formations},
	pages = {253 -- 266},
	annote = {Cited by: 2; Conference name: 2nd International Workshop on Computer Modeling and Intelligent Systems, CMIS 2019; Conference date: 15 April 2019 through 19 April 2019; Conference code: 147677},
	annote = {Cited by: 2; Conference name: 2nd International Workshop on Computer Modeling and Intelligent Systems, CMIS 2019; Conference date: 15 April 2019 through 19 April 2019; Conference code: 147677},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{f_ceur_2018,
	title = {{CEUR} {Workshop} {Proceedings}},
	volume = {2075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045432027&partnerID=40&md5=065c142a3a91f8b57173f8ad49bb552e},
	abstract = {The proceedings contain 35 papers. The topics discussed include: how to deal with inaccurate service requirements? insights in our current approach and new ideas; requirements quality defect detection with the Qualicen requirements scout; CORDULA: software requirements extraction utilizing Chatbot as communication interface; research on NLP for RE at CNR-ISTI: a report; back to basics: extracting software requirements with a syntactic approach; research on NLP for RE at Fraunhofer FKIE: a report on grouping requirements; which semantics for requirements engineering: from shallow to deep; knowledge representation of requirements documents using natural language processing; is there really a need for using NLP to elicit requirements? a benchmarking study to assess scalability of manual analysis; managing multi-lingual user feedback: the SUPERSEDE project experience; educating for empathy in software engineering course; requirements-driven supervision of socio-technical systems; analysis of requirement problems regarding their causes and effects for projects with the objective to model qualitative PRIS empirical study; towards a systematic approach for designing gamification for RE; the interactive narrator tool: effective requirements exploration and discussion through visualization; and tool support for value modeling and risk analysis of e-services.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	editor = {F, Dalpiaz and X, Franch and M, Kirikova and J, Ralyte and P, Spoletini and Y, Chisik and A, Ferrari and N, Madhavji and C, Palomares and M, Sabetzadeh and D, van der Linden and K, Schmid and E.B, Charrada and P, Sawyer and P, Forbrig and A, Zamansky},
	year = {2018},
	note = {ISSN: 16130073
Type: Conference review},
	annote = {Cited by: 0; Conference name: 24th Joint International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, REFSQ-JP 2018; Conference date: 19 March 2018; Conference code: 135277},
	annote = {Cited by: 0; Conference name: 24th Joint International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, REFSQ-JP 2018; Conference date: 19 March 2018; Conference code: 135277},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{kasenberg_generating_2019,
	title = {Generating justifications for norm-related agent decisions},
	isbn = {978-1-950737-94-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087179257&partnerID=40&md5=c88b0936abcb5c7e7b3c47cc33ed7d7b},
	abstract = {We present an approach to generating natural language justifications of decisions derived from norm-based reasoning. Assuming an agent which maximally satisfies a set of rules specified in an object-oriented temporal logic, the user can ask factual questions (about the agent’s rules, actions, and the extent to which the agent violated the rules) as well as “why” questions that require the agent comparing actual behavior to counterfactual trajectories with respect to these rules. To produce natural-sounding explanations, we focus on the subproblem of producing natural language clauses from statements in a fragment of temporal logic, and then describe how to embed these clauses into explanatory sentences. We use a human judgment evaluation on a testbed task to compare our approach to variants in terms of intelligibility, mental model and perceived trust. ©2019 Association for Computational Linguistics},
	language = {English},
	booktitle = {{INLG} 2019 - 12th {International} {Conference} on {Natural} {Language} {Generation}, {Proceedings} of the {Conference}},
	publisher = {Association for Computational Linguistics (ACL)},
	author = {Kasenberg, Daniel and Roque, Antonio and Thielstrom, Ravenna and Chita-Tegmark, Meia and Scheutz, Matthias},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Temporal logic, Computer circuits, Based reasonings, Human judgments, Mental model, Object oriented, Perceived trusts, Set of rules},
	pages = {484 -- 493},
	annote = {Cited by: 10; Conference name: 12th International Conference on Natural Language Generation, INLG 2019; Conference date: 29 October 2019 through 1 November 2019; Conference code: 160343},
	annote = {Cited by: 11; Conference name: 12th International Conference on Natural Language Generation, INLG 2019; Conference date: 29 October 2019 through 1 November 2019; Conference code: 160343},
	annote = {RELEVANCE: LOW
},
}


@article{ahmed_formal_2018,
	title = {Formal specification languages: {Features}, challenges and future directions},
	volume = {7},
	issn = {2227524X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082343232&partnerID=40&md5=588c722423e9fb02dac3674c2c7000f7},
	abstract = {Natural language is used as a popular way for Software Requirements Specification (SRS) to ensure successful communication between stakeholders. However, natural language suffers from ambiguity which motivated software community to devise Formal Specification Languages (FSLs) to state requirements precisely. Since the advent of FSLs, a heated debate among researchers and practioners was raised to judge on the practical use of FSLs in industry. In this research, a contemporary review is conducted to shed light upon the features, challenges and future directions of FSLs. © 2018 Authors.},
	language = {English},
	number = {4.19 Special Issue 19},
	journal = {International Journal of Engineering and Technology(UAE)},
	author = {Ahmed, Hussin and Hussain, Azham and Baharom, Fauziah},
	year = {2018},
	note = {Publisher: Science Publishing Corporation Inc
Type: Article},
	pages = {164 -- 167},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: LOW
},
}


@article{hurriyetoglu_estimating_2018,
	title = {Estimating time to event of future events based on linguistic cues on twitter},
	volume = {740},
	issn = {1860949X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034852163&doi=10.1007%2f978-3-319-67056-0_5&partnerID=40&md5=e78763e1af6f026d0f10e871d85da395},
	doi = {10.1007/978-3-319-67056-0_5},
	abstract = {Given a stream of Twitter messages about an event, we investigate the predictive power of features generated from words and temporal expressions in the messages to estimate the time to event (TTE). From labeled training data average TTE values of the predictive features are learned, so that when they occur in an event-related tweet the TTE estimate can be provided for that tweet. We utilize temporal logic rules and a historical context integration function to improve the TTE estimation precision. In experiments on football matches and music concerts we show that the estimates of the method are off by 4 and 10 h in terms of mean absolute error on average, respectively. We find that the type and size of the event affect the estimation quality. An out-of-domain test on music concerts shows that models and hyperparameters trained and optimized on football matches can be used to estimate the remaining time to concerts. Moreover, mixing in concert events in training improves the precision of the average football event estimate. © 2018, Springer International Publishing AG.},
	language = {English},
	journal = {Studies in Computational Intelligence},
	author = {Hürriyetoǧlu, Ali and Oostdijk, Nelleke and van den Bosch, Antal},
	year = {2018},
	note = {Publisher: Springer Verlag
Type: Book chapter},
	pages = {67 -- 97},
	annote = {Cited by: 3},
	annote = {Cited by: 3},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{kasenberg_engaging_2019,
	title = {Engaging in dialogue about an agent’s norms and behaviors},
	isbn = {978-1-950737-70-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092006255&partnerID=40&md5=5192806bf2a4632b1e1a08b22f9e7901},
	abstract = {We present a set of capabilities allowing an agent planning with moral and social norms represented in temporal logic to respond to queries about its norms and behaviors in natural language, and for the human user to add and remove norms directly in natural language. The user may also pose hypothetical modifications to the agent’s norms and inquire about their effects. © 2019 Association for Computational Linguistics.},
	language = {English},
	booktitle = {{NL4XAI} 2019 - 1st {Workshop} on {Interactive} {Natural} {Language} {Technology} for {Explainable} {Artificial} {Intelligence}, {Proceedings} of the {Workshop}},
	publisher = {Association for Computational Linguistics (ACL)},
	author = {Kasenberg, Daniel and Roque, Antonio and Thielstrom, Ravenna and Scheutz, Matthias},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Artificial intelligence, Social norm, Human users},
	pages = {26 -- 28},
	annote = {Cited by: 2; Conference name: 1st Workshop on Interactive Natural Language Technology for Explainable Artificial Intelligence, NL4XAI 2019, held as part of the 12th International Conference on Natural Language Generation INLG 2019; Conference date: 29 October 2019; Conference code: 160344},
	annote = {Cited by: 2; Conference name: 1st Workshop on Interactive Natural Language Technology for Explainable Artificial Intelligence, NL4XAI 2019, held as part of the 12th International Conference on Natural Language Generation INLG 2019; Conference date: 29 October 2019; Conference code: 160344},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{r_ceur_2018,
	title = {{CEUR} {Workshop} {Proceedings}},
	volume = {2051},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045835642&partnerID=40&md5=75b0efcef014f82a39edcf5f9e51ad31},
	abstract = {The proceedings contain 6 papers. The topics discussed include: the AThOS project: first steps towards computational accountability; instrumenting accountability in MAS with blockchain; towards the specification of natural language accountability policies with AccLab: the laptop policy use case; requirements for a temporal logic of daily activities for supportive technology; open data for accountability in the fight against corruption; and classifying the autonomy and morality of artificial agents.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	editor = {R, Micalizio and Universita degli Studi di Torino, Dipartimento di Informatica, C.so Svizzera, Torino and C, Baroglio and Universita degli Studi di Torino, Dipartimento di Informatica, C.so Svizzera, Torino and M, Baldoni and Universita degli Studi di Torino, Dipartimento di Informatica, C.so Svizzera 185, Torino},
	year = {2018},
	note = {ISSN: 16130073
Type: Conference review},
	annote = {Cited by: 0; Conference name: 1st Workshop on Computational Accountability and Responsibility in Multiagent Systems, CARe-MAS 2017; Conference date: 31 October 2017; Conference code: 133737},
	annote = {Cited by: 0; Conference name: 1st Workshop on Computational Accountability and Responsibility in Multiagent Systems, CARe-MAS 2017; Conference date: 31 October 2017; Conference code: 133737},
	annote = {RELEVANCE LOW
},
}


@inproceedings{zhai_c2s_2020,
	title = {{C2S}: {Translating} natural language comments to formal program specifications},
	isbn = {978-1-4503-7043-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097166035&doi=10.1145%2f3368089.3409716&partnerID=40&md5=c247b0b8e31798c15801c9734b79dbd4},
	doi = {10.1145/3368089.3409716},
	abstract = {Formal program specifications are essential for various software engineering tasks, such as program verification, program synthesis, code debugging and software testing. However, manually inferring formal program specifications is not only time-consuming but also error-prone. In addition, it requires substantial expertise. Natural language comments contain rich semantics about behaviors of code, making it feasible to infer program specifications from comments. Inspired by this, we develop a tool, named C2S, to automate the specification synthesis task by translating natural language comments into formal program specifications. Our approach firstly constructs alignments between natural language word and specification tokens from existing comments and their corresponding specifications. Then for a given method comment, our approach assembles tokens that are associated with words in the comment from the alignments into specifications guided by specification syntax and the context of the target method. Our tool successfully synthesizes 1,145 specifications for 511 methods of 64 classes in 5 different projects, substantially outperforming the state-of-the-art. The generated specifications are also used to improve a number of software engineering tasks like static taint analysis, which demonstrates the high quality of the specifications. © 2020 ACM.},
	language = {English},
	booktitle = {{ESEC}/{FSE} 2020 - {Proceedings} of the 28th {ACM} {Joint} {Meeting} {European} {Software} {Engineering} {Conference} and {Symposium} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Zhai, Juan and Shi, Yu and Pan, Minxue and Zhou, Guian and Liu, Yongxiang and Fang, Chunrong and Ma, Shiqing and Tan, Lin and Zhang, Xiangyu},
	editor = {P, Devanbu and M, Cohen and T, Zimmermann},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Natural languages, Semantics, Specifications, Software testing, Verification, Program debugging, Translation (languages), High quality, Alignment, State of the art, Code debugging, Formal programs, Program specification, Program synthesis, Program translators, Program Verification},
	pages = {25 -- 37},
	annote = {Cited by: 15; Conference name: 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2020; Conference date: 8 November 2020 through 13 November 2020; Conference code: 164831},
	annote = {Cited by: 17; Conference name: 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2020; Conference date: 8 November 2020 through 13 November 2020; Conference code: 164831},
	annote = {RELEVANCE: MEDIUM
},
}


@article{pi_automated_2019-1,
	title = {Automated {Mining} and {Checking} of {Formal} {Properties} in {Natural} {Language} {Requirements}},
	volume = {11776 LNAI},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077116773&doi=10.1007%2f978-3-030-29563-9_8&partnerID=40&md5=0f073f51cf59b3fbaed8a1dc3eedecec},
	doi = {10.1007/978-3-030-29563-9_8},
	abstract = {Bridging the gap between natural language requirements (NLR) and precise formal specifications is a crucial task of knowledge engineering. Software system development has become more complex in recent years, and it includes many requirements in different domains that users need to understand. Many of these requirements are expressed in natural language, which may be incomplete and ambiguous. However, the formal language with its rigorous semantics may accurately represent certain temporal logic properties and allow for automatic validation analysis. It is difficult for software engineers to understand the formal temporal logic from numerous requirements. In this paper, we propose a novel method to automatically mine the linear temporal logic (LTL) from the natural language requirements and check the consistency among different formal properties. We use natural language processing (NLP) to parse requirement sentences and map syntactic dependencies to LTL formulas by using our extraction rules. Also, we apply the automata-based model checking to assess the correctness and consistency of the extracted properties. Through implementation and case studies, we demonstrate that our approach is well suited to deal with the temporal logic requirements upon which the natural language is based. © 2019, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Pi, Xingxing and Shi, Jianqi and Huang, Yanhong and Wei, Hansheng},
	editor = {C, Douligeris and D, Apostolou and D, Karagiannis},
	year = {2019},
	note = {ISBN: 978-303029562-2
Publisher: Springer
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Semantics, Temporal logic, Natural language requirements, NAtural language processing, Formal languages, Linear temporal logic, Model checking, Computer circuits, Automata-based model, Automatic validation, Syntactic dependencies, Temporal logic properties},
	pages = {75 -- 87},
	annote = {Cited by: 0; Conference name: 12th International Conference on Knowledge Science, Engineering and Management, KSEM 2019; Conference date: 28 August 2019 through 30 August 2019; Conference code: 230379},
}


@inproceedings{deshmukh_anomaly_2019,
	title = {Anomaly detection using temporal logic based learning for terminal airspace operations},
	isbn = {978-1-62410-578-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083943485&doi=10.2514%2f6.2019-0682&partnerID=40&md5=f879fbb38cf7a4d295f794fb6c3ac02a},
	doi = {10.2514/6.2019-0682},
	abstract = {An anomaly is a rare event with a potential for a meaningful operational or safety related risk. To assist air traffic controllers (ATCs) with airspace operation while ensuring high efficiency and safety, it is important to understand aircraft anomalies as observed by ATCs, and to analyze how operational anomalies are monitored. Modern data-mining and time-series data analysis techniques are powerful tools to generate anomaly detection models through machine learning, so that normal and abnormal time-series data can be identified. In this paper, we propose a temporal logic based learning algorithm that can generate data driven models for anomaly detection in the terminal airspace operations, which are easy to be interpreted in natural language and can express system properties such as human-readable bounds on time and physical parameters, thereby facilitating human feedback. The proposed algorithm is demonstrated with real terminal airspace surveillance data, obtained from Airport Surface Detection Equipment-Model X (ASDE-X) and Terminal Automation Information Service (TAIS) datasets. © 2019 by German Aerospace Center (DLR). Published by the American Institute of Aeronautics and Astronautics, Inc.},
	language = {English},
	booktitle = {{AIAA} {Scitech} 2019 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics Inc, AIAA},
	author = {Deshmukh, Raj and Hwang, Inseok},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Natural languages, Data mining, Temporal logic, Computer circuits, Safety engineering, Learning algorithms, Time series, Learning systems, Time series analysis, Information services, Anomaly detection, Aviation, Air traffic control, Air traffic controller, Airport security, Anomaly detection models, Data-driven model, Physical parameters, Terminal airspace, Terminal automation, Time series data analysis},
	annote = {Cited by: 15; Conference name: AIAA Scitech Forum, 2019; Conference date: 7 January 2019 through 11 January 2019; Conference code: 225819},
	annote = {Cited by: 15; Conference name: AIAA Scitech Forum, 2019; Conference date: 7 January 2019 through 11 January 2019; Conference code: 225819},
	annote = {RELEVANCE: LOW
},
}


@article{gervasi_ambiguity_2019,
	title = {Ambiguity in {Requirements} {Engineering}: {Towards} a {Unifying} {Framework}},
	volume = {11865 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073690565&doi=10.1007%2f978-3-030-30985-5_12&partnerID=40&md5=815e14d66c5950d2e94db73481135335},
	doi = {10.1007/978-3-030-30985-5_12},
	abstract = {A long stream of research in RE has been devoted to analyzing the occurrences and consequences of ambiguity in requirements documents. Ambiguity often occurs in documents, most often in natural language (NL) ones, but occasionally also in formal specifications, be it because of abstraction, or of imprecise designation of which real-world entities are denotated by certain expressions. In many of those studies, ambiguity has been considered a defect to be avoided. In this paper, we investigate the nature of ambiguity, and advocate that the simplistic view of ambiguity as merely a defect in the document does not do justice to the complexity of this phenomenon. We offer a more extensive analysis, based on the multiple linguistic sources of ambiguity, and present a list of real-world cases, both in written matter and in oral interviews, that we analyze based on our framework. We hope that a better understanding of the phenomenon can help in the analysis of practical experiences and in the design of more effective methods to detect, mark and handle ambiguity. © 2019, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Gervasi, Vincenzo and Ferrari, Alessio and Zowghi, Didar and Spoletini, Paola},
	year = {2019},
	note = {Publisher: Springer Verlag
Type: Book chapter},
	keywords = {Defects, Natural languages, Artificial intelligence, Requirements document, Computer science, Real-world, Computers, Practical experience, Real-world entities},
	pages = {191 -- 210},
	annote = {Cited by: 11; All Open Access, Green Open Access},
	annote = {Cited by: 12; All Open Access, Green Open Access},
	annote = {RELEVANCE: MEDIUM

},
}


@inproceedings{zaki-ismail_rcm-extractor_2021,
	title = {{RCM}-{Extractor}: {Automated} extraction of a semi formal representation model from natural language requirements},
	isbn = {978-989-758-487-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103016713&partnerID=40&md5=51343518983358f6d7356bee885f811d},
	abstract = {Formal verification requires system requirements to be specified in formal notations. Formalisation of system requirements manually is a time-consuming and error-prone process, and requires engineers to have strong mathematical and domain expertise. Most existing requirements formalisation techniques assume requirements to be specified in pre-defined templates and these techniques employ pre-defined transformation rules to transform requirements specified in the predefined templates to formal notations. These techniques tend to have limited expressiveness and more importantly require system engineers to re-write their system requirements following these templates. In this paper, we introduces an automated extraction technique (RCM-Extractor) to extract the key constructs of a comprehensive and formalisable semi-formal representation model from textual requirements. We have evaluated our RCM-Extractor on a dataset of 162 requirements curated from the literature. RCM-Extractor achieved 95\% precision, 79\% recall, 86\% F-measure and 75\% accuracy. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	language = {English},
	booktitle = {{MODELSWARD} 2021 - {Proceedings} of the 9th {International} {Conference} on {Model}-{Driven} {Engineering} and {Software} {Development}},
	publisher = {SciTePress},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {S, Hammoudi and L.F, Pires and E, Seidewitz and R, Soley},
	year = {2021},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Requirements engineering, Software design, Extraction, Natural language requirements, System requirements, Formal notations, Semi-formal representations, Transformation rules, Automated extraction, Domain expertise, Error-prone process},
	pages = {270 -- 277},
	annote = {Cited by: 6; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 167487},
	annote = {RELEVANCE: LOW old version
},
}


@article{luo_generating_2020,
	title = {Generating {Linear} {Temporal} {Logics} {Based} on {Property} {Specification} {Templates}},
	volume = {850},
	issn = {1860949X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071605507&doi=10.1007%2f978-3-030-26428-4_1&partnerID=40&md5=049deb5fcd11d1578865925e76542ed5},
	doi = {10.1007/978-3-030-26428-4_1},
	abstract = {Temporal logics are widely used in software verification such as model checking. However, creating temporal logics such as linear temporal logics (LTLs) based on property specifications written in a natural language is difficult due to practitioners’ unfamiliarity with property specifications and notations of temporal logics. Although property specification patterns have been introduced to help write correct temporal logics, creating temporal logics using property specification patterns requires an understanding of the pattern system. Since some patterns are difficult to understand, especially for beginners, and the final temporal logics are usually complicated, creating temporal logics using pattern systems is time consuming and error-prone. Here, we introduce a method to create LTLs based on property specification patterns. We experimentally compare the required time and accuracy of our approach to those using property specification patterns. Our approach can improve the creation of LTLs in terms of speed and accuracy. Although our experiment is implemented in Japanese, the results should be applicable to other languages such as English. We also provide a visualization scheme so that practitioners can understand the generated LTLs and confirm that they are correct. © 2020, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Studies in Computational Intelligence},
	author = {Luo, Weibin and Washizaki, Hironori and Fukazawa, Yoshiaki},
	year = {2020},
	note = {Publisher: Springer Verlag
Type: Book chapter},
	pages = {1 -- 15},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{habib_detecting_2021,
	title = {Detecting {Requirements} {Smells} {With} {Deep} {Learning}: {Experiences}, {Challenges} and {Future} {Work}},
	doi = {10.1109/REW53955.2021.00027},
	abstract = {Requirements Engineering (RE) is one of the initial phases when building a software system. The success or failure of a software project is firmly tied to this phase, based on communication among stakeholders using natural language. The problem with natural language is that it can easily lead to different understandings if it is not expressed precisely by the stakeholders involved. This results in building a product which is different from the expected one. Previous work proposed to enhance the quality of the software requirements by detecting language errors based on ISO 29148 requirements language criteria. The existing solutions apply classical Natural Language Processing (NLP) to detect them. NLP has some limitations, such as domain dependability which results in poor generalization capability. Therefore, this work aims to improve the previous work by creating a manually labeled dataset and using ensemble learning, Deep Learning (DL), and techniques such as word embeddings and transfer learning to overcome the generalization problem that is tied with classical NLP and improve precision and recall metrics using a manually labeled dataset. The current findings show that the dataset is unbalanced and which class examples should be added more. It is tempting to train algorithms even if the dataset is not considerably representative. Whence, the results show that models are overfitting; in Machine Learning this issue is adressed by adding more instances to the dataset, improving label quality, removing noise, and reducing the learning algorithms complexity, which is planned for this research.},
	booktitle = {2021 {IEEE} 29th {International} {Requirements} {Engineering} {Conference} {Workshops} ({REW})},
	author = {Habib, Mohammad Kasra and Wagner, Stefan and Graziotin, Daniel},
	month = sep,
	year = {2021},
	pages = {153--156},
	annote = {medium
},
}


@inproceedings{ye_natural_2022,
	title = {A {Natural} {Language} {Instruction} {Disambiguation} {Method} for {Robot} {Grasping}},
	url = {https://doi.org/10.1109/ROBIO54168.2021.9739456},
	doi = {10.1109/ROBIO54168.2021.9739456},
	abstract = {Robot grasping under the instruction of natural language has attracted increasing attention in various applications for its advantages in enabling natural and smooth human-robot interaction. At present, mainstream algorithms mainly solve problems of utilizing simple natural language instructions to guide the robot arm to perform some specific grasping. However, for two natural language instructions with different temporal logic and the same semantics, it is usually difficult for the robot to achieve semantic disambiguation, which further leads to the failure of the grasping task. In order to address this problem, we propose a new natural language instruction disambiguation method for robot grasping by combining sentence vector similarity calculation model and sentence temporal logic model. Firstly, the word vector is obtained through the Skip-gram model in Word2vec and a sentence vector is constructed. The semantic similarity of the sentence is then calculated by using the proposed cost function. Based on the semantic similarity of the sentence, the correct temporal logic form of the sentence is then extracted according to the temporal adverbial priority to further guide the grabbing process of the robot arm. The experimental results show that our method can successfully realize the semantic disambiguation for natural language instructions with different temporal logics and the same semantics, and further guide the robot arm to complete more complicated tasks than previous tasks.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Biomimetics} ({ROBIO})},
	publisher = {IEEE Press},
	author = {Ye, Rongguang and Xu, Qingchuan and Liu, Jie and Hong, Yang and Sun, Chengfeng and Chi, Wenzheng and Sun, Lining},
	year = {2022},
	note = {Place: Sanya, China},
	keywords = {Natural languages, Semantics, Temporal logic, Calculations, Computer circuits, Cost functions, Human robot interaction, Robotics, Disambiguation method, Natural language instruction, Robot arms, Robot grasping, Robotic arms, Semantic disambiguation, Semantic similarity, Sentence vector similarity calculation, Similarity calculation, Vector similarity, Vectors},
	pages = {601--606},
	annote = {Cited by: 1; Conference name: 2021 IEEE International Conference on Robotics and Biomimetics, ROBIO 2021; Conference date: 27 December 2021 through 31 December 2021; Conference code: 178223},
	annote = {Cited by: 1; Conference name: 2021 IEEE International Conference on Robotics and Biomimetics, ROBIO 2021; Conference date: 27 December 2021 through 31 December 2021; Conference code: 178223},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{bugayenko_combining_2021,
	address = {New York, NY, USA},
	series = {{BCNC} 2021},
	title = {Combining {Object}-{Oriented} {Paradigm} and {Controlled} {Natural} {Language} for {Requirements} {Specification}},
	isbn = {978-1-4503-9125-2},
	url = {https://doi.org/10.1145/3486949.3486963},
	doi = {10.1145/3486949.3486963},
	abstract = {Natural language is the dominant form of writing software requirements. Its essential ambiguity causes inconsistency of requirements, which leads to scope creep. On the other hand, formal requirements specification notations such as Z, Petri Nets, SysML, and others are difficult to understand by non-technical project stakeholders. They often become a barrier between developers and requirements providers. The article presents a controlled natural language that looks like English but is a strongly typed object-oriented language compiled to UML/XMI. Thus, it is easily understood, at the same time, by non-technical people, programmers, and computers. Moreover, it is formally verifiable and testable. It was designed, developed, and tested in three commercial software projects in order to validate the assumption that object-oriented design can be applied to requirements engineering at the level of specifications writing. The article outlines key features of the language and summarizes the experience obtained during its practical application.},
	booktitle = {Proceedings of the 1st {ACM} {SIGPLAN} {International} {Workshop} on {Beyond} {Code}: {No} {Code}},
	publisher = {Association for Computing Machinery},
	author = {Bugayenko, Yegor},
	year = {2021},
	note = {event-place: Chicago, IL, USA},
	keywords = {Petri nets, Natural language processing systems, Natural languages, Requirements engineering, Software requirements, Specifications, Software testing, Requirements specifications, Object oriented programming, Requirement, Controlled natural language, Formal requirement specifications, Requirements, Natural Language Processing, Object-oriented languages, Object-oriented paradigm, Project stakeholders, Technical programme},
	pages = {11--17},
	annote = {Cited by: 1; Conference name: 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, BCNC 2021, co-located with SPLASH 2021; Conference date: 17 October 2021; Conference code: 172642},
	annote = {Cited by: 1; Conference name: 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, BCNC 2021, co-located with SPLASH 2021; Conference date: 17 October 2021; Conference code: 172642},
	annote = {Cited by: 1; Conference name: 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, BCNC 2021, co-located with SPLASH 2021; Conference date: 17 October 2021; Conference code: 172642},
	annote = {Cited by: 1; Conference name: 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, BCNC 2021, co-located with SPLASH 2021; Conference date: 17 October 2021; Conference code: 172642},
	annote = {Cited by: 1; Conference name: 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, BCNC 2021, co-located with SPLASH 2021; Conference date: 17 October 2021; Conference code: 172642},
	annote = {event-place: Chicago, IL, USA},
	annote = {event-place: Chicago, IL, USA},
	annote = {event-place: Chicago, IL, USA},
	annote = {RELEVANCE: MEDIUM

Controlled natural language

},
}


@article{stukachev_approximation_2021,
	title = {Approximation spaces of temporal processes and effectiveness of interval semantics},
	volume = {1242 AISC},
	issn = {21945357},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089609964&doi=10.1007%2f978-3-030-53829-3_5&partnerID=40&md5=59809741a1a99f2532bc9359ed020854},
	doi = {10.1007/978-3-030-53829-3_5},
	abstract = {A series of positive results related to the generalized problem of Yu.L. Ershov on the structure of Σ-degrees of dense linear orders is obtained. In particular, we prove that interval models of temporal logic, as well as finite fragments of approximation spaces generated by interval Boolean algebras, are Σ-definable (effectively interpretable) in hereditarily finite superstructures over dense linear orders. These results are used in the analysis of semantics of verbs in natural languages within the approach in formal semantics proposed by R. Montague. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.},
	language = {English},
	journal = {Advances in Intelligent Systems and Computing},
	author = {Stukachev, Alexey},
	editor = {S, Rodríguez González and J, Prieto and A, González-Briones and A, Gola and G, Katranas and M, Ricca and R, Loukanova and R, Loukanova},
	year = {2021},
	note = {ISBN: 978-303053828-6
Publisher: Springer
Type: Conference paper},
	keywords = {Natural languages, Semantics, Formal Semantics, Artificial intelligence, Formal methods, Computation theory, Boolean algebra, Approximation spaces, Interval models, Linear order},
	pages = {53 -- 61},
	annote = {Cited by: 2; Conference name: 17th International Symposium on Distributed Computing and Artificial Intelligence, DCAI 2020; Conference date: 17 June 2020 through 19 June 2020; Conference code: 243089},
	annote = {Cited by: 2; Conference name: 17th International Symposium on Distributed Computing and Artificial Intelligence, DCAI 2020; Conference date: 17 June 2020 through 19 June 2020; Conference code: 243089},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{a_abdelnabi_algorithmic_2021,
	address = {New York, NY, USA},
	series = {{ICEMIS}'21},
	title = {An {Algorithmic} {Approach} for {Generating} {Behavioral} {UML} {Models} {Using} {Natural} {Language} {Processing}},
	isbn = {978-1-4503-9044-6},
	url = {https://doi.org/10.1145/3492547.3492612},
	doi = {10.1145/3492547.3492612},
	abstract = {The process of transformation from informal requirements stated in natural language into a formal specification such as Unified Modeling Language (UML) is an important challenge. User requirements that are expressed in natural language can be very problematic, which makes the requirements analysis a difficult task. In this paper, we propose a method to analyze the natural language requirements and generate sequence and collaboration diagrams from these requirements, which are commonly used to describe the behavior of software systems. A case study was accomplished to compare the diagrams generated by the proposed approach to the diagrams produced by other approaches. The results showed that the elements of the sequence and collaboration diagrams extracted through our approach are very satisfactory and they would be acceptable as initial analysis models.},
	booktitle = {The 7th {International} {Conference} on {Engineering} \&amp; {MIS} 2021},
	publisher = {Association for Computing Machinery},
	author = {A. Abdelnabi, Esra and M. Maatuk, Abdelsalam and M. Abdelaziz, Tawfig},
	year = {2021},
	note = {event-place: Almaty, Kazakhstan},
	keywords = {Natural language processing systems, Natural languages, User requirements, Unified Modeling Language, Requirement analysis, Language model, Algorithmic approach, Algorithmic languages, Collaboration diagram, Graphic methods, Informal requirements, NLP tools, Sequence and Collaboration diagrams, Sequence diagrams, UML diagrams, Unified modeling language diagrams},
	annote = {Cited by: 3; Conference name: 7th International Conference on Engineering and MIS, ICEMIS 2021; Conference date: 11 October 2021 through 13 October 2021; Conference code: 175544},
	annote = {Cited by: 4; Conference name: 7th International Conference on Engineering and MIS, ICEMIS 2021; Conference date: 11 October 2021 through 13 October 2021; Conference code: 175544},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{zhang_automated_2020,
	address = {San Jose, CA, USA},
	series = {{DATE} '20},
	title = {Automated {Generation} of {LTL} {Specifications} for {Smart} {Home} {IoT} {Using} {Natural} {Language}},
	isbn = {978-3-9819263-4-7},
	abstract = {Ordinary users can build their smart home automation system easily nowadays, but such user-customized systems could be error-prone. Using formal verification to prove the correctness of such systems is necessary. However, to conduct formal proof, formal specifications such as Linear Temporal Logic (LTL) formulas have to be provided, but ordinary users cannot author LTL formulas but only natural language.To address this problem, this paper presents a novel approach that can automatically generate formal LTL specifications from natural language requirements based on domain knowledge and our proposed ambiguity refining techniques. Experimental results show that our approach can achieve a high correctness rate of 95.4\% in converting natural language sentences into LTL formulas from 481 requirements of real examples.},
	booktitle = {Proceedings of the 23rd {Conference} on {Design}, {Automation} and {Test} in {Europe}},
	publisher = {EDA Consortium},
	author = {Zhang, Shiyu and Zhai, Juan and Bu, Lei and Chen, Mingsong and Wang, Linzhang and Li, Xuandong},
	year = {2020},
	note = {event-place: Grenoble, France},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Temporal logic, Natural language requirements, Linear temporal logic, Internet of things, Automated generation, Automation, Formal proofs, Correctness rates, Domain knowledge, Real example},
	pages = {622--625},
	annote = {Cited by: 8; Conference name: 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020; Conference date: 9 March 2020 through 13 March 2020; Conference code: 161220},
	annote = {Cited by: 8; Conference name: 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020; Conference date: 9 March 2020 through 13 March 2020; Conference code: 161220},
	annote = {Cited by: 12; Conference name: 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020; Conference date: 9 March 2020 through 13 March 2020; Conference code: 161220},
	annote = {Cited by: 12; Conference name: 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020; Conference date: 9 March 2020 through 13 March 2020; Conference code: 161220},
	annote = {event-place: Grenoble, France},
	annote = {RELEVANCE: HIGH
},
	annote = {Type: Conference paper},
}


@inproceedings{ye_components_2020,
	address = {New York, NY, USA},
	series = {{WSSE} '20},
	title = {Components {Interaction} {Safety} {Analysis} {Method} {Based} on {STAMP} and {Formal} {Verification}},
	isbn = {978-1-4503-8787-3},
	url = {https://doi.org/10.1145/3425329.3425390},
	doi = {10.1145/3425329.3425390},
	abstract = {The traditional safety analysis method is based on the event chain theory, which is not suitable for analyzing the accident caused by components interaction problems of complex system. However, the System Theoretic Accident Model and Process(STAMP) can overcome this difficulty. There are some shortcomings in the current research on STAMP, such as describing the model with natural language and relying on manual analysis. Therefore, this paper proposes a components interaction safety analysis method based on STAMP and formal verification. Taking the aero-engine control system as an example, the root cause of system hazard is obtained and the feasibility of the proposed method is verified.},
	booktitle = {Proceedings of the 2nd {World} {Symposium} on {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Ye, Nan and Zhang, Jianguo and Wu, Jie},
	year = {2020},
	note = {event-place: Chengdu, China},
	keywords = {Natural languages, Formal verification, Aircraft engines, Safety analysis, Accident models, Accidents, Aero-engine, aero-engine control system, Chain theory, Components interaction, Manual analysis, model checking, STAMP, System hazards, system safety analysis},
	pages = {46--50},
	annote = {Cited by: 0; Conference name: 2nd World Symposium on Software Engineering, WSSE 2020; Conference date: 25 September 2020 through 27 September 2020; Conference code: 165162},
	annote = {Cited by: 0; Conference name: 2nd World Symposium on Software Engineering, WSSE 2020; Conference date: 25 September 2020 through 27 September 2020; Conference code: 165162},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{xu_formal_2020,
	title = {Formal software requirement elicitation based on semantic algebra and cognitive computing},
	isbn = {978-1-72819-594-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112866725&doi=10.1109%2fICCICC50026.2020.9450275&partnerID=40&md5=fa9032f4eb9beb62da3d79fe3b2503c2},
	doi = {10.1109/ICCICC50026.2020.9450275},
	abstract = {Autonomous software requirement analysis and generation are a persistent challenge to theories and technologies of software engineering. A cognitive system is demanded to automatically elicit and rigorously refine informal software requirements in natural language descriptions into formal specifications. This paper presents a novel software requirements elicitation methodology based on latest advances in software science and denotational mathematics such as semantic algebra and concept algebra. It is found that user requirements for a software system in natural language may be either expressed in to-be sentences for software structures or to-do sentences for software behaviors. Thus, formal software requirements may be elicited by two sets of structural and functional models. This approach is implemented by a tool for Formal Requirement Elicitation and Analysis (FREA). Experimental results demonstrate that the FREA tool may rigorously elicit and generate formal requirements for arbitrary software systems specified in real-time process algebra (RTPA) or equivalent notations. This technology paves a way towards autonomous code generation in software engineering. ©2020 IEEE},
	language = {English},
	booktitle = {Proceedings of 2020 {IEEE} 19th {International} {Conference} on {Cognitive} {Informatics} and {Cognitive} {Computing}, {ICCI}*{CC} 2020},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Xu, James Y. and Wang, Yingxu},
	editor = {Y, Wang and N, Ge and J, Lu and X, Tao and P, Soda and N, Howard and B, Widrow and J, Feldman},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Requirements engineering, Semantics, Requirement elicitation, Software requirements, Computer software, Algebra, Autonomous software, Cognitive Computing, Cognitive systems, Computation theory, Denotational mathematics, Real time systems, Real-time process algebra, Software behavior, Software structures},
	pages = {187 -- 194},
	annote = {Cited by: 0; Conference name: 19th IEEE International Conference on Cognitive Informatics and Cognitive Computing, ICCI*CC 2020; Conference date: 26 September 2020 through 28 September 2020; Conference code: 170851},
	annote = {Cited by: 0; Conference name: 19th IEEE International Conference on Cognitive Informatics and Cognitive Computing, ICCI*CC 2020; Conference date: 26 September 2020 through 28 September 2020; Conference code: 170851},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{wein_fully_2021,
	title = {A {Fully} {Automated} {Approach} to {Requirement} {Extraction} from {Design} {Documents}},
	volume = {2021-March},
	isbn = {978-1-72817-436-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111403199&doi=10.1109%2fAERO50100.2021.9438170&partnerID=40&md5=28e38fdf40c788256a15d42ee52109d3},
	doi = {10.1109/AERO50100.2021.9438170},
	abstract = {Design documents are intended to outline the goals of a system or project, which are utilized in the creation of specific software requirements. At the NASA Jet Propulsion Laboratory, California Institute of Technology, Functional Design Description (FDD) documents describe the scope of the project and reflect the design and implementation of the system. The specifications in the document are not explicitly written as requirements, though these guidelines must be reflected in the official software requirements. In this work we present a fully automatic approach to extracting software requirements from design documents as well as comparing the extracted requirements to those that exist in the official software requirement database. We do this through (1) sentence extraction from the design document, (2) the incorporation of coreferent text, and (3) aligning the extracted text to the official software requirements. Via natural language processing and information retrieval techniques, our system results in an automated process that ensures that the specifications in the design document result in official software requirements. We find that extraction of imperatives results in a recall rate of 0.73 and the TF-IDF cosine similarity metric is shown to be a useful and successful way to compare requirements. Though there has been recent work investigating the usefulness of natural language processing techniques in requirement engineering, this has not been made use of in the aerospace industry. Aerospace requirement engineering is a field particularly ripe for this type of innovation because these techniques can both automate some of needlessly manual work and contribute to aerospace safety practices by identifying issues that a human may miss. We present the first fully automated approach that extracts requirements from a design document and compares them to a database, and use these findings as encouragement for future work that makes use of natural language processing techniques in aerospace requirement engineering. © 2021 IEEE.},
	language = {English},
	booktitle = {{IEEE} {Aerospace} {Conference} {Proceedings}},
	publisher = {IEEE Computer Society},
	author = {Wein, Shira and Briggs, Paul},
	year = {2021},
	note = {ISSN: 1095323X
Type: Conference paper},
	keywords = {Natural language processing systems, Requirements engineering, Extraction, NAtural language processing, Software requirements, Specifications, Automation, Requirement engineering, Aerospace engineering, Aerospace industry, Automatic approaches, California Institute of Technology, Cosine similarity metric, Design and implementations, NASA, Search engines, Sentence extraction},
	annote = {Cited by: 3; Conference name: 2021 IEEE Aerospace Conference, AERO 2021; Conference date: 6 March 2021 through 13 March 2021; Conference code: 170491},
	annote = {Cited by: 4; Conference name: 2021 IEEE Aerospace Conference, AERO 2021; Conference date: 6 March 2021 through 13 March 2021; Conference code: 170491},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{pogodin_use_2021-1,
	title = {The {Use} of {Model}-{Theoretical} {Methods} for {Automated} {Knowledge} {Extraction} from {Medical} {Texts}},
	volume = {2021-June},
	isbn = {978-1-66541-498-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113540901&doi=10.1109%2fEDM52169.2021.9507606&partnerID=40&md5=8ffa62f464302049483ed4aaa229d535},
	doi = {10.1109/EDM52169.2021.9507606},
	abstract = {The paper is devoted to the application of model-theoretical methods for extraction of knowledge from medical texts and documents and its formal representation. The aim of the work is to automate the filling of knowledge bases of the IACPaaS platform using knowledge from texts of disease descriptions. IACPaaS is a cloud platform for the development, management and remote use of intelligent cloud services. The peculiarities of disease description texts are the presence of medical word terms (such as 'blood pressure') and the abundance of sentences with clauses and homogeneous sentence members. To solve the problem of knowledge extraction, methods of transforming natural language sentences into quantifier-free formulas of the first-order predicate logic are used. Knowledge extracted from texts is formalized in the form of sets of atomic sentences that form fragments of atomic diagrams of algebraic systems. Further, a knowledge tree is built from the fragments of atomic diagrams, which serves as an intermediate representation of knowledge for subsequent translation into the format of IACPaaS information resources. The software system allows medical workers to fill knowledge bases with descriptions of diseases in shorter time, and gives the opportunity to check the consistency of the obtained formal specifications automatically. © 2021 IEEE.},
	language = {English},
	booktitle = {International {Conference} of {Young} {Specialists} on {Micro}/{Nanotechnologies} and {Electron} {Devices}, {EDM}},
	publisher = {IEEE Computer Society},
	author = {Pogodin, Ruslan S. and Palchunov, Dmitry},
	year = {2021},
	note = {ISSN: 23254173
Type: Conference paper},
	keywords = {Natural languages, Data mining, Extraction, Software systems, Formal representations, Intermediate representations, Algebraic system, Atoms, Blood pressure, Electron devices, Information resource, Knowledge extraction, Theoretical methods},
	pages = {555 -- 560},
	annote = {Cited by: 0; Conference name: 22nd IEEE International Conference of Young Professionals in Electron Devices and Materials, EDM 2021; Conference date: 30 June 2021 through 4 July 2021; Conference code: 171291},
}


@inproceedings{paudel_context-aware_2021,
	title = {Context-{Aware} {IoT} {Device} {Functionality} {Extraction} from {Specifications} for {Ensuring} {Consumer} {Security}},
	isbn = {978-1-66544-496-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125622500&doi=10.1109%2fCNS53000.2021.9705050&partnerID=40&md5=1b3c2f21c4685e159b0668fc2fb51908},
	doi = {10.1109/CNS53000.2021.9705050},
	abstract = {Internet of Thing (IoT) devices are being widely used in smart homes and organizations. An IoT device has some intended purposes, but may also have hidden functionalities. Typically, the device is installed in a home or an organization and the network traffic associated with the device is captured and analyzed to infer high-level functionality to the extent possible. However, such analysis is dynamic in nature, and requires the installation of the device and access to network data which is often hard to get for privacy and confidentiality reasons. We propose an alternative static approach which can infer the functionality of a device from vendor materials using Natural Language Processing (NLP) techniques. Information about IoT device functionality can be used in various applications, one of which is ensuring security in a smart home. We demonstrate how security policies associated with device functionality in a smart home can be formally represented using the NIST Next Generation Access Control (NGAC) model and automatically analyzed using Alloy, which is a formal verification tool. This will provide assurance to the consumer that these devices will be compliant to the home or organizational policy even before they have been purchased. © 2021 IEEE.},
	language = {English},
	booktitle = {2021 {IEEE} {Conference} on {Communications} and {Network} {Security}, {CNS} 2021},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Paudel, Upakar and Dolan, Andy and Majumdar, Suryadipta and Ray, Indrakshi},
	year = {2021},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Internet of things, Automation, Access control, Consumer security, Context-Aware, Device functionality, Intelligent buildings, Language processing techniques, Network data, Network traffic, Next-generation access, Security policy, Smart homes, Static approach},
	pages = {155 -- 163},
	annote = {Cited by: 3; Conference name: 2021 IEEE Conference on Communications and Network Security, CNS 2021; Conference date: 4 October 2021 through 6 October 2021; Conference code: 177213},
	annote = {Cited by: 3; Conference name: 2021 IEEE Conference on Communications and Network Security, CNS 2021; Conference date: 4 October 2021 through 6 October 2021; Conference code: 177213},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{osama_enhancing_2021,
	title = {Enhancing {NL} {Requirements} {Formalisation} {Using} a {Quality} {Checking} {Model}},
	isbn = {978-1-66542-856-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123199170&doi=10.1109%2fRE51729.2021.00064&partnerID=40&md5=fb7e14a8d605ba964f0167d995428138},
	doi = {10.1109/RE51729.2021.00064},
	abstract = {The formalisation of natural language (NL) requirements is a challenging problem because NL is inherently vague and imprecise. Existing formalisation approaches only support requirements adhering to specific boilerplates or templates, and are affected by the requirements quality issues. Several quality models are developed to assess the quality of NL requirements. However, they do not focus on the quality issues affecting the formalisability of requirements. Such issues can greatly compromise the operation of complex systems and even lead to catastrophic consequences or loss of life (in case of critical systems). In this paper, we propose a requirements quality checking approach utilising natural language processing (NLP) analysis. The approach assesses the quality of the requirements against a quality model that we developed to enhance the formalisability of NL requirements. We evaluate the effectiveness of our approach by comparing the formalisation efficiency of a recent automatic formalisation technique before and after utilising our approach. The results show an increase of approximately 15\% in the F-measure (from 83.8\% to 98\%). © 2021 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Requirements} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Osama, Mohamed and Zaki-Ismail, Aya and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {A, Moreira and K, Schneider and M, Vierhauser and J, Cleland-Huang},
	year = {2021},
	note = {ISSN: 1090705X
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Quality control, Requirements engineering, Natural language requirements, Requirements formalizations, Requirements specifications, Formalisation, Quality analyse, Quality issues, Quality modeling, Requirement analysis, Support requirements},
	pages = {448 -- 449},
	annote = {Cited by: 1; Conference name: 29th IEEE International Requirements Engineering Conference, RE 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 174516},
	annote = {Cited by: 1; Conference name: 29th IEEE International Requirements Engineering Conference, RE 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 174516},
	annote = {RELEVANCE: MEDIUM

},
}


@inproceedings{mishra_survey_2021,
	title = {A {Survey} on {Formal} {Specification} of {Security} {Requirements}},
	isbn = {978-1-66543-811-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126935073&doi=10.1109%2fICAC3N53548.2021.9725779&partnerID=40&md5=27397a787675136ecb401bfb3d15d085},
	doi = {10.1109/ICAC3N53548.2021.9725779},
	abstract = {Formalization of security requirements ensures the correctness of any safety-critical system, software system, and web applications through specification and verification. Although there is a gap between security requirements expressed in natural language and formal language. Formal language is a more powerful tool based on higher-order mathematics to express unambiguous and concise security requirements.it remains an active research challenge to express precise, concrete, and correct security requirements. Identification of security requirements is also a challenging task because requirement inherent in the software changes frequently. Specification through formal methods is possible only after fixing the security requirements. In this study, we propose a formal specification software process model (FSSPM). The proposed model indicates the use of formal specification at the early phase of software development is cost-effective, time saving, and reduces the possibility of error at the later phase of software development. © 2021 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2021 3rd {International} {Conference} on {Advances} in {Computing}, {Communication} {Control} and {Networking}, {ICAC3N} 2021},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Mishra, Aditya Dev and Mustafa, Khurram},
	editor = {V, Sharma and R, Srivastava and M, Singh},
	year = {2021},
	note = {Type: Conference paper},
	keywords = {Formal specification, Software design, Formal languages, Formal verification, Cryptography, Security requirements, Safety engineering, Formalisation, Software-systems, Security properties, Application programs, Cost effectiveness, Safety critical systems, Specification and verification, System applications, System softwares, WEB application, Web applications},
	pages = {1453 -- 1456},
	annote = {Cited by: 0; Conference name: 3rd International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2021; Conference date: 17 December 2021 through 18 December 2021; Conference code: 177627},
	annote = {Cited by: 2; Conference name: 3rd International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2021; Conference date: 17 December 2021 through 18 December 2021; Conference code: 177627},
	annote = {RELEVANCE: MEDIUM check
},
}


@inproceedings{lano_automated_2021,
	title = {Automated {Requirements} {Formalisation} for {Agile} {MDE}},
	isbn = {978-1-66542-484-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124017516&doi=10.1109%2fMODELS-C53483.2021.00030&partnerID=40&md5=bcdcf680a1ed1d48fa0655c2496c7546},
	doi = {10.1109/MODELS-C53483.2021.00030},
	abstract = {Model-driven engineering (MDE) of software systems from precise specifications has become established as an important approach for rigorous software development. However, the use of MDE requires specialised skills and tools, which has limited its adoption.In this paper we describe techniques for automating the derivation of software specifications from requirements statements, in order to reduce the effort required in creating MDE specifications, and hence to improve the usability and agility of MDE. Natural language processing (NLP) and Machine learning (ML) are used to recognise the required data and behaviour elements of systems from textual and graphical documents, and formal specification models of the systems are created. These specifications can then be used as the basis of manual software development, or as the starting point for automated software production using MDE. © 2021 IEEE.},
	language = {English},
	booktitle = {Companion {Proceedings} - 24th {International} {Conference} on {Model}-{Driven} {Engineering} {Languages} and {Systems}, {MODELS}-{C} 2021},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Lano, Kevin and Yassipour-Tehrani, Sobhan and Umar, M.A.},
	year = {2021},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Software design, Requirements formalizations, Specification models, Agile development, Agile manufacturing systems, Agile models, Behavior elements, Data elements, Engineering specification, Learning algorithms, Model-driven Engineering, Software Specification, Software-systems},
	pages = {173 -- 180},
	annote = {Cited by: 0; Conference name: 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021; Conference date: 10 October 2021 through 15 October 2021; Conference code: 175737},
	annote = {Cited by: 3; Conference name: 24th International Conference on Model-Driven Engineering Languages and Systems, MODELS-C 2021; Conference date: 10 October 2021 through 15 October 2021; Conference code: 175737},
	annote = {RELEVANCE: high
},
}


@inproceedings{koscinski_natural_2021,
	title = {A {Natural} {Language} {Processing} {Technique} for {Formalization} of {Systems} {Requirement} {Specifications}},
	volume = {2021-September},
	isbn = {978-1-66541-898-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118422069&doi=10.1109%2fREW53955.2021.00062&partnerID=40&md5=279e4d6dd34f6250d402fd03fc69ac44},
	doi = {10.1109/REW53955.2021.00062},
	abstract = {Natural language processing techniques have proven to be useful for analysis of technical specifications documents. One such technique, information extraction (IE), can help automate the analysis of software systems requirement specifications (SysRS) by extracting structured information from unstructured or semi-structured natural language data, allowing for requirements to be converted into formal logic. Current IE techniques are not designed for SysRS data, and often do not extract the information needed for requirements formalization. In this work, we introduce an IE method specifically designed for SysRS data. We provide a description of our approach, analysis of the technique on a set of real requirements, example of how information obtained using our technique can be converted into a formal logic representation, and discussion of our technique and its benefits in automated SysRS analysis tasks. © 2021 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Requirements} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Koscinski, Viktoria and Gambardella, Celeste and Gerstner, Estey and Zappavigna, Mark and Cassetti, Jennifer and Mirakhorli, Mehdi},
	editor = {T, Yue and M, Mirakhorli},
	year = {2021},
	note = {ISSN: 1090705X
Type: Conference paper},
	keywords = {Natural language processing systems, Requirements engineering, Data mining, Artificial intelligence, Information retrieval, Computer circuits, Requirements formalizations, Semi-structured, Language processing techniques, Formalisation, Requirement analysis, Software-systems, Formal logic, Specifications document, Structured information, System requirements specifications, Technical specifications},
	pages = {350 -- 356},
	annote = {Cited by: 5; Conference name: 29th IEEE International Requirements Engineering Conference Workshops, REW 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 173221},
	annote = {Cited by: 5; Conference name: 29th IEEE International Requirements Engineering Conference Workshops, REW 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 173221},
	annote = {RELEVANCE: MEDIUM
},
}


@article{gilpin_smooth_2021,
	title = {A {Smooth} {Robustness} {Measure} of {Signal} {Temporal} {Logic} for {Symbolic} {Control}},
	volume = {5},
	issn = {24751456},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087456350&doi=10.1109%2fLCSYS.2020.3001875&partnerID=40&md5=4016d48448485291745678f0e3412d0e},
	doi = {10.1109/LCSYS.2020.3001875},
	abstract = {Recent years have seen an increasing use of Signal Temporal Logic (STL) as a formal specification language for symbolic control, due to its expressiveness and closeness to natural language. Furthermore, STL specifications can be encoded as cost functions using STL's robust semantics, transforming the synthesis problem into an optimization problem. Unfortunately, these cost functions are non-smooth and non-convex, and exact solutions using mixed-integer programming do not scale well. Recent work has focused on using smooth approximations of robustness, which enable faster gradient-based methods to find local maxima, at the expense of soundness and/or completeness. We propose a novel robustness approximation that is smooth everywhere, sound, and asymptotically complete. Our approach combines the benefits of existing approximations, while enabling an explicit tradeoff between conservativeness and completeness. © 2017 IEEE.},
	language = {English},
	number = {1},
	journal = {IEEE Control Systems Letters},
	author = {Gilpin, Yann and Kurtz, Vince and Lin, Hai},
	year = {2021},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.
Type: Article},
	keywords = {Formal specification, Natural languages, Semantics, Temporal logic, Specification languages, Computer circuits, Cost functions, Gradient-based method, Integer programming, Mixed integer programming, Optimization problems, Robustness (control systems), Robustness measures, Smooth approximation, Symbolic controls, Synthesis problems},
	pages = {241 -- 246},
	annote = {Cited by: 25; All Open Access, Bronze Open Access, Green Open Access},
	annote = {Cited by: 36; All Open Access, Bronze Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{germiniani_informal_2021,
	title = {From {Informal} {Specifications} to an {ABV} {Framework} for {Industrial} {Firmware} {Verification}},
	volume = {621},
	issn = {18684238},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112716925&doi=10.1007%2f978-3-030-81641-4_9&partnerID=40&md5=ee9eabe0c615fd3e045261439c8ef026},
	doi = {10.1007/978-3-030-81641-4_9},
	abstract = {Firmware verification for small and medium industries is a challenging task; as a matter of fact, they generally do not have personnel dedicated to such activity. In this context, verification is executed very late in the design flow, and it is usually carried on by the same engineers involved in coding and testing. The specifications initially discussed with the customers are generally not formalised, leading to ambiguity in the expected functionalities. The adoption of a more formal design flow would require the recruitment of people with expertise in formal and semi-formal verification, which is not often compatible with the budget resources of small and medium industries. The alternative is helping the existing engineers with tools and methodologies they can easily adopt without being experts in formal methods. The paper follows this direction by presenting MIST, a framework for the automatic generation of an assertion-based verification environment and its integrated execution inside an off-the-shelf industrial design tool. In particular, MIST allows generating a complete environment to verify C/C++ firmware starting from informal specifications. Given a set of specifications written in natural language, the tool guides the user in translating each specification into an XML formal description, capturing a temporal behaviour that must hold in the design. Our XML format guarantees the same expressiveness of linear temporal logic, but it is designed to be used by designers that are not familiar with formal methods. Once each behaviour is formalised, MIST automatically generates the corresponding testbench and checker to stimulate and verify the design. To guide the verification process, MIST employs a clustering procedure that classifies the internal states of the firmware. Such classification aims at finding an effective ordering to check the expected behaviours and to advise for possible specification holes. MIST has been fully integrated into the IAR System EmbeddedWorkbench. Its effectiveness and efficiency have been evaluated to formalise and check a complex test plan for industrial firmware. © 2021, IFIP International Federation for Information Processing.},
	language = {English},
	journal = {IFIP Advances in Information and Communication Technology},
	author = {Germiniani, Samuele and Bragaglio, Moreno and Pravadelli, Graziano},
	editor = {A, Calimera and P, Gaillardon and K, Korgaonkar and S, Kvatinsky and R, Reis},
	year = {2021},
	note = {ISBN: 978-303081640-7
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Product design, Formal specification, Linear temporal logic, Formal verification, XML, C++ (programming language), Clustering procedure, Effectiveness and efficiencies, Firmware, Formal Description, Verification process, VLSI circuits, Automatic Generation, Budget control, Assertion-based verification, Semi-formal verifications},
	pages = {179 -- 204},
	annote = {Cited by: 0; Conference name: 28th IFIP WG 10.5/IEEE International Conference on Very Large Scale Integration, VLSI-SoC 2020; Conference date: 6 October 2020 through 9 October 2020; Conference code: 262759},
	annote = {Cited by: 0; Conference name: 28th IFIP WG 10.5/IEEE International Conference on Very Large Scale Integration, VLSI-SoC 2020; Conference date: 6 October 2020 through 9 October 2020; Conference code: 262759; All Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{frattini_automatic_2021,
	address = {New York, NY, USA},
	series = {{ASE} '20},
	title = {Automatic {Extraction} of {Cause}-{Effect}-{Relations} from {Requirements} {Artifacts}},
	isbn = {978-1-4503-6768-4},
	url = {https://doi.org/10.1145/3324884.3416549},
	doi = {10.1145/3324884.3416549},
	abstract = {Background: The detection and extraction of causality from natural language sentences have shown great potential in various fields of application. The field of requirements engineering is eligible for multiple reasons: (1) requirements artifacts are primarily written in natural language, (2) causal sentences convey essential context about the subject of requirements, and (3) extracted and formalized causality relations are usable for a (semi-)automatic translation into further artifacts, such as test cases.Objective: We aim at understanding the value of interactive causality extraction based on syntactic criteria for the context of requirements engineering.Method: We developed a prototype of a system for automatic causality extraction and evaluate it by applying it to a set of publicly available requirements artifacts, determining whether the automatic extraction reduces the manual effort of requirements formalization.Result: During the evaluation we analyzed 4457 natural language sentences from 18 requirements documents, 558 of which were causal (12.52\%). The best evaluation of a requirements document provided an automatic extraction of 48.57\% cause-effect graphs on average, which demonstrates the feasibility of the approach.Limitation: The feasibility of the approach has been proven in theory but lacks exploration of being scaled up for practical use. Evaluating the applicability of the automatic causality extraction for a requirements engineer is left for future research.Conclusion: A syntactic approach for causality extraction is viable for the context of requirements engineering and can aid a pipeline towards an automatic generation of further artifacts from requirements artifacts.},
	booktitle = {Proceedings of the 35th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Frattini, Julian and Junker, Maximilian and Unterkalmsteiner, Michael and Mendez, Daniel},
	year = {2021},
	note = {event-place: Virtual Event, Australia},
	keywords = {natural language processing, Requirements engineering, Extraction, Requirements formalizations, Automatic extraction, Automatic translation, Syntactics, Software engineering, Automatic Generation, causality extraction, Interactive causality, pattern matching, requirements artifacts, Requirements document, Syntactic approach, Syntactic criteria},
	pages = {561--572},
	annote = {Cited by: 5; Conference name: 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020; Conference date: 22 September 2020 through 25 September 2020; Conference code: 166082; All Open Access, Green Open Access},
	annote = {Cited by: 5; Conference name: 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020; Conference date: 22 September 2020 through 25 September 2020; Conference code: 166082; All Open Access, Green Open Access},
	annote = {Cited by: 5; Conference name: 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020; Conference date: 22 September 2020 through 25 September 2020; Conference code: 166082; All Open Access, Green Open Access},
	annote = {Cited by: 5; Conference name: 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020; Conference date: 22 September 2020 through 25 September 2020; Conference code: 166082; All Open Access, Green Open Access},
	annote = {Cited by: 5; Conference name: 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020; Conference date: 22 September 2020 through 25 September 2020; Conference code: 166082; All Open Access, Green Open Access},
	annote = {event-place: Virtual Event, Australia},
	annote = {event-place: Virtual Event, Australia},
	annote = {event-place: Virtual Event, Australia},
	annote = {RELEVANCE: LOW

Focus in causality

},
}


@article{costescu_building_2020-1,
	title = {Building on a {Traffic} {Code} {Violating} {Monitor} for {Autonomous} {Vehicles}: {Trio} {Overtaking} {Model}},
	volume = {Part F1380},
	issn = {25233440},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171570344&doi=10.1007%2f978-3-030-38666-5_44&partnerID=40&md5=41e33c46ccdbf096a221f51c12e666b4},
	doi = {10.1007/978-3-030-38666-5_44},
	abstract = {The present study aims at filling the gap between the existing traffic regulation and the technical specification for construction or behavior in operation of autonomous vehicles. The former is provided in generic and often complicated texts as the lawyers tend to cover with a single formulation all possible cases, including those not yet identified. On the contrary, for the latter, the engineers need to identify any possible situation in advance and produce precise instructions to assess, approach and deal with it, to be embedded in the safety and security logic of the self-driving vehicle. The author builds on his previous work regarding the formalization of traffic code from the natural language to computer language, in a three steps methodology including Legal, Logic and Engineering Analyses. The previous development on Logic Analysis was extended with the multi-level hierarchy of predicates and their interpretation for Perform-Overtaking phase and with their associated Linear Temporal Logic (LTL) Formulas. This codification prepared the ground for the Engineering Analysis where the Trio Overtaking Model (TOM) was developed, considering the influence of the forerunner car over the dynamics of Overtaking (Autonomous) and of overtaken vehicle. As a premiere for three vehicle case, 25 combined scenarios were defined as matrix and for their analysis, the formal definitions, theorems, Collision Matrix and the Safe Distance Matrix were introduced. Applications for runtime checking and monitoring, synchronous (runtime enforcement) and asynchronous (e.g. black box analyze) within a Traffic Code Violating Monitor, were proposed. © 2020, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Intelligent Transportation and Infrastructure},
	author = {Costescu, Dan M.},
	year = {2020},
	note = {Publisher: Springer Nature
Type: Book chapter},
	pages = {415 -- 426},
	annote = {Cited by: 0},
}


@article{carlan_fastensafe_2020,
	title = {{FASTEN}.{Safe}: {A} {Model}-{Driven} {Engineering} {Tool} to {Experiment} with {Checkable} {Assurance} {Cases}},
	volume = {12234 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090096108&doi=10.1007%2f978-3-030-54549-9_20&partnerID=40&md5=c3e76fd8225edeb55ea8096f64ca4301},
	doi = {10.1007/978-3-030-54549-9_20},
	abstract = {The Goal Structuring Notation (GSN) is popular among safety engineers for modeling assurance cases. GSN elements are specified using plain natural language text, this giving safety engineers great flexibility to express their arguments. However, pure textual arguments introduce ambiguities and prevent automation. Currently, assurance cases are verified by manual reviews, which are error prone, time consuming, and not adequate for today’s systems complexity and agile development methodologies. In this paper we present our research tool FASTEN.Safe, which extends GSN with a set of higher-level modeling language constructs capturing recurring argumentation patterns and integrating formal system models. This allows automatically checking 1) the intrinsic consistency of assurance models, 2) the consistency of arguments with system models and 3) the verification of safety claims themselves by using external verification tools. FASTEN.Safe is open source and allows experimenting with language abstractions to bridge the world of GSN-based arguments that are common among safety engineers and the world of formal methods that enable automation. Last but not least, we report on the preliminary experience gained with FASTEN.Safe. © 2020, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Cârlan, Carmen and Ratiu, Daniel},
	editor = {A, Casimiro and P, Ferreira and F, Ortmeier and F, Bitsch},
	year = {2020},
	note = {ISBN: 978-303054548-2
Publisher: Springer
Type: Conference paper},
	keywords = {Natural language text, Verification tools, Modeling languages, Formal verification, Safety engineering, Model-driven Engineering, Agile development methodologies, Engineers, Formal system models, Goal structuring notation, Language constructs, Research tools},
	pages = {298 -- 306},
	annote = {Cited by: 3; Conference name: 39th International Conference on Computer Safety, Reliability and Security, SAFECOMP 2020; Conference date: 16 September 2020 through 18 September 2020; Conference code: 243989},
	annote = {Cited by: 4; Conference name: 39th International Conference on Computer Safety, Reliability and Security, SAFECOMP 2020; Conference date: 16 September 2020 through 18 September 2020; Conference code: 243989},
	annote = {RELEVANCE LOW
},
}


@inproceedings{anwer_formal_2020,
	title = {A formal model for behavior trees based on context - {Free} grammar},
	volume = {2020-December},
	isbn = {978-1-72819-553-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102362391&doi=10.1109%2fAPSEC51365.2020.00057&partnerID=40&md5=7946f1d87e09fdc6e1f08d34994ba49e},
	doi = {10.1109/APSEC51365.2020.00057},
	abstract = {In the last two decades, several studies have been carried out to translate Behavior Trees (BTs) into other formal languages. However, as BTs are usually drawn directly from natural languages, there is no formal grammar to define what is a valid BT. In this research, we first propose a normal form for requirement BT as a building block for a valid BT, and then design a context-free grammar that can generate and verify all valid BTs. This work provides a solid foundation for BT research and will improve the quality of requirements modeling by identifying some common requirement defects. © 2020 IEEE.},
	language = {English},
	booktitle = {Proceedings - {Asia}-{Pacific} {Software} {Engineering} {Conference}, {APSEC}},
	publisher = {IEEE Computer Society},
	author = {Anwer, Sajid and Wen, Lian and Wang, Zhe},
	year = {2020},
	note = {ISSN: 15301362
Type: Conference paper},
	keywords = {Natural languages, Formal languages, Behavior trees, Building blockes, Context free grammars, Engineering research, Forestry, Formal grammars, Formal model, Normal form, Requirements Models, Software engineering},
	pages = {465 -- 469},
	annote = {Cited by: 0; Conference name: 27th Asia-Pacific Software Engineering Conference, APSEC 2020; Conference date: 1 December 2020 through 4 December 2020; Conference code: 167624},
	annote = {Cited by: 0; Conference name: 27th Asia-Pacific Software Engineering Conference, APSEC 2020; Conference date: 1 December 2020 through 4 December 2020; Conference code: 167624},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{trakhtenbrot_approach_2019,
	title = {An approach to validation of combined natural language and formal requirements for control systems},
	isbn = {978-1-72815-165-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078019988&doi=10.1109%2fREW.2019.00025&partnerID=40&md5=999f0266012e9da0e731864cee90c46e},
	doi = {10.1109/REW.2019.00025},
	abstract = {The paper presents a novel approach to validation of behavioral requirements for control systems. A requirement is specified by a natural language pattern and its expression in Linear Temporal Logic (LTL). This way flexibility and understandability of natural language is combined with advantages of formalization that is a basis for various stages of system development, testing and verification. Still, validity of the requirements remains a major challenge. The paper considers application of mutation analysis for capturing of correct behavioral requirements. Generation and exploration of mutants supports a better understanding of requirements, The novelty of the approach is that the suggested mutations are semantic-based, as opposed to the more common syntax-based mutation analysis. A significant advantage of the approach is that it allows to focus only on plausible potential faults in understanding of the required system behavior, and to avoid generation of a vast amount of mutants that are irrelevant to the intended meaning of the requirements. Moreover, in many cases the effect of semantic-based mutations just can not be achieved by usual syntax-based mutations of LTL formulas associated with requirements. The approach is illustrated using a rail cross control example. © 2019 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2019 {IEEE} 27th {International} {Requirements} {Engineering} {Conference} {Workshops}, {REW} 2019},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Trakhtenbrot, Mark},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Natural languages, Requirements engineering, Semantics, Temporal logic, Linear temporal logic, Software testing, Syntactics, Control system analysis, Control systems, Mutation analysis, Natural language patterns, Potential faults, Requirements validation, System development, Understandability},
	pages = {110 -- 115},
	annote = {Cited by: 0; Conference name: 27th IEEE International Requirements Engineering Conference Workshops, REW 2019; Conference date: 23 September 2019 through 27 September 2019; Conference code: 156154},
	annote = {Cited by: 0; Conference name: 27th IEEE International Requirements Engineering Conference Workshops, REW 2019; Conference date: 23 September 2019 through 27 September 2019; Conference code: 156154},
	annote = {RELEVANCE: MEDIUM
},
}


@article{torres_decoder_2019,
	title = {{DECODER} - {DEveloper} {COmpanion} for {Documented} and {annotatEd} code {Reference}},
	volume = {11915 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076554165&doi=10.1007%2f978-3-030-35333-9_44&partnerID=40&md5=e1f4c2322b7511b1201600f05f73cd53},
	doi = {10.1007/978-3-030-35333-9_44},
	abstract = {Software is everywhere and the productivity of Software Engineers has increased radically with the advent of new specifications, design and programming paradigms and languages. The main objective of the DECODER project is to introduce radical solutions to increase productivity by increasing the abstraction level, at specification stage, using requirements engineering techniques to integrate more complete specifications into the development process, and formal methods to reduce the time and efforts for integration testing. DECODER project will develop a methodology and tools to improve the productivity of the software development process for medium-criticality applications in the domains of IoT, Cloud Computing, and Operating Systems by combining Natural Language Processing techniques, modelling techniques and Formal Methods. A radical improvement is expected from the management and transformation of informal data into material (herein called “knowledge”) that can be assimilated by any party involved in a development process. The project expects an average benefit of 20\% in terms of efforts on several use cases belonging to the beforehand mentioned domains and will provide recommendations on how to generalize the approach to other medium-critical domains. © Springer Nature Switzerland AG 2019.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Torres, Victoria and Gil, Miriam and Pelechano, Vicente},
	editor = {X, Franch and T, Männistö and S, Martínez-Fernández},
	year = {2019},
	note = {ISBN: 978-303035332-2
Publisher: Springer
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Software design, NAtural language processing, Requirements analysis, Software development process, Modeling languages, Computer programming languages, Metadata, Software engineering, Application programs, Productivity, Open systems, Decoding, Process engineering, Computer operating systems, Open source software, Modelling techniques, Development process, Integration testing, Programming paradigms, Requirements engineering techniques, Specification stage},
	pages = {596 -- 601},
	annote = {Cited by: 0; Conference name: 20th International Conference on Product-Focused Software Process Improvement, PROFES 2019; Conference date: 27 November 2019 through 29 November 2019; Conference code: 234099; All Open Access, Green Open Access},
	annote = {Cited by: 0; Conference name: 20th International Conference on Product-Focused Software Process Improvement, PROFES 2019; Conference date: 27 November 2019 through 29 November 2019; Conference code: 234099; All Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{zinovia_stefanidiasterios_leonidismargherita_antona_multi-stage_2019,
	title = {A {Multi}-stage {Approach} to {Facilitate} {Interaction} with {Intelligent} {Environments} via {Natural} {Language}},
	url = {{http://link.springer.com/chapter/10.1007/978-3-030-30712-7_9}},
	doi = {10.1007/978-3-030-30712-7_9},
	journal = {HCI International 2019 – Late Breaking Posters},
	author = {{Zinovia StefanidiAsterios LeonidisMargherita Antona}},
	year = {2019},
	keywords = {Natural language processing systems, NAtural language processing, Internet of things, Chatbot, Intelligent agents, Human computer interaction, Conversational agents, Home automation, Intelligent environment, Intelligent home},
	annote = {Cited by: 3; Conference name: 21st International Conference on Human Computer Interaction, HCII 2019; Conference date: 26 July 2019 through 31 July 2019; Conference code: 232579},
	annote = {Cited by: 3; Conference name: 21st International Conference on Human Computer Interaction, HCII 2019; Conference date: 26 July 2019 through 31 July 2019; Conference code: 232579},
	annote = {RELEVANCE: MEDUM
},
}


@article{moitra_automating_2019,
	title = {Automating {Requirements} {Analysis} and {Test} {Case} {Generation}},
	volume = {24},
	issn = {0947-3602},
	url = {https://doi.org/10.1007/s00766-019-00316-x},
	doi = {10.1007/s00766-019-00316-x},
	abstract = {Writing clear and unambiguous requirements that are conflict-free and complete is no easy task. Incorrect requirements lead to errors being introduced early in the design process. The longer the gap between error introduction and error discovery, the higher the cost associated with the error. To address the growing cost of system development, we introduce a tool called Analysis of Semantic Specifications and Efficient generation of Requirements-based Tests (ASSERT™) for capturing requirements, backed by a formal requirements analysis engine. ASSERT also automatically generates a complete set of requirements-based test cases. The requirements are captured in a structured natural language that is both human- and machine-readable. Formal analysis of these requirements with an automated theorem prover identifies errors as soon as requirements are written. It also addresses the historical problem that analysis engines are hard to use and understand for someone without formal methods expertise and analysis results are often difficult for the end-user to understand and make actionable. ASSERT's major contribution is to bring powerful requirements capture and analysis capability to the domain of the end-user. We provide explainable and automated formal analysis, something we found important for a tool's adoptability in industry. Automating test case generation in ASSERT also provides clear and measurable productivity gains in system development.},
	number = {3},
	journal = {Requir. Eng.},
	author = {Moitra, Abha and Siu, Kit and Crapo, Andrew W. and Durling, Michael and Li, Meng and Manolios, Panagiotis and Meiners, Michael and Mcmillan, Craig},
	month = sep,
	year = {2019},
	note = {Place: Berlin, Heidelberg
Publisher: Springer-Verlag},
	keywords = {Testing, Requirements engineering, Semantics, Ontology, Formal methods, Requirements analysis, Requirements formalizations, Automation, Engines, Analysis capabilities, Automated formal analysis, Automated requirements-based test generation, Automated theorem prover, Cost benefit analysis, Errors, Formal analysis, Formal analysis of requirements, Productivity, Requirements formalization, Semantic specification, Test generations},
	pages = {341--364},
	annote = {Cited by: 11},
	annote = {Cited by: 11},
	annote = {Cited by: 11},
	annote = {Cited by: 11},
	annote = {Cited by: 13},
	annote = {Place: Berlin, Heidelberg Publisher: Springer-Verlag},
	annote = {Place: Berlin, Heidelberg Publisher: Springer-Verlag},
	annote = {Place: Berlin, Heidelberg Publisher: Springer-Verlag},
	annote = {RELEVANCE: HIGH

Until 2018, NLP techniques were barely used: Transformation techniques Fig. 8
},
}


@inproceedings{liu_lightweight_2019,
	title = {A lightweight framework for regular expression verification},
	volume = {2019-January},
	isbn = {978-1-5386-8540-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064004332&doi=10.1109%2fHASE.2019.00011&partnerID=40&md5=6081a94c1eda3f1e600f84bb0de57bb8},
	doi = {10.1109/HASE.2019.00011},
	abstract = {Regular expressions and finite state automata have been widely used in programs for pattern searching and string matching. Unfortunately, despite the popularity, regular expressions are difficult to understand and verify even for experienced programmers. Conventional testing techniques remain a challenge as large regular expressions are constantly used for security purposes such as input validation and network intrusion detection. In this paper, we present a lightweight verification framework for regular expressions. In this framework, instead of a large number of test cases, it takes in requirements in natural language descriptions to automatically synthesize formal specifications. By checking the equivalence between the synthesized specifications and target regular expressions, errors will be detected and counterexamples will be reported. We have built a web application prototype and demonstrated its usability with two case studies. ©2019 IEEE.},
	language = {English},
	booktitle = {Proceedings of {IEEE} {International} {Symposium} on {High} {Assurance} {Systems} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Liu, Xiao and Jiang, Yufei and Wu, Dinghao},
	editor = {V, Nguyen and C, Jiang and D, Yu},
	year = {2019},
	note = {ISSN: 15302059
Type: Conference paper},
	keywords = {Testing, Natural language processing systems, Formal specification, Natural languages, Conventional testing, Domain specific languages, Input validation, Intrusion detection, Lightweight frameworks, Network intrusion detection, Network security, Pattern matching, Problem oriented languages, Regular expressions, Systems engineering, Verification, Verification framework},
	pages = {1 -- 8},
	annote = {Cited by: 4; Conference name: 19th IEEE International Symposium on High Assurance Systems Engineering, HASE 2019; Conference date: 3 January 2019 through 5 January 2019; Conference code: 146546},
	annote = {Cited by: 6; Conference name: 19th IEEE International Symposium on High Assurance Systems Engineering, HASE 2019; Conference date: 3 January 2019 through 5 January 2019; Conference code: 146546},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{kulik_compliance_2019,
	title = {Compliance verification of a cyber security standard for {Cloud}-connected {SCADA}},
	isbn = {978-1-72812-171-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073889676&doi=10.1109%2fGIOTS.2019.8766363&partnerID=40&md5=0183f9b380ac59af71e723474f921cca},
	doi = {10.1109/GIOTS.2019.8766363},
	abstract = {Advances in IoT and cloud computing are revolutionizing the architecture of industrial control systems by changing them from isolated architectures to decentralized ones. This leads to increased complexity that exposes these systems to cyber threats from both the cloud and the control environment. Different cyber security standards have been proposed for securing these systems based on a set of security requirements. However, these requirements are often specified in natural language, which makes formal verification of security properties against the standards challenging. In this paper we propose a framework for modeling cloud-connected SCADA systems and formally verify their compliance with the IEC-62443-3-3 standard. We model the system and the security requirements from the standards using the formal modeling language TLA+ in order to formally verify compliance with the standard using the TLC model checker. The applicability of our technique is demonstrated using an industrial case study. © 2019 IEEE.},
	language = {English},
	booktitle = {Global {IoT} {Summit}, {GIoTS} 2019 - {Proceedings}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Kulik, Tomas and Tran-Jorgensen, Peter W. V. and Boudjadar, Jalil},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Distributed computer systems, Regulatory compliance, Model checking, Modeling languages, Compliance control, Formal verification, Clouds, Compliance verification, Control environment, Cryptography, Cyber security, Formal modeling language, Formal Verification of Security, Industrial case study, Industrial control systems, Internet of things, SCADA systems, Security requirements},
	annote = {Cited by: 3; Conference name: 3rd Global IoT Summit, GIoTS 2019; Conference date: 17 June 2019 through 21 June 2019; Conference code: 149876},
	annote = {Cited by: 5; Conference name: 3rd Global IoT Summit, GIoTS 2019; Conference date: 17 June 2019 through 21 June 2019; Conference code: 149876},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{kibret_category_2019,
	title = {Category theoretic based formalization of the verifiable design process},
	isbn = {978-1-5386-8396-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073152659&doi=10.1109%2fSYSCON.2019.8836804&partnerID=40&md5=d697fed6765af8ca59972686b3128910},
	doi = {10.1109/SYSCON.2019.8836804},
	abstract = {The verifiable design process (VDP) is a systems engineering methodology that integrates formal methods and model based systems engineering to achieve a correct-by-construction system. Formal methods are used in the design process to verify correct behavior of system as specified in the requirements. In order to aid development and analysis, the verifiable design process is organized in abstraction layers. The layers are represented using models that include requirements in natural language form, requirements in ontological form, specifications in logic form together with a proof process and interconnected models and their simulations. The models are intelligently coupled with each other to enable the formal verification and model-based validation of a system. In this work, we will show how to formalize the verifiable design process using category theory. We first show how to represent the different representations (models) of VDP as a category. Suitable categorical structures are employed to analyze them. Furthermore, we define each abstraction layer as a category (category of categories) with the models forming the objects and the relations among them forming the morphisms (functors). We then use pushout structure to represent the objects and their relations to provide analysis of the design process. The functors defined will formalize the relations between the different forms of representations. © 2019 IEEE.},
	language = {English},
	booktitle = {{SysCon} 2019 - 13th {Annual} {IEEE} {International} {Systems} {Conference}, {Proceedings}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Kibret, Nadew and Edmonson, William and Gebreyohannes, Solomon},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Formal methods, Systems engineering, Abstracting, Algebra, Categorical structure, Correct-by-construction, Engineering methodology, Forms of representation, Interconnected models, Model-based systems engineering, Model-based validation, Structural design, Verifiable designs},
	annote = {Cited by: 7; Conference name: 13th Annual IEEE International Systems Conference, SysCon 2019; Conference date: 8 April 2019 through 11 April 2019; Conference code: 151993},
	annote = {Cited by: 7; Conference name: 13th Annual IEEE International Systems Conference, SysCon 2019; Conference date: 8 April 2019 through 11 April 2019; Conference code: 151993},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{janpitak_information_2019,
	title = {Information security requirement extraction from regulatory documents using {GATE}/{ANNIC}},
	isbn = {978-1-72810-729-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077960723&doi=10.1109%2fiEECON45304.2019.8938899&partnerID=40&md5=4aa23ad714e5626c1b441451cc21dcb9},
	doi = {10.1109/iEECON45304.2019.8938899},
	abstract = {Compliance is a concept of acting in accordance with established laws, regulations, etc. In order to judge that an organization is following the given rules or not, a compliance auditing is required. A compliance checking is an important activity of compliance auditing which require the extraction of compliance requirement from legal documents. There have been a more and more research challenges to automate the extraction of compliance requirements from the legal documents. This is because most legal documents are embodied in natural language which cannot be understood by the traditional computer system. Though a regulatory document comprises thousands of words, not every word is required in the automation of compliance checking requirement. Extracting only the essential content from the regulatory document can help to shorten the process of compliance requirement retrieving. This paper presents a methodology to extract the compliance requirements in term of goals (subject, object, target, action) which is the essential contents from the legal or regulatory documents by using GATE. GATE is a widely used tool for language engineering to support the machine to process the information extraction (IE) for queries and reasoning. Most researchers proposed to use the readymade application named ANNIE in GATE to extract the essential statements from any target documents. In our proposed method, we add the ANNIC which is a plug-in tool in GATE to help in searching for annotations, visualizing them and inspecting features. Using ANNIC can extract more detail from the ANNIE outcomes which is still in form of unstructured text into structured data such as table. © 2019 IEEE.},
	language = {English},
	booktitle = {{iEECON} 2019 - 7th {International} {Electrical} {Engineering} {Congress}, {Proceedings}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Janpitak, Nanta and Sathitwiriyawong, Chanboon and Pipatthanaudomdee, Phatwarat},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Regulatory compliance, ANNIC, ANNIE, Authentication, Compliance checking, Compliance control, GATE, Information retrieval, ISO27002, Legal documents},
	annote = {Cited by: 4; Conference name: 7th International Electrical Engineering Congress, iEECON 2019; Conference date: 6 March 2019 through 8 March 2019; Conference code: 156205},
	annote = {Cited by: 5; Conference name: 7th International Electrical Engineering Congress, iEECON 2019; Conference date: 6 March 2019 through 8 March 2019; Conference code: 156205},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{halim_detecting_2019,
	title = {Detecting {Non}-{Atomic} {Requirements} in {Software} {Requirements} {Specifications} {Using} {Classification} {Methods}},
	isbn = {978-1-72811-472-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074430720&doi=10.1109%2fICORIS.2019.8874888&partnerID=40&md5=5d3ccb263f56bd39d2b3d525f6bb6d79},
	doi = {10.1109/ICORIS.2019.8874888},
	abstract = {Requirements engineering is the most important stage in software engineering, one of which is to carry out specifications on requirements. Errors that occur at this stage will have a very bad impact on the next stages. A mistake that often occurs is a misunderstanding between stakeholders regarding the document specifications, and this is due to different backgrounds or fields of science. In addition, errors can also occur when making specification documents, for example, there are still non-atomic requirements in the document. Non-atomic requirements are a statement of requirements in which there is not only one element/function of the system. This research was conducted to develop a model that can detect non-atomic requirements in the software specification requirements written in natural languages. The initial stage of this research was to make a list of expert annotations (corpus) containing statements of atomic and non-atomic requirements. This Corpus later used as training data and test data in this study. Based on the corpus created, feature extraction and keyword generation carried out. The best model built in this research was produced by the classification method that used the Bayes Net algorithm. The result of the classification model was evaluated against human annotator using Cohen Kappa. The reliability of the model is considered fair for non-balance data in detecting non-atomic requirements in the software requirements specification. The reliability of the model is considered moderate for balance data in detecting non-atomic requirements. © 2019 IEEE.},
	language = {English},
	booktitle = {2019 1st {International} {Conference} on {Cybernetics} and {Intelligent} {System}, {ICORIS} 2019},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Halim, Fahrizal and Siahaan, Daniel},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Software requirements specifications, Software reliability, Atoms, Software Specification, Classification (of information), Classification methods, Classification models, Expert annotations, Intelligent systems, non-atomic requirements, Text classification, Text processing},
	pages = {269 -- 273},
	annote = {Cited by: 6; Conference name: 1st International Conference on Cybernetics and Intelligent System, ICORIS 2019; Conference date: 22 August 2019 through 23 August 2019; Conference code: 152983},
	annote = {Cited by: 8; Conference name: 1st International Conference on Cybernetics and Intelligent System, ICORIS 2019; Conference date: 22 August 2019 through 23 August 2019; Conference code: 152983},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{shen_evaluate_2018,
	title = {Evaluate concurrent state machine of {SysML} model with {Petri} net},
	isbn = {978-1-5386-3757-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050161688&doi=10.1109%2fICIEA.2018.8398057&partnerID=40&md5=aa8c20c879d7cd9a986448bb6a20ea4f},
	doi = {10.1109/ICIEA.2018.8398057},
	abstract = {Systems Modeling Language (SysML) is the extension and development of Unified Modeling Language (UML) in the field of system engineering. It is gradually applied to the architecture analysis and design of complex hardware and software systems. SysML provides a visual modeling approach in the field of systems engineering that enables a clear explanation of the system's design. However, SysML uses a semi-formal description method [1], which uses natural language to describe the constraints and detailed semantics of systems. This leads to the fact that SysML itself lacks the accurate semantics and it is difficult to conduct rigorous semantic analysis and model quality verification directly. This paper provides a method that transforms SysML state machine into Petri net in propose of overcoming the difficulty of analysis and verification under the dynamic behavior of the state machine. This method also can avoid the formal verification of SysML directly. © 2018 IEEE.},
	language = {English},
	booktitle = {Proceedings of the 13th {IEEE} {Conference} on {Industrial} {Electronics} and {Applications}, {ICIEA} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Shen, Jieshi and Liu, Lei and Hu, Xiaoguang and Zhang, Guofeng and Xiao, Jin},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Petri nets, Quality control, Semantics, Systems engineering, Formal verification, Analysis and verifications, Architecture analysis, Equations of state, Formal description methods, Industrial electronics, Petri, State equations, State machine, SysML, Systems modeling languages, Unified Modeling Language},
	pages = {2106 -- 2111},
	annote = {Cited by: 2; Conference name: 13th IEEE Conference on Industrial Electronics and Applications, ICIEA 2018; Conference date: 31 May 2018 through 2 June 2018; Conference code: 137520},
	annote = {Cited by: 2; Conference name: 13th IEEE Conference on Industrial Electronics and Applications, ICIEA 2018; Conference date: 31 May 2018 through 2 June 2018; Conference code: 137520},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{nuzzo_chase_2018,
	title = {{CHASE}: {Contract}-based requirement engineering for cyber-physical system design},
	volume = {2018-January},
	isbn = {978-3-9819263-1-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048747121&doi=10.23919%2fDATE.2018.8342122&partnerID=40&md5=ec4fdce1752d7253749d735f4218bcc2},
	doi = {10.23919/DATE.2018.8342122},
	abstract = {This paper presents CHASE, a framework for requirement capture, formalization, and validation for cyber-physical systems. CHASE combines a practical front-end formal specification language based on patterns with a rigorous verification back-end based on assume-guarantee contracts. The front-end language can express temporal properties of networks using a declarative style, and supports automatic translation from natural-language constructs to low-level mathematical languages. The verification back-end leverages the mathematical formalism of contracts to reason about system requirements and determine inconsistencies and dependencies between them. CHASE features a modular and extensible software infrastructure that can support different domain-specific languages, modeling formalisms, and analysis tools. We illustrate its effectiveness on industrial design examples, including control of aircraft power distribution networks and arbitration of a mixed-criticality automotive bus. © 2018 EDAA.},
	language = {English},
	booktitle = {Proceedings of the 2018 {Design}, {Automation} and {Test} in {Europe} {Conference} and {Exhibition}, {DATE} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Nuzzo, Pierluigi and Lora, Michele and Feldman, Yishai A. and Sangiovanni-Vincentelli, Alberto L.},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Product design, Model checking, Specification languages, Modeling languages, Problem oriented languages, Automatic translation, Cyber Physical System, Embedded systems, Fighter aircraft, Mathematical formalism, Mathematical languages, Mixed criticalities, Modeling formalisms, Requirement engineering, Software infrastructure, System requirements, XML},
	pages = {839 -- 844},
	annote = {Cited by: 23; Conference name: 2018 Design, Automation and Test in Europe Conference and Exhibition, DATE 2018; Conference date: 19 March 2018 through 23 March 2018; Conference code: 136090},
	annote = {Cited by: 26; Conference name: 2018 Design, Automation and Test in Europe Conference and Exhibition, DATE 2018; Conference date: 19 March 2018 through 23 March 2018; Conference code: 136090},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{le_formalization_2018,
	title = {Formalization and verification of autosar os standard's memory protection},
	volume = {2018-January},
	isbn = {978-1-5386-7305-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062351894&doi=10.1109%2fTASE.2018.00017&partnerID=40&md5=388099855b7543a2710c4238ea43403a},
	doi = {10.1109/TASE.2018.00017},
	abstract = {AUTOSAR OS is a standard for automotive operating systems, which provides a specification that consists of functionalities such as scheduling services, timing services, and memory protection. In this paper, we focus on memory protection features among them. As the AUTOSAR OS specification is described in natural language, its ambiguity may confuse developers as well as cause the contradiction of the specification, then eventually lead to serious problems of automotive systems such as bugs and errors. These problems in automotive systems relate directly to the safety of human being. Thus, it is very important to ensure the unambiguity and consistency of the specification. Our solution for the problems is formalizing the AUTOSAR OS specification using Event-B specification language which allows us to formally specify the functionalities of AUTOSAR OS and reduce the ambiguity of natural language. We developed a formal specification of the memory protection of AUTOSAR OS and verified its consistency. In this verification, we found the inconsistency of the specification during discharging proof obligations generated by RODIN which is a tool for Event-B. This inconsistency comes from the ambiguity of the original specification, and finding it by reviewing based on natural language description is very hard. In this paper, we explain how we found the inconsistency existed in the AUTOSAR OS standard after showing our approach to formalize and verify it with Event-B. © 2018 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2018 12th {International} {Symposium} on {Theoretical} {Aspects} of {Software} {Engineering}, {TASE} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Le, Khanh Trinh and Chibay, Yuki and Aoki, Toshiaki},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Formal specification, Natural languages, Specification languages, Verification, Automotive Systems, AutoSAR, Formalization, Human being, Memory protection, Program debugging, Proof obligations, Scheduling service},
	pages = {68 -- 75},
	annote = {Cited by: 4; Conference name: 12th International Symposium on Theoretical Aspects of Software Engineering, TASE 2018; Conference date: 29 August 2018 through 31 August 2018; Conference code: 143497},
	annote = {Cited by: 4; Conference name: 12th International Symposium on Theoretical Aspects of Software Engineering, TASE 2018; Conference date: 29 August 2018 through 31 August 2018; Conference code: 143497},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{kuchta_extracting_2018,
	title = {Extracting concepts from the software requirements specification using natural language processing},
	isbn = {978-1-5386-5023-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052743136&doi=10.1109%2fHSI.2018.8431221&partnerID=40&md5=c7b57a276a06432546717a2a4855422e},
	doi = {10.1109/HSI.2018.8431221},
	abstract = {Extracting concepts from the software requirements is one of the first step on the way to automating the software development process. This task is difficult due to the ambiguity of the natural language used to express the requirements specification. The methods used so far consist mainly of statistical analysis of words and matching expressions with a specific ontology of the domain in which the planned software will be applicable. This article proposes a method and a tool to extract concepts based on a grammatical analysis of requirements written in English without the need to refer to specialized ontology. These concepts can be further expressed in the class model, which then can be the basis for the object-oriented analysis of the problem. This method uses natural language processing (NLP) techniques to recognize parts of speech and to divide sentences into phrases and also the WordNet dictionary to search for known concepts and recognize relationships between them. © 2018 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2018 11th {International} {Conference} on {Human} {System} {Interaction}, {HSI} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Kuchta, Jaroslaw and Padhiyar, Priti},
	editor = {M, Kaczmarek and A, Bujnowski and J, Ruminski},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Software design, Software requirements specifications, Ontology, Software development process, Software requirement specification, Requirements specifications, Requirement engineering, Domain ontologies, Object oriented programming, Object-oriented analysis, Syntactics, Wordnet},
	pages = {443 -- 448},
	annote = {Cited by: 1; Conference name: 2018 11th International Conference on Human System Interaction, HSI 2018; Conference date: 4 July 2018 through 6 July 2018; Conference code: 138573},
	annote = {Cited by: 1; Conference name: 2018 11th International Conference on Human System Interaction, HSI 2018; Conference date: 4 July 2018 through 6 July 2018; Conference code: 138573},
	annote = {RELEVANCE: LOW
},
}


@article{fornari_checking_2018,
	title = {Checking business process correctness in apromore},
	volume = {317},
	issn = {18651348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048614124&doi=10.1007%2f978-3-319-92901-9_11&partnerID=40&md5=037f64e25407dd00694dc448d526c3e0},
	doi = {10.1007/978-3-319-92901-9_11},
	abstract = {In this paper we present the integration of BProVe - Business Process Verifier - into the Apromore open-source process analytics platform. Given a BPMN model BProVe enables the verification of properties such as soundness and safeness. Differently from established techniques for BPMN verification, that rely on the availability of a mapping into a transition based formalism (e.g. Petri Nets), BProVe takes advantage of a direct formalisation of the BPMN semantics in terms of Structural Operational Semantics rules. On the one side, this still permits to give precise meaning to BPMN models, otherwise impossible due to the usage of natural language in the BPMN standard specification. On the other side, it permits to overcome some issues related to the mapping of BPMN to other formal languages equipped with their own semantics (e.g. non local effects of BPMN elements such as termination). The defined BPMN semantics has been implemented in MAUDE. Through the MAUDE Linear Temporal Logic (LTL) model checker, correctness properties encoded in LTL formulae are evaluated and the result is then presented to the user. The integration into Apromore allows model designers to use the Apromore BPMN editor to design models and to interact with BProVe to verify properties of the designed model. The results are shown graphically on top of the process model, so as to highlight behavioural paths that violate the correctness properties. Designers can then easily identify the violation and repair the model accordingly. © Springer International Publishing AG, part of Springer Nature 2018.},
	language = {English},
	journal = {Lecture Notes in Business Information Processing},
	author = {Fornari, Fabrizio and La Rosa, Marcello and Polini, Andrea and Re, Barbara and Tiezzi, Francesco},
	editor = {J, Mendling and H, Mouratidis},
	year = {2018},
	note = {ISBN: 978-331992900-2
Publisher: Springer Verlag
Type: Conference paper},
	keywords = {Business Process, Petri nets, Natural languages, Semantics, Temporal logic, Big data, Correctness properties, Formal languages, Information systems, Information use, Linear temporal logic, Mapping, Model checking, Non-local effect, Process Modeling, Standard specifications, Structural operational semantics},
	pages = {114 -- 123},
	annote = {Cited by: 1; Conference name: CAiSE Forum 2018 held as part of the 30th International Conference on Advanced Information Systems Engineering, CAiSE 2018; Conference date: 11 June 2018 through 15 June 2018; Conference code: 214159},
	annote = {Cited by: 1; Conference name: CAiSE Forum 2018 held as part of the 30th International Conference on Advanced Information Systems Engineering, CAiSE 2018; Conference date: 11 June 2018 through 15 June 2018; Conference code: 214159},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{kasenberg_inferring_2018,
	title = {Inferring and {Obeying} {Norms} in {Temporal} {Logic}},
	isbn = {978-1-4503-5615-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045283466&doi=10.1145%2f3173386.3176914&partnerID=40&md5=426c04ec8b53dc4cee2f1e1305607b11},
	doi = {10.1145/3173386.3176914},
	abstract = {Robots and other artificial agents are increasingly being considered in domains involving complex decision-making and interaction with humans. These agents must adhere to human moral social norms: agents that fail to do so will be at best unpopular, and at worst dangerous. Artificial agents should have the ability to learn (both from natural language instruction and from observing other agents? behavior) and obey multiple, potentially conflicting norms. © 2018 Author.},
	language = {English},
	booktitle = {{ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {IEEE Computer Society},
	author = {Kasenberg, Daniel},
	year = {2018},
	note = {ISSN: 21672148
Type: Conference paper},
	keywords = {Decision making, Natural languages, Temporal logic, Behavioral research, Markov processes, Computer circuits, Markov Decision Processes, Artificial agents, Complex decision, Human robot interaction, Man machine systems, markov decision processes, moral and social norms, Social norm, temporal logic},
	pages = {301 -- 302},
	annote = {Cited by: 0; Conference name: 13th Annual ACM/IEEE International Conference on Human Robot Interaction, HRI 2018; Conference date: 5 March 2018 through 8 March 2018; Conference code: 135192},
	annote = {Cited by: 0; Conference name: 13th Annual ACM/IEEE International Conference on Human Robot Interaction, HRI 2018; Conference date: 5 March 2018 through 8 March 2018; Conference code: 135192},
	annote = {RELEVANCE: NULL - only extended abstract


},
}


@inproceedings{shweta_automatic_2018,
	title = {Automatic {Extraction} of {Structural} {Model} from {Semi} {Structured} {Software} {Requirement} {Specification}},
	isbn = {978-1-5386-5892-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055694820&doi=10.1109%2fICIS.2018.8466406&partnerID=40&md5=4f106d93f6eb6949c90f91b1c6453314},
	doi = {10.1109/ICIS.2018.8466406},
	abstract = {The software requirement specifications are usually documented either in unstructured, semi structured or structured format. The requirements specified in unstructured format are written in simple continuous paragraph and the structured format specifies requirements by means of diagrams. The semi-structured format represents requirements with the help of some keywords. Literature suggests that the rule based work has been the common choice for unstructured format of documenting. However, these rule based works do not yield satisfactory results for semi-structured format. Consequently, these rules need to re-framed in order to apply them for the semi-structured formatted documents. In this paper, we present an improvement on the existing rules considering the keywords present in the text. The technique involves automatic extraction of the class diagrams using NLP tools and techniques. Along with existing rules, the newly formulated rules have been tested for different case studies and suitable metrics have been devised to evaluate the obtained results. Results show that the automatically generated class diagram have 82\% average precision value and 94\% average recall value when compared to the class diagrams generated by the human experts. © 2018 IEEE.},
	language = {English},
	booktitle = {Proceedings - 17th {IEEE}/{ACIS} {International} {Conference} on {Computer} and {Information} {Science}, {ICIS} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {{Shweta} and Sanyal, Ratna and Ghoshal, Bibhas},
	editor = {W, Xiong and W, Shang and S, Xu and H.-K, Lee},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Extraction, Unified Modeling Language, Automatic extraction, Automatically generated, Case-studies, Class diagrams, Computer software, Encoding (symbols), Semi-structured, Software requirement specification, Structural modeling, Use-case},
	pages = {543 -- 548},
	annote = {Cited by: 9; Conference name: 17th IEEE/ACIS International Conference on Computer and Information Science, ICIS 2018; Conference date: 6 June 2018 through 8 June 2018; Conference code: 139965},
	annote = {Cited by: 10; Conference name: 17th IEEE/ACIS International Conference on Computer and Information Science, ICIS 2018; Conference date: 6 June 2018 through 8 June 2018; Conference code: 139965},
	annote = {RELEVANCE: LOW
},
}


@article{santos_formal_2018,
	title = {Formal modelling of environment restrictions from natural-language requirements},
	volume = {11254 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057236351&doi=10.1007%2f978-3-030-03044-5_16&partnerID=40&md5=f02ddeb4bd0f60ca45769818fcfe6000},
	doi = {10.1007/978-3-030-03044-5_16},
	abstract = {When creating system models, further to system behaviour one should take into account properties of the environment in order to achieve more meaningful models. Here, we extend a strategy that formalises data-flow reactive systems as CSP processes to take into account environment restrictions. Initially, these restrictions are written in natural language. Afterwards, with the aid of case-grammar theory, they are formalised by deriving LTL formulae automatically. Finally, these formulae are used to prune infeasible scenarios from the CSP-based system specification, in the light of the environment restrictions. Considering examples from the literature, and from the aerospace (Embraer) and the automotive (Mercedes) industry, we show the efficacy of our proposal in terms of state space reduction, up to 61\% in some cases. © Springer Nature Switzerland AG 2018.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Santos, Tainã and Carvalho, Gustavo and Sampaio, Augusto},
	editor = {T, Massoni and M.R, Mousavi},
	year = {2018},
	note = {ISBN: 978-303003043-8
Publisher: Springer Verlag
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Temporal logic, Linear temporal logic, Specifications, Formal methods, Case grammars, Communicating sequential process, Computer operating procedures, Environment restrictions, Modeling languages},
	pages = {252 -- 270},
	annote = {Cited by: 3; Conference name: 21st Brazilian Symposium on Formal Methods, SBMF 2018; Conference date: 26 November 2018 through 30 November 2018; Conference code: 221099},
	annote = {Cited by: 4; Conference name: 21st Brazilian Symposium on Formal Methods, SBMF 2018; Conference date: 26 November 2018 through 30 November 2018; Conference code: 221099},
	annote = {RELEVANCE: LOW
},
}


@article{snook_domain-specific_2019,
	title = {Domain-specific scenarios for refinement-based methods},
	volume = {1085},
	issn = {18650929},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075663380&doi=10.1007%2f978-3-030-32213-7_2&partnerID=40&md5=be24bddeba838e9480994c071bfb696d},
	doi = {10.1007/978-3-030-32213-7_2},
	abstract = {Formal methods use abstraction and rigorously verified refinement to manage the design of complex systems, ensuring that they satisfy important invariant properties. However, formal verification is not sufficient: models must also be tested to ensure that they behave according to the informal requirements and validated by domain experts who may not be expert in formal modelling. This can be satisfied by scenarios that complement the requirements specification. The model can be animated to check that the scenario is feasible in the model and that the model reaches states expected in the scenario. However, there are two problems with this approach. (1) The provided scenarios are at the most concrete level corresponding to the full requirements and cannot be used until all the refinements have been completed in the model. (2) The natural language used to describe the scenarios is often verbose, ambiguous and therefore difficult to understand; especially if the modeller is not a domain expert. In this paper we propose a method of abstracting scenarios from concrete ones so that they can be used to test early refinements of the model. We also show by example how a precise and concise domain specific language can be used for writing these abstract scenarios in a style that can be easily understood by the domain expert (for validation purposes) as well as the modeller (for behavioural verification). We base our approach on the Cucumber framework for scenarios and the Event-B modelling language and tool set. We illustrate the proposed methods on the ERTMS/ETCS Hybrid Level 3 specification for railway controls (The example model and scenario scripts supporting this paper are openly available at https://doi.org/10.5258/SOTON/D1026 ). © Springer Nature Switzerland AG 2019.},
	language = {English},
	journal = {Communications in Computer and Information Science},
	author = {Snook, Colin and Hoang, Thai Son and Dghaym, Dana and Butler, Michael},
	editor = {C, Attiogbé and F, Ferrarotti and S, Maabout},
	year = {2019},
	note = {ISBN: 978-303032212-0
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Cucumber, Modeling languages, Domain specific languages, Problem oriented languages, Abstracting, Formal verification, Requirements specifications, Informal requirements, Validation, Event-B, Invariant properties},
	pages = {18 -- 31},
	annote = {Cited by: 1; Conference name: 9th International Conference on New Trends in Model and Data Engineering, MEDI 2019; Conference date: 28 October 2019 through 31 October 2019; Conference code: 233649; All Open Access, Green Open Access},
	annote = {Cited by: 1; Conference name: 9th International Conference on New Trends in Model and Data Engineering, MEDI 2019; Conference date: 28 October 2019 through 31 October 2019; Conference code: 233649; All Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{chen_automating_2019,
	title = {Automating {Consistency} {Verification} of {Safety} {Requirements} for {Railway} {Interlocking} {Systems}},
	doi = {10.1109/RE.2019.00040},
	abstract = {Consistency verification of safety requirements is an important but still challenging task for safety-critical systems such as rail transit systems. That is mainly because requirements are typically written in natural language and with strong time constraints. Driven by the practical need from industry, in this paper we propose a systematic approach to specify safety requirements in a quasi-natural language and automatically verify their consistency using formal methods. Specifically, we define a domain specific language SafeNL to specify safety requirements, and then automatically transform them into formal constraints defined in the Clock Constraint Specification Language (CCSL). The transformed constraints can be automatically and efficiently verified by model checking. We conduct two practical case studies to analyze the safety requirements of an interlocking system in CASCO Signal Ltd. Results of the studies show the validity and utility of our approach can pragmatically contribute to industrial practice. We also report some lessons learned from case studies.},
	booktitle = {2019 {IEEE} 27th {International} {Requirements} {Engineering} {Conference} ({RE})},
	author = {Chen, Xiaohong and Zhong, Zhiwei and Jin, Zhi and Zhang, Min and Li, Tong and Chen, Xiang and Zhou, Tingliang},
	month = sep,
	year = {2019},
	note = {ISSN: 2332-6441},
	keywords = {Natural language processing systems, Requirements engineering, Model checking, Specification languages, Problem oriented languages, Formal verification, Accident prevention, Safety requirements, CCSL, Consistency verifications, Interlocking signals, Interlocking systems, SafeNL, Safety devices},
	pages = {308--318},
	annote = {Cited by: 5; Conference name: 27th IEEE International Requirements Engineering Conference, RE 2019; Conference date: 23 September 2019 through 27 September 2019; Conference code: 155831},
	annote = {Cited by: 10; Conference name: 27th IEEE International Requirements Engineering Conference, RE 2019; Conference date: 23 September 2019 through 27 September 2019; Conference code: 155831},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{buzhinsky_formalization_2019,
	title = {Formalization of natural language requirements into temporal logics: {A} survey},
	volume = {2019-July},
	isbn = {978-1-72812-927-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079053792&doi=10.1109%2fINDIN41052.2019.8972130&partnerID=40&md5=d98fe5baa7407ebcf859e1c8630898b6},
	doi = {10.1109/INDIN41052.2019.8972130},
	abstract = {One of the challenges of requirements engineering is the fact that requirements are often formulated in natural language. This represents difficulty if requirements must be processed by formal approaches, especially if these approaches are intended to check the requirements. In model checking, a formal technique of verification by exhaustive state space exploration, requirements must be stated in formal languages (most commonly, temporal logics) which are essentially supersets of the Boolean propositional logic. Translation of natural language requirements to these languages is a process which requires much knowledge and expertise in model checking as well the ability to correctly understand these requirements, and hence automating this process is desirable. This paper reviews existing approaches of requirements formalization that are applicable for, or at least can be adapted to generation of discrete time temporal logic requirements. Based on the review, conclusions are made regarding the practical applicability of these approaches for the considered problem. © 2019 IEEE.},
	language = {English},
	booktitle = {{IEEE} {International} {Conference} on {Industrial} {Informatics} ({INDIN})},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Buzhinsky, Igor},
	year = {2019},
	note = {ISSN: 19354576
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Temporal logic, Natural language requirements, Formal languages, Model checking, Boolean functions, Computer circuits, Discrete time, Formal approach, Formal techniques, Industrial informatics, Propositional logic, Requirements formalizations, Space research, State space exploration},
	pages = {400 -- 406},
	annote = {Cited by: 17; Conference name: 17th IEEE International Conference on Industrial Informatics, INDIN 2019; Conference date: 22 July 2019 through 25 July 2019; Conference code: 157260},
	annote = {Cited by: 22; Conference name: 17th IEEE International Conference on Industrial Informatics, INDIN 2019; Conference date: 22 July 2019 through 25 July 2019; Conference code: 157260},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{wang_automated_2018,
	title = {Automated {Generation} of {Constraints} from {Use} {Case} {Specifications} to {Support} {System} {Testing}},
	isbn = {978-1-5386-5012-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048426250&doi=10.1109%2fICST.2018.00013&partnerID=40&md5=6c1adc98017c52f2b272dda5c1d6feac},
	doi = {10.1109/ICST.2018.00013},
	abstract = {System testing plays a crucial role in safety-critical domains, e.g., automotive, where system test cases are used to demonstrate the compliance of software with its functional and safety requirements. Unfortunately, since requirements are typically written in natural language, significant engineering effort is required to derive test cases from requirements. In such a context, automated support for generating system test cases from requirements specifications written in natural language would be highly beneficial. Unfortunately, existing approaches have limited applicability. For example, some of them require that software engineers provide formal specifications that capture some of the software behavior described using natural language. The effort needed to define such specifications is usually a significant deterrent for software developers. This paper proposes an approach, OCLgen, which largely automates the generation of the additional formal specifications required by an existing test generation approach named UMTG. More specifically, OCLgen relies on semantic analysis techniques to automatically derive the pre-A nd post-conditions of the activities described in use case specifications. The generated conditions are used by UMTG to identify the test inputs that cover all the use case scenarios described in use case specifications. In practice, the proposed approach enables the automated generation of test cases from use case specifications while avoiding most of the additional modeling effort required by UMTG. Results from an industrial case study show that the approach can automatically and correctly generate more than 75\% of the pre-A nd post-conditions characterizing the activities described in use case specifications. © 2018 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2018 {IEEE} 11th {International} {Conference} on {Software} {Testing}, {Verification} and {Validation}, {ICST} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Wang, Chunhui and Pastore, Fabrizio and Briand, Lionel},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Semantics, Requirements analysis, Software testing, Verification, Industrial case study, Automated generation, Automatic test pattern generation, Automation, Constraints generation, Requirements specifications, Safety engineering, Safety testing, Safety-critical domain, System testing, System theory, Use case specifications},
	pages = {23 -- 33},
	annote = {Cited by: 14; Conference name: 11th IEEE International Conference on Software Testing, Verification and Validation, ICST 2018; Conference date: 9 April 2018 through 13 April 2018; Conference code: 136754; All Open Access, Green Open Access},
	annote = {Cited by: 15; Conference name: 11th IEEE International Conference on Software Testing, Verification and Validation, ICST 2018; Conference date: 9 April 2018 through 13 April 2018; Conference code: 136754},
	annote = {RELEVANCE: LOW
},
}


@article{winter_detecting_2018-1,
	title = {Detecting {Constraints} and {Their} {Relations} from {Regulatory} {Documents} {Using} {NLP} {Techniques}},
	volume = {11229 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055833260&doi=10.1007%2f978-3-030-02610-3_15&partnerID=40&md5=037bbecf4bd88af57b6643fd3290a881},
	doi = {10.1007/978-3-030-02610-3_15},
	abstract = {Extracting constraints and process models from natural language text is an ongoing challenge. While the focus of current research is merely on the extraction itself, this paper presents a three step approach to group constraints as well as to detect and display relations between constraints in order to ease their implementation. For this, the approach uses NLP techniques to extract sentences containing constraints, group them by, e.g., stakeholders or topics, and detect redundant, subsuming, and conflicting pairs of constraints. These relations are displayed using network maps. The approach is prototypically implemented and evaluated based on regulatory documents from the financial sector as well as expert interviews. © 2018, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Winter, Karolin and Rinderle-Ma, Stefanie},
	editor = {H.A, Proper and R, Meersman and C.A, Ardagna and H, Panetto and C, Debruyne and D, Roman},
	year = {2018},
	note = {ISBN: 978-303002609-7
Publisher: Springer Verlag
Type: Conference paper},
	keywords = {Compliance, Natural language processing systems, Data mining, Distributed computer systems, Extraction, Financial sectors, Group constraints, Multi agent systems, Natural language text, Nlp techniques, Regulatory compliance, Regulatory documents, Semantics, Text mining, Three-step approach},
	pages = {261 -- 278},
	annote = {Cited by: 16; Conference name: Confederated International Conferences: Cooperative Information Systems, CoopIS 2018, Ontologies, Databases, and Applications of Semantics, ODBASE 2018, and Cloud and Trusted Computing, C and TC, held as part of OTM 2018; Conference date: 22 October 2018 through 26 October 2018; Conference code: 219839},
}


@article{kabaale_ensuring_2018,
	title = {Ensuring conformance to process standards through formal verification},
	volume = {918},
	issn = {18650929},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054849764&doi=10.1007%2f978-3-030-00623-5_17&partnerID=40&md5=977a4ac5f65f091bcfa67c46c1d26173},
	doi = {10.1007/978-3-030-00623-5_17},
	abstract = {Software process standards and models encapsulate best practices and guidelines for engineering and managing software. These are usually prescribed in natural language. However, natural language based process specifications can be inconsistent and ambiguous that makes it difficult to monitor and verify if they have been fully implemented and adhered too in a given software project. Besides the process of defining and documenting the necessary evidence to comply with process standard requirements is often manual, time consuming and laborious. In earlier studies, we developed a translation scheme and metamodel for consistent and uniform software process formalisation. In the current study, we leverage the formal process specification to develop a two-step formal process verification approach; first we extract process requirements from the standard documents and translate them into logical axioms. We then augment these axioms with additional information in a process verification ontology. This ontology is then utilised in conformance verification of a performed process. We demonstrate the feasibility of our approach with software requirements analysis process and a case study. © Springer Nature Switzerland AG 2018.},
	language = {English},
	journal = {Communications in Computer and Information Science},
	author = {Kabaale, Edward and Wen, Lian and Wang, Zhe and Rout, Terry},
	editor = {I, Stamelos and T, Rout and R.V, O’Connor and A, Dorling},
	year = {2018},
	note = {ISBN: 978-303000622-8
Publisher: Springer Verlag
Type: Conference paper},
	keywords = {Requirements engineering, Ontology, Specifications, Verification, Formal verification, Standards, Translation (languages), Process engineering, Processing, Process specification, Circuit simulation, Formal process verifications, Process requirements, Process standards, Process verifications, Software requirements analysis, Standard documents, Translation schemes},
	pages = {248 -- 262},
	annote = {Cited by: 3; Conference name: 18th International Conference on Software Process Improvement and Capability Determination, SPICE 2018; Conference date: 9 October 2018 through 10 October 2018; Conference code: 219099; All Open Access, Green Open Access},
	annote = {Cited by: 3; Conference name: 18th International Conference on Software Process Improvement and Capability Determination, SPICE 2018; Conference date: 9 October 2018 through 10 October 2018; Conference code: 219099; All Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{hou_enabling_2018,
	title = {Enabling temporal reasoning for fact statements: {A} web-based approach},
	volume = {10829 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059027187&doi=10.1007%2f978-3-319-91455-8_9&partnerID=40&md5=a150b5b678cff5ad5b852f0707013844},
	doi = {10.1007/978-3-319-91455-8_9},
	abstract = {There exists a precise time period during which a given fact such as an event or a status is valid. In this paper, we propose a new approach to determine the validity time of a fact statement by leveraging unstructured and noisy data from the Web, while overcoming the limitations of existing natural language processing technologies designed for the same task. Given a fact and its temporal relevance text, the proposed solution first constructs a Semantic Bayesian Network, then estimates the validity probabilities of time points using the constructed network. In the interest of dealing with the semantic complexity of keywords, we also present a technique based on relative standard deviation to estimate distortion risks of keywords and incorporate their risk estimation into the process of probability computation. Our experiments on real data shows that the proposed approach can achieve considerable improvements in performance over 2 state-of-the-art alternatives, and the proposed risk reduction technique can effectively improve validity time reasoning’s precision. © Springer International Publishing AG, part of Springer Nature 2018.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Hou, Boyi and Nafa, Youcef},
	editor = {J, Li and L, Zou and C, Liu},
	year = {2018},
	note = {ISBN: 978-331991454-1
Publisher: Springer Verlag
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Semantics, Temporal logic, Database systems, Bayesian networks, Temporal reasoning, State of the art, Risk perception, Constructed networks, Probability computations, Relative standard deviations, Temporal relevance, Web-based approach},
	pages = {99 -- 107},
	annote = {Cited by: 0; Conference name: 23rd International Conference on Database Systems for Advanced Applications, DASFAA 2018; Conference date: 21 May 2018 through 24 May 2018; Conference code: 213579},
	annote = {Cited by: 0; Conference name: 23rd International Conference on Database Systems for Advanced Applications, DASFAA 2018; Conference date: 21 May 2018 through 24 May 2018; Conference code: 213579},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{hedblom__2018,
	address = {New York, NY, USA},
	series = {{SAC} '18},
	title = {In, out and through: {Formalising} {Some} {Dynamic} {Aspects} of the {Image} {Schema} {Containment}},
	isbn = {978-1-4503-5191-1},
	url = {https://doi.org/10.1145/3167132.3167233},
	doi = {10.1145/3167132.3167233},
	abstract = {In the cognitive sciences, image schemas are considered to be the conceptual building blocks learned from sensorimotor processes in early infancy. They are used in language and higher levels of cognition as information skeletons. Despite the potential of integrating image schemas into formal systems to aid for instance common-sense reasoning, computational analogy and concept invention, normalisations of image schemas are sparse. In particular in respect to their dynamic nature. In this paper, we therefore describe how some of the dynamic aspects of the image schema Containment can be formally approached using an image schema logic based on the Region Connection Calculus (RCC8), the Qualitative Trajectory Calculus (QTC), Ligozat's cardinal directions (CD), and Linear Temporal Logic over the reals (RTL), with 3D Euclidean space assumed for the spatial domain. The distinctions in our formalisations are motivated with concrete examples from natural language, derived from semi-automated image schema extraction, and illustrate that we target some of the essential distinctions regarding containers and movement.},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Hedblom, Maria M. and Gromann, Dagmar and Kutz, Oliver},
	year = {2018},
	note = {event-place: Pau, France},
	keywords = {Linear temporal logic, Calculations, Computer circuits, Computation theory, Cardinal direction, Cognitive science, common-sense reasoning, Commonsense reasoning, Image processing, image schemas, Image schemas, knowledge representation, Knowledge representation, natural language understanding, Natural language understanding, Region connection calculus, spatial logic, Spatial logic},
	pages = {918--925},
	annote = {Cited by: 10; Conference name: 33rd Annual ACM Symposium on Applied Computing, SAC 2018; Conference date: 9 April 2018 through 13 April 2018; Conference code: 137816},
	annote = {Cited by: 11; Conference name: 33rd Annual ACM Symposium on Applied Computing, SAC 2018; Conference date: 9 April 2018 through 13 April 2018; Conference code: 137816},
	annote = {RELEVANCE: NULL


},
}


@inproceedings{frehse_toolchain_2018,
	title = {A {Toolchain} for {Verifying} {Safety} {Properties} of {Hybrid} {Automata} via {Pattern} {Templates}},
	volume = {2018-June},
	isbn = {978-1-5386-5428-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052587784&doi=10.23919%2fACC.2018.8431324&partnerID=40&md5=bae511d6880ed2ae35a24038270c8752},
	doi = {10.23919/ACC.2018.8431324},
	abstract = {In this paper, we provide a toolchain that facilitates the integration of formal verification techniques into model-based design. Applying verification tools to industrially relevant models requires three main ingredients: a formal model, a formal verification method, and a set of formal specifications. Our focus is on hybrid automata as the model and on reachability analysis as the method. Much progress has been made towards developing efficient and scalable reachability algorithms tailored to hybrid automata. However, it is not easy to encode rich formal specifications such that they can be interpreted by existing tools for reachability. Herein, we consider specifications expressed in pattern templates which are predefined properties with placeholders for state predicates. Pattern templates are close to the natural language and can be easily understood by both expert and non-expert users. We provide (i) formal definitions for selected patterns in the formalism of hybrid automata and (ii) monitors which encode the properties as the reachability of an error state. By composing these monitors with the formal model under study, the property can be checked by off-the-shelf fully automated verification tools. We illustrate the workflow on an electro-mechanical brake use case. © 2018 AACC.},
	language = {English},
	booktitle = {Proceedings of the {American} {Control} {Conference}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Frehse, Goran and Kekatos, Nikolaos and Nickovic, Dejan and Oehlerking, Jens and Schuler, Simone and Walsch, Alexander and Woehrle, Matthias},
	year = {2018},
	note = {ISSN: 07431619
Type: Conference paper},
	pages = {2384 -- 2391},
	annote = {Cited by: 2; Conference name: 2018 Annual American Control Conference, ACC 2018; Conference date: 27 June 2018 through 29 June 2018; Conference code: 138710},
	annote = {Cited by: 3; Conference name: 2018 Annual American Control Conference, ACC 2018; Conference date: 27 June 2018 through 29 June 2018; Conference code: 138710},
	annote = {RELEVANCE: LOW
},
}


@article{frederik_s_baumermichaela_geierhos_how_2018,
	title = {How to {Deal} with {Inaccurate} {Service} {Descriptions} in {On}-{The}-{Fly} {Computing}: {Open} {Challenges}},
	url = {{http://link.springer.com/chapter/10.1007/978-3-319-91947-8_53}},
	doi = {10.1007/978-3-319-91947-8_53},
	journal = {Natural Language Processing and Information Systems},
	author = {{Frederik S. BäumerMichaela Geierhos}},
	year = {2018},
	keywords = {Natural language processing systems, Information systems, Information use, Service compositions, Automatic composition, On-The-Fly Computing, Service description, Software composition, Software description, Software functions, Software services},
	annote = {Cited by: 0; Conference name: 23rd International Conference on Natural Language and Information Systems, NLDB 2018; Conference date: 13 June 2018 through 15 June 2018; Conference code: 213789},
	annote = {Cited by: 0; Conference name: 23rd International Conference on Natural Language and Information Systems, NLDB 2018; Conference date: 13 June 2018 through 15 June 2018; Conference code: 213789},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{al-nuaimi_computational_2018,
	title = {Computational {Framework} for {Verifiable} {Decisions} of {Self}-{Driving} {Vehicles}},
	isbn = {978-1-5386-7698-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056896346&doi=10.1109%2fCCTA.2018.8511432&partnerID=40&md5=f3622c12f94a2a9a91255ce4ebb8fedc},
	doi = {10.1109/CCTA.2018.8511432},
	abstract = {A framework is presented for the verification of an agent's decision making in autonomous driving applications by checking the logic of the agent for instability and inconsistency. The framework verifies the decisions of a rational agent implemented in Natural Language Programming (NLP) and based on a belief-desire-intention (BDI) paradigm using sEnglish and Jason code. The main results are methods of verification for the correctness of real-time agent decisions expressed in computational tree logic (CTL) formulae. The methods rely on the Model Checker for Multi-Agent Systems (MCMAS) verification tool. To test the new verification system, an autonomous vehicle (AV) has been modelled and simulated, which is capable of planning, navigation, objects detection and obstacle avoidance using a rational agent. The agent's decisions are based on information received from mono-cameras and LiDAR sensor that feed into logic-based decisions of the AV. The model of the AV and its environment has been implemented in the Robot Operating System (ROS) and the Gazebo virtual reality simulator. © 2018 IEEE.},
	language = {English},
	booktitle = {2018 {IEEE} {Conference} on {Control} {Technology} and {Applications}, {CCTA} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Al-Nuaimi, Mohammed and Qu, Hongyang and Veres, Sandor M.},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Decision making, Multi agent systems, Temporal logic, Model checking, Robots, Computer circuits, Autonomous agents, Belief-desire-intentions, Computational framework, Computational tree logic, Methods of verifications, Object detection, Optical radar, Robot operating systems (ROS), Self-driving vehicles, Verification systems, Virtual reality, Virtual reality simulator},
	pages = {638 -- 645},
	annote = {Cited by: 3; Conference name: 2nd IEEE Conference on Control Technology and Applications, CCTA 2018; Conference date: 21 August 2018 through 24 August 2018; Conference code: 141667},
	annote = {Cited by: 3; Conference name: 2nd IEEE Conference on Control Technology and Applications, CCTA 2018; Conference date: 21 August 2018 through 24 August 2018; Conference code: 141667},
	annote = {RELEVANCE: LOW
},
}


@article{ricciotti_formalization_2022,
	title = {A {Formalization} of {SQL} with {Nulls}},
	volume = {66},
	issn = {0168-7433},
	url = {https://doi.org/10.1007/s10817-022-09632-4},
	doi = {10.1007/s10817-022-09632-4},
	abstract = {SQL is the world’s most popular declarative language, forming the basis of the multi-billion-dollar database industry. Although SQL has been standardized, the full standard is based on ambiguous natural language rather than formal specification. Commercial SQL implementations interpret the standard in different ways, so that, given the same input data, the same query can yield different results depending on the SQL system it is run on. Even for a particular system, mechanically checked formalization of all widely-used features of SQL remains an open problem. The lack of a well-understood formal semantics makes it very difficult to validate the soundness of database implementations. Although formal semantics for fragments of SQL were designed in the past, they usually did not support set and bag operations, lateral joins, nested subqueries, and, crucially, null values. Null values complicate SQL’s semantics in profound ways analogous to null pointers or side-effects in other programming languages. Since certain SQL queries are equivalent in the absence of null values, but produce different results when applied to tables containing incomplete data, semantics which ignore null values are able to prove query equivalences that are unsound in realistic databases. A formal semantics of SQL supporting all the aforementioned features was only proposed recently. In this paper, we report about our mechanization of SQL semantics covering set/bag operations, lateral joins, nested subqueries, and nulls, written in the Coq proof assistant, and describe the validation of key metatheoretic properties. Additionally, we are able to use the same framework to formalize the semantics of a flat relational calculus (with null values), and show a certified translation of its normal forms into SQL.},
	number = {4},
	journal = {J. Autom. Reason.},
	author = {Ricciotti, Wilmer and Cheney, James},
	month = nov,
	year = {2022},
	note = {Place: Berlin, Heidelberg
Publisher: Springer-Verlag},
	keywords = {Query processing, Natural languages, Semantics, Formal Semantics, Calculations, Formalization, Formalisation, Search engines, Coq, Database systems, Declarative Languages, Input datas, Machinery, Null, Null value, Nulls, SQL, Sub-queries, Theorem proving},
	pages = {989--1030},
	annote = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE: LOW

SQL is the world’s most popular declarative language, forming the basis of the multi-billion-dollar database industry. Although SQL has been standardized, the full standard is basedon ambiguous natural language rather than formal specification


},
}


@article{bougacha_extending_2022,
	title = {Extending {SysML} with {Refinement} and {Decomposition} {Mechanisms} to {Generate} {Event}-{B} {Specifications}},
	volume = {13299 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135034189&doi=10.1007%2f978-3-031-10363-6_18&partnerID=40&md5=9d2a9aba490291d68534e2e520caa840},
	doi = {10.1007/978-3-031-10363-6_18},
	abstract = {SysML, dedicated to system design, provides graphical models. One of the strengths of these graphical models is that they can be validated by domain experts. However, the semantics of SysML is given in natural language, which does not allow formal and rigorous reasoning necessary for critical systems for which safety and security are major concerns. Our project aims at modeling and verifying high-level architectures of critical complex systems, in particular railways systems, that must be validated by domain experts. For that, we propose to combine SysML and the Event-B formal method. To master the complexity of such systems, Event-B provides refinement and decomposition mechanisms that allow a step-by-step design and make proofs easier to discharge. This paper proposes to extend SysML with safety relevant Event-B mechanisms that enable an automatic translation from SysML diagrams to Event-B specifications. We focus on diagrams that facilitate high-level architecture design, namely package, block-definition, state-transition and sequence diagrams. © 2022, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Bougacha, Racem and Laleau, Régine and Collart-Dutilleul, Simon and Ayed, Rahma Ben},
	editor = {Y, Aït-Ameur and F, Crăciun},
	year = {2022},
	note = {ISBN: 978-303110362-9
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Formal specification, Semantics, SysML, Domain experts, Model transformation, Graphic methods, Decomposition, Architecture, High level architecture, Event-B, B-method, Decomposition mechanism, Event-B method, GraphicaL model, Refinement mechanisms},
	pages = {256 -- 273},
	annote = {Cited by: 1; Conference name: 16th International Symposium on Theoretical Aspects of Software Engineering, TASE 2022; Conference date: 8 July 2022 through 10 July 2022; Conference code: 280219},
	annote = {Cited by: 3; Conference name: 16th International Symposium on Theoretical Aspects of Software Engineering, TASE 2022; Conference date: 8 July 2022 through 10 July 2022; Conference code: 280219},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{hsiung_generalizing_2022,
	title = {Generalizing to {New} {Domains} by {Mapping} {Natural} {Language} to {Lifted} {LTL}},
	url = {https://doi.org/10.1109/ICRA46639.2022.9812169},
	doi = {10.1109/ICRA46639.2022.9812169},
	abstract = {Recent work on using natural language to specify commands to robots has grounded that language to LTL. However, mapping natural language task specifications to LTL task specifications using language models require probability distributions over finite vocabulary. Existing state-of-the-art methods have extended this finite vocabulary to include unseen terms from the input sequence to improve output generalization. However, novel out-of-vocabulary atomic propositions cannot be generated using these methods. To overcome this, we introduce an intermediate contextual query representation which can be learned from single positive task specification examples, associating a contextual query with an LTL template. We demonstrate that this intermediate representation allows for generalization over unseen object references, assuming accurate groundings are available. We compare our method of mapping natural language task specifications to intermediate contextual queries against state-of-the-art CopyNet models capable of translating natural language to LTL, by evaluating whether correct LTL for manipulation and navigation task specifications can be output, and show that our method outperforms the CopyNet model on unseen object references. We demonstrate that the grounded LTL our method outputs can be used for planning in a simulated OO-MDP environment. Finally, we discuss some common failure modes encountered when translating natural language task specifications to grounded LTL.},
	booktitle = {2022 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE Press},
	author = {Hsiung, Eric and Mehta, Hiloni and Chu, Junchi and Liu, Xinyu and Patel, Roma and Tellex, Stefanie and Konidaris, George},
	year = {2022},
	note = {Place: Philadelphia, PA, USA},
	keywords = {Natural languages, Mapping, Specifications, Task specifications, Translation (languages), Language model, Atomic propositions, Generalisation, Input sequence, Linearization, Object reference, Probability distributions, Probability: distributions, Query representations, State-of-the-art methods},
	pages = {3624--3630},
	annote = {Cited by: 3; Conference name: 39th IEEE International Conference on Robotics and Automation, ICRA 2022; Conference date: 23 May 2022 through 27 May 2022; Conference code: 180851; All Open Access, Green Open Access},
	annote = {Cited by: 3; Conference name: 39th IEEE International Conference on Robotics and Automation, ICRA 2022; Conference date: 23 May 2022 through 27 May 2022; Conference code: 180851; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH

},
}


@inproceedings{grasler_efficient_2022,
	title = {Efficient {Extraction} of {Technical} {Requirements} {Applying} {Data} {Augmentation}},
	isbn = {978-1-66548-182-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146926373&doi=10.1109%2fISSE54508.2022.10005452&partnerID=40&md5=1640610e2c705d8af3b55ebcfc416fdf},
	doi = {10.1109/ISSE54508.2022.10005452},
	abstract = {Requirements for complex technical systems are documented in natural language sources. Manually extracting requirements from these documents-e.g., to transfer them to a requirements management tool-is time-consuming and error-prone. Today, machine learning approaches are used to classify natural language requirements and thus enable extraction of these requirements. However, in practice there is often not enough labeled domain-specific data available to train such models. For this reason, this work investigates the performance in artificially generating requirements through data augmentation. First, success criteria for a method for extracting and augmenting requirements are elicited in cooperation with industry experts. Second, the performance in the augmentation of requirements data is investigated. The results show that GPT-J is suitable for generating artificial requirements: weighted average F1-score: 62.74 \%. Third, a method is developed to extract requirements from specifications, augment requirements data, and then classify the requirements. As a final step, the method is evaluated with requirements data from three industry case examples of the engineering service provider EDAG Engineering GmbH: Assembly latch hood, adjustable stopper hood and trunk curtain roller blind. Evaluation shows that especially the transferability of models is improved when they are trained with augmented data. The developed method facilitates eliciting complete requirements sets. Performance of artificial intelligence models in requirements extraction is improved applying augmented data and therefore the method leads to efficient product development. © 2022 IEEE.},
	language = {English},
	booktitle = {{ISSE} 2022 - 2022 8th {IEEE} {International} {Symposium} on {Systems} {Engineering}, {Conference} {Proceedings}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Grasler, Iris and Preus, Daniel and Brandt, Lukas and Mohr, Michael},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Requirements engineering, Data mining, Extraction, Requirement engineering, Machine learning, Learning algorithms, Language processing, Complex technical systems, Data augmentation, Machine-learning, Natural language processing, Performance, Requirement management tools, Technical requirement},
	annote = {Cited by: 2; Conference name: 8th IEEE International Symposium on Systems Engineering, ISSE 2022; Conference date: 24 October 2022 through 26 October 2022; Conference code: 185962},
	annote = {Cited by: 2; Conference name: 8th IEEE International Symposium on Systems Engineering, ISSE 2022; Conference date: 24 October 2022 through 26 October 2022; Conference code: 185962},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{luckcuck_methodology_2022,
	title = {A {Methodology} for {Developing} a {Verifiable} {Aircraft} {Engine} {Controller} from {Formal} {Requirements}},
	volume = {2022-March},
	isbn = {978-1-66543-760-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123429477&doi=10.1109%2fAERO53065.2022.9843589&partnerID=40&md5=7493b05faada29438601fb8c15d30b60},
	doi = {10.1109/AERO53065.2022.9843589},
	abstract = {Verification of complex, safety-critical systems is a significant challenge. Manual testing and simulations are often used, but are only capable of exploring a subset of the system's reachable states. Formal methods are mathematically-based techniques for the specification and development of software, which can provide proofs of properties and exhaustive checks over a system's state space. In this paper, we present a formal requirements-driven methodology, applied to a model of an aircraft engine controller that has been provided by our industrial partner. Our methodology begins by formalising the controller's natural-language requirements using the (pre-existing) Formal Requirements Elicitation Tool (FRET), iteratively, in consultation with our industry partner. Once formalised, FRET can automatically translate the requirements to enable their verification alongside a Simulink model of the aircraft engine controller; the requirements can also guide formal verification using other approaches. These two parallel streams in our methodology seek to combine the results from formal requirements elicitation, classical verification approaches, and runtime verification; to support the verification of aerospace systems modelled in Simulink, from the requirements phase through to execution. Our methodology harnesses the power of formal methods in a way that complements existing verification techniques, and supports the traceability of requirements throughout the verification process. This methodology streamlines the process of developing verifiable aircraft engine controllers, by ensuring that the requirements are formalised up-front and useable during development. In this paper we give an overview of FRET, describe our methodology and work to-date on the formalisation and verification of the requirements, and outline future work using our methodology. © 2022 IEEE.},
	language = {English},
	booktitle = {{IEEE} {Aerospace} {Conference} {Proceedings}},
	publisher = {IEEE Computer Society},
	author = {Luckcuck, Matt and Farrell, Marie and Sheridan, Oisin and Monahan, Rosemary},
	year = {2022},
	note = {ISSN: 1095323X
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural language requirements, Requirements elicitation, Formal verification, Safety engineering, Safety critical systems, Aircraft engines, Controllers, Engine controller, Engines, Industrial partners, Iterative methods, Manual testing, Property, Requirement-driven, State-space, System state},
	annote = {Cited by: 3; Conference name: 2022 IEEE Aerospace Conference, AERO 2022; Conference date: 5 March 2022 through 12 March 2022; Conference code: 181782; All Open Access, Green Open Access},
	annote = {Cited by: 3; Conference name: 2022 IEEE Aerospace Conference, AERO 2022; Conference date: 5 March 2022 through 12 March 2022; Conference code: 181782; All Open Access, Green Open Access},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{liu_automated_2022,
	title = {Automated {Inconsistency} {Analysis} of {Real}-{Time} {Requirements}: {A} {Domain} {Expert} {Friendly} {Approach}},
	isbn = {979-835031993-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152231523&doi=10.1109%2fHPCC-DSS-SmartCity-DependSys57074.2022.00175&partnerID=40&md5=2dc88697076c903ad0f9d81708f89c20},
	doi = {10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00175},
	abstract = {Many safety-critical systems need to meet increasing real-time requirements, which asks for formal inconsistency analysis. However, most of the current formal approaches are unfriendly to domain experts. It is a heavy burden for them to formalize the natural language requirements and use formal methods to analyze the inconsistency. To help the domain experts, in this paper, we define a real-time requirements pattern language, and propose an automated real-time requirements inconsistency analysis approach based on constraint solving. A case study on automotive lighting systems shows the feasibility of our approach. © 2022 IEEE.},
	language = {English},
	booktitle = {Proceedings - 24th {IEEE} {International} {Conference} on {High} {Performance} {Computing} and {Communications}, 8th {IEEE} {International} {Conference} on {Data} {Science} and {Systems}, 20th {IEEE} {International} {Conference} on {Smart} {City} and 8th {IEEE} {International} {Conference} on {Dependability} in {Sensor}, {Cloud} and {Big} {Data} {Systems} and {Application}, {HPCC}/{DSS}/{SmartCity}/{DependSys} 2022},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Liu, Shaobin and Chen, Xiaohong and Jin, Zhi and Zhang, Min},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Natural language requirements, Formal methods, Formal approach, Requirements formalizations, Safety engineering, Real time systems, Safety critical systems, 'current, Codes (symbols), Constraint Solving, Domain experts, Inconsistency analyse, Logic programming, Pattern languages, Real time requirement},
	pages = {1109 -- 1114},
	annote = {Cited by: 0; Conference name: 24th IEEE International Conference on High Performance Computing and Communications, 8th IEEE International Conference on Data Science and Systems, 20th IEEE International Conference on Smart City and 8th IEEE International Conference on Dependability in Sensor, Cloud and Big Data Systems and Application, HPCC/DSS/SmartCity/DependSys 2022; Conference date: 18 December 2022 through 20 December 2022; Conference code: 187557},
	annote = {Cited by: 0; Conference name: 24th IEEE International Conference on High Performance Computing and Communications, 8th IEEE International Conference on Data Science and Systems, 20th IEEE International Conference on Smart City and 8th IEEE International Conference on Dependability in Sensor, Cloud and Big Data Systems and Application, HPCC/DSS/SmartCity/DependSys 2022; Conference date: 18 December 2022 through 20 December 2022; Conference code: 187557},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{neider_expanding_2022,
	title = {Expanding the {Horizon} of {Linear} {Temporal} {Logic} {Inference} for {Explainability}},
	isbn = {978-1-66546-000-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142270653&doi=10.1109%2fREW56159.2022.00026&partnerID=40&md5=d0b451e3b1393227b80c40085342e543},
	doi = {10.1109/REW56159.2022.00026},
	abstract = {Linear Temporal Logic (LTL), a logical formalism originally developed for the verification of reactive systems, has emerged as a popular model for explaining the behavior of complex systems. The popularity of LTL as explanations can mainly be attributed to its similarity to natural language and its ease of use owing to its simple syntax and semantics. To aid the explanations using LTL, a task commonly known as inference of Linear Temporal Logic formulas, or LTL inference in short, has been of growing interest in recent years. Roughly, this task asks to infer succinct LTL formulas that describe a system based on its recorded observations. Inferring LTL formulas from a given set of positive and negative examples is a well-studied setting, with a number of competing approaches to tackle it. However, for the widespread applicability of LTL as explanations, we argue that one still needs to consider a number of different settings. In this vision paper, we, thus, discuss different problem settings of LTL inference and highlight how one can expand the horizon of LTL inference by investigating these settings. © 2022 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Requirements} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Neider, Daniel and Roy, Rajarshi},
	editor = {E, Knauss and G, Mussbacher and C, Arora and M, Bano and J.-G, Schneider},
	year = {2022},
	note = {ISSN: 1090705X
Type: Conference paper},
	keywords = {Natural languages, Semantics, Temporal logic, Reactive system, Linear temporal logic, Computer circuits, Temporal logic formula, Constraint satisfiability, Ease-of-use, Linear temporal logic constraint satisfiability explainable AI, Logic constraints, Logic inferences, Logical formalism},
	pages = {103 -- 107},
	annote = {Cited by: 0; Conference name: 30th IEEE International Requirements Engineering Conference Workshops, REW 2022; Conference date: 15 August 2022 through 19 August 2022; Conference code: 183744},
	annote = {Cited by: 1; Conference name: 30th IEEE International Requirements Engineering Conference Workshops, REW 2022; Conference date: 15 August 2022 through 19 August 2022; Conference code: 183744},
	annote = {RELEVANCE: MEDIUM
},
}


@article{nayak_req2spec_2022-1,
	title = {{Req2Spec}: {Transforming} {Software} {Requirements} into {Formal} {Specifications} {Using} {Natural} {Language} {Processing}},
	volume = {13216 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127033698&doi=10.1007%2f978-3-030-98464-9_8&partnerID=40&md5=41b06868600570e3f0f0b3e53ce5c111},
	doi = {10.1007/978-3-030-98464-9_8},
	abstract = {[Context and motivation] Requirement analysis and Test specification generation are critical activities in the Software Development Life Cycle (SDLC), which if not done correctly can lead to defects in the software system. Manually performing these tasks on Natural Language Requirements (NLR) is time consuming and error prone. [Question/problem] The problem is to facilitate the automation of these activities by transforming the NLR into Formal Specifications. [Principal ideas/results] In this paper we present Req2Spec, a Natural Language Processing (NLP) based pipeline that performs syntactic and semantic analysis on NLR to generate formal specifications that can be readily consumed by HANFOR, an industry scale Requirements analysis and Test specification generation tool. We considered 222 automotive domain software requirements at BOSCH, 71\% of which were correctly formalized. [Contribution] Req2Spec will be an aid to stakeholders of the SDLC as it seamlessly integrates with HANFOR enabling automation. © 2022, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Nayak, Anmol and Timmapathini, Hari Prasad and Murali, Vidhya and Ponnalagu, Karthikeyan and Venkoparao, Vijendran Gopalan and Post, Amalinda},
	editor = {V, Gervasi and A, Vogelsang},
	year = {2022},
	note = {ISBN: 978-303098463-2
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Software design, Semantics, Natural language requirements, Software requirements, Software testing, Requirements formalizations, Requirement analysis, Software-systems, Life cycle, Language model, Error prones, Software development life-cycle, Critical activities, Test specification generation},
	pages = {87 -- 95},
	annote = {Cited by: 3; Conference name: 28th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2022; Conference date: 21 March 2022 through 24 March 2022; Conference code: 274709},
}


@inproceedings{zaki-ismail_arf_2021,
	title = {{ARF}: {Automatic} {Requirements} {Formalisation} {Tool}},
	isbn = {978-1-66542-856-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123207416&doi=10.1109%2fRE51729.2021.00060&partnerID=40&md5=7eab04396607347c04259a0968dae2a2},
	doi = {10.1109/RE51729.2021.00060},
	abstract = {Formal verification techniques enable the detection of complex quality issues within system specifications. However, the majority of system requirements are usually specified in natural language (NL). Manual formalisation of NL requirements is an error-prone and labour-intensive process requiring strong mathematical expertise, and can be infeasible for large numbers of requirements. Existing automatic formalisation techniques usually support heavily constrained natural language relying on requirement boilerplates or templates. In this paper, we introduce ARF: Automatic Requirements Formalisation Tool. ARF can automatically transform free-format natural language requirements into temporal logic based formal notations. This is achieved through two steps: 1) extraction of key requirement attributes into an intermediate representation (RCM: Requirement Capturing Model), and 2) transformation rules that convert requirements from the RCM format to formal notations. © 2021 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Requirements} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {A, Moreira and K, Schneider and M, Vierhauser and J, Cleland-Huang},
	year = {2021},
	note = {ISSN: 1090705X
Type: Conference paper},
	keywords = {Natural language processing systems, Requirements engineering, Extraction, Natural language requirements, Specifications, Formal verification, Requirements formalizations, Requirement engineering, System requirements, Formalisation, Quality issues, Formal notations, Requirement extraction, Systems specification, Verification techniques},
	pages = {440 -- 441},
	annote = {Cited by: 1; Conference name: 29th IEEE International Requirements Engineering Conference, RE 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 174516},
	annote = {Cited by: 1; Conference name: 29th IEEE International Requirements Engineering Conference, RE 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 174516},
	annote = {RELEVANCE: HIGH
},
}


@article{soavi_contract_2020,
	title = {{ContracT} – from {Legal} {Contracts} to {Formal} {Specifications}: {Preliminary} {Results}},
	volume = {400},
	issn = {18651348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097073162&doi=10.1007%2f978-3-030-63479-7_9&partnerID=40&md5=ca9e5259305d86e56588fa22f6934f30},
	doi = {10.1007/978-3-030-63479-7_9},
	abstract = {We are interested in semi-automating the process of generating a formal specification from a legal contract in natural language text form. Towards this end, we present a tool, named ContracT, that annotates legal contract text using an ontology for legal contracts. In the last part of the paper, we present results from a preliminary empirical evaluation of the tool that provided encouraging results in identifying contract concepts in text and discuss critical points to be tackled in future studies. © 2020, IFIP International Federation for Information Processing.},
	language = {English},
	journal = {Lecture Notes in Business Information Processing},
	author = {Soavi, Michele and Zeni, Nicola and Mylopoulos, John and Mich, Luisa},
	editor = {J, Grabis and D, Bork},
	year = {2020},
	note = {ISBN: 978-303063478-0
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Formal specification, Natural language text, Data processing, Empirical evaluations, Legal contracts},
	pages = {124 -- 137},
	annote = {Cited by: 3; Conference name: 13th IFIP Working Conference on the Practice of Enterprise Modeling, PoEM 2020; Conference date: 25 November 2020 through 27 November 2020; Conference code: 251829; All Open Access, Green Open Access},
	annote = {Cited by: 3; Conference name: 13th IFIP Working Conference on the Practice of Enterprise Modeling, PoEM 2020; Conference date: 25 November 2020 through 27 November 2020; Conference code: 251829; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{ibrahim_z_2020,
	title = {The {Z} {Specification} for {Exam} {Scheduling} {System} ({ESS}) thru {Genetic} {Algorithm}},
	isbn = {978-1-72812-680-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098450911&doi=10.1109%2fICCIT-144147971.2020.9213749&partnerID=40&md5=3460945d31710ee0904e291a53658e74},
	doi = {10.1109/ICCIT-144147971.2020.9213749},
	abstract = {Formal methods are widely used by using mathematical notations to precisely express requirements specification. In this paper, we discuss the formal specification using a case study of Examination Scheduling System (ESS). ESS is a system that generates exam schedule by using genetic algorithm. ESS is developed to solve the exam scheduling problem in order to reduce time-consuming for conventional manually managing the exam venue. By using genetic algorithm, it helps to generate exam schedule very fast and reduce time taken on processing the exam schedule manually. The formal specification of ESS using Z language is also presented in order to show the mapping of the implementation of ESS with its design by using the formal specification. The Z schema can effectively remove ambiguity presents in natural language specification. Hence, this will help to reduce defect in developing the system during implementation phase. © 2020 IEEE.},
	language = {English},
	booktitle = {2020 {International} {Conference} on {Computing} and {Information} {Technology}, {ICCIT} 2020},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Ibrahim, Rosziati and Bani Amin, Ammar Aminuddin and Zainuri Saringat, Mohd},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Scheduling, Genetic algorithms, Formal specification, Requirements specifications, Natural language specifications, Mathematical notations, Reduce time, Scheduling problem, Scheduling systems, Z language, Z specifications},
	annote = {Cited by: 3; Conference name: 2020 International Conference on Computing and Information Technology, ICCIT 2020; Conference date: 9 September 2020 through 10 September 2020; Conference code: 165300},
	annote = {Cited by: 4; Conference name: 2020 International Conference on Computing and Information Technology, ICCIT 2020; Conference date: 9 September 2020 through 10 September 2020; Conference code: 165300},
	annote = {RELEVANCE: LOW
},
}


@book{harris_generation_2020,
	title = {Generation of verification artifacts from natural language descriptions},
	isbn = {978-3-030-52273-5 978-3-030-52271-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148547855&doi=10.1007%2f978-3-030-52273-5_3&partnerID=40&md5=ddd23ce069f3d91f899db13661255e16},
	abstract = {This chapter describes the generation of formal verification artifacts from natural language (NL) hardware specifications. Difficulties in the formalization process are described, including the linguistic variation problem which causes the mapping from NL to formal artifacts to be many-to-one. The use of semantic parsers is described as an approach which can map NL to formal models while addressing problems including linguistic variation. This chapter presents two approaches which use semantic parsing to generate formal models. The first approach uses an attribute grammar to generate SystemVerilog properties, and the second approach generates bus transactors which can be used as golden models of bus behavior. © Springer Nature Switzerland AG 2020.},
	language = {English},
	publisher = {Springer International Publishing},
	author = {Harris, Ian G. and Harris, Christopher B.},
	year = {2020},
	doi = {10.1007/978-3-030-52273-5_3},
	note = {Publication Title: Natural Language Processing for Electronic Design Automation
Type: Book chapter},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Publication Title: Natural Language Processing for Electronic Design Automation Type: Book},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{hu_constructing_2020,
	title = {Constructing formal specification models from domain specific natural language requirements},
	isbn = {978-0-7381-0497-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098324503&doi=10.1109%2fISSSR51244.2020.00017&partnerID=40&md5=a89cd94768651813a00341752759776d},
	doi = {10.1109/ISSSR51244.2020.00017},
	abstract = {One important way to improve the quality of safety-critical software is to produce a good software requirement satisfying several key properties, such as: integrity, consistency, and well organized, etc. Our work is based on airborne software domain, and propose a framework to translate the software requirements, which are itemized with domain natural language in avionics, effectively into a formal specification model VRM (Variable Relation Model), which has table-style structures with formal semantics. Firstly, considering avionics domain characteristics, a domain concept library is established including different types of variables and concepts. Then, a set of domain-oriented requirements templates are defined, such as: general event/condition, display event/condition, etc. According to VRM model element semantics, three types model construction algorithms are designed to complete the translation automatically. And in the case study, the Engine Indication and Crew Warning System (EICAS) was selected to show how to construct formal models from natural language requirements. © 2020 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2020 6th {International} {Symposium} on {System} and {Software} {Reliability}, {ISSSR} 2020},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Hu, Jun and Hu, Jiancheng and Wang, Wenxuan and Kang, Jiexiang and Wang, Hui and Gao, Zhongjie},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Semantics, Natural language requirements, Software requirements, Safety engineering, Avionics, Domain template library, Engine indication and crew warning system, Model transition, Relation models, Safety critical software, Specification models, Template libraries, Translation (languages), Variable relation model},
	pages = {52 -- 60},
	annote = {Cited by: 6; Conference name: 6th International Symposium on System and Software Reliability, ISSSR 2020; Conference date: 24 October 2020 through 25 October 2020; Conference code: 165486},
	annote = {Cited by: 8; Conference name: 6th International Symposium on System and Software Reliability, ISSSR 2020; Conference date: 24 October 2020 through 25 October 2020; Conference code: 165486},
	annote = {RELEVANCE: HIGH
},
}


@article{van_der_aa_say_2020,
	title = {Say it in your own words: {Defining} declarative process models using speech recognition},
	volume = {392 LNBIP},
	issn = {18651348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091292402&doi=10.1007%2f978-3-030-58638-6_4&partnerID=40&md5=0b6d7e6d605b2156ce4b34a1359b0e7f},
	doi = {10.1007/978-3-030-58638-6_4},
	abstract = {Declarative, constraint-based approaches have been proposed to model loosely-structured business processes, mediating between support and flexibility. A notable example is the Declare framework, equipped with a graphical declarative language whose semantics can be characterized with several logic-based formalisms. Up to now, the main problem hampering the use of Declare constraints in practice has been the difficulty of modeling them: Declare’s formal notation is difficult to understand for users without a background in temporal logic, whereas its graphical notation has been shown to be unintuitive. Therefore, in this work, we present and evaluate an analysis toolkit that aims at bypassing this issue by providing users with the possibility to model Declare constraints using their own way of expressing them. The toolkit contains a Declare modeler equipped with a speech recognition mechanism. It takes as input a vocal statement from the user and converts it into the closest (set of) Declare constraint(s). The constraints that can be modeled with the tool cover the entire Multi-Perspective extension of Declare (MP-Declare), which complements control-flow constraints with data and temporal perspectives. Although we focus on Declare, the work presented in this paper represents the first attempt to test the feasibility of speech recognition in business process modeling as a whole. © Springer Nature Switzerland AG 2020.},
	language = {English},
	journal = {Lecture Notes in Business Information Processing},
	author = {van der Aa, Han and Balder, Karl Johannes and Maggi, Fabrizio Maria and Nolte, Alexander},
	editor = {D, Fahland and C, Ghidini and J, Becker and M, Dumas},
	year = {2020},
	note = {ISBN: 978-303058637-9
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Semantics, Computer circuits, Declarative process models, Graphical notation, Declarative Languages, Speech recognition, Enterprise resource management, Business process model, Multi-perspective, Analysis toolkits, Logic based formalism, Recognition mechanism},
	pages = {51 -- 67},
	annote = {Cited by: 4; Conference name: 18th International Conference on Business Process Management, BPM 2020; Conference date: 13 September 2020 through 18 September 2020; Conference code: 244799},
}


@article{gavran_interactive_2020,
	title = {Interactive {Synthesis} of {Temporal} {Specifications} from {Examples} and {Natural} {Language}},
	volume = {4},
	url = {https://doi.org/10.1145/3428269},
	doi = {10.1145/3428269},
	abstract = {Motivated by applications in robotics, we consider the task of synthesizing linear temporal logic (LTL) specifications based on examples and natural language descriptions. While LTL is a flexible, expressive, and unambiguous language to describe robotic tasks, it is often challenging for non-expert users. In this paper, we present an interactive method for synthesizing LTL specifications from a single example trace and a natural language description. The interaction is limited to showing a small number of behavioral examples to the user who decides whether or not they exhibit the original intent. Our approach generates candidate LTL specifications and distinguishing examples using an encoding into optimization modulo theories problems. Additionally, we use a grammar extension mechanism and a semantic parser to generalize synthesized specifications to parametric task descriptions for subsequent use. Our implementation in the tool LtlTalk starts with a domain-specific language that maps to a fragment of LTL and expands it through example-based user interactions, thus enabling natural language-like robot programming, while maintaining the expressive power and precision of a formal language. Our experiments show that the synthesis method is precise, quick, and asks only a few questions to the users, and we demonstrate in a case study how LtlTalk generalizes from the synthesized tasks to other, yet unseen, tasks.},
	number = {OOPSLA},
	journal = {Proc. ACM Program. Lang.},
	author = {Gavran, Ivan and Darulova, Eva and Majumdar, Rupak},
	month = nov,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {natural language processing, Natural language processing systems, Natural languages, Semantics, Temporal logic, Formal languages, Specifications, Domain specific languages, Problem oriented languages, Robotics, End effectors, Expressive power, Extension mechanisms, Interactive methods, Linear temporal logic specifications, LTL, program synthesis, Robot programming, robots, specification, Synthesis method, Temporal specification},
	annote = {Cited by: 6; All Open Access, Bronze Open Access},
	annote = {Cited by: 7; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: HIGH

They present LTLtalk

In this paper, we present an interactive method for synthesizing LTL specifications from a single example trace and a natural language description.
LTL provides a flexible, expressive, and unambiguous mechanism to describe complex task. Unfortunately, specifying tasks in LTL is challenging for untrained users

First, a synthesis procedure that takes a natural language description of a task and an example execution trace from the user and generates a set of candidate LTL specifications. Second, an interactive loop that uses distinguishing examples to identify the correct LTL specification. Third, a generalization step that eventually learns a parameterized LTL specification. The three components ensure the following properties.

Natural Language Interfaces for Robotics. In an attempt to provide a more natural specificationlanguage for robotics, but keep the precision of a formal language, Kress-Gazit et al. [2008] proposea controlled, natural looking language that matches a fragment of LTL.

cited in:

Learning Linear Temporal Properties for Autonomous Robotic Systems
Differentiable Inference of Temporal Logic Formulas
Formal Specifications from Natural Language

},
}


@inproceedings{frederiksen_automated_2020,
	title = {Automated {Assertion} {Generation} from {Natural} {Language} {Specifications}},
	volume = {2020-November},
	isbn = {978-1-72819-113-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100202487&doi=10.1109%2fITC44778.2020.9325264&partnerID=40&md5=b0c5018ea8d5d4176bf1c4f53d5ad711},
	doi = {10.1109/ITC44778.2020.9325264},
	abstract = {We explore contemporary natural language processing (NLP) techniques for converting NL specifications found in design documents directly to an temporal logic-like intermediate representation (IR). Generally, attempts to use NLP for assertion generation have relied on restrictive sentence formats and grammars as well as being difficult to handle new sentence formats. We tackle these issues by first implementing a system that uses commonsense mappings to process input sentences into a normalized form. Then we use frame semantics to convert the normalized sentences into an IR based on the information and context contained in the Frames. Through this we are able to handle a large number of sentences from real datasheets allowing for complex formats using temporal conditions, property statements, and compound statements; all order agnostic. Our system can also be easy extended by modifying an external, rather than internal, commonsense knowledge-base to handle new sentence formats without requiring code changes or intimate knowledge of the algorithms used. © 2020 IEEE.},
	language = {English},
	booktitle = {Proceedings - {International} {Test} {Conference}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Frederiksen, Steven J. and Aromando, John and Hsiao, Michael S.},
	year = {2020},
	note = {ISSN: 10893539
Type: Conference paper},
	keywords = {Natural language processing systems, Semantics, Intermediate representations, NAtural language processing, Specifications, Natural language specifications, Assertion generations, Commonsense knowledge base, Design documents, Frame semantics, Knowledge based systems, Process inputs},
	annote = {Cited by: 1; Conference name: 2020 IEEE International Test Conference, ITC 2020; Conference date: 1 November 2020 through 6 November 2020; Conference code: 166654},
	annote = {Cited by: 2; Conference name: 2020 IEEE International Test Conference, ITC 2020; Conference date: 1 November 2020 through 6 November 2020; Conference code: 166654},
	annote = {RELEVANCE:  MEDIUM
},
}


@article{osama_comprehensive_2022,
	title = {A {Comprehensive} {Requirement} {Capturing} {Model} {Enabling} the {Automated} {Formalisation} of {NL} {Requirements}},
	volume = {4},
	url = {https://doi.org/10.1007/s42979-022-01449-7},
	doi = {10.1007/s42979-022-01449-7},
	abstract = {Formalising natural language (NL) requirements is essential to have formal specifications that enable formal checking and improve the quality of requirements. However, the existing formalisation techniques require engineers to (re)write the system requirements using a set of requirements templates with predefined and limited structure and semantics. The main drawback of using such templates, usually with a fixed format, is the inability to capture diverse requirements outside the scope of the template structure. To address this limitation, a comprehensive reference model is needed to enable capturing key requirement properties regardless of their format, order, or structure. NLP technique can then be used to convert unrestricted NL requirements into the reference model. Using a set of transformation rules, the reference model representing the requirements can be transformed into the target formal notation. In this paper, we introduce requirement capturing model (RCM) to represent NL requirements by adapting to their key properties and without imposing constraints on how the requirements are written. We also implemented a requirements formalisation approach that supports transforming RCM into temporal logic (TL). In addition, we developed an automated similarity checking approach to check the correctness of the constructed RCM structures against the source NL requirements. We carried out extensive evaluation of RCM by comparing it against 15 existing requirements representation approaches on a dataset of 162 requirement sentences. The results show that RCM supports a much wider range of requirements formats compared to any of the existing approaches.},
	number = {1},
	journal = {SN Comput. Sci.},
	author = {Osama, Mohamed and Zaki-Ismail, Aya and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	month = nov,
	year = {2022},
	note = {Place: Berlin, Heidelberg
Publisher: Springer-Verlag},
	keywords = {Requirement engineering, Requirement formalisation, Requirement modelling, Requirement representation},
	annote = {Cited by: 0},
	annote = {Cited by: 1},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{pan_data-efficient_2023,
	title = {Data-{Efficient} {Learning} of {Natural} {Language} to {Linear} {Temporal} {Logic} {Translators} for {Robot} {Task} {Specification}},
	volume = {2023-May},
	isbn = {979-835032365-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168663890&doi=10.1109%2fICRA48891.2023.10161125&partnerID=40&md5=5329f8f8d7fb1f2a3e74425517d4e2e2},
	doi = {10.1109/ICRA48891.2023.10161125},
	abstract = {To make robots accessible to a broad audience, it is critical to endow them with the ability to take universal modes of communication, like commands given in natural language, and extract a concrete desired task specification, defined using a formal language like linear temporal logic (LTL). In this paper, we present a learning-based approach for translating from natural language commands to LTL specifications with very limited human-labeled training data. This is in stark contrast to existing natural-language to LTL translators, which require large human-labeled datasets, often in the form of labeled pairs of LTL formulas and natural language commands, to train the translator. To reduce reliance on human data, our approach generates a large synthetic training dataset through algorithmic generation of LTL formulas, conversion to structured English, and then exploiting the paraphrasing capabilities of modern large language models (LLMs) to synthesize a diverse corpus of natural language commands corresponding to the LTL formu-las. We use this generated data to finetune an LLM and apply a constrained decoding procedure at inference time to ensure the returned LTL formula is syntactically correct. We evaluate our approach on three existing LTL/natural language datasets and show that we can translate natural language commands at 75\% accuracy with far less human data (≤12 annotations). Moreover, when training on large human-annotated datasets, our method achieves higher test accuracy (95\% on average) than prior work. Finally, we show the translated formulas can be used to plan long-horizon, multi-stage tasks on a 12D quadrotor. © 2023 IEEE.},
	language = {English},
	booktitle = {Proceedings - {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Pan, Jiayi and Chou, Glen and Berenson, Dmitry},
	year = {2023},
	note = {ISSN: 10504729
Type: Conference paper},
	keywords = {Natural languages, Temporal logic, Formal languages, Linear temporal logic, Specifications, Task specifications, Computer circuits, Automation, Translation (languages), Temporal logic formula, Efficient learning, Human data, Language model, Large dataset, Learning-based approach, Natural extracts, Robot tasks, Data models, Training, Decoding, Training data},
	pages = {11554 -- 11561},
	annote = {Cited by: 0; Conference name: 2023 IEEE International Conference on Robotics and Automation, ICRA 2023; Conference date: 29 May 2023 through 2 June 2023; Conference code: 190430; All Open Access, Green Open Access},
	annote = {Cited by: 1; Conference name: 2023 IEEE International Conference on Robotics and Automation, ICRA 2023; Conference date: 29 May 2023 through 2 June 2023; Conference code: 190430; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{salari_experiment_2023,
	title = {An {Experiment} in {Requirements} {Engineering} and {Testing} using {EARS} {Notation} for {PLC} {Systems}},
	isbn = {979-835033335-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163061454&doi=10.1109%2fICSTW58534.2023.00016&partnerID=40&md5=addb89c7f9e42b90b0b70781b546b00a},
	doi = {10.1109/ICSTW58534.2023.00016},
	abstract = {Regulatory standards for engineering safety-critical systems often demand both traceable requirements and specification-based testing, during development. Requirements are often written in natural language, yet for specification purposes, this may be supplemented by formal or semi-formal descriptions, to increase clarity. However, the choice of notation of the latter is often constrained by the training, skills, and preferences of the designers.The Easy Approach to Requirements Syntax (EARS) addresses the inherent imprecision of natural language requirements with respect to potential ambiguity and lack of accuracy. This paper investigates requirement formalization using EARS and specification-based testing of embedded software written in the IEC 61131-3 language, a programming standard used for developing Programmable Logic Controllers (PLC). Further, we investigate, by means of an experiment, how human participants translate natural language requirements into EARS and how they use the latter to test PLC software. We report our observations during the experiments, including the type of EARS patterns participants use to structure natural language requirements and challenges during the specification phase, as well as present the results of testing based on EARS-formalized requirements. © 2023 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2023 {IEEE} 16th {International} {Conference} on {Software} {Testing}, {Verification} and {Validation} {Workshops}, {ICSTW} 2023},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Salari, Mikael Ebrahimi and Paul Enoiu, Eduard and Afzal, Wasif and Seceleanu, Cristina},
	year = {2023},
	note = {Type: Conference paper},
	keywords = {Programming, Testing, Natural language processing systems, Natural languages, Natural language requirements, Specifications, Software testing, Safety engineering, Safety testing, Requirement engineering, Syntactics, Safety critical systems, Controller systems, Easy approach to requirement syntax, Engineering safety, Programmable logic controllers, Regulatory standards, Specification Based Testing, Traceable requirements, Well testing, Training, Ear, EARS, PLC, Programmable logic devices, Requirement Engineering},
	pages = {10 -- 17},
	annote = {Cited by: 0; Conference name: 16th IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2023; Conference date: 16 April 2023 through 20 April 2023; Conference code: 189070},
	annote = {Cited by: 0; Conference name: 16th IEEE International Conference on Software Testing, Verification and Validation Workshops, ICSTW 2023; Conference date: 16 April 2023 through 20 April 2023; Conference code: 189070},
	annote = {RELEVANCE: LOW
},
}


@article{soavi_legal_2022,
	title = {From {Legal} {Contracts} to {Formal} {Specifications}: {A} {Systematic} {Literature} {Review}},
	volume = {3},
	url = {https://doi.org/10.1007/s42979-022-01228-4},
	doi = {10.1007/s42979-022-01228-4},
	abstract = {The opportunity to automate and monitor the execution of legal contracts is gaining increasing interest in Business and Academia, thanks to the advent of smart contracts, blockchain technologies, and the Internet of Things. A critical issue in developing smart contract systems is the formalization of legal contracts, which are traditionally expressed in natural language with all the pitfalls that this entails. This paper presents a systematic literature review of papers for the main steps related to the transformation of a legal contract expressed in natural language into a formal specification. Key research studies have been identified, classified, and analyzed according to a four-step transformation process: (a) structural and semantic annotation to identify legal concepts in text, (b) identification of relationships among concepts, (c) contract domain modeling, and (d) generation of a formal specification. Each one of these steps poses serious research challenges that have been the subject of research for decades. The systematic review offers an overview of the most relevant research efforts undertaken to address each step and identifies promising approaches, best practices, and existing gaps in the literature.},
	number = {5},
	journal = {SN Comput. Sci.},
	author = {Soavi, Michele and Zeni, Nicola and Mylopoulos, John and Mich, Luisa},
	month = jun,
	year = {2022},
	note = {Place: Berlin, Heidelberg
Publisher: Springer-Verlag},
	keywords = {Requirement, Conceptual model, Legal contract, Semantic annotation, Specification, Systematic literature review},
	annote = {Cited by: 4; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 6; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{soavi_contratto_2022,
	title = {Contratto – {A} {Method} for {Transforming} {Legal} {Contracts} into {Formal} {Specifications}},
	volume = {446 LNBIP},
	issn = {18651348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130940713&doi=10.1007%2f978-3-031-05760-1_20&partnerID=40&md5=9ac2508c4cf1c3835e5b5fc77d541178},
	doi = {10.1007/978-3-031-05760-1_20},
	abstract = {Legal contracts have been used for millennia to conduct business transactions world-wide. Such contracts are expressed in natural language, and usually come in written form. We are interested in producing formal specifications from such legal text that can be used to formally analyze contracts, also serve as launching pad for generating smart contracts, information systems that partially automate, monitor and control the execution of legal contracts. We have been developing a method for transforming legal contract documents into specifications, adopting a semantic approach where transformation is treated as a text classification, rather than a natural language processing problem. The method consists of five steps that (a) Identify domain terms in the contract and manually disambiguate them when necessary, in consultation with stakeholders; (b) Semantically annotate text identifying obligations, powers, contracting parties, assets and situations; (c) Identify relationships among the concepts mined in (b); (d) Generate a domain model based on the terms identified in (a), as well as parameters and local variables for the contract; (e) Generate expressions that formalize the conditions of obligations and powers using terms identified in earlier steps in a contract specification language. This paper presents the method through an illustrative example, also reports on a prototype implementation of an environment that supports the method. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Business Information Processing},
	author = {Soavi, Michele and Zeni, Nicola and Mylopoulos, John and Mich, Luisa},
	editor = {R, Guizzardi and J, Ralyté and X, Franch},
	year = {2022},
	note = {ISBN: 978-303105759-5
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Semantics, Specification languages, Classification (of information), Text processing, Smart contract, Ontology's, Information retrieval systems, Monitor and control, Semantic annotations, Legal contracts, Business transaction, Contract document, Domain model, Legal texts, Power},
	pages = {338 -- 353},
	annote = {Cited by: 1; Conference name: 16th International Conference on Research Challenges in Information Science, RCIS 2022; Conference date: 17 May 2022 through 20 May 2022; Conference code: 277829},
	annote = {Cited by: 1; Conference name: 16th International Conference on Research Challenges in Information Science, RCIS 2022; Conference date: 17 May 2022 through 20 May 2022; Conference code: 277829},
	annote = {RELEVANCE: HIGH
},
}


@article{sin_timeline_2022,
	title = {{TimeLine} {Depiction}: {An} {Approach} to {Graphical} {Notation} for {Supporting} {Temporal} {Property} {Specification}},
	volume = {19},
	issn = {1614-5046},
	url = {https://doi.org/10.1007/s11334-022-00501-2},
	doi = {10.1007/s11334-022-00501-2},
	abstract = {The finite-state verification techniques such as model checking allow for automated checking whether system model described with automata satisfy temporal properties, or not. The temporal properties should be typically specified in temporal logic formulae, which is a difficult task for programmers who aren’t verification experts. Therefore, there is a few of research to propose description languages with which non-experts can accurately express temporal requirements on system’s behaviors and the methods transforming them automatically into temporal property specification of particular model checker. We analyzed various researches aimed at the construction of property specifications, that is, machine translation from natural language to temporal logical formula, property specification pattern and graphical scenarios for specifying property, and so on. Based on the analysis, in this paper, we present a visual language called TimeLineDepic, which is a user-friendly graphical notation for temporal property description and whose expressive power is same as other languages. And we propose a method to transform TimeLineDepic to buchi automata (never claim) and insert it in promela-based model for model checker SPIN.},
	number = {3},
	journal = {Innov. Syst. Softw. Eng.},
	author = {Sin, Chun-Ok and Kim, Yong-Sok},
	month = dec,
	year = {2022},
	note = {Place: Berlin, Heidelberg
Publisher: Springer-Verlag},
	keywords = {Model checking, Specifications, Graphical notation, Verification techniques, Models checking, Temporal logic formula, Automata theory, Property Specification, Buchi automata, Finite state verification, Model checker, Property specification, System models, Temporal property, Visual language, Visual languages},
	pages = {319--335},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: LOW  - STL
The temporal properties should be typically specified in temporal logic formulae, which is a difficult task for programmers who aren’t verification experts. Therefore, there is a few of research to propose description languages with which non-experts can accurately express temporal requirements on system’s behaviors and the methods transforming them automatically into temporal property specification of particular model checker.

Saw that researchers aim to machine translation from natural language to temporal logical formula,

Propose visual language called “TimeLineDepic”

They cite ARSENAL [15] inputs requirements described in natural languages for safety–critical systems and generates property specifications which are described by SAL or LTL logic formula.

Very nice intro

Parece que solo se centra en control flow
},
}


@article{vogel_property_2023,
	title = {A {Property} {Specification} {Pattern} {Catalog} for {Real}-{Time} {System} {Verification} with {UPPAAL}},
	volume = {154},
	issn = {0950-5849},
	url = {https://doi.org/10.1016/j.infsof.2022.107100},
	doi = {10.1016/j.infsof.2022.107100},
	number = {C},
	journal = {Inf. Softw. Technol.},
	author = {Vogel, Thomas and Carwehl, Marc and Rodrigues, Genaína Nunes and Grunske, Lars},
	month = feb,
	year = {2023},
	note = {Place: USA
Publisher: Butterworth-Heinemann},
	keywords = {Natural language processing systems, Specification patterns, Temporal logic, Natural language requirements, Model checking, Specifications, Computer circuits, Automation, Translation (languages), Real time systems, Verification process, Real time requirement, System verifications, Automata theory, Interactive computer systems, Observer automata, Property Specification, Property specification pattern, Property specification patterns, Real - Time system, Real-time systems, Timed temporal logic},
	annote = {Cited by: 1; All Open Access, Green Open Access},
	annote = {Cited by: 1; All Open Access, Green Open Access},
	annote = {Cited by: 3; All Open Access, Green Open Access},
	annote = {RELEVANCE:  LOW
18 pages, not very clear


},
}


@inproceedings{madala_comprehensive_2023,
	title = {A {Comprehensive} {Analysis} of {Methods} to {Write} {Requirements} for {Machine} {Learning} {Components} used in {Autonomous} {Vehicles}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160730652&doi=10.4271%2f2023-01-0866&partnerID=40&md5=eef0dcb38b52d09bc0673a1db803e589},
	doi = {10.4271/2023-01-0866},
	abstract = {Machine learning components are widely used in autonomous vehicles for implementing functionalities related to perception and planning. To verify if the vehicle-level functionalities are as specified, one of the widely used approaches is requirements-based testing. However, writing testable requirements for machine learning components can be challenging since the machine learning outcomes are seldom known in advance. Nevertheless, it is important to have a specification that details the expected behavior from machine learning components. In this paper, we discuss different approaches to write a specification for machine learning algorithms that are used in autonomous vehicles. These approaches include natural language requirements, user stories, use case specifications, behavioral diagrams, data as requirements, and formal specification methods. We also propose a tabular specification method for specifying requirements of machine learning algorithms. We use a sample operational design domain (ODD) and system architecture to discuss the advantages and disadvantages of each of the techniques. We also discuss which approaches can aid with testing as well as error analysis of the model generated using the machine learning algorithms. © 2023 SAE International. All Rights Reserved.},
	booktitle = {{SAE} {Technical} {Papers}},
	author = {Madala, Kaushik and Krishnamoorthy, Jayalekshmi and Gil Batres, Andrea and Avalos Gonzalez, Carlos and Chang, Melody},
	year = {2023},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural language requirements, Use case specifications, Machine learning, Learning algorithms, Machine-learning, Well testing, Autonomous vehicles, Machine learning algorithms, Machine components, User stories, Autonomous Vehicles, Behavioral diagrams, Comprehensive analysis, Formal specification method, Learning outcome},
	annote = {Cited by: 0},
	annote = {Cited by: 0; Conference name: SAE 2023 World Congress Experience, WCX 2023; Conference date: 18 April 2023 through 20 April 2023; Conference code: 187990},
	annote = {Cited by: 0; Conference name: SAE 2023 World Congress Experience, WCX 2023; Conference date: 18 April 2023 through 20 April 2023; Conference code: 187990},
	annote = {RELEVANCE: MEDIUM

},
}


@article{andre_formalizing_2023,
	title = {Formalizing {UML} {State} {Machines} for {Automated} {Verification} - {A} {Survey}},
	volume = {55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149011792&doi=10.1145%2f3579821&partnerID=40&md5=13d5484a94733991d66dafc778a7c47a},
	doi = {10.1145/3579821},
	abstract = {The Unified Modeling Language (UML) is a standard for modeling dynamic systems. UML behavioral state machines are used for modeling the dynamic behavior of object-oriented designs. The UML specification, maintained by the Object Management Group (OMG), is documented in natural language (in contrast to formal language). The inherent ambiguity of natural languages may introduce inconsistencies in the resulting state machine model. Formalizing UML state machine specification aims at solving the ambiguity problem and at providing a uniform view to software designers and developers. Such a formalization also aims at providing a foundation for automatic verification of UML state machine models, which can help to find software design vulnerabilities at an early stage and reduce the development cost. We provide here a comprehensive survey of existing work from 1997 to 2021 related to formalizing UML state machine semantics for the purpose of conducting model checking at the design stage. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	number = {13s},
	journal = {ACM Computing Surveys},
	author = {André, Étienne and Liu, Shuang and Liu, Yang and Choppy, Christine and Sun, Jun and Dong, Jin Song},
	year = {2023},
	note = {Type: Article},
	keywords = {Formal specification, Natural languages, Software design, Semantics, Formal languages, Model checking, Formal verification, Unified Modeling Language, Object oriented programming, Automated verification, State-machine, Dynamic behaviors, Object management, Behavioral state machines, Language specification, Model dynamics, Object-oriented design, State machine models},
	annote = {Cited by: 1},
	annote = {Cited by: 1},
	annote = {Cited by: 4},
	annote = {RELEVANCE: LOW
},
}


@article{wanli_zhanjun_hulisong_wangjiarun_lv_simulation_2022,
	title = {A {Simulation} {Framework} for {VRM} {Requirement} {Model}},
	url = {{http://link.springer.com/chapter/10.1007/978-981-19-0390-8_114}},
	doi = {10.1007/978-981-19-0390-8_114},
	journal = {Communications, Signal Processing, and Systems},
	author = {{WanLi ZhanJun HuLiSong WangJiaRun Lv}},
	year = {2022},
	keywords = {Natural language processing systems, Requirements engineering, Modeling languages, SysML, System requirements, Requirements modeling, Modeling simulation, Design problems, Mode, Research method, Simulation behavior, Simulation framework, VRM},
	annote = {Cited by: 0; Conference name: 10th International Conference on Communications, Signal Processing, and Systems, CSPS 2021; Conference date: 24 July 2021 through 25 July 2021; Conference code: 276119},
	annote = {Cited by: 0; Conference name: 10th International Conference on Communications, Signal Processing, and Systems, CSPS 2021; Conference date: 24 July 2021 through 25 July 2021; Conference code: 276119},
	annote = {RELEVANCE: LOW
},
}


@article{nguyen_identifying_2024,
	title = {Identifying and fixing ambiguities in, and semantically accurate formalisation of, behavioural requirements},
	issn = {16191366},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187920481&doi=10.1007%2fs10270-023-01142-0&partnerID=40&md5=bede97effff98417b65b4ba85f6e4fe3},
	doi = {10.1007/s10270-023-01142-0},
	abstract = {To correctly formalise requirements expressed in natural language, ambiguities must first be identified and then fixed. This paper focuses on behavioural requirements (i.e. requirements related to dynamic aspects and phenomena). Its first objective is to show, based on a practical, public case study, that the disambiguation process cannot be fully automated: even though natural language processing (NLP) tools and machine learning might help in the identification of ambiguities, fixing them often requires a deep, application-specific understanding of the reasons of being of the system of interest, of the characteristics of its environment, of which trade-offs between conflicting objectives are acceptable, and of what is achievable and what is not; it may also require arduous negotiations between stakeholders. Such an understanding and consensus-making ability is not in the reach of current tools and technologies, and will likely remain so for a long while. Beyond ambiguity, requirements are often marred by various other types of defects that could lead to wholly unacceptable consequences. In particular, operational experience shows that requirements inadequacy (whereby, in some of the situations the system could face, what is required is woefully inappropriate or what is necessary is left unspecified) is a significant cause for systems failing to meet expectations. The second objective of this paper is to propose a semantically accurate behavioural requirements formalisation format enabling tool-supported requirements verification, notably with simulation. Such support is necessary for the engineering of large and complex cyber-physical and socio-technical systems to ensure, first, that the specified requirements indeed reflect the true intentions of their authors and second, that they are adequate for all the situations the system could face. To that end, the paper presents an overview of the BASAALT (Behaviour Analysis and Simulation All Along systems Life Time) systems engineering method, and of FORM-L (FOrmal Requirements Modelling Language), its supporting language, which aims at representing as accurately and completely as possible the semantics expressed in the original, natural language behavioural requirements, and is markedly different from languages intended for software code generation. The paper shows that generally, semantically accurate formalisation is not a simple paraphrasing of the original natural language requirements: additional elements are often needed to fully and explicitly reflect all that is implied in natural language. To provide such complements for the case study presented in the paper, we had to follow different formalisation patterns, i.e. sequences of formalisation steps. For this paper, to avoid being skewed by what a particular automatic tool can and cannot do, BASAALT and FORM-L were applied manually. Still, the lessons learned could be used to specify and develop NLP tools that could assist the disambiguation and formalisation processes. However, more studies are needed to determine whether an exhaustive set of formalisation patterns can be identified to fully automate the formalisation process. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.},
	language = {English},
	journal = {Software and Systems Modeling},
	author = {Nguyen, Thuy and Sayar, Imen and Ebersold, Sophie and Bruel, Jean-Michel},
	year = {2024},
	note = {Publisher: Springer Science and Business Media Deutschland GmbH
Type: Article},
	keywords = {Natural language processing systems, Natural languages, Requirements engineering, Semantics, Modeling languages, Case-studies, Computer software, Formalisation, Learning algorithms, Computer simulation languages, Requirement, Economic and social effects, Analysis and simulation, Behavior analysis, Behaviors simulation, Disambiguation, K3 case study, Natural Language Processing Tools},
	annote = {Publisher: Springer Science and Business Media Deutschland GmbH Type: Article},
}


@article{hu_deploying_2024,
	title = {Deploying and {Evaluating} {LLMs} to {Program} {Service} {Mobile} {Robots}},
	volume = {9},
	issn = {23773766},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184339520&doi=10.1109%2fLRA.2024.3360020&partnerID=40&md5=5d19a1c212d9481a8e5052da1f046aae},
	doi = {10.1109/LRA.2024.3360020},
	abstract = {Recent advancements in large language models (LLMs) have spurred interest in using them for generating robot programs from natural language, with promising initial results. We investigate the use of LLMs to generate programs for service mobile robots leveraging mobility, perception, and human interaction skills, and where accurate sequencing and ordering of actions is crucial for success. We contribute CodeBotler, an open-source robot-agnostic tool to program service mobile robots from natural language, and RoboEval, a benchmark for evaluating LLMs' capabilities of generating programs to complete service robot tasks. CodeBotler performs program generation via few-shot prompting of LLMs with an embedded domain-specific language (eDSL) in Python, and leverages skill abstractions to deploy generated programs on any general-purpose mobile robot. RoboEval evaluates the correctness of generated programs by checking execution traces starting with multiple initial states, and checking whether the traces satisfy temporal logic properties that encode correctness for each task. RoboEval also includes multiple prompts per task to test for the robustness of program generation. We evaluate several popular state-of-the-art LLMs with the RoboEval benchmark, and perform a thorough analysis of the modes of failures, resulting in a taxonomy that highlights common pitfalls of LLMs at generating robot programs. © 2016 IEEE.},
	language = {English},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Hu, Zichao and Lucchetti, Francesca and Schlesinger, Claire and Saxena, Yash and Freeman, Anders and Modak, Sadanand and Guha, Arjun and Biswas, Joydeep},
	year = {2024},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.
Type: Article},
	keywords = {Natural languages, Robots, Software testing, Problem oriented languages, Software-tools, Benchmarking, Human robot interaction, Robot programming, Python, Task analysis, Job analysis, Open source software, Benchmark testing, Service robots, Mobile robots, Human centered robotics, Reproducibilities, Service robotics, Social HRI, Software tool for benchmarking and reproducibility, Software tool for robot programming, human-centered robotics, service robotics, social HRI, Software tools for benchmarking and reproducibility, software tools for robot programming},
	pages = {2853 -- 2860},
	annote = {Cited by: 0; All Open Access, Green Open Access},
	annote = {Cited by: 0; All Open Access, Green Open Access},
	annote = {Cited by: 0; All Open Access, Green Open Access},
	annote = {Publisher: Institute of Electrical and Electronics Engineers Inc. Type: Article},
}


@inproceedings{zeraatkar_advancements_2024,
	title = {Advancements in {Secure} {Computing}: {Exploring} {Automated} {Repair} {Debugging} and {Verification} {Techniques} for {Hardware} {Design}},
	isbn = {979-835036013-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186749020&doi=10.1109%2fCCWC60891.2024.10427806&partnerID=40&md5=4a29f87c7a18f0a23afc06dbf4b51a6e},
	doi = {10.1109/CCWC60891.2024.10427806},
	abstract = {This paper studies the recent advancement of techniques for automating the repair and verification of hardware designs. Challenges associated with debugging and fixing bugs in hardware designs are discussed, emphasizing the importance of addressing these issues prior to the manufacturing of chips. It categorizes approaches according to their contributions and indicates specific techniques used in each approach. The studies demonstrate the effectiveness of different methodologies, such as fault localization, confidence scoring, Large Language Models, and learning-based approaches, in automatically repairing as well as hardware design verification. According to the results of each approach, these techniques have the potential to enhance the security and reliability of hardware systems. © 2024 IEEE.},
	language = {English},
	booktitle = {2024 {IEEE} 14th {Annual} {Computing} and {Communication} {Workshop} and {Conference}, {CCWC} 2024},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Zeraatkar, Alireza Abolhasani and Kamran, Parnian Shabani and Al-Asaad, Hussain},
	editor = {R, Paul and A, Kundu},
	year = {2024},
	note = {Type: Conference paper},
	keywords = {Manufacturing, Security, Formal verification, Program debugging, Verification techniques, Language model, Hardware, Maintenance engineering, Computational linguistics, Repair, Computer aided design, Formal Verification, Model based approach, Hardware design, Automatic code repair, Automatic codes, Fault localization, Fuzzing, Language learning, Large language model, Large Language Models, Computer bugs, Automatic Code Repair, Debugging, Location awareness},
	pages = {357 -- 364},
	annote = {Conference name: 2024 IEEE 14th Annual Computing and Communication Workshop and Conference, CCWC 2024; Conference date: 8 January 2024 through 10 January 2024; Conference code: 197315},
	annote = {Conference name: 2024 IEEE 14th Annual Computing and Communication Workshop and Conference, CCWC 2024; Conference date: 8 January 2024 through 10 January 2024; Conference code: 197315},
	annote = {Conference name: 2024 IEEE 14th Annual Computing and Communication Workshop and Conference, CCWC 2024; Conference date: 8 January 2024 through 10 January 2024; Conference code: 197315},
	annote = {Type: Conference paper},
}


@article{ban_iotfuzz_2024,
	title = {{IoTFuzz}: {Automated} {Discovery} of {Violations} in {Smart} {Homes} with {Real} {Environment}},
	volume = {11},
	issn = {23274662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174854428&doi=10.1109%2fJIOT.2023.3325851&partnerID=40&md5=6d23e81fbeb4bc149ff3c5b652fb28b4},
	doi = {10.1109/JIOT.2023.3325851},
	abstract = {Smart homes (SHs) are rapidly evolving to incorporate intelligent features, including environment management, home automation, and human-machine interactions. However, safety and security risks of SHs hinder their wide adoption. Many work attempts to provide defense mechanisms to ensure safety and security against interrule vulnerabilities and spoofing attacks. This article proposes IoTFuzz, a fuzzing framework that dynamically address cyber security and physical safety aspects of SHs through targeted policies. IoTFuzz mutates the inputs from policies, human activities, indoor environment, and real-life outdoor weather conditions. In addition to the binary status of devices, the continuous-value status in SHs is leveraged to perform mutation and simulation. The policies are expressed as temporal logic formulas with time constraints. For large-scale testing, IoTFuzz employs digital twins to simulate normal behaviors, outdoor environment impacts, and human activities in SHs. Moreover, IoTFuzz can also intelligently infer rule-policy correlation based on natural language processing (NLP) techniques. The evaluation of IoTFuzz in a configured SH with 15 rules and 10 predefined unique policies demonstrates its effectiveness in revealing the impacts of real-life outdoor environment. The experimental results demonstrate a range of violations, with a maximum of 4154 violations and a minimum of 41 violations observed over an 8-year period under varying weather conditions. IoTFuzz also identifies the potential risks associated with improper human activities, accounting for up to 35.4\% of risky situations in SHs. © 2014 IEEE.},
	language = {English},
	number = {6},
	journal = {IEEE Internet of Things Journal},
	author = {Ban, Xinbo and Ding, Ming and Liu, Shigang and Chen, Chao and Zhang, Jun},
	year = {2024},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.
Type: Article},
	keywords = {Testing, Internet of Things, Security, Natural language processing systems, Natural languages, Model checking, Internet of things, Automation, Safety testing, Intelligent buildings, Models checking, Language processing, Natural language processing, model checking, Digital twin, Safety, IoT, natural language processing (NLP), Internet of Things (IoT), Digital twins, Meteorology, Fuzzing, Cybersecurity, Safety and securities, fuzzing, safety and security},
	pages = {10183 -- 10196},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Publisher: Institute of Electrical and Electronics Engineers Inc. Type: Article},
}


@inproceedings{yan_neuro-symbolic_2022,
	title = {Neuro-symbolic {Models} for {Interpretable} {Time} {Series} {Classification} using {Temporal} {Logic} {Description}},
	volume = {2022-November},
	isbn = {978-1-66545-099-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147736516&doi=10.1109%2fICDM54844.2022.00072&partnerID=40&md5=3354b04651d0bc93bf9248f3b69c32f4},
	doi = {10.1109/ICDM54844.2022.00072},
	abstract = {Most existing Time series classification (TSC) models lack interpretability and are difficult to inspect. Interpretable machine learning models can aid in discovering patterns in data as well as give easy-to-understand insights to domain specialists. In this study, we present Neuro-Symbolic Time Series Classification (NSTSC), a neuro-symbolic model that leverages signal temporal logic (STL) and neural network (NN) to accomplish TSC tasks using multi-view data representation and expresses the model as a human-readable, interpretable formula. In NSTSC, each neuron is linked to a symbolic expression, i.e., an STL (sub)formula. The output of NSTSC is thus interpretable as an STL formula akin to natural language, describing temporal and logical relations hidden in the data. We propose an NSTSC-based classifier that adopts a decision-tree approach to learn formula structures and accomplish a multiclass TSC task. The proposed smooth activation functions enable the model to be learned in an end-to-end fashion. We test NSTSC on a real-world wound healing dataset from mice and benchmark datasets from the UCR time-series repository, demonstrating that NSTSC achieves comparable performance with the state-of-the-art models. Furthermore, NSTSC can generate interpretable formulas that match domain knowledge. © 2022 IEEE.},
	language = {English},
	booktitle = {Proceedings - {IEEE} {International} {Conference} on {Data} {Mining}, {ICDM}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Yan, Ruixuan and Ma, Tengfei and Fokoue, Achille and Chang, Maria and Julius, Agung},
	editor = {X, Zhu and S, Ranka and My.T, Thai and T, Washio and X, Wu},
	year = {2022},
	note = {ISSN: 15504786
Type: Conference paper},
	keywords = {Temporal logic, Computer circuits, Classification models, Benchmarking, Classification tasks, Data representations, Decision trees, Interpretability, Logic networks, Machine learning models, Mammals, Multi-view datum, Neural-networks, Statistical tests, Symbolic modeling, Time series, Time series classifications},
	pages = {618 -- 627},
	annote = {Cited by: 0; Conference name: 22nd IEEE International Conference on Data Mining, ICDM 2022; Conference date: 28 November 2022 through 1 December 2022; Conference code: 186511; All Open Access, Green Open Access},
	annote = {Cited by: 0; Conference name: 22nd IEEE International Conference on Data Mining, ICDM 2022; Conference date: 28 November 2022 through 1 December 2022; Conference code: 186511; All Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{first_baldur_2023,
	title = {Baldur: {Whole}-{Proof} {Generation} and {Repair} with {Large} {Language} {Models}},
	isbn = {979-840070327-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165657273&doi=10.1145%2f3611643.3616243&partnerID=40&md5=cbea766af4fc339a605db51562ca945b},
	doi = {10.1145/3611643.3616243},
	abstract = {Formally verifying software is a highly desirable but labor-intensive task. Recent work has developed methods to automate formal verification using proof assistants, such as Coq and Isabelle/HOL, e.g., by training a model to predict one proof step at a time and using that model to search through the space of possible proofs. This paper introduces a new method to automate formal verification: We use large language models, trained on natural language and code and fine-tuned on proofs, to generate whole proofs at once. We then demonstrate that a model fine-tuned to repair generated proofs further increasing proving power. This paper: (1) Demonstrates that whole-proof generation using transformers is possible and is as effective but more efficient than search-based techniques. (2) Demonstrates that giving the learned model additional context, such as a prior failed proof attempt and the ensuing error message, results in proof repair that further improves automated proof generation. (3) Establishes, together with prior work, a new state of the art for fully automated proof synthesis. We reify our method in a prototype, Baldur, and evaluate it on a benchmark of 6,336 Isabelle/HOL theorems and their proofs, empirically showing the effectiveness of whole-proof generation, repair, and added context. We also show that Baldur complements the state-of-the-art tool, Thor, by automatically generating proofs for an additional 8.7\% of the theorems. Together, Baldur and Thor can prove 65.7\% of the theorems fully automatically. This paper paves the way for new research into using large language models for automating formal verification. © 2023 ACM.},
	language = {English},
	booktitle = {{ESEC}/{FSE} 2023 - {Proceedings} of the 31st {ACM} {Joint} {Meeting} {European} {Software} {Engineering} {Conference} and {Symposium} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery, Inc},
	author = {First, Emily and Rabe, Markus and Ringer, Talia and Brun, Yuriy},
	editor = {S, Chandra and K, Blincoe and P, Tonella},
	year = {2023},
	note = {Type: Conference paper},
	keywords = {Formal verification, Automation, Machine learning, Machine-learning, Language model, Theorem proving, machine learning, Computational linguistics, State of the art, Repair, Proof assistant, Isabelle, large language models, Large language model, Automated formal verification, Automated proofs, Proof repair, Proof synthesis, automated formal verification, Proof assistants, proof repair, proof synthesis},
	pages = {1229 -- 1241},
	annote = {Cited by: 1; Conference name: 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2023; Conference date: 3 December 2023 through 9 December 2023; Conference code: 195093; All Open Access, Green Open Access},
	annote = {Cited by: 1; Conference name: 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2023; Conference date: 3 December 2023 through 9 December 2023; Conference code: 195093; All Open Access, Green Open Access},
	annote = {event-place: {\textbackslash}textlessconf-loc{\textbackslash}textgreater, {\textbackslash}textlesscity{\textbackslash}textgreaterSan Francisco{\textbackslash}textless/city{\textbackslash}textgreater, {\textbackslash}textlessstate{\textbackslash}textgreaterCA{\textbackslash}textless/state{\textbackslash}textgreater, {\textbackslash}textlesscountry{\textbackslash}textgreaterUSA{\textbackslash}textless/country{\textbackslash}textgreater, {\textbackslash}textless/conf-loc{\textbackslash}textgreater},
	annote = {event-place: {\textbackslash}textlessconf-loc{\textbackslash}textgreater, {\textbackslash}textlesscity{\textbackslash}textgreaterSan Francisco{\textbackslash}textless/city{\textbackslash}textgreater, {\textbackslash}textlessstate{\textbackslash}textgreaterCA{\textbackslash}textless/state{\textbackslash}textgreater, {\textbackslash}textlesscountry{\textbackslash}textgreaterUSA{\textbackslash}textless/country{\textbackslash}textgreater, {\textbackslash}textless/conf-loc{\textbackslash}textgreater},
	annote = {Type: Conference paper},
}


@article{s_11th_2023,
	title = {11th {International} {Workshop} on {Structured} {Object}-{Oriented} {Formal} {Language} and {Method}, {SOFL}+{MSVL} 2022},
	volume = {13854 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152514422&partnerID=40&md5=2531aeef37b4d49810717a19a1f04860},
	abstract = {The proceedings contain 12 papers. The special focus in this conference is on Structured Object-Oriented Formal Language and Method. The topics include: Verifying and Improving Neural Networks Using Testing-Based Formal Verification; alternating Projection Temporal Epistemic Logic; an Approach of Transforming Non-Markovian Reward to Markovian Reward; A JPSL Based Model Checking Approach for Java Programs; Implementation of Matlab matfun Toolkit Based on MSVL; extending Visibly Pushdown Automata over Multi-matching Nested Relations; schedulability Analysis of Rate-Monotonic Algorithm on Concurrent Execution of Digraph Real-Time Tasks; Formalization of Natural Language into PPTL Specification via Neural Machine Translation; testing Program Segments to Detect Runtime Exceptions in Java; inferring Exact Domains to Efficiently Generate Valid Test Cases via Testing.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {S, Liu and A, Liu and Z, Duan},
	year = {2023},
	note = {ISBN: 978-303129475-4
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: 11th International Workshop on Structured Object-Oriented Formal Language and Method, SOFL+MSVL 2022; Conference date: 24 October 2022 through 27 October 2022; Conference code: 292559},
	annote = {Cited by: 0; Conference name: 11th International Workshop on Structured Object-Oriented Formal Language and Method, SOFL+MSVL 2022; Conference date: 24 October 2022 through 27 October 2022; Conference code: 292559},
	annote = {RELEVANCE: NULL - procedings
},
}


@inproceedings{onishi_reducing_2022,
	title = {Reducing {Syntactic} {Complexity} for {Information} {Extraction} from {Japanese} {Requirement} {Specifications}},
	volume = {2022-December},
	isbn = {978-1-66545-537-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149172821&doi=10.1109%2fAPSEC57359.2022.00051&partnerID=40&md5=d1d714e04e1c7e5814744ffe19f5be25},
	doi = {10.1109/APSEC57359.2022.00051},
	abstract = {In software development, ambiguities in requirements described in natural language (NL) prevent the application of formal approaches, posing a difficulty that has heretofore been avoided in two main ways: discovery based on formal specifications generated from NL requirements, and the creation of non-ambiguous NL requirements. In the former, NL is more expressive and does not rely on the user's expertise, but instead makes the automatic generation of formal specifications difficult. The latter facilitates the automatic generation of formal specifications and has the advantage of reduced syntactic complexity, but in exchange for reduced expressiveness of NL. In this paper, we take an approach that allows users to describe highly expressive NL requirements and reduces syntactic complexity to support the automatic generation of formal specifications from NL requirements. We also propose an information extraction method using syntactic patterns of low syntactic complexity. Applying our method to practical requirement sentences reveals that it is effective in reducing the complexity of information extraction rules. We expect that our method can support the automatic generation of formal specifications from NL requirements without compromising the expressive power of the language. © 2022 IEEE.},
	language = {English},
	booktitle = {Proceedings - {Asia}-{Pacific} {Software} {Engineering} {Conference}, {APSEC}},
	publisher = {IEEE Computer Society},
	author = {Onishi, Maiko and Ogata, Shinpei and Okano, Kozo and Bekki, Daisuke},
	year = {2022},
	note = {ISSN: 15301362
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Software design, Natural language requirements, Information retrieval, Formal approach, Requirements specifications, Requirement engineering, Syntactics, Application programs, Automatic Generation, Information extraction, Information extraction methods, Japanese CCG parse, Syntactic complexity},
	pages = {387 -- 396},
	annote = {Cited by: 0; Conference name: 29th Asia-Pacific Software Engineering Conference, APSEC 2022; Conference date: 6 December 2022 through 9 December 2022; Conference code: 186795},
	annote = {Cited by: 0; Conference name: 29th Asia-Pacific Software Engineering Conference, APSEC 2022; Conference date: 6 December 2022 through 9 December 2022; Conference code: 186795},
	annote = {RELEVANCE: LOW
},
}


@article{c_proceedings_2023,
	title = {Proceedings of the 35th {International} {Conference} on {Computer} {Aided} {Verification}, {CAV} 2023},
	volume = {13965 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172195349&partnerID=40&md5=250cee05e98172b1f16c5c118bddc4f9},
	abstract = {The proceedings contain 21 papers. The special focus in this conference is on Computer-Aided Verification. The topics include: CoqCryptoLine: A Verified Model Checker with Certified Results; incremental Dead State Detection in Logarithmic Time; model Checking Race-Freedom When “Sequential Consistency for Data-Race-Free Programs” is Guaranteed; searching for i-Good Lemmas to Accelerate Safety Model Checking; second-Order Hyperproperties; Certifying the Fairness of KNN in the Presence of Dataset Bias; monitoring Algorithmic Fairness; nl2spec: Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models; NNV 2.0: The Neural Network Verification Tool; decision Procedures for Sequence Theories; QEBVerif: Quantization Error Bound Verification of Neural Networks; verifying Generalization in Deep Learning; exploiting Adjoints in Property Directed Reachability Analysis; fast Approximations of Quantifier Elimination; local Search for Solving Satisfiability of Polynomial Formulas; partial Quantifier Elimination and Property Generation; rounding Meets Approximate Model Counting; satisfiability Modulo Finite Fields; Solving String Constraints Using SAT.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {C, Enea and A, Lal},
	year = {2023},
	note = {ISBN: 978-303137702-0
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: Proceedings of the 35th International Conference on Computer Aided Verification, CAV 2023; Conference date: 17 July 2023 through 22 July 2023; Conference code: 298359},
	annote = {Cited by: 0; Conference name: Proceedings of the 35th International Conference on Computer Aided Verification, CAV 2023; Conference date: 17 July 2023 through 22 July 2023; Conference code: 298359},
	annote = {RELEVANCE: LOW - procedings
},
}


@inproceedings{ge_automtlspec_2023,
	title = {{AutoMTLSpec}: {Learning} to {Generate} {MTL} {Specifications} from {Natural} {Language} {Contracts}},
	isbn = {979-835034004-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179523728&doi=10.1109%2fICECCS59891.2023.00018&partnerID=40&md5=0232781811239fea834036e9ecaf463f},
	doi = {10.1109/ICECCS59891.2023.00018},
	abstract = {A smart legal contract is a legally binding contract in which some or all of the contractual obligations are defined and performed automatically by a computer program. As its software requirement, the legal contract is composed of legal clauses expressing the execution logic and time constraints between events in natural language. When formally verifying a smart legal contract to ensure the requirements' conformance, it is necessary to translate the time-constrained functional requirements (TFRs) into property specifications like Metric temporal logic (MTL) as the input of a model checker. Instead of costly and error-prone manual writing, this work automates the TFR detection and the specification generation using deep learning, named AutoMTL-Spec. We separate the MTL specification generation approach into four tasks: TFR detection, intermediate representation structure extraction, event sequence/time point extraction, and MTL generation, respectively. We construct a dataset including 43 contracts of four categories, 4608 terms, and 277 TFRs. The experimental results showed that all three models significantly outperform the baselines. Most of the indicators of the three learning tasks reached near to or more than 90\%. © 2023 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Engineering} of {Complex} {Computer} {Systems}, {ICECCS}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Ge, Ning and Yang, Jinwen and Yu, Tianyu and Liu, Wei},
	year = {2023},
	note = {ISSN: 27708527
Type: Conference paper},
	keywords = {Measurement, Formal specification, Natural languages, Extraction, Temporal logic, Model checking, Computer circuits, Functional requirement, Temporal property, Metric temporal logic, deep learning, Deep learning, Software, Writing, Manuals, Specification generations, Legal contracts, Law, Formal specification generation, Metric temporal property, Smart legal contract, Time-constrained functional requirement, formal specification generation, metric temporal property, smart legal contract, time-constrained functional requirements},
	pages = {71 -- 80},
	annote = {Cited by: 0; Conference name: 27th International Conference on Engineering of Complex Computer Systems, ICECCS 2023; Conference date: 14 June 2023 through 16 June 2023; Conference code: 194655},
	annote = {Cited by: 0; Conference name: 27th International Conference on Engineering of Complex Computer Systems, ICECCS 2023; Conference date: 14 June 2023 through 16 June 2023; Conference code: 194655},
	annote = {ISSN: 27708527 Type: Conference paper},
}


@article{huitzil_towards_2022,
	title = {Towards {Automated} {Compliance} {Checking} of {Building} {Regulations}: {smartNorms4BIM}},
	volume = {356},
	issn = {09226389},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141664535&doi=10.3233%2fFAIA220322&partnerID=40&md5=670c888ecb1e9f90f63581d99b05ae4f},
	doi = {10.3233/FAIA220322},
	abstract = {This paper describes a preliminary approach towards automating the compliance checking of constructions with respect to building regulations. We describe a prototype that supports such automated checking by specifying regulations in terms of an ontology, and reasoning with the Building Information Models (BIM) of constructions. The first step in our approach is to translate regulations into a machine-readable format with the support of controlled natural language specifications of rules. Then, we propose a formal specification of the building regulations in OWL2, the de facto standard for ontology engineering on the web. We sub-sequently populate this ontology with data of real-world BIM specifications based on Industry Foundation Classes (IFC) in order to check their compliance with the formalized regulations. Finally, our prototype offers to the end-users a verification report in text and a graphical visualiser with the results of the compliance check. To explain how our prototype works and to demonstrate its applicability, we show some examples taken from a concrete use case. © 2022 The authors and IOS Press.},
	language = {English},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Huitzil, Ignacio and Schorlemmer, Marco and Osman, Nardine and Garcia, Pere and Coll, Josep and Coll, Xavier},
	editor = {A, Cortes and F, Grimaldo and T, Flaminio},
	year = {2022},
	note = {ISBN: 978-164368326-3
Publisher: IOS Press BV
Type: Conference paper},
	keywords = {Formal specification, Ontology, Compliance checking, Compliance control, Natural language specifications, Controlled natural language, Information theory, Architectural design, Building Information Modelling, Ontology's, Automated compliance checking, Building regulations, Machine-readable format, Preliminary approach, Rule-compliance checking},
	pages = {95 -- 104},
	annote = {Cited by: 0; Conference name: 24th International Conference of the Catalan Association for Artificial Intelligence, CCIA 2022; Conference date: 19 October 2022 through 21 October 2022; Conference code: 183583; All Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 0; Conference name: 24th International Conference of the Catalan Association for Artificial Intelligence, CCIA 2022; Conference date: 19 October 2022 through 21 October 2022; Conference code: 183583; All Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{y_24th_2023,
	title = {24th {International} {Conference} on {Formal} {Engineering} {Methods}, {ICFEM} 2023},
	volume = {14308 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177204855&partnerID=40&md5=ada4907a3ac3ef55ca3bc0d8a9614058},
	abstract = {The proceedings contain 22 papers. The special focus in this conference is on Formal Engineering Methods. The topics include: Guided Integration of Formal Verification in Assurance Cases; validation-Driven Development; incremental Property Directed Reachability; Proving Local Invariants in ASTDs; formal Verification of the Burn-to-Claim Blockchain Interoperable Protocol; early and Systematic Validation of Formal Models; verifying Neural Networks by Approximating Convex Hulls; eager to Stop: Efficient Falsification of Deep Neural Networks; A Runtime Verification Framework for Cyber-Physical Systems Based on Data Analytics and LTL Formula Learning; an Idealist’s Approach for Smart Contract Correctness; unified Verification of Neural Networks’ Robustness and Privacy in Computer Vision; ioT Software Vulnerability Detection Techniques through Large Language Model; vulnerability Detection via Typestate-Guided Code Representation Learning; Active Inference of EFSMs Without Reset; learning Mealy Machines with Local Timers; compositional Vulnerability Detection with Insecurity Separation Logic; dynamic Extrapolation in Extended Timed Automata; formalizing Robustness Against Character-Level Perturbations for Neural Network Language Models; trace Models of Concurrent Valuation Algebras; branch and Bound for Sigmoid-Like Neural Network Verification.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {Y, Li and S, Tahar},
	year = {2023},
	note = {ISBN: 978-981997583-9
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: 24th International Conference on Formal Engineering Methods, ICFEM 2023; Conference date: 21 November 2023 through 24 November 2023; Conference code: 303749},
	annote = {Cited by: 0; Conference name: 24th International Conference on Formal Engineering Methods, ICFEM 2023; Conference date: 21 November 2023 through 24 November 2023; Conference code: 303749},
	annote = {ISBN: 978-981997583-9 Publisher: Springer Science and Business Media Deutschland GmbH Type: Conference review},
}


@article{ky_15th_2023,
	title = {15th {International} {Symposium} on {NASA} {Formal} {Methods}, {NFM} 2023},
	volume = {13903 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164033821&partnerID=40&md5=6f125073da8ebc58fba1b6b686f25010},
	abstract = {The proceedings contain 29 papers. The special focus in this conference is on NASA Formal Methods. The topics include: Reasoning with Metric Temporal Logic and Resettable Skewed Clocks; centralized Multi-agent Synthesis with Spatial Constraints via Mixed-Integer Quadratic Programming; a Framework for Policy Based Negotiation; rewrite-Based Decomposition of Signal Temporal Logic Specifications; Quantitative Verification and Strategy Synthesis for BDI Agents; Multi-objective Task Assignment and Multiagent Planning with Hybrid GPU-CPU Acceleration; reasoning over Test Specifications Using Assume-Guarantee Contracts; from the Standards to Silicon: Formally Proved Memory Controllers; Formalising Liveness Properties in Event-B with the Reflexive EB4EB Framework; open- and Closed-Loop Neural Network Verification Using Polynomial Zonotopes; formalized High Level Synthesis with Applications to Cryptographic Hardware; From Natural Language Requirements to the Verification of Programmable Logic Controllers: Integrating FRET into PLCverif; automata-Based Software Model Checking of Hyperproperties; condition Synthesis Realizability via Constrained Horn Clauses; a Toolkit for Automated Testing of Dafny; Verified ALL(*) Parsing with Semantic Actions and Dynamic Input Validation; Subtropical Satisfiability for SMT Solving; a Linear Weight Transfer Rule for Local Search; adiar 1.1: Zero-Suppressed Decision Diagrams in External Memory; satisfiability of Non-linear Transcendental Arithmetic as a Certificate Search Problem; verifying Attention Robustness of Deep Neural Networks Against Semantic Perturbations; formalizing Piecewise Affine Activation Functions of Neural Networks in Coq; verifying an Aircraft Collision Avoidance Neural Network with Marabou; strategy Synthesis in Markov Decision Processes Under Limited Sampling Access; learning Symbolic Timed Models from Concrete Timed Data; reward Shaping from Hybrid Systems Models in Reinforcement Learning; conservative Safety Monitors of Stochastic Dynamical Systems.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {K.Y, Rozier and S, Chaudhuri},
	year = {2023},
	note = {ISBN: 978-303133169-5
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: 15th International Symposium on NASA Formal Methods, NFM 2023; Conference date: 16 May 2023 through 18 May 2023; Conference code: 296139},
	annote = {Cited by: 0; Conference name: 15th International Symposium on NASA Formal Methods, NFM 2023; Conference date: 16 May 2023 through 18 May 2023; Conference code: 296139},
	annote = {RELEVANCE: NULL - procedings
},
}


@inproceedings{rim_integrated_2023,
	title = {Integrated {Annotation} of {Event} {Structure}, {Object} {States}, and {Entity} {Coreference}},
	isbn = {978-1-955917-02-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184664373&partnerID=40&md5=6598075fde5b86b41661f1cdb8b4f9af},
	abstract = {Understanding coreference and anaphora is still considered as a hard problem for NLP applications. Recent studies on modeling and annotating coreference and/or anaphoric relations show that the problem is a hard problem even for human expert annotators. In this work, we demonstrate an annotation environment that enables quick and easy, but still flexible annotation of coreference relations based on event semantics and argument structure, and constraints arsing from temporal logic. The main focus of the environment is to integrate annotation of lexically anchored entity state change tracking and coreference chains along the event-based entity transformation. The scheme and environment is developed as open source, and is publicly available. © 2023 EMNLP 2023 - Proceedings of the 6th Workshop on Computational Models of Reference, Anaphora and Coreference, CRAC 2023. All rights reserved.},
	language = {English},
	booktitle = {{EMNLP} 2023 - {Proceedings} of the 6th {Workshop} on {Computational} {Models} of {Reference}, {Anaphora} and {Coreference}, {CRAC} 2023},
	publisher = {Association for Computational Linguistics (ACL)},
	author = {Rim, Kyeongmin and Pustejovsky, James},
	editor = {M, Ogrodniczuk and V, Ng and S, Pradhan and M, Poesio},
	year = {2023},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Semantics, Computation theory, Argument structures, Event semantics, Coreference, Event structures, Hard problems, Human expert, Relation-based, Semantic structures, States change, Study on models},
	pages = {71 -- 77},
	annote = {Cited by: 0; Conference name: 6th Workshop on Computational Models of Reference, Anaphora and Coreference, CRAC 2023; Conference date: 6 December 2023 through 7 December 2023; Conference code: 196536},
	annote = {Cited by: 0; Conference name: 6th Workshop on Computational Models of Reference, Anaphora and Coreference, CRAC 2023; Conference date: 6 December 2023 through 7 December 2023; Conference code: 196536},
	annote = {Type: Conference paper},
}


@inproceedings{chen_nl2tl_2023,
	title = {{NL2TL}: {Transforming} {Natural} {Languages} to {Temporal} {Logics} using {Large} {Language} {Models}},
	isbn = {979-889176060-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184819932&partnerID=40&md5=89d5356accb387e971dc9083e6cc3a3c},
	abstract = {Temporal Logic (TL) can be used to rigorously specify complex high-level specification for systems in many engineering applications. The translation between natural language (NL) and TL has been under-explored due to the lack of dataset and generalizable model across different application domains. In this paper, we propose an accurate and generalizable transformation framework of English instructions from NL to TL, exploring the use of Large Language Models (LLMs) at multiple stages. Our contributions are twofold. First, we develop a framework to create a dataset of NL-TL pairs combining LLMs and human annotation. We publish a dataset with 28K NL-TL pairs. Then, we finetune T5 models on the lifted versions (i.e., the specific Atomic Propositions (AP) are hidden) of the NL and TL. The enhanced generalizability originates from two aspects: 1) Usage of lifted NL-TL characterizes common logical structures, without constraints of specific domains. 2) Application of LLMs in dataset creation largely enhances corpus richness. We test the generalization of trained models on five varied domains. To achieve full NL-TL transformation, we either combine the lifted model with AP recognition task or do the further finetuning on each specific domain. During the further finetuning, our model achieves higher accuracy ({\textgreater}95\%) using only {\textless}10\% training data, compared with the baseline sequence to sequence (Seq2Seq) model. ©2023 Association for Computational Linguistics.},
	language = {English},
	booktitle = {{EMNLP} 2023 - 2023 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}, {Proceedings}},
	publisher = {Association for Computational Linguistics (ACL)},
	author = {Chen, Yongchao and Gandhi, Rujul and Zhang, Yang and Fan, Chuchu},
	editor = {H, Bouamor and J, Pino and K, Bali},
	year = {2023},
	note = {Type: Conference paper},
	keywords = {Natural languages, Temporal logic, Computer circuits, Language model, Atomic propositions, Generalisation, Computational linguistics, Applications domains, Human annotations, Engineering applications, High level specification, Logical structure, Multiple stages},
	pages = {15880 -- 15903},
	annote = {Cited by: 0; Conference name: 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196512},
	annote = {Cited by: 0; Conference name: 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196512},
	annote = {Type: Conference paper},
}


@article{ozkaya_practitioners_2023,
	title = {Practitioners’ {Perspectives} towards {Requirements} {Engineering}: {A} {Survey}},
	volume = {11},
	issn = {20798954},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149217529&doi=10.3390%2fsystems11020065&partnerID=40&md5=f7c55d939577b75b596c10e48cf69c16},
	doi = {10.3390/systems11020065},
	abstract = {In this paper, we discuss the results of our survey among 84 practitioners in order to understand practitioners’ perspectives towards requirements engineering. We asked 28 questions to learn the practitioners’ motivations, the techniques and technologies used for different activities, practitioners’ experiences with customer involvement, and any challenges encountered. Some important results are as follows: the practitioners’ top motivations are the precise communication of requirements and analyzing the requirements to detect issues. Most practitioners (i) insist on using natural languages, (ii) specify requirements as the use case and scenario descriptions, (iii) neglect using/transforming requirements for making high-level decisions and reasoning about requirements, (iv) neglect the specifications of quality requirements and their reasoning while considering quality requirements important, and (v) neglect any technologies for facilitating requirements engineering (e.g., meta-modeling technologies, formal verification tools, and advanced tools). Practitioners are challenged by the cost and effort spent in specifying requirements, the omissions of errors, misinterpretations of requirements and their incorrect (manual) transformations, and customers’ lack of technical knowledge. With the survey results, practitioners can gain an awareness on the general perspectives, academics can trigger new research addressing the observed issues, and tool vendors can improve their tools with regard to the weaknesses determined. © 2023 by the authors.},
	language = {English},
	number = {2},
	journal = {Systems},
	author = {Ozkaya, Mert and Akdur, Deniz and Toptani, Etem Cetin and Kocak, Burak and Kardas, Geylani},
	year = {2023},
	note = {Publisher: MDPI
Type: Article},
	annote = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{nistala_towards_2022,
	title = {Towards digitalization of requirements: generating context-sensitive user stories from diverse specifications},
	volume = {29},
	issn = {09288910},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125628911&doi=10.1007%2fs10515-022-00324-2&partnerID=40&md5=bceef0abdc4b94d8a51b0373a4938e51},
	doi = {10.1007/s10515-022-00324-2},
	abstract = {Requirements Engineering in the industry is expertise-driven, heavily manual, and centered around various types of requirement specification documents being prepared and maintained. These specification documents are in diverse formats and vary depending on whether it is a business requirement document, functional specification, interface specification, client specification, and so on. These diverse specification documents embed crucial product knowledge such as functional decomposition of the domain into features, feature hierarchy, feature types and their specific feature characteristics, dependencies, business context, etc. Moreover, in a product development scenario, thousands of pages of requirement specification documentation is created over the years. Comprehending functionality and its associated context from large volumes of specification documents is a highly complex task. To address this problem, we propose to digitalize the requirement specification documents into processable models. This paper discusses the salient aspects involved in the digitalization of requirements knowledge from diverse requirement specification documents. It proposes an AI engine for the automatic transformation of diverse text-based requirement specifications into machine-processable models using NLP techniques and the generation of context-sensitive user stories. The paper describes the key requirement abstractions and concepts essential in an industrial scenario, the conceptual meta-model, and DizReq engine (AI engine for digitalizing requirements) implementation for automatically transforming diverse requirement specifications into user stories embedding the business context. The evaluation results from digitalizing specifications of an IT product suite are discussed: mean feature extraction efficiency is 40 features/file, mean user story extraction efficiency is 71 user stories/file, feature extraction accuracy is 94\%, and requirement extraction accuracy is 98\%. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	language = {English},
	number = {1},
	journal = {Automated Software Engineering},
	author = {Nistala, Padmalata V. and Rajbhoj, Asha and Kulkarni, Vinay and Soni, Shivani and Nori, Kesav V. and Reddy, Raghu},
	year = {2022},
	note = {Publisher: Springer
Type: Article},
	keywords = {Natural language processing systems, Extraction, Specifications, Requirements specifications, Engines, Feature extraction, Efficiency, Meta model, Metamodeling, User stories, Feature classification, Feature models, Model extraction, NLP4RE, Product context, Requirement digitalization, Requirement meta-model},
	annote = {Cited by: 1},
	annote = {Cited by: 5},
	annote = {RELEVANCE: HIGH
https://link.springer.com/content/pdf/10.1007/s10515-022-00324-2.pdf?pdf=button
},
}


@inproceedings{zhao_digitization_2023,
	title = {Digitization of {Traffic} {Laws}: {Methodologies} and {Usage} for {Monitoring} {Driving} {Compliance}},
	isbn = {979-835039946-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186531733&doi=10.1109%2fITSC57777.2023.10422600&partnerID=40&md5=0066f42dd627bb319cf9d3e66231dbec},
	doi = {10.1109/ITSC57777.2023.10422600},
	abstract = {Autonomous Vehicles (AVs) must adhere to traffic laws designed for human-driven vehicles. However, since current traffic laws are expressed in natural language and are inherently ambiguous, AVs encounter challenges in comprehending these laws. Therefore, digitizing traffic laws into a format that AVs can understand is crucial for safe and efficient driving. In this paper, a process for digitizing regulations is proposed, where each regulation is digitized into a temporal logic expression composed of computable atomic propositions. Based on this process, a vehicle-side online violation monitoring architecture is established. These works make AVs understand traffic laws easily. Several common but important regulations are used as examples to illustrate our work and are deployed on an AV for verification. The results demonstrate that the proposed monitoring architecture can monitor ego vehicle's illegal behavior in real-time and provide compliance suggestions, thereby helping AVs operate more safely. © 2023 IEEE.},
	language = {English},
	booktitle = {{IEEE} {Conference} on {Intelligent} {Transportation} {Systems}, {Proceedings}, {ITSC}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Zhao, Chengxiang and Yu, Wenhao and Ma, Xiaohan and Zhao, Yuzhuang and Li, Boqi and Wang, Weida and Hu, Jia and Wang, Hong and Zhao, Ding},
	year = {2023},
	note = {ISSN: 21530009
Type: Conference paper},
	keywords = {Natural languages, 'current, Real-time systems, Autonomous vehicles, Traffic laws, Atomic propositions, Monitoring, Regulation, Computer architecture, Trajectory, Real- time, Vehicles, Laws and legislation, Behavioral sciences, Autonomous Vehicles, Digitisation, Logic expressions, Monitoring architecture},
	pages = {2376 -- 2383},
	annote = {Conference name: 26th IEEE International Conference on Intelligent Transportation Systems, ITSC 2023; Conference date: 24 September 2023 through 28 September 2023; Conference code: 197273},
	annote = {Conference name: 26th IEEE International Conference on Intelligent Transportation Systems, ITSC 2023; Conference date: 24 September 2023 through 28 September 2023; Conference code: 197273},
	annote = {ISSN: 21530009 Type: Conference paper},
}


@inproceedings{perez_monitoring_2022,
	title = {Monitoring {ROS2}: from {Requirements} to {Autonomous} {Robots}},
	volume = {371},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139824330&doi=10.4204%2fEPTCS.371.15&partnerID=40&md5=5675034093a80323d1fad7c2bccb5a08},
	doi = {10.4204/EPTCS.371.15},
	abstract = {Runtime verification (RV) has the potential to enable the safe operation of safety-critical systems that are too complex to formally verify, such as Robot Operating System 2 (ROS2) applications. Writing correct monitors can itself be complex, and errors in the monitoring subsystem threaten the mission as a whole. This paper provides an overview of a formal approach to generating runtime monitors for autonomous robots from requirements written in a structured natural language. Our approach integrates the Formal Requirement Elicitation Tool (FRET) with Copilot, a runtime verification framework, through the Ogma integration tool. FRET is used to specify requirements with unambiguous semantics, which are then automatically translated into temporal logic formulæ. Ogma generates monitor specifications from the FRET output, which are compiled into hard-real time C99. To facilitate integration of the monitors in ROS2, we have extended Ogma to generate ROS2 packages defining monitoring nodes, which run the monitors when new data becomes available, and publish the results of any violations. The goal of our approach is to treat the generated ROS2 packages as black boxes and integrate them into larger ROS2 systems with minimal effort. © 2022.},
	language = {English},
	booktitle = {Electronic {Proceedings} in {Theoretical} {Computer} {Science}, {EPTCS}},
	publisher = {Open Publishing Association},
	author = {Perez, Ivan and Mavridou, Anastasia and Pressburger, Tom and Will, Alexander and Martin, Patrick J.},
	editor = {M, Luckcuck and M, Farrell},
	year = {2022},
	note = {ISSN: 20752180
Type: Conference paper},
	keywords = {Natural languages, Semantics, Requirements elicitation, Verification framework, Formal approach, Safety engineering, Safety critical systems, Run-time verification, Integration tools, Monitoring robot, Runtime monitors, Safe operation},
	pages = {208 -- 216},
	annote = {Cited by: 1; Conference name: 4th International Workshop on Formal Methods for Autonomous Systems, FMAS 2022 and 4th International Workshop on Automated and Verifiable Software sYstem DEvelopment, ASYDE 2022; Conference date: 26 September 2022 through 27 September 2022; Conference code: 182975; All Open Access, Gold Open Access},
	annote = {Cited by: 3; Conference name: 4th International Workshop on Formal Methods for Autonomous Systems, FMAS 2022 and 4th International Workshop on Automated and Verifiable Software sYstem DEvelopment, ASYDE 2022; Conference date: 26 September 2022 through 27 September 2022; Conference code: 182975; All Open Access, Gold Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{s_35th_2023,
	title = {35th {IFIPWG} 6.1 {International} {Conference} on {Testing} {Software} and {Systems}, {ICTSS} 2023},
	volume = {14131 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174462244&partnerID=40&md5=68bd339f3d3d3719be5a315e0e37fa5f},
	abstract = {The proceedings contain 20 papers. The special focus in this conference is on IFIPWG 6.1 International Conference on Testing Software and Systems. The topics include: RQCODE: Security Requirements Formalization with Testing; understanding Problem Solving in Software Testing: An Exploration of Tester Routines and Behavior; who Is Afraid of Test Smells? Assessing Technical Debt from Developer Actions; GResilience: Trading Off Between the Greenness and the Resilience of Collaborative AI Systems; a Systematic Literature Review on Prioritizing Software Test Cases Using Markov Chains; on the Evaluation of Photometric Stereo Applications Testing Using Image Modifications; Multi-device, Robust, and Integrated Android GUI Testing: A Conceptual Framework; how Do Different Types of Testing Goals Affect Test Case Design?; automated Testing of Systems of Systems; enhancing Synthetic Test Data Generation with Language Models Using a More Expressive Domain-Specific Language; Testing Quality of Training in QoE-Aware SFC Orchestration Based on DRL Approach; CATANA: Replay Testing for the Ethereum Blockchain; applying Pairwise Combinatorial Testing to Large Language Model Testing; prioritizing Test Cases with Markov Chains: A Preliminary Investigation; complete Property-Oriented Module Testing; Empirical Verification of TQED - A New Test Design Heuristic Technique; Probabilistic Approach for Minimizing Checking Sequences for Non-deterministic FSMs; compositionality in Model-Based Testing; a Rapid Review on Fuzz Security Testing for Software Protocol Implementations.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {S, Bonfanti and A, Gargantini and P, Salvaneschi},
	year = {2023},
	note = {ISBN: 978-303143239-2
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: 35th IFIPWG 6.1 International Conference on Testing Software and Systems, ICTSS 2023; Conference date: 18 September 2023 through 20 September 2023; Conference code: 301639},
	annote = {Cited by: 0; Conference name: 35th IFIPWG 6.1 International Conference on Testing Software and Systems, ICTSS 2023; Conference date: 18 September 2023 through 20 September 2023; Conference code: 301639},
	annote = {ISBN: 978-303143239-2 Publisher: Springer Science and Business Media Deutschland GmbH Type: Conference review},
}


@article{naumcheva_teaching_2023,
	title = {Teaching {Object}-{Oriented} {Requirements} {Techniques}: {An} {Experiment}},
	volume = {354 SIST},
	issn = {21903018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163329765&doi=10.1007%2f978-981-99-3068-5_32&partnerID=40&md5=4a0f41f661a83ed2a1aaa5bc54b86dba},
	doi = {10.1007/978-981-99-3068-5_32},
	abstract = {Scenario-based software requirements specifications, due to limitations of natural language and scenarios, lack precision and abstraction. Formal methods address this problem, but are rarely used. A Unified Object-Oriented (OO) approach complements the simplicity and appeal of scenario techniques with the rigor and clarity of software contracts. In this study we conduct a teaching experiment to evaluate the perception of usefulness and difficulty of the approach. The obtained results demonstrate that the unified OO requirements approach has a potential to be adopted by requirements engineering practitioners. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	language = {English},
	journal = {Smart Innovation, Systems and Technologies},
	author = {Naumcheva, Maria},
	editor = {G, Jezic and M, Kusek and J, Chen-Burger and R, Sperka and R.J, Howlett and R.J, Howlett and R.J, Howlett and L.C, Jain},
	year = {2023},
	note = {ISBN: 978-981993067-8
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Requirements engineering, Software requirements specifications, Requirement engineering, Object oriented programming, Object oriented, Object oriented approach, Engineering practitioners, Requirements techniques, Scenario technique, Scenario-based, Software contracts},
	pages = {347 -- 353},
	annote = {Cited by: 0; Conference name: 17th International KES Conference on Agents and Multi-Agent Systems: Technologies and Applications, KES-AMSTA 2023; Conference date: 14 June 2023 through 16 June 2023; Conference code: 295689},
	annote = {Cited by: 0; Conference name: 17th International KES Conference on Agents and Multi-Agent Systems: Technologies and Applications, KES-AMSTA 2023; Conference date: 14 June 2023 through 16 June 2023; Conference code: 295689},
	annote = {RELEVANCE: NULL
},
}


@inproceedings{huang_customer_2023,
	title = {Customer {Requirements} {Extraction} {Based} on {Transformer}},
	isbn = {979-835030961-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187367301&doi=10.1109%2fICEACE60673.2023.10442158&partnerID=40&md5=2746260fe604114bab9cb753acf8415f},
	doi = {10.1109/ICEACE60673.2023.10442158},
	abstract = {With the rapid development of the Internet, text data on social platforms has become a valuable resource. As the main means for customers to express their opinions, the utilization of such data has significant implications. In particular, in the field of natural language processing (NLP), extracting customer needs is a challenging but highly meaningful task. Automatically extracting customer needs can enable downstream tasks that carry out valuable business activities, such as building personalized recommendation systems and making business decisions involving product and service improvements. This study applies the Transformer model based on the Encoder-Decoder architecture to achieve customer demand extraction by fine-tuning the model. The model takes a customer review as input and, after end-to-end training, generates a sequence that can express the customer's product needs. The model used in this study introduces an attention mechanism to better capture information related to demands in customer reviews. This approach can greatly improve the accuracy of demand extraction. Finally, using comment data obtained from social platforms, a dataset comprising customer comments and demands was constructed, and automatic extraction of customer needs was achieved on this dataset. © 2023 IEEE.},
	language = {English},
	booktitle = {2023 {IEEE} {International} {Conference} on {Electrical}, {Automation} and {Computer} {Engineering}, {ICEACE} 2023},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Huang, Guangyu},
	year = {2023},
	note = {Type: Conference paper},
	pages = {1118 -- 1121},
	annote = {Cited by: 0; Conference name: 2023 IEEE International Conference on Electrical, Automation and Computer Engineering, ICEACE 2023; Conference date: 29 December 2023 through 31 December 2023; Conference code: 197685},
	annote = {Cited by: 0; Conference name: 2023 IEEE International Conference on Electrical, Automation and Computer Engineering, ICEACE 2023; Conference date: 29 December 2023 through 31 December 2023; Conference code: 197685},
	annote = {Type: Conference paper},
}


@article{soavi_semantic_2022,
	title = {Semantic {Annotation} of {Legal} {Contracts} with {ContrattoA}},
	volume = {9},
	issn = {22279709},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144672537&doi=10.3390%2finformatics9040072&partnerID=40&md5=979eb3f6f5a0ef291c140037150d9b9f},
	doi = {10.3390/informatics9040072},
	abstract = {The aim of the research is to semi-automate the process of generating formal specifications from legal contracts in natural language text form. Towards this end, the paper presents a tool, named ContrattoA, that semi-automatically conducts semantic annotation of legal contract text using an ontology for legal contracts. ContrattoA was developed through two iterations where lexical patterns were defined for legal concepts and their effectiveness was evaluated with experiments. The first iteration was based on a handful of sample contracts and resulted in defining lexical patterns for recognizing concepts in the ontology; these were evaluated with an empirical study where one group of subjects was asked to annotate legal text manually, while a second group edited the annotations generated by ContrattoA. The second iteration focused on the lexical patterns for the core contract concepts of obligation and power where results of the first iteration were mixed. On the basis of an extended set of sample contracts, new lexical patterns were derived and those were shown to substantially improve the performance of ContrattoA, nearing in quality the performance of experts. The experiments suggest that good quality annotations can be generated for a broad range of contracts with minor refinements to the lexical patterns. © 2022 by the authors.},
	language = {English},
	number = {4},
	journal = {Informatics},
	author = {Soavi, Michele and Zeni, Nicola and Mylopoulos, John and Mich, Luisa},
	year = {2022},
	note = {Publisher: MDPI
Type: Article},
	annote = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{guo_eventoa_2023,
	title = {{EventOA}: {An} {Event} {Ontology} {Alignment} {Benchmark} {Based} on {FrameNet} and {Wikidata}},
	isbn = {978-1-959429-62-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175431080&partnerID=40&md5=8973c0ac98b02f9d0f0f90fb4e039946},
	abstract = {Event ontology provides a shared and formal specification about what happens in the real world and can benefit many natural language understanding tasks. However, the independent development of event ontologies often results in heterogeneous representations that raise the need for establishing alignments between semantically related events. There exists a series of works about ontology alignment (OA), but they only focus on the entity-based OA, and neglect the event-based OA. To fill the gap, we construct an Event Ontology Alignment (EventOA) dataset based on FrameNet and Wikidata, which consists of 900+ event type alignments and 8,000+ event argument alignments. Furthermore, we propose a multi-view event ontology alignment (MEOA) method, which utilizes description information (i.e., name, alias and definition) and neighbor information (i.e., subclass and superclass) to obtain richer representation of the event ontologies. Extensive experiments show that our MEOA outperforms the existing entity-based OA methods and can serve as a strong baseline for EventOA research. © 2023 Association for Computational Linguistics.},
	language = {English},
	booktitle = {Proceedings of the {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics (ACL)},
	author = {Guo, Shaoru and Wang, Chenhao and Chen, Yubo and Liu, Kang and Li, Ru and Zhao, Jun},
	year = {2023},
	note = {ISSN: 0736587X
Type: Conference paper},
	keywords = {Ontology, Natural language understanding, Real-world, Computational linguistics, FrameNet, Alignment methods, Description information, Event ontology, Event Types, Event-based, Multi-views, Ontology alignment},
	pages = {10038 -- 10052},
	annote = {Cited by: 0; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867},
	annote = {Cited by: 0; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867},
	annote = {ISSN: 0736587X Type: Conference paper},
}


@inproceedings{grasler_ai-based_2023,
	title = {{AI}-based extraction of requirements from regulations for automotive engineering; [{KI}-basierte {Extrahierung} von {Anforderungen} aus {Regularien} für die {Automobilentwicklung}]},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185827385&doi=10.35199%2fdfx2023.17&partnerID=40&md5=7c4ee52d6b78ff3a4478a474ff3539e8},
	doi = {10.35199/dfx2023.17},
	abstract = {Automotive engineering requires compliance with regulations for certification. In specifications, regulations are referenced, which need to be analyzed manually to elicit requirements. This process is time-consuming and leads to high costs. The aim of this research is to evaluate artificial intelligence (AI) models in terms of extracting requirements automatically from regulations. Relevant AI models are identified in a systematic literature analysis and evaluated using success criteria. The most promising AI models are implemented in a pipeline for requirements extraction. The performance of these AI models is assessed in a comparative study using automotive regulations. The results show which AI models are best suited for this task. © 2023 die Autoren.},
	language = {German},
	booktitle = {Proceedings of the 34th {Symposium} {Design} for {X}, {DFX} 2023},
	publisher = {The Design Society},
	author = {Gräßler, Iris and Özcan, Deniz and Preuß, Daniel},
	editor = {D, Krause and K, Paetzold-Byhain and S, Wartzack},
	year = {2023},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Requirements engineering, Artificial intelligence, Requirement engineering, Language processing, Natural language processing, Performance, Automobiles, Literature analysis, Comparatives studies, Automotives, High costs, Intelligence models},
	annote = {Conference name: 34th Symposium Design for X, DFX 2023; Conference date: 14 September 2023 through 15 September 2023; Conference code: 197182; All Open Access, Bronze Open Access},
	annote = {Conference name: 34th Symposium Design for X, DFX 2023; Conference date: 14 September 2023 through 15 September 2023; Conference code: 197182; All Open Access, Bronze Open Access},
	annote = {Type: Conference paper},
}


@inproceedings{liu_grounding_2023,
	title = {Grounding {Complex} {Natural} {Language} {Commands} for {Temporal} {Tasks} in {Unseen} {Environments}},
	volume = {229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184348122&partnerID=40&md5=399947535998ac88d4712acb7c0a19e3},
	abstract = {Grounding navigational commands to linear temporal logic (LTL) leverages its unambiguous semantics for reasoning about long-horizon tasks and verifying the satisfaction of temporal constraints. Existing approaches require training data from the specific environment and landmarks that will be used in natural language to understand commands in those environments. We propose Lang2LTL, a modular system and a software package that leverages large language models (LLMs) to ground temporal navigational commands to LTL specifications in environments without prior language data. We comprehensively evaluate Lang2LTL for five well-defined generalization behaviors. Lang2LTL demonstrates the state-of-the-art ability of a single model to ground navigational commands to diverse temporal specifications in 21 city-scaled environments. Finally, we demonstrate a physical robot using Lang2LTL can follow 52 semantically diverse navigational commands in two indoor environments. © 2023 Proceedings of Machine Learning Research. All Rights Reserved.},
	language = {English},
	booktitle = {Proceedings of {Machine} {Learning} {Research}},
	publisher = {ML Research Press},
	author = {Liu, Jason Xinyu and Yang, Ziyi and Idrees, Ifrah and Liang, Sam and Schornstein, Benjamin and Tellex, Stefanie and Shah, Ankit},
	editor = {J, Tan and M, Toussaint and K, Darvish},
	year = {2023},
	note = {ISSN: 26403498
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Semantics, Temporal logic, Linear temporal logic, Language grounding, Robots, Machine learning, Language model, Linear temporal logic specifications, Generalisation, Temporal constraints, Training data, Modular system, Navigation, Robot navigation},
	annote = {Cited by: 0; Conference name: 7th Conference on Robot Learning, CoRL 2023; Conference date: 6 November 2023 through 9 November 2023; Conference code: 196640},
	annote = {Cited by: 0; Conference name: 7th Conference on Robot Learning, CoRL 2023; Conference date: 6 November 2023 through 9 November 2023; Conference code: 196640},
	annote = {ISSN: 26403498 Type: Conference paper},
}


@article{li_formalization_2023,
	title = {Formalization of {Natural} {Language} into {PPTL} {Specification} via {Neural} {Machine} {Translation}},
	volume = {13854 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152527374&doi=10.1007%2f978-3-031-29476-1_7&partnerID=40&md5=801df6dcc2dd3b26e89d7c3b762731a7},
	doi = {10.1007/978-3-031-29476-1_7},
	abstract = {Propositional Projection Temporal Logic (PPTL) has been widely used in formal verification, and its expressiveness is suitable for the description of security requirements. However, the expression and application of temporal logic formulas rely on a strong mathematical background, which is difficult for non-domain experts, thus bridging the chasm between natural language descriptions and formal languages is urgently needed. This paper proposes an innovative architecture for neural machine automatic translation named NL2PPTL, which transforms natural language into PPTL specification via utilizing data preprocessing, encoder-decoder network and stack sequentially. To evaluate the performance of our method, the experimental verification is realized on real datasets. The experiment conducted shows that our method has effectiveness on temporal logic specification generation. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Li, Chunyi and Chang, Jiajun and Wang, Xiaobing and Zhao, Liang and Mao, Wenjie},
	editor = {S, Liu and A, Liu and Z, Duan},
	year = {2023},
	note = {ISBN: 978-303129475-4
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Temporal logic, Formal languages, Formal verification, Computer circuits, Security requirements, Automatic translation, Formalisation, Domain experts, Temporal logic formula, Temporal logic specifications, Neural machine translation, Propositional projection temporal logic, Computational linguistics, Computer aided language translation, Data preprocessing, Language description},
	pages = {79 -- 92},
	annote = {Cited by: 0; Conference name: 11th International Workshop on Structured Object-Oriented Formal Language and Method, SOFL+MSVL 2022; Conference date: 24 October 2022 through 27 October 2022; Conference code: 292559},
}


@article{hoseinpour_dehkordi_linear_2023,
	title = {Linear {Temporal} {Public} {Announcement} {Logic}: {A} {New} {Perspective} for {Reasoning} {About} the {Knowledge} of {Multi}-classifiers},
	volume = {49},
	issn = {10186301},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149971473&doi=10.1007%2fs41980-023-00757-9&partnerID=40&md5=0ce0669917749993dc90a312c0b197e8},
	doi = {10.1007/s41980-023-00757-9},
	abstract = {In this paper, a formal transition system model is presented called Linear Temporal Public Announcement Logic (LTPAL) to extract knowledge in a classification process. The model combines Public Announcement Logic (PAL) and Linear Temporal Logic (LTL). For this purpose, first, an epistemic logic model is created to capture information gathered by classifiers in single-framed data input. Next, using LTL, classifiers are considered for data stream inputs. Then, a verification method is proposed for such data streams. Finally, we formalize natural language properties in LTPAL with a video-stream object detection sample. © 2023, The Author(s) under exclusive licence to Iranian Mathematical Society.},
	language = {English},
	number = {2},
	journal = {Bulletin of the Iranian Mathematical Society},
	author = {Hoseinpour Dehkordi, Amirhoshang and Alizadeh, Majid and Movaghar, Ali},
	year = {2023},
	note = {Publisher: Springer
Type: Article},
	annote = {Cited by: 0; All Open Access, Green Open Access},
	annote = {Cited by: 0; All Open Access, Green Open Access},
	annote = {Cited by: 0; All Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{manas_semantic_2023,
	title = {Semantic {Role} {Assisted} {Natural} {Language} {Rule} {Formalization} for {Intelligent} {Vehicle}},
	volume = {14244 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176010676&doi=10.1007%2f978-3-031-45072-3_13&partnerID=40&md5=3dc265e287ae8eced83eaded10712efa},
	doi = {10.1007/978-3-031-45072-3_13},
	abstract = {This paper proposes a novel pipeline to translate natural language rules and instructions for intelligent vehicles into temporal logic. The pipeline uses semantic role labeling (SRL), soft rule-based selection restrictions, and large language models (LLMs) to extract predicates, arguments, and temporal aspects from natural language rules and instruction. We then use the language understanding capability of LLMs to generate temporal logic rules from unstructured natural language text and additional information provided by SRL. We envision our model as a human-in-the-loop system that can facilitate the automated rule formalization for planning and verification systems in automated driving and drone planning. We demonstrate that our method can generate semantically correct temporal logic formulas from natural language text and provide implicit explanations of the output by showing the intermediate reasoning steps involved. This paper illustrates the integration of additional semantic knowledge and LLM and its application for the intelligent system domain of automated driving and drone planning. Our generalizable pipeline can easily extend to new logic formalization types, traffic rules, drone planning instructions, and application domains. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Manas, Kumar and Paschke, Adrian},
	editor = {A, Fensel and A, Ozaki and D, Roman and A, Soylu},
	year = {2023},
	note = {ISBN: 978-303145071-6
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Semantics, Temporal logic, Computer circuits, Automation, Formalisation, Intelligent systems, Language processing, Language model, Knowledge representation, Pipelines, Natural languages texts, Automated driving, Semantic role labeling, Drones, Intelligent vehicle highway systems, Knowledge-representation, Rule formalization, Semantic natural language processing},
	pages = {175 -- 189},
	annote = {Cited by: 0; Conference name: 7th International Joint Conference on Rules and Reasoning, RuleML+RR 2023; Conference date: 18 September 2023 through 20 September 2023; Conference code: 303029},
}


@inproceedings{bertram_neural_2022,
	title = {Neural {Language} {Models} and {Few} {Shot} {Learning} for {Systematic} {Requirements} {Processing} in {MDSE}},
	isbn = {978-1-4503-9919-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143075634&doi=10.1145%2f3567512.3567534&partnerID=40&md5=b112dc6c3f61cf73c0968a6a4416738b},
	doi = {10.1145/3567512.3567534},
	abstract = {Systems engineering, in particular in the automotive domain, needs to cope with the massively increasing numbers of requirements that arise during the development process. The language in which requirements are written is mostly informal and highly individual. This hinders automated processing of requirements as well as the linking of requirements to models. Introducing formal requirement notations in existing projects leads to the challenge of translating masses of requirements and the necessity of training for requirements engineers. In this paper, we derive domain-specific language constructs helping us to avoid ambiguities in requirements and increase the level of formality. The main contribution is the adoption and evaluation of few-shot learning with large pretrained language models for the automated translation of informal requirements to structured languages such as a requirement DSL. © 2022 ACM.},
	language = {English},
	booktitle = {{SLE} 2022 - {Proceedings} of the 15th {ACM} {SIGPLAN} {International} {Conference} on {Software} {Language} {Engineering}, co-located with {SPLASH} 2022},
	publisher = {Association for Computing Machinery, Inc},
	author = {Bertram, Vincent and Boß, Miriam and Kusmenko, Evgeny and Nachmann, Imke Helene and Rumpe, Bernhard and Trotta, Danilo and Wachtmeister, Louis},
	editor = {B, Fischer and L, Burgueno and W, Cazzola},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Requirements engineering, Modeling languages, Problem oriented languages, Translation (languages), Learning algorithms, Model-driven Engineering, Language processing, Natural language processing, Language model, Learning systems, Computational linguistics, Personnel training, Development process, Automated processing, Automotive domains, Few-shot learning, Model-driven requirements engineerings},
	pages = {260 -- 265},
	annote = {Cited by: 0; Conference name: 15th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2022, co-located with the ACM SIGPLAN conference on Systems, Programming, Languages, and Applications. SPLASH 2022; Conference date: 6 December 2022 through 7 December 2022; Conference code: 186053},
	annote = {Cited by: 2; Conference name: 15th ACM SIGPLAN International Conference on Software Language Engineering, SLE 2022, co-located with the ACM SIGPLAN conference on Systems, Programming, Languages, and Applications. SPLASH 2022; Conference date: 6 December 2022 through 7 December 2022; Conference code: 186053},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{lyu_platform_2022,
	title = {Platform of {Formal} {Modeling} and {Analysis} for {Airborne} {Software} {Requirements}},
	isbn = {978-1-4503-9714-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150485584&doi=10.1145%2f3573428.3573646&partnerID=40&md5=8aa5008827546f0309b6f2d240dea33a},
	doi = {10.1145/3573428.3573646},
	abstract = {Airborne software systems play very important roles in modern civil aircraft systems, and there are several safety standards, including DO-178B/C, etc., that are compulsory to be satisfied before airborne software can be certificated by the authority of government. According to the DO-178B/C, the consistency and integrity of airborne software requirements must be analyzed and verified in the early stage of software development. In this paper, we introduce a formal modeling and analysis tool platform (ART: Avionics Requirement Tools) for airborne software natural language requirements, and a case study of the requirements of the software subsystem of the Indication-Recording System (IRS) is provided. Firstly, we give the semantics of a formal Variable Relationship Model (VRM), the platform architecture, and toolchain of ART. Then a methodology of formal analysis of requirement consistency and integrity based on a multi-paradigm is given. After that, some details of the case study of IRS are shown including: how to make a preproccessing of original requirements and the automatic analysis process of the requirement model, such as the preprocessing and standardization of original requirement items, automatic generation of VRM models and multi-paradigm based formal analysis, etc. Lastly, some experiences of this case study are shown. © 2022 Association for Computing Machinery.},
	language = {English},
	booktitle = {{ACM} {International} {Conference} {Proceeding} {Series}},
	publisher = {Association for Computing Machinery},
	author = {Lyu, Jiarun and Hu, Jun and Wang, Lisong},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Software design, Semantics, Natural language requirements, Modeling languages, Case-studies, Relation models, Variable relation model, Airborne software, Formal modeling, Formal modeling and analysis, Formal modeling for airborne software, Natural language requirement modeling, Requirements modeling},
	pages = {1221 -- 1234},
	annote = {Cited by: 0; Conference name: 6th International Conference on Electronic Information Technology and Computer Engineering, EITCE 2022; Conference date: 21 October 2022 through 23 October 2022; Conference code: 187251},
	annote = {Cited by: 0; Conference name: 6th International Conference on Electronic Information Technology and Computer Engineering, EITCE 2022; Conference date: 21 October 2022 through 23 October 2022; Conference code: 187251},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{lukacs_transformation_2022,
	title = {Transformation domain requirements specification into computation tree logic language},
	isbn = {978-1-66547-631-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160439746&doi=10.1109%2fCogMob55547.2022.10117911&partnerID=40&md5=898480f829fb72546c3298a48483a367},
	doi = {10.1109/CogMob55547.2022.10117911},
	abstract = {The requirements specification languages are frequently challenged in every domain - including the safety aspects of cognitive mobility. The correct formalization and communication of the expectations related to the systems is a decisively important step (i.e. the intra cognitive mobility aspect of this early design step) because the effects of the mistakes made during the development and analysis of the requirements are magnified in the later phases of the development life cycle. Formal description and modeling of the requirements become even more imperative with the increasing level of automation in transport as there is gradually less human supervision and intervention in case of undesired/erroneous behavior. For this reason, regulations and standards recommend the use of semi-formal and formal requirement description languages during the development of systems. However, it can be difficult for experts of a specific field to use a field-independent, completely formal method, partly due to their lack of necessary background knowledge, and partly because formal descriptions are difficult to read. It is, therefore worthwhile to strive for a compromise, and to develop a formalism that fits the specific field and is a little closer to natural language. This paper presents a possible methodology (transformation process) for developing and applying of such an intermediate language. The constructed intermediate language (we call it 'restricted textual template') provides an easy-to-apply, practice-oriented language compared to currently available solutions. We aim to support the work of the transportation engineers who work in the development of industrial control systems. © 2022 IEEE.},
	language = {English},
	booktitle = {2022 {IEEE} 1st {International} {Conference} on {Cognitive} {Mobility}, {CogMob} 2022},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Lukacs, Gabor and Bartha, Tamas},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Formal specification, Temporal logic, Model checking, Specification languages, Computer circuits, Requirements specifications, Cognitive systems, Formal Description, Computation tree logic, Domain requirements, Intermediate languages, Life cycle, Logic languages, Models checking, Requirements specification language, Safety aspects, Transformation domain},
	pages = {73 -- 78},
	annote = {Cited by: 0; Conference name: 1st IEEE International Conference on Cognitive Mobility, CogMob 2022; Conference date: 12 October 2022 through 13 October 2022; Conference code: 188685},
	annote = {Cited by: 0; Conference name: 1st IEEE International Conference on Cognitive Mobility, CogMob 2022; Conference date: 12 October 2022 through 13 October 2022; Conference code: 188685},
	annote = {RELEVANCE: HIGH
https://ieeexplore.ieee.org/document/10117911
},
}


@article{wang_requirement_2023,
	title = {Requirement specification extraction and analysis based on propositional projection temporal logic},
	issn = {20477481},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150895714&doi=10.1002%2fsmr.2558&partnerID=40&md5=d57ddd6c9d5323fd9d0605497391ca43},
	doi = {10.1002/smr.2558},
	abstract = {At present, formal methods significantly facilitate the specification and verification of security requirements in requirement engineering, which can reduce requirement errors in the early stage of system development. Extracting formal specifications from security requirements and then evaluating the quality of the requirements are regarded as a promising solution to ensure software quality. Propositional projection temporal logic (PPTL) with a strong mathematical basis and full regular expressiveness is a suitable language for formal specifications. Inspired by natural language processing and text mining techniques, this paper designs and implements a tool, namely, NL2PPTL, to generate formal coarse-grained and fine-grained specifications in terms of PPTL formulas automatically. In specific, the grammatical production rules are defined to construct the syntax tree, and then, the formula is obtained by post-order traversal of the tree. The satisfiability of the PPTL specifications can be checked utilizing PPTLSAT. In addition, the state transformation model is constructed from fine-grained specifications, so as to discover scope conflicts and verify the security properties of the requirement case. © 2023 John Wiley \& Sons Ltd.},
	language = {English},
	journal = {Journal of Software: Evolution and Process},
	author = {Wang, Xiaobing and Li, Chunyi and Zhao, Liang},
	year = {2023},
	note = {Publisher: John Wiley and Sons Ltd
Type: Article},
	keywords = {Natural language processing systems, Computer software selection and evaluation, Formal specification, Temporal logic, Computer circuits, Cryptography, Security requirements, Requirements specifications, Requirement engineering, System development, Specification and verification, Propositional projection temporal logic, Trees (mathematics), Fine grained, Mathematical basis, Requirement errors, Software Quality},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: HIGH
},
}


@article{russo_supporting_2023,
	title = {Supporting decision making in design creativity through requirements identification and evaluation},
	volume = {11},
	issn = {21650349},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150790330&doi=10.1080%2f21650349.2023.2189625&partnerID=40&md5=eeb8ab51f067397176523e60c2aa6963},
	doi = {10.1080/21650349.2023.2189625},
	abstract = {Product innovation, based on the identification and implementation of new solutions, is essential to keep a company competitive. However, the risk of failure of a new solution must be properly weighted during the decision-making in the design activity. This study proposes a method to evaluate a new design solution through the comparison with an old one to be substituted, and based on their requirements. In order to better evaluate the new solution, new requirements about its specific peculiarities are extracted from patents of similar solutions and considered in the evaluation. Requirements extraction is carried out automatically, through natural language processing, while the evaluation considers technical, marketing, and economic criteria. In particular, financial proceeds and patents investments were considered. The proposed method was applied in a real industrial case study were the substitution of carbon fiber heating mat over the copper heating mat was assessed. This study contributes to support creativity in innovation design by providing unknown requirements on which to work on the new product. In addition, it can stimulate the designer on this aim, by presenting the requirements along with new ideas, already implementing them in other fields/contexts that can act as sources of inspiration or creativity triggers. © 2023 Informa UK Limited, trading as Taylor \& Francis Group.},
	language = {English},
	number = {3},
	journal = {International Journal of Design Creativity and Innovation},
	author = {Russo, Davide and Spreafico, Matteo and Spreafico, Christian},
	year = {2023},
	note = {Publisher: Taylor and Francis Ltd.
Type: Article},
	pages = {209 -- 225},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: NULL not freely available
},
}


@inproceedings{sharma_instructing_2023,
	title = {Instructing {Robots} with {Natural} {Language} via {Bi}-{RNNs} for {Temporal} {Logic} {Translation}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184383465&partnerID=40&md5=9a09f07a3d2022b763a0a17f7d14289d},
	abstract = {We consider the problem of planning trajectories that satisfy natural language instruction. We explore translating natural language commands to temporal logic formulae to resolve ambiguities for planning. Our main contribution is a new bi-directional recurrent neural network (Bi-RNN) architecture for this translation task. We experimentally show that the proposed Bi-RNN architecture achieves 1.6\% better accuracy, 20\% faster inference time, and 98\% faster training time compared to leading models owing to bidirectional processing. The overall system, including a planning algorithm, exhibits useful diverse behaviours that satisfy given instructions. © 2023 Australasian Robotics and Automation Association. All rights reserved.},
	language = {English},
	booktitle = {Australasian {Conference} on {Robotics} and {Automation}, {ACRA}},
	publisher = {Australasian Robotics and Automation Association},
	author = {Sharma, Suryansh and Brian Lee, Ki Myung and Brown, Mason and Best, Graeme},
	year = {2023},
	note = {ISSN: 14482053
Type: Conference paper},
	keywords = {Natural languages, Temporal logic, Computer circuits, Translation (languages), Temporal logic formula, Robotics, Recurrent neural networks, Network architecture, Bi-directional, Bidirectional processing, Fast inference, Leading models, Planning algorithms, Recurrent neural network architectures, Training time},
	annote = {Conference name: 2023 Australasian Conference on Robotics and Automation, ACRA 2023; Conference date: 4 December 2023 through 6 December 2023; Conference code: 196740},
	annote = {Conference name: 2023 Australasian Conference on Robotics and Automation, ACRA 2023; Conference date: 4 December 2023 through 6 December 2023; Conference code: 196740},
	annote = {ISSN: 14482053 Type: Conference paper},
}


@article{v_proceedings_2023,
	title = {Proceedings of the 20th {European} {Conference} on {Multi}-{Agent} {Systems}, {EUMAS} 2023},
	volume = {14282 LNAI},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172032229&partnerID=40&md5=0eb439b72b7cf1c1801d2a5b6ebe2295},
	abstract = {The proceedings contain 45 papers. The special focus in this conference is on Multi-Agent Systems. The topics include: SHAPE: A Framework for Evaluating the Ethicality of Influence; modelling Group Performance in Multiagent Systems: Introducing the CollabQuest Simulation Game; towards Developing an Agent-Based Model of Price Competition in the European Pharmaceutical Parallel Trade Market; Using a BDI Agent to Represent a Human on the Factory Floor of the ARIAC 2023 Industrial Automation Competition; Symbolic LTLf Best-Effort Synthesis; robust Explanations for Human-Neural Multi-agent Systems with Formal Verification; LTLf Synthesis Under Environment Specifications for Reachability and Safety Properties; logic-Based Approximations of Preferences; a Comparative Analysis of Multi-agent Simulation Platforms for Energy and Mobility Management; on the Graph Theory of Majority Illusions; observational Preorders for Alternating Transition Systems; synthesising Reward Machines for Cooperative Multi-Agent Reinforcement Learning; adaptive Cognitive Agents: Updating Action Descriptions and Plans; pretty Good Strategies and Where to Find Them; a Multi-agent Sudoku Through the Wave Function Collapse; AGAMAS: A New Agent-Oriented Traffic Simulation Framework for SUMO; coordinating Systems of Digital Twins with Digital Practices; on Admissible Behaviours for Goal-Oriented Decision-Making of Value-Aware Agents; multi-tasking Resource-Constrained Agents Reach Higher Accuracy When Tasks Overlap; election Manipulation on Social Networks with Abstention; qualitative Uncertainty Reasoning in AgentSpeak; supporting Adaptive Multi-Agent Systems with Digital Twins Environments; A Step Forward to Widespread BDI AOP: JaKtA; a Brief Overview of an Approach Towards Ethical Decision-Making; on Verifying Unbounded Client-Server Systems; Capacity ATL: Reasoning About Agent Profiles and Applications to Cybersecurity; value-Awareness Engineering: Towards Learning Context-Based Value Taxonomies; virtual Environments via Natural Language Agents; reasoning About Smart Parking; Towards the Optimization of Speculative PDES Platforms in Shared-Memory Multi-core Machines; decidability Borders of Verification of Communicating Datalog Agents; JaKtA: BDI Agent-Oriented Programming in Pure Kotlin; ltlf Best-Effort Synthesis for Single and Multiple Goal and Planning Domain Specifications; optimal Rescue Sequences in Disastrous Incidents; Behavioral QLTL.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {V, Malvone and A, Murano},
	year = {2023},
	note = {ISBN: 978-303143263-7
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: Proceedings of the 20th European Conference on Multi-Agent Systems, EUMAS 2023; Conference date: 14 September 2023 through 15 September 2023; Conference code: 300419},
	annote = {Cited by: 0; Conference name: Proceedings of the 20th European Conference on Multi-Agent Systems, EUMAS 2023; Conference date: 14 September 2023 through 15 September 2023; Conference code: 300419},
	annote = {RELEVANCE:LOW - procedings
},
}


@article{korel_text--ontology_2023,
	title = {Text-to-{Ontology} {Mapping} via {Natural} {Language} {Processing} with {Application} to {Search} for {Relevant} {Ontologies} in {Catalysis} †},
	volume = {12},
	issn = {2073431X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146810459&doi=10.3390%2fcomputers12010014&partnerID=40&md5=2cb5d123a804a5861652a5337e14b843},
	doi = {10.3390/computers12010014},
	abstract = {The paper presents a machine-learning based approach to text-to-ontology mapping. We explore a possibility of matching texts to the relevant ontologies using a combination of artificial neural networks and classifiers. Ontologies are formal specifications of the shared conceptualizations of application domains. While describing the same domain, different ontologies might be created by different domain experts. To enhance the reasoning and data handling of concepts in scientific papers, finding the best fitting ontology regarding description of the concepts contained in a text corpus. The approach presented in this work attempts to solve this by selection of a representative text paragraph from a set of scientific papers, which are used as data set. Then, using a pre-trained and fine-tuned Transformer, the paragraph is embedded into a vector space. Finally, the embedded vector becomes classified with respect to its relevance regarding a selected target ontology. To construct representative embeddings, we experiment with different training pipelines for natural language processing models. Those embeddings in turn are later used in the task of matching text to ontology. Finally, the result is assessed by compressing and visualizing the latent space and exploring the mappings between text fragments from a database and the set of chosen ontologies. To confirm the differences in behavior of the proposed ontology mapper models, we test five statistical hypotheses about their relative performance on ontology classification. To categorize the output from the Transformer, different classifiers are considered. These classifiers are, in detail, the Support Vector Machine (SVM), k-Nearest Neighbor, Gaussian Process, Random Forest, and Multilayer Perceptron. Application of these classifiers in a domain of scientific texts concerning catalysis research and respective ontologies, the suitability of the classifiers is evaluated, where the best result was achieved by the SVM classifier. © 2023 by the authors.},
	language = {English},
	number = {1},
	journal = {Computers},
	author = {Korel, Lukáš and Yorsh, Uladzislau and Behr, Alexander S. and Kockmann, Norbert and Holeňa, Martin},
	year = {2023},
	note = {Publisher: MDPI
Type: Article},
	annote = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{sudhi_natural_2023,
	title = {Natural {Language} {Processing} for {Requirements} {Formalization}: {How} to {Derive} {New} {Approaches}?},
	volume = {1091 SCI},
	issn = {1860949X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163377601&doi=10.1007%2f978-3-031-26651-5_1&partnerID=40&md5=59946197913f204f8e38fa1596520c70},
	doi = {10.1007/978-3-031-26651-5_1},
	abstract = {It is a long-standing desire of industry and research to automate the software development and testing process as much as possible. Model-based design and testing methods have been developed to automate several process steps and handle the growing complexity and variability of software systems. However, major effort is still required to create specification models from a large set of functional requirements provided in natural language. Numerous approaches based on natural language processing (NLP) have been proposed in the literature to generate requirements models using mainly syntactic properties. Recent advances in NLP show that semantic quantities can also be identified and used to provide better assistance in the requirements formalization process. In this work, we present and discuss principal ideas and state-of-the-art methodologies from the field of NLP in order to guide the readers on how to derive new requirements formalization approaches according to their specific use case and needs. We demonstrate our approaches on two industrial use cases from the automotive and railway domains and show that the use of current pre-trained NLP models requires less effort to adapt to a specific use case. Furthermore, we outline findings and shortcomings of this research area and propose some promising future developments. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Studies in Computational Intelligence},
	author = {Sudhi, Viju and Kutty, Libin and Gröpler, Robin},
	editor = {B, Schlingloff and T, Vogel and A, Skowron},
	year = {2023},
	note = {ISBN: 978-303126650-8
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	pages = {1 -- 27},
	annote = {Cited by: 0; Conference name: 29th International Workshop on Concurrency, Specification and Programming, CS and P 2021; Conference date: 27 September 2021 through 28 September 2021; Conference code: 294419; All Open Access, Green Open Access},
	annote = {Cited by: 0; Conference name: 29th International Workshop on Concurrency, Specification and Programming, CS and P 2021; Conference date: 27 September 2021 through 28 September 2021; Conference code: 294419; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{bombieri_mapping_2023,
	title = {Mapping natural language procedures descriptions to linear temporal logic templates: an application in the surgical robotic domain},
	volume = {53},
	issn = {0924669X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168563884&doi=10.1007%2fs10489-023-04882-0&partnerID=40&md5=ca7b984a2effef53e105490cf558f48a},
	doi = {10.1007/s10489-023-04882-0},
	abstract = {Natural language annotations and manuals can provide useful procedural information and relations for the highly specialized scenario of autonomous robotic task planning. In this paper, we propose and publicly release AUTOMATE, a pipeline for automatic task knowledge extraction from expert-written domain texts. AUTOMATE integrates semantic sentence classification, semantic role labeling, and identification of procedural connectors, in order to extract templates of Linear Temporal Logic (LTL) relations that can be directly implemented in any sufficiently expressive logic programming formalism for autonomous reasoning, assuming some low-level commonsense and domain-independent knowledge is available. This is the first work that bridges natural language descriptions of complex LTL relations and the automation of full robotic tasks. Unlike most recent similar works that assume strict language constraints in substantially simplified domains, we test our pipeline on texts that reflect the expressiveness of natural language used in available textbooks and manuals. In fact, we test AUTOMATE in the surgical robotic scenario, defining realistic language constraints based on a publicly available dataset. In the context of two benchmark training tasks with texts constrained as above, we show that automatically extracted LTL templates, after translation to a suitable logic programming paradigm, achieve comparable planning success in reduced time, with respect to logic programs written by expert programmers. © 2023, The Author(s).},
	language = {English},
	number = {22},
	journal = {Applied Intelligence},
	author = {Bombieri, Marco and Meli, Daniele and Dall’Alba, Diego and Rospocher, Marco and Fiorini, Paolo},
	year = {2023},
	note = {Publisher: Springer
Type: Article},
	keywords = {Natural language processing systems, Natural languages, Semantics, Temporal logic, Linear temporal logic, Computer circuits, Translation (languages), Logic programming, Language processing, Natural language processing, Statistical tests, Robot programming, Pipelines, Program translators, Autonomous planning, Autonomous robotics, Logic-programming, Robotic surgery, Robotic tasks, Surgical robotics, Task planning},
	pages = {26351 -- 26363},
	annote = {Cited by: 0; All Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 0; All Open Access, Hybrid Gold Open Access},
	annote = {Place: USA Publisher: Kluwer Academic Publishers},
	annote = {Place: USA Publisher: Kluwer Academic Publishers},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{haim_binding_2023,
	title = {Binding {Language} in {Administrative} {Guidance} {Documents}},
	isbn = {979-840070197-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177840215&doi=10.1145%2f3594536.3595127&partnerID=40&md5=b019317716bad449c377dd858d8e5bbe},
	doi = {10.1145/3594536.3595127},
	abstract = {Do regulatory guidance documents use binding language despite being purportedly non-binding? Regulatory agencies play a crucial role in modern societies by issuing regulations. While most regulations are promulgated as rules with public notice and comment procedures, administrative guidance documents are as abundant but less studied. They have less formal requirements and are meant as non-binding guidelines, yet skeptics argue they are often used to evade judicial review, and courts turn to their text to inquire whether they are effectively binding. Recent advancements in text analysis methods have allowed scholars to analyze regulatory text, including the measurement of binding language. However, guidance documents have not been part of this trend, largely due to their inaccessibility. This article contributes to the field of empirical legal studies and administrative law by constructing a novel dataset of guidance documents, leveraging a unique policy change. It uses text analysis methods with qualitative insights from doctrinal court decisions, and finds that guidance documents are in fact less binding than rules, but that binding language increased over time and that substantial portions of available documents score higher than a document struck down by a court. © ICAIL 2023. All rights reserved.},
	language = {English},
	booktitle = {19th {International} {Conference} on {Artificial} {Intelligence} and {Law}, {ICAIL} 2023 - {Proceedings} of the {Conference}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Haim, Amit},
	year = {2023},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Language processing, Natural language processing, Regulation, Laws and legislation, Administrative law, Guidance, Guidance document, Regulatory guidance, Rule, Text-analysis methods},
	pages = {407 -- 411},
	annote = {Cited by: 0; Conference name: 19th International Conference on Artificial Intelligence and Law, ICAIL 2023; Conference date: 19 June 2023 through 23 June 2023; Conference code: 193952},
	annote = {Cited by: 0; Conference name: 19th International Conference on Artificial Intelligence and Law, ICAIL 2023; Conference date: 19 June 2023 through 23 June 2023; Conference code: 193952},
	annote = {Type: Conference paper},
}


@inproceedings{hains_machine_2023,
	title = {Machine {Learning} {Pseudo}-{Natural} {Language} for {Temporal} {Logic} {Requirements} of {Embedded} {Systems}},
	isbn = {979-835032974-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178520056&doi=10.1109%2fKSE59128.2023.10299468&partnerID=40&md5=9923076b0db1afb9d8e849603a3fbf4e},
	doi = {10.1109/KSE59128.2023.10299468},
	abstract = {Requirements formalization is a critical part of any verification methodology for embedded systems like those in the automotive industry. There is a strong tension between techniques that enter requirements as logic- or code-like formal expressions and others that use natural language. The former are much safer but require user training and have low productivity. As a compromise we proposed a context-free grammar for entering real-time system requirements and translating them to temporal logic (TL) unambiously and reversibly. It has been demonstrated on hundreds of examples and became validated by a recent patent. But building or extending the grammar itself requires a precise understanding of the translation rules. To aleviate this new hurdle we have found that neural nets inspired by NLP can learn and then replace the pseudo-English-to-TL translation, and allow extending it without the explicit use of a grammar. The paper explains how we mixed real-life and synthetic datasets and overcame the initial limitations of the neural nets. © 2023 IEEE.},
	language = {English},
	booktitle = {Proceedings - {International} {Conference} on {Knowledge} and {Systems} {Engineering}, {KSE}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Hains, Gaetan and Fenek, Ouarda},
	editor = {H.T.T, Binh and V.T, Hoang and L.M, Nguyen and S.V, Le and T.D, Vu and D.T, Pham},
	year = {2023},
	note = {ISSN: 26944804
Type: Conference paper},
	keywords = {natural language processing, Natural language processing systems, Natural languages, Requirements engineering, Temporal logic, Computer circuits, Requirements formalizations, Safety engineering, Embedded systems, Translation (languages), Machine learning, Real time systems, Learning algorithms, Software engineering, Safety critical systems, Language processing, Natural language processing, Learning systems, Interactive computer systems, Real-time systems, Productivity, Requirements formalization, Neural networks, deep learning, Deep learning, Training, Adaptation models, Real-time embedded systems, Automotive industry, Embedded-system, Engineering productivity, Software engineering productivity, real-time embedded systems, safety-critical systems, software engineering productivity},
	annote = {Cited by: 0; Conference name: 15th International Conference on Knowledge and Systems Engineering, KSE 2023; Conference date: 18 October 2023 through 20 October 2023; Conference code: 194303},
	annote = {Cited by: 0; Conference name: 15th International Conference on Knowledge and Systems Engineering, KSE 2023; Conference date: 18 October 2023 through 20 October 2023; Conference code: 194303},
	annote = {ISSN: 26944804 Type: Conference paper},
}


@article{manzanas_lopez_empirical_2024,
	title = {Empirical {Analysis} of {Benchmark} {Generation} for the {Verification} of {Neural} {Network} {Image} {Classifiers}},
	volume = {14380 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180626727&doi=10.1007%2f978-3-031-46002-9_21&partnerID=40&md5=a76eab7194236986a054fcf102e5b2c4},
	doi = {10.1007/978-3-031-46002-9_21},
	abstract = {Deep Learning success in a wide range of applications, such as image recognition and natural language processing, has led to the increasing usage of this technology in many domains, including safety-critical applications such as autonomous cars and medicine. The usage of the models, e.g., neural networks, in safety critical applications demands a thorough evaluation from a component and system level perspective. In these domains, formal methods have the ability to guarantee the correct operation of these components. Despite great efforts in the formal verification of neural networks in the past decade, several challenges remain. One of these challenges is the development of neural networks for easier verification. In this work, we present an empirical analysis, presented as a Latin Hypercube experiment design, in which we evaluate how regularization and initialization methods across different random seeds on two datasets affect the verification analysis of a reachability analysis technique for the verification of neural networks. We show that there are certain training routines that simplify the formal verification task. Lastly, a discussion on how these training approaches impact the robustness verification and reachability computation of the method utilized is included. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Manzanas Lopez, Diego and Johnson, Taylor T.},
	editor = {B, Steffen},
	year = {2024},
	note = {ISBN: 978-303146001-2
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Formal verification, Safety engineering, Learning algorithms, Language processing, Neural-networks, Deep learning, Medical imaging, Safety critical applications, Autonomous car, Component levels, Empirical analysis, Image classification, Image Classifiers, Image recognition, Reachability analysis},
	pages = {331 -- 347},
	annote = {Cited by: 1; Conference name: 1st International Conference on Bridging the Gap between AI and Reality, AISoLA 2023; Conference date: 23 October 2023 through 28 October 2023; Conference code: 305199},
}


@article{bozzano_model-based_2021,
	title = {Model-based {Safety} {Assessment} of a {Triple} {Modular} {Generator} with {xSAP}},
	volume = {33},
	issn = {09345043},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103672804&doi=10.1007%2fs00165-021-00532-9&partnerID=40&md5=d83c9d143fa80082a512ca1746854197},
	doi = {10.1007/s00165-021-00532-9},
	abstract = {The system design process needs to cope with the increasing complexity and size of systems,motivating the replacement of labor intensivemanual techniques with automated and semi-automated approaches.Recently, formal methods techniques, such as model-based verification and safety assessment, have been increasingly used to model systems under fault and to analyze them, generating artifacts such as fault trees and FMEA tables. In this paper, we show how to apply model-based techniques to a realistic case study from the avionics domain: a high integrity power distribution system, the Triple Modular Generator (TMG). The TMG is composed of a redundant and reconfigurable plant and a controller that must guarantee a high level of reliability. The case study is a significant challenge, from the modeling perspective, since it implements a complex reconfiguration policy, specified via a number of requirements in natural language, including a set of mutually dependent and potentially conflicting priority constraints. Moreover, from the verification standpoint, the controller must be able to handle an exponential number of possible faulty configurations. Our contribution is twofold. First, we formalize and validate the requirements and, using a constraint-based modeling style, we synthesize a correct by construction controller, avoiding the enumeration of all possible fault configurations, as is currently done by manual approaches. Second, we describe a comprehensive methodology and process, supported by the xSAP safety analysis platform that targets the modeling and safety assessment of faulty systems. Using xSAP, we are able to automatically extract minimal cut sets for the TMG. We demonstrate the scalability of our approach by analyzing a parametric version of the TMG case study that contains more than 700 variables and 90 faults. © 2021, British Computer Society.},
	language = {English},
	number = {2},
	journal = {Formal Aspects of Computing},
	author = {Bozzano, Marco and Cimatti, Alessandro and Gario, Marco and Jones, David and Mattarei, Cristian},
	year = {2021},
	note = {Publisher: Springer Science and Business Media Deutschland GmbH
Type: Article},
	keywords = {Modeling languages, Formal verification, Correct-by-construction, Automation, Safety engineering, Controllers, Constraint-based modeling, Exponential numbers, Model based techniques, Model based verification, Model-based safety assessments, Power distribution system, System design process},
	pages = {251 -- 295},
	annote = {Cited by: 2; All Open Access, Bronze Open Access},
	annote = {Cited by: 5; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{sadovykh_veridevops_2021,
	title = {{VeriDevOps}: {Automated} {Protection} and {Prevention} to {Meet} {Security} {Requirements} in {DevOps}},
	volume = {2021-February},
	isbn = {978-3-9819263-5-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108370840&doi=10.23919%2fDATE51398.2021.9474185&partnerID=40&md5=d7f5410a5d4b5d820e2f2eda0800f889},
	doi = {10.23919/DATE51398.2021.9474185},
	abstract = {Current software development practices are increasingly based on using both COTS and legacy components which make such systems prone to security vulnerabilities. The modern practice addressing ever changing conditions, DevOps, promotes frequent software deliveries, however, verification methods artifacts should be updated in a timely fashion to cope with the pace of the process. VeriDevOps, Horizon 2020 project, aims at providing a faster feedback loop for verifying the security requirements and other quality attributes of large scale cyber-physical systems. VeriDevOps focuses on optimizing the security verification activities, by automatically creating verifiable models directly from security requirements formulated in natural language, using these models to check security properties on design models and then generating artefacts such as, tests or monitors that can be used later in the DevOps process. The main drivers for these advances are: Natural Language Processing, a combined formal verification and model-based testing approach, and machine-learning-based security monitors. VeriDevOps is in its initial stage - the project started on 1.10.2020 and it will run for three years. In this paper we will present the major conceptual ideas behind the project approach as well as the organizational settings. © 2021 EDAA.},
	language = {English},
	booktitle = {Proceedings -{Design}, {Automation} and {Test} in {Europe}, {DATE}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Sadovykh, Andrey and Widforss, Gunnar and Truscan, Dragos and Enoiu, Eduard Paul and Mallouli, Wissam and Iglesias, Rosa and Bagnto, Alessandra and Hendel, Olga},
	year = {2021},
	note = {ISSN: 15301591
Type: Conference paper},
	keywords = {Natural language processing systems, Software design, NAtural language processing, Model checking, Formal verification, Cryptography, Security requirements, Automatic test pattern generation, Automation, Embedded systems, DevOps, Legacy systems, Model-based testing approaches, Organizational setting, Security properties, Security verification, Security vulnerabilities, Software development practices},
	pages = {1330 -- 1333},
	annote = {Cited by: 6; Conference name: 2021 Design, Automation and Test in Europe Conference and Exhibition, DATE 2021; Conference date: 1 February 2021 through 5 February 2021; Conference code: 170447},
	annote = {Cited by: 9; Conference name: 2021 Design, Automation and Test in Europe Conference and Exhibition, DATE 2021; Conference date: 1 February 2021 through 5 February 2021; Conference code: 170447},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{noauthor_proceedings_2020,
	title = {Proceedings - 2020 6th {International} {Symposium} on {System} and {Software} {Reliability}, {ISSSR} 2020},
	isbn = {978-0-7381-0497-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098326173&partnerID=40&md5=c8e65793702026036485444757671cc1},
	abstract = {The proceedings contain 25 papers. The topics discussed include: a novel Bayesian algorithm for reliability of exponential model under zero failure environment; constructing formal specification models from domain specific natural language requirements; a method of safe and fast Bluetooth connection and energy saving for educational environment; reliability on deep learning models: a comprehensive observation; application of NB-IoT technology in city open water monitoring; automatic test case generation from formal requirement model for avionics software; and generating adversarial examples for sentiment classifier of Chinese sentences.},
	language = {English},
	booktitle = {Proceedings - 2020 6th {International} {Symposium} on {System} and {Software} {Reliability}, {ISSSR} 2020},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	year = {2020},
	note = {Type: Conference review},
	annote = {Cited by: 0; Conference name: 6th International Symposium on System and Software Reliability, ISSSR 2020; Conference date: 24 October 2020 through 25 October 2020; Conference code: 165486},
	annote = {Cited by: 0; Conference name: 6th International Symposium on System and Software Reliability, ISSSR 2020; Conference date: 24 October 2020 through 25 October 2020; Conference code: 165486},
	annote = {RELEVANCE:LOW - procedings
},
}


@inproceedings{alman_rule_2020,
	title = {Rule mining with {RuM}},
	isbn = {978-1-72819-832-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094822179&doi=10.1109%2fICPM49681.2020.00027&partnerID=40&md5=88689bb1f14c791a3e3fe876ecb34018},
	doi = {10.1109/ICPM49681.2020.00027},
	abstract = {Declarative process modeling languages are especially suitable to model loosely-structured, unpredictable business processes. One of the most prominent of these languages is Declare. The Declare language can be used for all process mining branches and a plethora of techniques have been implemented to support process mining with Declare. However, using these techniques can become cumbersome in practical situations where different techniques need to be combined for analysis. In addition, the use of Declare constraints in practice is often hampered by the difficulty of modeling them: The formal expression of Declare is difficult to understand for users without a background in temporal logics, whereas its graphical notation has been shown to be unintuitive. In this paper, we present RuM, a novel application for rule mining that addresses the abovementioned issues by integrating multiple Declare-based process mining methods into a single unified application. The process mining techniques provided in RuM strongly rely on the use of Declare models expressed in natural language, which has the potential of mitigating the barriers of the language bias. The application has been evaluated by conducting a qualitative user evaluation with eight process analysts. © 2020 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2020 2nd {International} {Conference} on {Process} {Mining}, {ICPM} 2020},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Alman, Anti and Ciccio, Claudio Di and Haas, Dominik and Maggi, Fabrizio Maria and Nolte, Alexander},
	editor = {B, van Dongen and M, Montali and M.T, Wynn},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Business Process, Process mining, Natural languages, Data mining, Modeling languages, Declarative process models, Formal expressions, Graphical notation, Mining, Novel applications, User evaluations},
	pages = {121 -- 128},
	annote = {Cited by: 17; Conference name: 2nd International Conference on Process Mining, ICPM 2020; Conference date: 4 October 2020 through 9 October 2020; Conference code: 164352; All Open Access, Green Open Access},
	annote = {Cited by: 22; Conference name: 2nd International Conference on Process Mining, ICPM 2020; Conference date: 4 October 2020 through 9 October 2020; Conference code: 164352; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
https://rulemining.org/
conformance checking

},
}


@inproceedings{de_brock_nlg4re_2022,
	title = {{NLG4RE}: {How} {NL} {Generation} {Can} {Support} {Validation} in {RE}},
	volume = {3122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128777167&partnerID=40&md5=c7f586d6766f6bad13b0bab16d420729},
	abstract = {Context and motivation: All too frequently functional requirements (FRs) for a (software) system are unclear. Written in natural language, FRs are underspecified for software developers; when written in formal language, FRs are insufficiently comprehensible for users. This is a well-known problem in RE. As long as this either/or dichotomy exists, FRs cannot be a “basis for common agreement among all parties involved”, as Barry Boehm puts it. Question/problem: On the one hand, FRs should unambiguously specify the functional behaviour of the system to be written or adapted, and on the other hand be fully understandable by the customer that must agree with them. What is required to achieve this goal? Principal ideas/results: A specification must describe the Statics as well as the Dynamics. In our approach it consists of a Conceptual Data Model (the data structure, i.e., the Statics) plus a set of System Sequence Descriptions (SSDs) representing the processes (i.e., the Dynamics). SSDs schematically depict the interactions between the primary actor (user), the system (as a black box), and other actors (if any), including the messages between them. We provide a set of rules to generate natural language expressions from both the Conceptual Data Model and the SSDs that are understandable by the user ('Informalisation of formal requirements'). Generating understandable representations of a specification is relevant for requirements validation tasks. Contribution to validation: We introduce a form of Natural Language Generation (the NLG in the title) by defining a grammar and mapping rules to precise and unambiguous expressions in natural language, in order to improve understandability of the FRs and the data model by the user community. © 2022 Copyright for this paper by its authors},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {de Brock, Bert and Suurmond, Coen},
	editor = {J, Fischbach and N, Condori-Fernandez and N, Condori-Fernandez and J, Doerr and M, Ruiz and J.-P, Steghofer and L, Pasquale and A, Zisman and R, Guizzardi and J, Horkoff and A, Perini and A, Susi and M, Daneva and A, Herrmann and K, Schneider and P, Mennig and F, Dalpiaz and D, Dell�Anna and S, Kopczynska and L, Montgomery and A.G, Darby and P, Sawyer},
	year = {2022},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Requirements engineering, Formal languages, Mapping, Specifications, Functional requirement, Validation, Grammar, Conceptual data models, Explainability, Support validations, Syntax-directed mapping, System sequence description, Use case},
	annote = {Cited by: 0; Conference name: Joint REFSQ-2022 Workshops, Doctoral Symposium, and Posters and Tools Track, REFSQ-JP 2022; Conference date: 21 March 2022; Conference code: 178725},
	annote = {Cited by: 0; Conference name: Joint REFSQ-2022 Workshops, Doctoral Symposium, and Posters and Tools Track, REFSQ-JP 2022; Conference date: 21 March 2022; Conference code: 178725},
	annote = {RELEVANCE: HIGH
},
}


@article{wang_spatio-clock_2021,
	title = {Spatio-{Clock} {Synchronous} {Constraint} {Guided} {Safe} {Reinforcement} {Learning} for {Autonomous} {Driving}; [面向无人驾驶时空同步约束制导的安全强化学习]},
	volume = {58},
	issn = {10001239},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121140394&doi=10.7544%2fissn1000-1239.2021.20211023&partnerID=40&md5=89365577615c30a8f26abfbdbf2fec59},
	doi = {10.7544/issn1000-1239.2021.20211023},
	abstract = {Autonomous driving systems integrate complex interactions between hardware and software. In order to ensure the safe and reliable operations, formal methods are used to provide rigorous guarantees to satisfy logical specifications and safety-critical requirements in the design stage. As a widely employed machine learning architecture, deep reinforcement learning (DRL) focuses on finding an optimal policy that maximizes a cumulative discounted reward by interacting with the environment, and has been applied to autonomous driving decision-making modules. However, black-box DRL-based autonomous driving systems cannot provide guarantees of safe operation and reward definition interpretability techniques for complex tasks, especially when they face unfamiliar situations and reason about a greater number of options. In order to address these problems, spatio-clock synchronous constraint is adopted to augment DRL safety and interpretability. Firstly, we propose a dedicated formal properties specification language for autonomous driving domain, i.e., spatio-clock synchronous constraint specification language, and present domain-specific knowledge requirements specification that is close to natural language to make the reward functions generation process more interpretable. Secondly, we present domain-specific spatio-clock synchronous automata to describe spatio-clock autonomous behaviors, i.e., controllers related to certain spatio- and clock-critical actions, and present safe state-action space transition systems to guarantee the safety of DRL optimal policy generation process. Thirdly, based on the formal specification and policy learning, we propose a formal spatio-clock synchronous constraint guided safe reinforcement learning method with the goal of easily understanding the safe reward function. Finally, we demonstrate the effectiveness of our proposed approach through an autonomous lane changing and overtaking case study in the highway scenario. © 2021, Science Press. All right reserved.},
	language = {Chinese},
	number = {12},
	journal = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
	author = {Wang, Jinyong and Huang, Zhiqiu and Yang, Deyan and Huang, Xiaowei and Zhu, Yi and Hua, Gaoyang},
	year = {2021},
	note = {Publisher: Science Press
Type: Article},
	keywords = {Decision making, Formal specification, Specification languages, Safety engineering, Reinforcement learning, Autonomous vehicles, Deep learning, Domain Knowledge, Autonomous driving, Autonomous driving safety, Constraint guided, Driving safety, Intelligent traffic simulation, Intelligent traffics, Safe reinforcement learning, Spatio-clock synchronoi constraint, Temporal differences, Traffic simulations},
	pages = {2585 -- 2603},
	annote = {Cited by: 1},
	annote = {Cited by: 3},
	annote = {RELEVANCE: NULL not in english
},
}


@inproceedings{germiniani_mist_2020,
	title = {{MIST}: {Monitor} generation from informal specifications for firmware verification},
	volume = {2020-October},
	isbn = {978-1-72815-409-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101080043&doi=10.1109%2fVLSI-SOC46417.2020.9344072&partnerID=40&md5=301a8b5d12762bab24892f155e33ab29},
	doi = {10.1109/VLSI-SOC46417.2020.9344072},
	abstract = {This paper presents MIST, an all-in-one tool capable of generating a complete environment to verify C/C++ firmwares starting from informal specifications. Given a set of specifications written in natural language, the tool guides the user in translating each specification into an XML formal description, capturing a temporal behavior that must hold in the design. Our XML format guarantees the same expressiveness of linear temporal logic, but it is designed to be used by designers that are not familiar with formal methods. Once each behavior is formalized, MIST automatically generates the corresponding test-bench and checker to stimulate and verify the design. In order to guide the verification process, MIST employs a clustering procedure that classifies the internal states of the firmware. Such classification aims at finding an effective ordering to check the expected behaviors and to advise for possible specification holes. MIST has been fully integrated into the IAR System Embedded Workbench. Its effectiveness and efficiency have been evaluated to formalize and check a complex test-plan for an industrial firmware. © 2020 IEEE.},
	language = {English},
	booktitle = {{IEEE}/{IFIP} {International} {Conference} on {VLSI} and {System}-on-{Chip}, {VLSI}-{SoC}},
	publisher = {IEEE Computer Society},
	author = {Germiniani, Samuele and Bragaglio, Moreno and Pravadelli, Graziano},
	year = {2020},
	note = {ISSN: 23248432
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Linear temporal logic, Formal verification, XML, C++ (programming language), Clustering procedure, Effectiveness and efficiencies, Firmware, Formal Description, Fully integrated, Temporal behavior, Verification process, VLSI circuits},
	pages = {111 -- 116},
	annote = {Cited by: 0; Conference name: 28th IFIP/IEEE International Conference on Very Large Scale Integration, VLSI-SOC 2020; Conference date: 5 October 2020 through 7 October 2020; Conference code: 167075},
	annote = {Cited by: 0; Conference name: 28th IFIP/IEEE International Conference on Very Large Scale Integration, VLSI-SOC 2020; Conference date: 5 October 2020 through 7 October 2020; Conference code: 167075},
	annote = {RELEVANCE: MEDIUM
},
}


@article{cai_re-introduction_2022,
	title = {Re-introduction to {Tibetan} {Case} {Structure} and {Its} {Grammatical} {Functions}},
	volume = {1587 CCIS},
	issn = {18650929},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135060069&doi=10.1007%2f978-3-031-06761-7_17&partnerID=40&md5=1acd86a983216ada33894b2fb937f935},
	doi = {10.1007/978-3-031-06761-7_17},
	abstract = {Tibetan linguistics has a long history and has formed a relatively complete traditional grammar system, but there is no recognized and relatively complete modern formal grammar framework of Tibetan. In order to inherit, expand, extend and deepen the traditional Tibetan grammar and its formal requirements, this paper makes comparative study on Fillmore case grammar with traditional Tibetan grammar, and introduces a new Tibetan grammatical unit called case structure, and demonstrates that the case structure plays an important role in Tibetan syntactic and semantic analysis. Different case structures of the same verb form Tibetan sentences, and one Tibetan sentence can be uniquely decomposed into one or more case structures. Case structure not only carries the syntactic structure of the sentence, but also reflects the semantic components of the sentence. Therefore, under this grammatical framework, Tibetan syntactic and semantic analysis can be studied in an integrated way. This opinion has some certain theoretical significance for Tibetan grammar research and Tibetan natural language processing. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Communications in Computer and Information Science},
	author = {Cai, Hua and Guan, Bai and Li, Kai},
	editor = {X, Sun and X, Zhang and Z, Xia and E, Bertino},
	year = {2022},
	note = {ISBN: 978-303106760-0
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Semantics, Case grammars, Syntactics, Formal grammars, Semantic analysis, Case structures, Comparatives studies, Computational grammars, Grammar systems, Grammatical functions, Syntactic analysis, Tibetan grammar, Tibetans},
	pages = {202 -- 213},
	annote = {Cited by: 0; Conference name: 8th International Conference on Artificial Intelligence and Security , ICAIS 2022; Conference date: 15 July 2022 through 20 July 2022; Conference code: 280409},
	annote = {Cited by: 0; Conference name: 8th International Conference on Artificial Intelligence and Security , ICAIS 2022; Conference date: 15 July 2022 through 20 July 2022; Conference code: 280409},
	annote = {RELEVANCE: LOW
},
}


@article{chen_ontology-based_2020,
	title = {Ontology-based requirement verification for complex systems},
	volume = {46},
	issn = {14740346},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089344185&doi=10.1016%2fj.aei.2020.101148&partnerID=40&md5=43a890218902027e6bdb67b77dfe4531},
	doi = {10.1016/j.aei.2020.101148},
	abstract = {Verification is a necessary part of Model-based systems engineering (MBSE) which is becoming a mainstream methodology for the design of complex systems. Verification in the early design stage has aroused widespread attention for its efficiency and cost-saving. Although there are numbers of researches on verification, some deficiencies still exist, such as the integration of design and verification needs to improve, the design problems are hard to trace and the behavior verification in the early design stage is often omitted. In this study, a novel ontology-based requirement verification method for complex systems is proposed to solve the above-mentioned problems. First, a requirement formalization method is proposed to avoid the ambiguousness of natural language, to make requirements easier to verify, and to make design problems easier to trace. Second, some transformation rules are defined to realize the automatic design ontology and rule generation. Based on these two steps, automated verification can be done through reasoning with ontology models and rules. This verification method is fully integrated with design tools and no additional expertise is needed for designers. To validate its feasibility and advantages, an example of a smart traffic light system is provided. © 2020},
	language = {English},
	journal = {Advanced Engineering Informatics},
	author = {Chen, Ruirui and Chen, Chun-Hsien and Liu, Yusheng and Ye, Xiaoping},
	year = {2020},
	note = {Publisher: Elsevier Ltd
Type: Article},
	keywords = {Natural languages, Ontology, Verification method, Requirement verifications, Automated verification, Transformation rules, Early design stages, Formalization method, Model-based systems engineering (MBSE), Traffic signs},
	annote = {Cited by: 6},
	annote = {Cited by: 9},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{zaki-ismail_rcm-extractor_2021-1,
	title = {{RCM}-{Extractor}: {Automated} {Extraction} of a {Semi} {Formal} {Representation} {Model} from {Natural} {Language} {Requirements}},
	isbn = {978-989-758-487-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173980705&doi=10.5220%2f0010270602700277&partnerID=40&md5=d56fd81ad96d9bb7cbd9a35f2abb4991},
	doi = {10.5220/0010270602700277},
	abstract = {Formal verification requires system requirements to be specified in formal notations. Formalisation of system requirements manually is a time-consuming and error-prone process, and requires engineers to have strong mathematical and domain expertise. Most existing requirements formalisation techniques assume requirements to be specified in pre-defined templates and these techniques employ pre-defined transformation rules to transform requirements specified in the predefined templates to formal notations. These techniques tend to have limited expressiveness and more importantly require system engineers to re-write their system requirements following these templates. In this paper, we introduces an automated extraction technique (RCMExtractor) to extract the key constructs of a comprehensive and formalisable semi-formal representation model from textual requirements. We have evaluated our RCM-Extractor on a dataset of 162 requirements curated from the literature. RCM-Extractor achieved 95\% precision, 79\% recall, 86\% F-measure and 75\% accuracy. © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	language = {English},
	booktitle = {International {Conference} on {Model}-{Driven} {Engineering} and {Software} {Development}},
	publisher = {Science and Technology Publications, Lda},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {E, Seidewitz and L, Ferreira Pires and S, Hammoudi},
	year = {2021},
	note = {ISSN: 21844348
Type: Conference paper},
	pages = {270 -- 277},
	annote = {Cited by: 0; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 300849; All Open Access, Hybrid Gold Open Access},
}


@article{lin_discrete_2021,
	title = {Discrete {Linear} {Temporal} {Logic} with {Knowing}-{Value} {Operator}},
	volume = {13039 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117122447&doi=10.1007%2f978-3-030-88708-7_11&partnerID=40&md5=c21b018c8fe5f586c25fbec9d46bfcd9},
	doi = {10.1007/978-3-030-88708-7_11},
	abstract = {In epistemic logic we are not only interested in the propositional knowledge expressed by “knowing that” operators, but also care about other types of knowledge used in natural language. In [1], Plaza proposed the “knowing value” operators and gave the complete axiomatization for the logic of knowledge with nonrigid designators. Moreover, in [2] Halpern and colleagues holds that, when analyzing a system in terms of knowledge, not only is the current state of knowledge of the agents in the system relevant, but also how that state of knowledge changes over time. So we introduce temporal logic operators ‘next’ and ‘until’ to extend Plaza’s system. The completeness proof is highly non-trivial and we referred to the work of [2, 3]. © 2021, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Lin, Kaiyang},
	editor = {S, Ghosh and T, Icard},
	year = {2021},
	note = {ISBN: 978-303088707-0
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural languages, Temporal logic, Linear temporal logic, Computer circuits, 'current, Common knowledge, Epistemic logic, Knowing value, Change-over time, Complete axiomatizations, Knowledge change, States of knowledge},
	pages = {141 -- 148},
	annote = {Cited by: 0; Conference name: 8th International Workshop on Logic, Rationality and Interaction, LORI 2021; Conference date: 16 October 2021 through 18 October 2021; Conference code: 266579},
}


@inproceedings{peng_itemization_2022,
	title = {Itemization {Framework} of {Requirements} using {Machine} {Reading} {Comprehension}},
	volume = {12451},
	isbn = {978-1-5106-6007-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142053006&doi=10.1117%2f12.2656629&partnerID=40&md5=5dbc5195c4e09c9734266e978171ce10},
	doi = {10.1117/12.2656629},
	abstract = {In practice, it is very important to determine the requirements items of the proposed software system from the requirements document. However, due to the problems of ambiguity, redundancy, ambiguity, and difficulty in traceability of changes in the requirements documents described in natural language, the estimation results are subject to a certain degree, and the process is labor-intensive and cost-intensive. In this paper, we propose a new method to automatically extract requirement entries from requirement text by leveraging a set of natural language processing techniques and machine learning models. Our method is inspired by imitating the process of expert extraction of itemized requirements, which usually consists of three main processes: locating requirement locations and boundaries, building models, and extracting fine-grained requirement semantics. We performed evaluations in the field of military arguments, and the results showed that our model was nearly 80 percent accurate. Our approach can provide sound advice to help industry practitioners extract requirements items faster and easier. © 2022 SPIE.},
	language = {English},
	booktitle = {Proceedings of {SPIE} - {The} {International} {Society} for {Optical} {Engineering}},
	publisher = {SPIE},
	author = {Peng, Siyu and Xu, Luo and Jiang, Wei},
	editor = {F, Zhao},
	year = {2022},
	note = {ISSN: 0277786X
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Requirements engineering, Extraction, Semantics, Requirement engineering, Learning algorithms, Software-systems, Requirement extraction, Requirements document, Attention mechanisms, Estimation results, Machine reading comprehension, Reading comprehension, Semantic Computing},
	annote = {Cited by: 0; Conference name: 5th International Conference on Computer Information Science and Application Technology, CISAT 2022; Conference date: 29 July 2022 through 31 July 2022; Conference code: 183755},
	annote = {Cited by: 0; Conference name: 5th International Conference on Computer Information Science and Application Technology, CISAT 2022; Conference date: 29 July 2022 through 31 July 2022; Conference code: 183755},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{yorsh_text--ontology_2022,
	title = {Text-to-{Ontology} {Mapping} via {Natural} {Language} {Processing} {Models}},
	volume = {3226},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139875540&partnerID=40&md5=6da54e850bc7b9fa8ff112f3ca724e7b},
	abstract = {The paper presents work in progress attempting to solve a text-to-ontology mapping problem. While ontologies are being created as formal specifications of shared conceptualizations of application domains, different users often create different ontologies to represent the same domain. For better reasoning about concepts in scientific papers, it is desired to pick the ontology which best matches concepts present in the input text. We have started to automatize this process and attack the problem by utilizing state-of-the-art NLP tools and neural networks. Given a specific set of ontologies, we experiment with different training pipelines for NLP machine learning models with the aim to construct representative embeddings for the text-to-ontology matching task. We assess the final result through visualizing the latent space and exploring the mappings between an input text and ontology classes. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Yorsh, Uladzislau and Behr, Alexander S. and Kockmann, Norbert and Holeňa, Martin},
	editor = {L, Ciencialova and M, Holena and R, Jajcay and T, Jajcayova and F, Mraz and D, Pardubska and M, Platek},
	year = {2022},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Ontology, Mapping, Learning algorithms, Language processing, Language model, Ontology's, BERT, Fasttext, Matching text to ontology, Matchings, Ontology mapping, Text analysis},
	pages = {28 -- 34},
	annote = {Cited by: 0; Conference name: 22nd Conference Information Technologies - Applications and Theory, ITAT 2022; Conference date: 23 September 2022 through 27 September 2022; Conference code: 183092},
	annote = {Cited by: 0; Conference name: 22nd Conference Information Technologies - Applications and Theory, ITAT 2022; Conference date: 23 September 2022 through 27 September 2022; Conference code: 183092},
	annote = {RELEVANCE: low - IT HAS NEW VERSION 2023
},
}


@inproceedings{zaki-ismail_rcm_2021,
	title = {{RCM}: {Requirement} capturing model for automated requirements formalisation},
	isbn = {978-989-758-487-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102991179&partnerID=40&md5=6141617e81ee4382b5d40b7d3c19ad96},
	abstract = {Most existing automated requirements formalisation techniques require system engineers to (re)write their requirements using a set of predefined requirement templates with a fixed structure and known semantics to simplify the formalisation process. However, these techniques require understanding and memorising requirement templates, which are usually fixed format, limit requirements captured, and do not allow capture of more diverse requirements. To address these limitations, we need a reference model that captures key requirement details regardless of their structure, format or order. Then, using NLP techniques we can transform textual requirements into the reference model. Finally, using a suite of transformation rules we can then convert these requirements into formal notations. In this paper, we introduce the first and key step in this process, a Requirement Capturing Model (RCM) - as a reference model - to model the key elements of a system requirement regardless of their format, or order. We evaluated the robustness of the RCM model compared to 15 existing requirements representation approaches and a benchmark of 162 requirements. Our evaluation shows that RCM breakdowns support a wider range of requirements formats compared to the existing approaches. We also implemented a suite of transformation rules that transforms RCM-based requirements into temporal logic(s). In the future, we will develop NLP-based RCM extraction technique to provide end-to-end solution. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	language = {English},
	booktitle = {{MODELSWARD} 2021 - {Proceedings} of the 9th {International} {Conference} on {Model}-{Driven} {Engineering} and {Software} {Development}},
	publisher = {SciTePress},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {S, Hammoudi and L.F, Pires and E, Seidewitz and R, Soley},
	year = {2021},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Software design, Semantics, System requirements, Formal notations, Transformation rules, End-to-end solutions, Extraction techniques, Reference modeling, Requirement capturing, System engineers},
	pages = {110 -- 121},
	annote = {Cited by: 4; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 167487},
	annote = {Cited by: 4; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 167487},
	annote = {RELEVANCE: MEDIUM
},
}


@article{g_16th_2022,
	title = {16th {KES} {International} {Conference} on {Agents} and {Multi}-{Agent} {Systems}: {Technologies} and {Applications}, {KES}-{AMSTA} 2022},
	volume = {306},
	issn = {21903018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137025923&partnerID=40&md5=4595c5fe95d5f5fc6f7fcafe81381281},
	abstract = {The proceedings contain 26 papers. The special focus in this conference is on Agents and Multi-Agent Systems: Technologies and Applications. The topics include: Impact of COVID-19 on Digital Business Models—Focus on Sustainability; an Investigation into Influences of Tweet Sentiments on Stock Market Movements; negotiation-Based Multi-agent System for Ambient Conditions Control in Accordance with Multiple User Preferences; preface; temporal Logic in Multi-agent Environment; altruistic Behavior Structural Holes and Team Performance; construction of a News Classification System Related to Information Security Incidents; system for Analyzing Innovation Activities in Mergers and Acquisitions by Measuring Technological Distance; how Can We Make the Best Use of Intellectual Capital? Building an Analysis System Through Agent-Based Models; a Customer Experience Mapping for Knowledge Extraction from Social Simulation Results; Corporate Governance Considerations for Driving ESG Performance; using the Knowledge of Competent Salespeople: Modeling Business Negotiation Topics to Obtain Customers’ Real Needs; Explainable AI for Autism Classification in Children; Voice Control System Through NLP (Natural Language Processing) as an Interactive Model for Scalable ERP Platforms in Industry 4.0; Use of Multi-agent System to Classify Control EEG Signals: A Preliminary Study; cost-Aware Dynamic Task Sharing Among Decentralized Autonomous Agents: Towards Dynamic Patient Sharing Among Hospitals; online Social Networks and Psychological Experiences: Analysis of Youth Perceptions Through Data Mining; implementation of an Intelligent Agent for Decision Making Tasks in the Hanoi Towers; a Systematic Review About Requirements Elicitation for Multi-Agent Systems; Implications of the Exact Time Use for the Simulation of Business Processes’ Costs with the TDABC Approach; coping with Diverse Product Demand Through Agent-Led Type Transitions.},
	language = {English},
	journal = {Smart Innovation, Systems and Technologies},
	editor = {G, Jezic and Y.J, Chen-Burger and M, Kusek and R, Šperka and R.J, Howlett and R.J, Howlett and R.J, Howlett and L.C, Jain and L.C, Jain},
	year = {2022},
	note = {ISBN: 978-981193358-5
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: 16th KES International Conference on Agents and Multi-Agent Systems: Technologies and Applications, KES-AMSTA 2022; Conference date: 20 June 2022 through 22 June 2022; Conference code: 282179},
	annote = {Cited by: 0; Conference name: 16th KES International Conference on Agents and Multi-Agent Systems: Technologies and Applications, KES-AMSTA 2022; Conference date: 20 June 2022 through 22 June 2022; Conference code: 282179},
	annote = {RELEVANCE: NULL - procedings
},
}


@article{j_3rd_2022,
	title = {3rd {International} {Conference} on {Process} {Mining}, {ICPM} 2021},
	volume = {433 LNBIP},
	issn = {18651348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127695076&partnerID=40&md5=23197c914f7741df0097450fe25e4cc3},
	abstract = {The proceedings contain 29 papers. The special focus in this conference is on Process Mining. The topics include: xPM: A Framework for Process Mining with Exogenous Data; root Cause Analysis in Process Mining with Probabilistic Temporal Logic; linac: A Smart Environment Simulator of Human Activities; Analyzing Multi-level BOM-Structured Event Data; visualizing Trace Variants from Partially Ordered Event Data; quantifying the Re-identification Risk in Published Process Models; discovering Care Pathways for Multi-morbid Patients Using Event Graphs; interactive Process Mining Applied in a Cardiology Outpatient Department; combining the Clinical and Operational Perspectives in Heterogeneous Treatment Effect Inference in Healthcare Processes; patient Discharge Classification Based on the Hospital Treatment Process; verifying Guideline Compliance in Clinical Treatment Using Multi-perspective Conformance Checking: A Case Study; on the Performance Analysis of the Adversarial System Variant Approximation Method to Quantify Process Model Generalization; towards a Natural Language Conversational Interface for Process Mining; probability Estimation of Uncertain Process Trace Realizations; An Event Data Extraction Approach from SAP ERP for Process Mining; continuous Performance Evaluation for Business Process Outcome Monitoring; PErrCas: Process Error Cascade Mining in Trace Streams; online Prediction of Aggregated Retailer Consumer Behaviour; quantifying Explainability in Outcome-Oriented Predictive Process Monitoring; prescriptive Process Monitoring Under Resource Constraints: A Causal Inference Approach; active Anomaly Detection for Key Item Selection in Process Auditing; event Log Sampling for Predictive Monitoring; can Deep Neural Networks Learn Process Model Structure? An Assessment Framework and Analysis; Rethinking the Input for Process Mining: Insights from the XES Survey and Workshop; preface; process Mining in Trusted Execution Environments: Towards Hardware Guarantees for Trust-Aware Inter-organizational Process Analysis; trustworthy Artificial Intelligence and Process Mining: Challenges and Opportunities.},
	language = {English},
	journal = {Lecture Notes in Business Information Processing},
	editor = {J, Munoz-Gama and X, Lu},
	year = {2022},
	note = {ISBN: 978-303098580-6
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: 3rd International Conference on Process Mining, ICPM 2021; Conference date: 31 October 2021 through 4 November 2021; Conference code: 275959},
	annote = {Cited by: 0; Conference name: 3rd International Conference on Process Mining, ICPM 2021; Conference date: 31 October 2021 through 4 November 2021; Conference code: 275959},
	annote = {RELEVANCE: NULL - procedings
},
}


@article{fischbach_how_2021,
	title = {How {Do} {Practitioners} {Interpret} {Conditionals} in {Requirements}?},
	volume = {13126 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121659573&doi=10.1007%2f978-3-030-91452-3_6&partnerID=40&md5=b52ebc67f40ff7559a210d02c7a738f7},
	doi = {10.1007/978-3-030-91452-3_6},
	abstract = {Context: Conditional statements like “If A and B then C” are core elements for describing software requirements. However, there are many ways to express such conditionals in natural language and also many ways how they can be interpreted. We hypothesize that conditional statements in requirements are a source of ambiguity, potentially affecting downstream activities such as test case generation negatively. Objective: Our goal is to understand how specific conditionals are interpreted by readers who work with requirements. Method: We conduct a descriptive survey with 104 RE practitioners and ask how they interpret 12 different conditional clauses. We map their interpretations to logical formulas written in Propositional (Temporal) Logic and discuss the implications. Results: The conditionals in our tested requirements were interpreted ambiguously. We found that practitioners disagree on whether an antecedent is only sufficient or also necessary for the consequent. Interestingly, the disagreement persists even when the system behavior is known to the practitioners. We also found that certain cue phrases are associated with specific interpretations. Conclusion: Conditionals in requirements are a source of ambiguity and there is not just one way to interpret them formally. This affects any analysis that builds upon formalized requirements (e.g., inconsistency checking, test-case generation). Our results may also influence guidelines for writing requirements. © 2021, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Fischbach, Jannik and Frattini, Julian and Mendez, Daniel and Unterkalmsteiner, Michael and Femmer, Henning and Vogelsang, Andreas},
	editor = {L, Ardito and A, Jedlitschka and M, Morisio and M, Torchiano},
	year = {2021},
	note = {ISBN: 978-303091451-6
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural languages, Requirements engineering, Software requirements, C (programming language), Requirement engineering, Test case generation, Formalisation, Descriptive survey, Logical interpretation, Surveys, Logical formulas, Core elements, Down-stream},
	pages = {85 -- 102},
	annote = {Cited by: 3; Conference name: 22nd International Conference on Product-Focused Software Process Improvement, PROFES 2021; Conference date: 26 November 2021 through 26 November 2021; Conference code: 269309; All Open Access, Green Open Access},
}


@article{rahman_semantic_2021,
	title = {Semantic {Annotations} in {Clinical} {Guidelines}},
	volume = {12611 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103556106&doi=10.1007%2f978-3-030-70650-0_12&partnerID=40&md5=4644b43d36e07823e9fa0f560c4cb040},
	doi = {10.1007/978-3-030-70650-0_12},
	abstract = {Clinical guidelines are evidence-based recommendations developed to assist practitioners in their decisions on appropriate care for patients with specific clinical circumstances. They provide succinct instructions such as what drugs should be given or taken for a particular condition, how long such treatment should be given, what tests should be conducted, or other situational clinical circumstances for certain diseases. However, as they are described in natural language, they are prone to problems such as variability and ambiguity. In this paper, we propose an approach to automatically infer the main components in clinical guideline sentences. Knowing the key concepts in the sentences, we can then feed them to model checkers to validate their correctness. We adapt semantic role labelling approach to mark the key entities in our problem domain. We also implement the technique used for Named-Entity Recognition (NER) task and compare the results. The aim of our work is to build a reasoning framework that combines the information gained from real patient data and clinical practice, with clinical guidelines to give more suitable personalised recommendations for treating patients. © 2021, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Rahman, Fahrurrozi and Bowles, Juliana},
	editor = {J, Bowles and G, Broccia and M, Nanni},
	year = {2021},
	note = {ISBN: 978-303070649-4
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Semantics, Model checking, Hospital data processing, Clinical guideline, Named entity recognition, Semantic annotations, Clinical practices, Particular condition, Personalised recommendations, Reasoning framework},
	pages = {190 -- 205},
	annote = {Cited by: 0; Conference name: 9th International Symposium on From Data Models and Back, DataMod 2020; Conference date: 20 October 2020 through 20 October 2020; Conference code: 256199; All Open Access, Green Open Access},
	annote = {Cited by: 0; Conference name: 9th International Symposium on From Data Models and Back, DataMod 2020; Conference date: 20 October 2020 through 20 October 2020; Conference code: 256199; All Open Access, Green Open Access},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{getmanova_semantic_2022,
	title = {Semantic {Classification} of {Event} {Driven} {Temporal} {Logic} {Requirements}},
	volume = {2022-June},
	isbn = {978-1-66549-804-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137363757&doi=10.1109%2fEDM55285.2022.9855053&partnerID=40&md5=32d40acf74febd1650fa9bfe78cae471},
	doi = {10.1109/EDM55285.2022.9855053},
	abstract = {The process of requirements engineering involves the elaboration of requirements for complex software systems. In our series of works, we consider formalized requirements, which can later be used in the process of formal verification of software system models. For reactive control programs that respond to events from sensors, we have previously proposed to express the requirements in a tabular form as a tuple of Boolean logic formulas. This form constituting a logical pattern with a given linear-time temporal semantics specific to control programs is much clearer than standard temporal logic formulas. However, we found that if one defined constant values instead of formulas in some cells of our table then the final formula can be significantly simplified. Moreover, different combinations of possible variants of cell values can correspond to the same resulting formulas. In this paper, we analyze classes of such formulas by implementing software to simplify the linear-time temporal logic formulas. This approach can be used to obtain a natural language representation of the requirements originally specified formally, with the goal that such representations have a minimal form. © 2022 IEEE.},
	language = {English},
	booktitle = {International {Conference} of {Young} {Specialists} on {Micro}/{Nanotechnologies} and {Electron} {Devices}, {EDM}},
	publisher = {IEEE Computer Society},
	author = {Getmanova, Anastasia N. and Garanina, Natalia O. and Staroletov, Sergey M. and Zyubin, Vladimir E. and Anureev, Igor S.},
	year = {2022},
	note = {ISSN: 23254173
Type: Conference paper},
	keywords = {Requirements engineering, Semantics, Temporal logic, Model checking, Formal verification, Computer circuits, Computer software, Requirement engineering, Models checking, Boolean algebra, Complex software systems, Control program, Control software, Event-driven, Formula simplification, Requirement, Semantic classification, Temporal logic formula},
	pages = {663 -- 668},
	annote = {Cited by: 1; Conference name: 23rd IEEE International Conference of Young Professionals in Electron Devices and Materials, EDM 2022; Conference date: 30 June 2022 through 4 July 2022; Conference code: 182213},
	annote = {Cited by: 2; Conference name: 23rd IEEE International Conference of Young Professionals in Electron Devices and Materials, EDM 2022; Conference date: 30 June 2022 through 4 July 2022; Conference code: 182213},
	annote = {RELEVANCE: NULL
},
}


@inproceedings{tuli_learning_2022,
	title = {Learning to {Follow} {Instructions} in {Text}-{Based} {Games}},
	volume = {35},
	isbn = {978-1-71387-108-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143069110&partnerID=40&md5=dfa7d76bc09dc3808d806a15fff9b7df},
	abstract = {Text-based games present a unique class of sequential decision making problem in which agents interact with a partially observable, simulated environment via actions and observations conveyed through natural language. Such observations typically include instructions that, in a reinforcement learning (RL) setting, can directly or indirectly guide a player towards completing reward-worthy tasks. In this work, we study the ability of RL agents to follow such instructions. We conduct experiments that show that the performance of state-of-the-art text-based game agents is largely unaffected by the presence or absence of such instructions, and that these agents are typically unable to execute tasks to completion. To further study and address the task of instruction following, we equip RL agents with an internal structured representation of natural language instructions in the form of Linear Temporal Logic (LTL), a formal language that is increasingly used for temporally extended reward specification in RL. Our framework both supports and highlights the benefit of understanding the temporal semantics of instructions and in measuring progress towards achievement of such a temporally extended behaviour. Experiments with 500+ games in TextWorld demonstrate the superior performance of our approach. © 2022 Neural information processing systems foundation. All rights reserved.},
	language = {English},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Neural information processing systems foundation},
	author = {Tuli, Mathieu and Li, Andrew C. and Vaezipoor, Pashootan and Klassen, Toryn Q. and Sanner, Scott and McIlraith, Sheila A.},
	editor = {S, Koyejo and S, Mohamed and A, Agarwal and D, Belgrave and K, Cho and A, Oh},
	year = {2022},
	note = {ISSN: 10495258
Type: Conference paper},
	keywords = {Decision making, Natural languages, Semantics, Temporal logic, Formal languages, Linear temporal logic, Performance, Reinforcement learning, Reinforcement learnings, State of the art, Reinforcement learning agent, Decision-making problem, Learning settings, Sequential decision making, Simulated environment},
	annote = {Cited by: 0; Conference name: 36th Conference on Neural Information Processing Systems, NeurIPS 2022; Conference date: 28 November 2022 through 9 December 2022; Conference code: 189185},
	annote = {Cited by: 2; Conference name: 36th Conference on Neural Information Processing Systems, NeurIPS 2022; Conference date: 28 November 2022 through 9 December 2022; Conference code: 189185},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{anderson_pyforel_2022,
	title = {{PyFoReL}: {A} {Domain}-{Specific} {Language} for {Formal} {Requirements} in {Temporal} {Logic}},
	volume = {2022-August},
	isbn = {978-1-66547-000-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133885496&doi=10.1109%2fRE54965.2022.00037&partnerID=40&md5=2ed4dd0e4e02455d8e8704e4cba5915a},
	doi = {10.1109/RE54965.2022.00037},
	abstract = {Temporal Logic (TL) bridges the gap between natural language and formal reasoning in the field of complex systems verification. However, in order to leverage the expressivity entailed by TL, the syntax and semantics must first be understood - a large task in itself. This significant knowledge gap leads to several issues: (1) the likelihood of adopting a TL-based verification method is decreased, and (2) the chance of poorly written and inaccurate requirements is increased. In this ongoing work, we present the Pythonic Formal Requirements Language (PyFoReL) tool: a Domain-Specific Language inspired by the programming language Python to simplify the elicitation of TL-based requirements for engineers and non-experts. © 2022 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Requirements} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Anderson, Jacob and Hekmatnejad, Mohammad and Fainekos, Georgios},
	editor = {E, Knauss and G, Mussbacher and C, Arora and M, Bano and J.-G, Schneider},
	year = {2022},
	note = {ISSN: 1090705X
Type: Conference paper},
	keywords = {Natural languages, Semantics, Temporal logic, Problem oriented languages, Computer circuits, Domains specific languages, Formal reasoning, Formal requirement, Knowledge gaps, Language tools, Requirement languages, Requirement-based testing, System verifications, Verification method},
	pages = {266 -- 267},
	annote = {Cited by: 0; Conference name: 30th IEEE International Requirements Engineering Conference, RE 2022; Conference date: 15 August 2022 through 19 August 2022; Conference code: 183667},
	annote = {Cited by: 1; Conference name: 30th IEEE International Requirements Engineering Conference, RE 2022; Conference date: 15 August 2022 through 19 August 2022; Conference code: 183667},
	annote = {RELEVANCE: HIGH - check code

https://par.nsf.gov/servlets/purl/10392510
},
}


@inproceedings{chattopadhyay_semantic_2021,
	title = {Semantic {Frames} for {Classifying} {Temporal} {Requirements}: {An} {Exploratory} {Study}},
	volume = {2857},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105598050&partnerID=40&md5=d41ee3c7c3c9d5f7f3d2a83252670c48},
	abstract = {Temporal requirements express the time-related system behaviors and properties. In engineering critical systems, experience has shown that temporal requirements are the most problematic type of requirements to verify. Researchers have thus used natural language processing (NLP) techniques most notably, part-of-speech (PoS) tagging to develop practical classifiers to distinguish temporal requirements from non-Temporal ones. In this paper, we explore frame semantics a linguistic approach to labeling a word s role in a sentence with respect to the events of interest to augment the temporal requirements classification task. Our experiments of 111 requirements sentences from the regulatory documents show that the best classification accuracy of 90.9\% is achieved when PoS features are replaced with, rather than combined with, frame semantics features. The results suggest the promising role of semantics-Augmented NLP support in an understudied requirements engineering task. © 2021 CEUR-WS. All rights reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Chattopadhyay, Aurek and Niu, Nan and Peng, Zedong and Zhang, Jianzhang},
	editor = {F.B, Aydemir and C, Gralha and M, Daneva and E.C, Groen and A, Herrmann and P, Mennig and S, Abualhaija and A, Ferrari and J, Guo and R, Guizzardi and J, Horkoff and A, Perini and A, Susi and T, Breaux and X, Franch and N, Ernst and E, Paja and N, Seyff},
	year = {2021},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Computer software selection and evaluation, Requirements engineering, Regulatory documents, Semantics, NAtural language processing, Classification (of information), Information retrieval systems, Part of speech tagging, Classification accuracy, Critical systems, Exploratory studies, Linguistic approach, Requirements classifications},
	annote = {Cited by: 2; Conference name: Joint Workshops of the 27th International Conference on Requirements Engineering, REFSQ 2021 - OpenRE, Posters and Tools Track, and Doctoral Symposium; Conference date: 12 April 2021; Conference code: 168710},
	annote = {Cited by: 3; Conference name: Joint Workshops of the 27th International Conference on Requirements Engineering, REFSQ 2021 - OpenRE, Posters and Tools Track, and Doctoral Symposium; Conference date: 12 April 2021; Conference code: 168710},
	annote = {RELEVANCE: LOW


},
}


@article{rajhans_specification_2021,
	title = {Specification and {Runtime} {Verification} of {Temporal} {Assessments} in {Simulink}},
	volume = {12974 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117499280&doi=10.1007%2f978-3-030-88494-9_17&partnerID=40&md5=d5c8735e3a1d06c89a4a72bfb631d1db},
	doi = {10.1007/978-3-030-88494-9_17},
	abstract = {Formalization of specifications is a key step towards rigorous system design of complex engineered systems such as cyber-physical systems. Temporal logics are a suitable expressive formalism for capturing temporal specifications. However, since engineers and practitioners are often unfamiliar with the symbols and vocabulary of temporal logic, informal natural-language specifications still are used abundantly in practice. This tool paper presents the Temporal Assessments feature in Simulink® TestTM that strives to achieve the best of both worlds. It provides graphical user interfaces and visual examples for users to interactively create temporal specifications without the need to author logical formulae by hand, yet any user-authored temporal assessment is a valid logical formula in an internal representation. Iterative folding of clauses enables the specification to be presented to read like English language sentences. Key highlights of the feature along with examples of authoring and runtime verification of temporal logic specifications are presented. © 2021, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Rajhans, Akshay and Mavrommati, Anastasia and Mosterman, Pieter J. and Valenti, Roberto G.},
	editor = {L, Feng and D, Fisman},
	year = {2021},
	note = {ISBN: 978-303088493-2
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Formal specification, Temporal logic, Formal verification, Computer circuits, Embedded systems, Formalisation, Model-based design, Simulink, Simulink test, Temporal specification, Graphical user interfaces, Run-time verification, Logical formulas, Complex engineered systems, Temporal assessment},
	pages = {288 -- 296},
	annote = {Cited by: 2; Conference name: 21st International Conference on Runtime Verification, RV 2021; Conference date: 11 October 2021 through 14 October 2021; Conference code: 266719},
}


@article{farrell_fretting_2022,
	title = {{FRETting} {About} {Requirements}: {Formalised} {Requirements} for an {Aircraft} {Engine} {Controller}},
	volume = {13216 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127046840&doi=10.1007%2f978-3-030-98464-9_9&partnerID=40&md5=93c4c67f6fcace06f9eab86597408f4c},
	doi = {10.1007/978-3-030-98464-9_9},
	abstract = {[Context \& motivation] Eliciting requirements that are detailed and logical enough to be amenable to formal verification is a difficult task. Multiple tools exist for requirements elicitation and some of these also support formalisation of requirements in a way that is useful for formal methods. [Question/problem] This paper reports on our experience of using the Formal Requirements Elicitation Tool (FRET) alongside our industrial partner. The use case that we investigate is an aircraft engine controller. In this context, we evaluate the use of FRET to bridge the communication gap between formal methods experts and aerospace industry specialists. [Principal ideas/results] We describe our journey from ambiguous, natural-language requirements to concise, formalised FRET requirements. We include our analysis of the formalised requirements from the perspective of patterns, translation into other formal methods and the relationship between parent-child requirements in this set. We also provide insight into lessons learned throughout this process and identify future improvements to FRET. [Contribution] Previous experience reports have been published by the FRET team, but this is the first such report of an industrial use case that was written by researchers that have not been involved FRET’s development. © 2022, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Farrell, Marie and Luckcuck, Matt and Sheridan, Oisín and Monahan, Rosemary},
	editor = {V, Gervasi and A, Vogelsang},
	year = {2022},
	note = {ISBN: 978-303098463-2
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Communication gaps, Natural language processing systems, Formal specification, Requirements engineering, Natural language requirements, Requirements elicitation, Systems engineering, Formalisation, Aerospace industry, Aircraft engines, Engine controller, Engines, Industrial partners, Formal requirement, Traceability, Formal requirement elicitation tool, Multiple tools},
	pages = {96 -- 111},
	annote = {Cited by: 5; Conference name: 28th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2022; Conference date: 21 March 2022 through 24 March 2022; Conference code: 274709; All Open Access, Green Open Access},
}


@article{sanchez-ferreres_unleashing_2021,
	title = {Unleashing textual descriptions of business processes},
	volume = {20},
	issn = {16191366},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106476225&doi=10.1007%2fs10270-021-00886-x&partnerID=40&md5=336f1f9c3ab33facad7cc6001f8e8290},
	doi = {10.1007/s10270-021-00886-x},
	abstract = {Textual descriptions of processes are ubiquitous in organizations, so that documentation of the important processes can be accessible to anyone involved. Unfortunately, the value of this rich data source is hampered by the challenge of analyzing unstructured information. In this paper we propose a framework to overcome the current limitations on dealing with textual descriptions of processes. This framework considers extraction and analysis and connects to process mining via simulation. The framework is grounded in the notion of annotated textual descriptions of processes, which represents a middle-ground between formalization and accessibility, and which accounts for different modeling styles, ranging from purely imperative to purely declarative. The contributions of this paper are implemented in several tools, and case studies are highlighted. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	language = {English},
	number = {6},
	journal = {Software and Systems Modeling},
	author = {Sànchez-Ferreres, Josep and Burattin, Andrea and Carmona, Josep and Montali, Marco and Padró, Lluís and Quishpi, Luís},
	year = {2021},
	note = {Publisher: Springer Science and Business Media Deutschland GmbH
Type: Article},
	keywords = {Business Process, Process mining, Case-studies, Software engineering, Computer simulation, Data-source, Current limitation, Textual description},
	pages = {2131 -- 2153},
	annote = {Cited by: 4; All Open Access, Green Open Access},
	annote = {Cited by: 6; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{blasi_memo_2021,
	title = {{MeMo}: {Automatically} identifying metamorphic relations in {Javadoc} comments for test automation},
	volume = {181},
	issn = {01641212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111574134&doi=10.1016%2fj.jss.2021.111041&partnerID=40&md5=8f45c141b12cb90b5a0dfa456e256d3e},
	doi = {10.1016/j.jss.2021.111041},
	abstract = {Software testing depends on effective oracles. Implicit oracles, such as checks for program crashes, are widely applicable but narrow in scope. Oracles based on formal specifications can reveal application-specific failures, but specifications are expensive to obtain and maintain. Metamorphic oracles are somewhere in-between. They test equivalence among different procedures to detect semantic failures. Until now, the identification of metamorphic relations has been a manual and expensive process, except for few specific domains where automation is possible. We present MeMo, a technique and a tool to automatically derive metamorphic equivalence relations from natural language documentation, and we use such metamorphic relations as oracles in automatically generated test cases. Our experimental evaluation demonstrates that 1) MeMo can effectively and precisely infer equivalence metamorphic relations, 2) MeMo complements existing state-of-the-art techniques that are based on dynamic program analysis, and 3) metamorphic relations discovered with MeMo effectively detect defects when used as test oracles in automatically-generated or manually-written test cases. © 2021 The Author(s)},
	language = {English},
	journal = {Journal of Systems and Software},
	author = {Blasi, Arianna and Gorla, Alessandra and Ernst, Michael D. and Pezzè, Mauro and Carzaniga, Antonio},
	year = {2021},
	note = {Publisher: Elsevier Inc.
Type: Article},
	keywords = {Formal specification, Natural languages, Semantics, Software testing, Automatically generated, Automatic test pattern generation, Experimental evaluation, Test Automation, Application specific, Equivalence relations, Metamorphic relations, State-of-the-art techniques},
	annote = {Cited by: 10; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 16; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{perez_automated_2022,
	title = {Automated {Translation} of {Natural} {Language} {Requirements} to {Runtime} {Monitors}},
	volume = {13243 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128492862&doi=10.1007%2f978-3-030-99524-9_21&partnerID=40&md5=7f097014d3630f9923d96a5f9e8e807d},
	doi = {10.1007/978-3-030-99524-9_21},
	abstract = {Runtime verification (RV) enables monitoring systems at runtime, to detect property violations early and limit their potential consequences. This paper presents an end-to-end framework to capture requirements in structured natural language and generate monitors that capture their semantics faithfully. We leverage NASA’s Formal Requirement Elicitation Tool (fret), and the RV system Copilot. We extend fret with mechanisms to capture additional information needed to generate monitors, and introduce Ogma, a new tool to bridge the gap between fret and Copilot. With this framework, users can write requirements in an intuitive format and obtain real-time C monitors suitable for use in embedded systems. Our toolchain is available as open source. © 2022, The Author(s).},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Perez, Ivan and Mavridou, Anastasia and Pressburger, Tom and Goodloe, Alwyn and Giannakopoulou, Dimitra},
	editor = {D, Fisman and G, Rosu},
	year = {2022},
	note = {ISBN: 978-303099523-2
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Semantics, Natural language requirements, Requirements elicitation, Embedded systems, Real time systems, NASA, Property, Runtimes, End to end, Run-time verification, Runtime monitors, Automated translation, Monitoring system},
	pages = {387 -- 395},
	annote = {Cited by: 6; Conference name: 28th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2022 held as part of 25th European Joint Conferences on Theory and Practice of Software, ETAPS 2022; Conference date: 2 April 2022 through 7 April 2022; Conference code: 276269; All Open Access, Hybrid Gold Open Access},
}


@article{seow_supremal_2022,
	title = {Supremal {Marker}-{Controllable} {Subformula} of a {Given} {Canonical} {Temporal}-{Safety} {Formula}},
	volume = {10},
	issn = {21693536},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132700748&doi=10.1109%2fACCESS.2022.3183198&partnerID=40&md5=f17ecd7e6a77352f8779f36555f3967d},
	doi = {10.1109/ACCESS.2022.3183198},
	abstract = {The existence of marker-progressive supervisory control - about ensuring constant marker progress under specified temporal safety for a class of fair discrete-event systems (DES's) - is a new control problem formulation that has been studied in terms of DES marker-controllability of a linear-time temporal logic (LTL) safety formula given in canonical form. In this paper, provided it exists, the supremal marker-controllable subformula of a given canonical temporal-safety formula for the fair DES model considered is characterized as the weakest fixpoint of some monotone operator Ømega . In the case where the DES model is finite state and the complete specification for constant marker progress under temporal safety is a formula of a decidable LTL fragment, it is shown that this fixpoint can be computed as the limit of the (finite) sequence of iterations of computing operator Ømega in the syntax of LTL. Marker-progressive control synthesis by fixpoint computation can therefore be made in the same natural-language motivated algebra of LTL as writing the specification, providing the unique opportunity to exploit not only the role of fair events in DES's, but also the human readability of LTL formulas and the associated, syntax-based calculational approach that is transparent; such fixpoint computation is illustrated with four examples. A discussion examines and illuminates the significance of this paper and its potential impact on the logic foundation of supervisory control; it includes making comparisons with related work, and explaining a straightforward generalization of DES marker-controllability that directly extends the proposed fixpoint computation to cover the full specification hierarchy of canonical LTL. © 2013 IEEE.},
	language = {English},
	journal = {IEEE Access},
	author = {Seow, Kiam Tian},
	year = {2022},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.
Type: Article},
	keywords = {Temporal logic, Specifications, Computer circuits, Syntactics, Computational modelling, Controllability, Discrete event simulation, Discrete events systems, Fair discrete-event system, Fixpoint computations, Hybrid systems, Linear control systems, Linear time temporal logic, Supervisory control, Symbol, System Dynamics, Temporal safety},
	pages = {66300 -- 66320},
	annote = {Cited by: 0; All Open Access, Gold Open Access},
	annote = {Cited by: 0; All Open Access, Gold Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{fb_refsq-jp_2021,
	title = {{REFSQ}-{JP} 2021 - {Joint} {Proceedings} of {REFSQ} 2021 {Workshops}, {OpenRE}, {Poster} and {ToolsTrack}, and {Doctoral} {Symposium}, co-located with the 27th {International} {Conference} on {Requirements} {Engineering}: {Foundation} for {Software} {Quality}, {REFSQ} 2021},
	volume = {2857},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105569688&partnerID=40&md5=a98039a122ec567a71bf78abb16733ca},
	abstract = {The proceedings contain 26 papers. The topics discussed include: divergent creativity for requirement elicitation amid pandemic: experience from real consulting project; continuous rationale identification in issue tracking and version control systems; a vision of understanding the users' view on software; an NLP-based chatbot to facilitate RE activities: an experience paper on human resources application; concept extraction in requirements elicitation session recordings: prototype and experimentation; semantic frames for classifying temporal requirements: an exploratory study; using recurrent neural networks for classification of natural language-based non-functional requirements; case study: how well can IBM's "requirements quality assistant" review automotive requirements?; and from legal contracts to formal specifications: a progress report.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	editor = {F.B, Aydemir and C, Gralha and M, Daneva and E.C, Groen and A, Herrmann and P, Mennig and S, Abualhaija and A, Ferrari and J, Guo and R, Guizzardi and J, Horkoff and A, Perini and A, Susi and T, Breaux and X, Franch and N, Ernst and E, Paja and N, Seyff},
	year = {2021},
	note = {ISSN: 16130073
Type: Conference review},
	annote = {Cited by: 0; Conference name: Joint Workshops of the 27th International Conference on Requirements Engineering, REFSQ 2021 - OpenRE, Posters and Tools Track, and Doctoral Symposium; Conference date: 12 April 2021; Conference code: 168710},
	annote = {Cited by: 0; Conference name: Joint Workshops of the 27th International Conference on Requirements Engineering, REFSQ 2021 - OpenRE, Posters and Tools Track, and Doctoral Symposium; Conference date: 12 April 2021; Conference code: 168710},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{perera_transformation_2020,
	title = {Transformation of contract descriptions in a domain specific language to solidity assembly},
	isbn = {978-1-72818-653-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100488359&doi=10.1109%2fICTer51097.2020.9325490&partnerID=40&md5=5562e246f15ab00b50c9b51cc1090a2d},
	doi = {10.1109/ICTer51097.2020.9325490},
	abstract = {There are a variety of contracts being traded in the financial markets. To eliminate the ambiguities imposed by the financial contracts written in natural languages, Peyton Jones and co-researchers proposed a contract definition language for standard representation of the financial contracts and a combinator library embedded in Haskell programming language to define financial contracts. Further, a special purpose compiler which is an extension to this work has been already proposed by exploiting major advancements such as autonomous contract execution and elimination of central counterparty in contemporary smart contracts, to transform contracts written in Peyton Jones' Contract Descriptive Language to Solidity which is the scripting language used in Ethereum smart contract platform. However, we have noticed that the cost related to the execution of contracts in Ethereum platform curtails the benefits received through the transformation of those contracts. Hence, we propose a novel approach to reduce the cost using different optimization techniques and it involves the direct transformation of the Peyton Jones' Contract Descriptive language to Solidity (inline) Assembly language which enables the manipulation of data locations in the Ethereum Virtual Machine. A formal verification is provided by verifying the semantic equivalence between the Peyton Jones' Contract Descriptive language and the proposed solution to ensure the correctness of the proposed approach is preserved while it is being optimized. © 2020 IEEE.},
	language = {English},
	booktitle = {20th {International} {Conference} on {Advances} in {ICT} for {Emerging} {Regions}, {ICTer} 2020 - {Proceedings}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Perera, K.S.M. and Gunawardana, K.G. and Keppitiyagama, C.I.},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Semantics, Domain specific languages, Problem oriented languages, Combinator library, Contract execution, Ethereum, Finance, Financial contracts, Haskell programming language, Metadata, Optimization techniques, Scripting languages, Semantic equivalences},
	pages = {89 -- 94},
	annote = {Cited by: 0; Conference name: 20th International Conference on Advances in ICT for Emerging Regions, ICTer 2020; Conference date: 5 November 2020 through 6 November 2020; Conference code: 166665},
	annote = {Cited by: 0; Conference name: 20th International Conference on Advances in ICT for Emerging Regions, ICTer 2020; Conference date: 5 November 2020 through 6 November 2020; Conference code: 166665},
	annote = {RELEVANCE: MEDIUM interesting

what is PeytonJones’ Contract Descriptive Language?
},
}


@inproceedings{chauhan_toward_2022,
	title = {{TOWARD} {GENERATING} {SYSTEM} {ARCHITECURE} {AND} {FORMAL} {FUNCTIONAL} {DESCRIPTION} {IN} {THE} {ARCHITECTURE} {ANALYSIS} \& {DESIGN} {LANGUAGE} ({AADL}) {WITH} {STRUCTURED} {NATURAL} {LANGUAGE}},
	volume = {2},
	isbn = {978-0-7918-8621-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142468135&doi=10.1115%2fDETC2022-90002&partnerID=40&md5=63016b3fcb9b421885a62948a05eae53},
	doi = {10.1115/DETC2022-90002},
	abstract = {Model based engineering has enabled automated analytical reasoning early in the design phase. As a result, inconsistencies and design errors can be captured early in the development lifecycle. But there is still a gap in the natural language-based specifications and its actual implementation. This is because the formal method-based tools utilize mathematical principles and theories of computation that require specific skills, thus reducing the usability of model-based engineering. Natural language is the most widely used method to represent specifications. So, it is intuitive to utilize natural language-based representation to generate system and formal annotations such that it will enable automated architectural analysis with much wider acceptance leading to a much broader impact. In our paper we focus on designing the above-mentioned approach that integrates representation of the specifications in a subset of English language which can then be used to generate system architecture in Architecture Analysis and Design Language along with the generation of functional specifications. We illustrate our approach by validating it with use cases from the aerospace and electromechanical domains. Copyright © 2022 by ASME.},
	language = {English},
	booktitle = {Proceedings of the {ASME} {Design} {Engineering} {Technical} {Conference}},
	publisher = {American Society of Mechanical Engineers (ASME)},
	author = {Chauhan, Anshumaan and Ganeriwala, Parth and Sen, Chiradeep and Bhattacharyya, Siddhartha},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Modeling languages, Architecture analysis, Computation theory, Life cycle, Language processing, Natural language processing, Computer architecture, Architecture, Analysis/design, ARCHITECTURE ANALYSIS \& DESIGN LANGUAGE, Architecture designs, Design languages, Function modelling, Model-based engineering},
	annote = {Cited by: 0; Conference name: ASME 2022 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, IDETC-CIE 2022; Conference date: 14 August 2022 through 17 August 2022; Conference code: 184286},
	annote = {Cited by: 1; Conference name: ASME 2022 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, IDETC-CIE 2022; Conference date: 14 August 2022 through 17 August 2022; Conference code: 184286},
	annote = {RELEVANCE: LOW
},
}


@article{a_23rd_2022,
	title = {23rd {International} {Conference} on {Formal} {Engineering} {Methods}, {ICFEM} 2022},
	volume = {13478 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141679549&partnerID=40&md5=98b46c05acfd9d12e02c9ae625e9d18a},
	abstract = {The proceedings contain 25 papers. The special focus in this conference is on Formal Engineering Methods. The topics include: PFMC: A Parallel Symbolic Model Checker for Security Protocol Verification; a Formal Methodology for Verifying Side-Channel Vulnerabilities in Cache Architectures; refined Modularization for Bounded Model Checking Through Precondition Generation; TTT/ik: Learning Accurate Mealy Automata Efficiently with an Imprecise Symbol Filter; a Proof System for Cyber-Physical Systems with Shared-Variable Concurrency; theorem Proving for Maude Specifications Using Lean; on How to Not Prove Faulty Controllers Safe in Differential Dynamic Logic; declassification Predicates for Controlled Information Release; trace Refinement in B and Event-B; canonical Narrowing for Variant-Based Conditional Rewrite Theories; model Checking B Models via High-Level Code Generation; on Probabilistic Extension of the Interaction Theory; extracting Weighted Finite Automata from Recurrent Neural Networks for Natural Languages; roboCert: Property Specification in Robotics; formally Verified Animation for RoboChart Using Interaction Trees; machine-Checked Executable Semantics of Stateflow; modular Analysis of Tree-Topology Models; non-linear Optimization Methods for Learning Regular Distributions; separation of Concerning Things: A Simpler Basis for Defining and Programming with the C/C++ Memory Model; creusot: A Foundry for the Deductive Verification of Rust Programs; generation of a Reversible Semantics for Erlang in Maude; program Slicing Techniques with Support for Unconditional Jumps; Formal Verification of the Inter-core Synchronization of a Multi-core RTOS Kernel.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {A, Riesco and M, Zhang},
	year = {2022},
	note = {ISBN: 978-303117243-4
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference review},
	annote = {Cited by: 0; Conference name: 23rd International Conference on Formal Engineering Methods, ICFEM 2022; Conference date: 24 October 2022 through 27 October 2022; Conference code: 285019},
	annote = {Cited by: 0; Conference name: 23rd International Conference on Formal Engineering Methods, ICFEM 2022; Conference date: 24 October 2022 through 27 October 2022; Conference code: 285019},
	annote = {RELEVANCE: NULL - procedings
},
}


@inproceedings{zaki-ismail_rcm-extractor_2021-2,
	title = {{RCM}-{Extractor}: {Automated} extraction of a semi formal representation model from natural language requirements},
	isbn = {978-989-758-487-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103016713&partnerID=40&md5=51343518983358f6d7356bee885f811d},
	abstract = {Formal verification requires system requirements to be specified in formal notations. Formalisation of system requirements manually is a time-consuming and error-prone process, and requires engineers to have strong mathematical and domain expertise. Most existing requirements formalisation techniques assume requirements to be specified in pre-defined templates and these techniques employ pre-defined transformation rules to transform requirements specified in the predefined templates to formal notations. These techniques tend to have limited expressiveness and more importantly require system engineers to re-write their system requirements following these templates. In this paper, we introduces an automated extraction technique (RCM-Extractor) to extract the key constructs of a comprehensive and formalisable semi-formal representation model from textual requirements. We have evaluated our RCM-Extractor on a dataset of 162 requirements curated from the literature. RCM-Extractor achieved 95\% precision, 79\% recall, 86\% F-measure and 75\% accuracy. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	language = {English},
	booktitle = {{MODELSWARD} 2021 - {Proceedings} of the 9th {International} {Conference} on {Model}-{Driven} {Engineering} and {Software} {Development}},
	publisher = {SciTePress},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {S, Hammoudi and L.F, Pires and E, Seidewitz and R, Soley},
	year = {2021},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Requirements engineering, Software design, Extraction, Natural language requirements, System requirements, Formal notations, Semi-formal representations, Transformation rules, Automated extraction, Domain expertise, Error-prone process},
	pages = {270 -- 277},
	annote = {Cited by: 6; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 167487},
}


@inproceedings{casaluce_process_2022,
	title = {Process {Mining} meets {Statistical} {Model} {Checking} to {Explain} {Threat} {Models}: {Novel} {Approach} to {Model} {Validation} and {Enhancement} ({Extended} {Abstract})},
	volume = {3299},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143890974&partnerID=40&md5=ece8d0046806ab90d1468e1722822cd5},
	abstract = {Formal verification of the dynamics of a system can be conducted by employing statistical analysis techniques, such as Statistical Model Checking (SMC). SMC techniques resort to probabilistic simulations to evaluate the system properties to help to circumvent the state space explosion problem, the well-known curse of the classic model checking techniques. Nevertheless, SMC provides only estimations and confidence intervals of the evaluated properties of the system without explaining why the analysis estimated a particular property value. This project aims to present a novel methodology that integrates SMC with process-oriented data-driven techniques known as process mining (PM) applied to threat models. This methodology will empower modelers to see their models’ unfolded behavior instead of just numerical aggregated values obtained by SMC analysis. In the present work, there are two research goals. The primary research goal focus on implementing and validating the novel methodology in which we enrich SMC techniques with PM techniques. The secondary research goals focus on implementing an approach to extract an attack pattern from its textual description and another to extract a textual description of the salient information from the process model discovered using PM techniques. The secondary research goals add the necessary means to assist a modeler in using this novel methodology. © 2022 Copyright for this paper by its authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Casaluce, Roberto},
	editor = {M, Hassani and A, Koschmider and M, Comuzzi and F.M, Maggi and L, Pufahl},
	year = {2022},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Process mining, Natural language processing systems, Natural languages, Data mining, Model checking, Mining, Language processing, Natural language processing, Validation, Novel methodology, Model-checking techniques, Natural language generation, Research goals, Statistical model checking},
	pages = {13 -- 17},
	annote = {Cited by: 0; Conference name: Doctoral Consortium and the Tool Demonstration Track of the 4th International Conference on Process Mining, ICPM-D 2022; Conference date: 23 October 2022 through 28 October 2022; Conference code: 184857},
	annote = {Cited by: 0; Conference name: Doctoral Consortium and the Tool Demonstration Track of the 4th International Conference on Process Mining, ICPM-D 2022; Conference date: 23 October 2022 through 28 October 2022; Conference code: 184857},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{gropler_nlp-based_2021,
	title = {{NLP}-based requirements formalization for automatic test case generation},
	volume = {2951},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115828064&partnerID=40&md5=04bc8919eac2d0d5edc5e50694938093},
	abstract = {Due to the growing complexity and rapid changes of software systems, the assurance of their quality becomes increasingly difficult. Model-based testing in agile development is a way to overcome these difficulties. However, major effort is still required to create specification models from a large set of functional requirements provided in natural language. This paper presents an approach for a machine-aided requirements formalization technique based on Natural Language Processing (NLP) to be used for an automatic test case generation. The goal of the presented method is to automate the process of model creation from requirements in natural language by utilizing appropriate algorithms, thus reducing cost and effort. The application of our procedure will be demonstrated using an industry example from the e-mobility domain. In this example, requirement models are generated for a charging approval system within a larger vehicle battery charging application. Additionally, existing tools for automated model synthesis and test case generation are applied to our models to evaluate whether valid test cases can be generated. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Gröpler, Robin and Sudhi, Viju and García, Emilio José Calleja and Bergmann, Andre},
	editor = {H, Schlingloff and T, Vogel},
	year = {2021},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Model checking, Requirements formalizations, Specification models, Requirement analysis, Agile development, Software-systems, Functional requirement, Test generations, Model based testing, Automatic testcase generation, Charging (batteries)},
	pages = {18 -- 30},
	annote = {Cited by: 3; Conference name: 29th International Workshop on Concurrency, Specification and Programming, CS and P 2021; Conference date: 27 September 2021 through 28 September 2021; Conference code: 171844},
	annote = {Cited by: 3; Conference name: 29th International Workshop on Concurrency, Specification and Programming, CS and P 2021; Conference date: 27 September 2021 through 28 September 2021; Conference code: 171844},
	annote = {RELEVANCE: HIGH
},
}


@article{wetter_openbuildingcontrol_2022,
	title = {{OpenBuildingControl}: {Digitizing} the control delivery from building energy modeling to specification, implementation and formal verification},
	volume = {238},
	issn = {03605442},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112436065&doi=10.1016%2fj.energy.2021.121501&partnerID=40&md5=10f2d6c59b520eac40dc8166c309b0fa},
	doi = {10.1016/j.energy.2021.121501},
	abstract = {The current process for specifying, installing and commissioning building control sequences is largely manual and based on ambiguous natural language specifications. It lacks a formal end-to-end quality control and it has been shown not to deliver high performance sequences at scale. While high-performance HVAC control sequences enable significant reductions in energy consumption, errors in implementing the control logic are common even for less advanced sequences. To improve this situation, we present a digitized building control delivery workflow with formal end-to-end verification, a Control Description Language for the digital specification of building control sequences within this workflow, and software tools that enable digitization of this process. Using the process and tools introduced here, mechanical designers can customize, test and improve these sequences within annual energy simulation, store them in a library for use in other projects, and export them for bidding. Control providers can implement the sequences on existing control product lines through code generation. Commissioning providers can formally verify whether as-installed sequences conform to the digital design specification that was exported by the mechanical designer. Moreover, control product development teams can use the reference implementations of these libraries within their product testing to ensure that their products reproduce the behavior of the reference implementations. This paper presents this process, the language and the supporting software, together with examples of all of the above steps. The presented work has given rise to a new proposed standard, ASHRAE 231P, that will allow digitizing the building control delivery process through the standardization of a control-vendor independent format for exchanging control logic that we pioneered through the here presented work. © 2021},
	language = {English},
	journal = {Energy},
	author = {Wetter, Michael and Ehrlich, Paul and Gautier, Antoine and Grahovac, Milica and Haves, Philip and Hu, Jianjun and Prakash, Anand and Robin, Dave and Zhang, Kun},
	year = {2022},
	note = {Publisher: Elsevier Ltd
Type: Article},
	keywords = {Simulation, Product design, Specifications, Software testing, Formal verification, Computer circuits, 'current, Performance, Computer aided software engineering, Process control, Energy utilization, performance assessment, digitization, quality control, Reference implementation, Buildings, Building controls, Building energy model, Control logic, Control sequences, implementation process, installation, Mechanical, numerical model, Specification implementation},
	annote = {Cited by: 9; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 17; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE: LOW
},
}


@article{katayama_proposal_2020,
	title = {Proposal of an algorithm to generate {VDM}++ specification based on its grammar by using word lists extracted from the natural language specification},
	volume = {7},
	issn = {23526386},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097074868&doi=10.2991%2fjrnal.k.200909.005&partnerID=40&md5=217b7406c7c735fb6d26ff9422fde565},
	doi = {10.2991/jrnal.k.200909.005},
	abstract = {The natural language includes ambiguous expressions. Vienna Development Method (VDM) is one of methodology on the formal methods to write the specification without ambiguity. Because VDM++ is written by strict grammar, it is difficult to write a VDM++ specification. This research attempts to generate a VDM++ specification automatically from a natural language specification by machine learning. To generate a VDM++ specification, it is necessary to extract words that consist of predicate corresponding to the function and nouns corresponding to variable from the natural language specification. This paper proposes an approach to generate a VDM++ specification based on its grammar from the classified word list. Identifiers are generated from the classified word list, and then the VDM++ specification can be generated by converting them into VDM++ grammar. © 2020 The Authors. Published by Atlantis Press B.V. This is an open access article distributed under the CC BY-NC 4.0 license (http://creativecommons.org/licenses/by-nc/4.0/).},
	language = {English},
	number = {3},
	journal = {Journal of Robotics, Networking and Artificial Life},
	author = {Katayama, Tetsuro and Shigyo, Yasuhiro and Kita, Yoshihiro and Yamaba, Hisaaki and Aburada, Kentaro and Okazaki, Naonobu},
	year = {2020},
	note = {Publisher: Atlantis Press
Type: Article},
	pages = {165 -- 169},
	annote = {Cited by: 1; All Open Access, Gold Open Access},
	annote = {Cited by: 1; All Open Access, Gold Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{naumcheva_object-oriented_2022,
	title = {Object-{Oriented} {Approach} for {Requirements} {Specification}},
	volume = {3122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128774392&partnerID=40&md5=80fc674def5d4a1a51b0bffc610406c1},
	abstract = {Although the software engineering community knows well the deficiencies of natural language documentation, it remains the predominant way of software requirements specification. The desired properties of software requirements that are hard to be reached with natural language specifications are unambiguity and traceability. This issue has been solved through several approaches, yet still most software projects rely on natural language requirements. This research aims at capitalizing on recent developments of programming language-based approaches to requirements with the purpose of devising a unified approach enriched with tools and methodology. This approach is based on the object-oriented technology as follows: the development process is seamless from the requirements specification to implementation and verification. An object-oriented language, Eiffel, is used as a requirements notation. It provides means of system modeling without using specific notation, which often becomes a barrier in formal methods adoption. The specification, design, implementation and tests are developed incrementally using the mechanisms of inheritance and refinement and relying on the notion of contracts. © 2022 Copyright for this paper by its authors},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Naumcheva, Maria},
	editor = {J, Fischbach and N, Condori-Fernandez and N, Condori-Fernandez and J, Doerr and M, Ruiz and J.-P, Steghofer and L, Pasquale and A, Zisman and R, Guizzardi and J, Horkoff and A, Perini and A, Susi and M, Daneva and A, Herrmann and K, Schneider and P, Mennig and F, Dalpiaz and D, Dell�Anna and S, Kopczynska and L, Montgomery and A.G, Darby and P, Sawyer},
	year = {2022},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Software requirements specifications, Natural language requirements, Software requirements, Requirements specifications, Object oriented programming, Natural language specifications, Property, Engineering community, Object oriented approach, Software project},
	annote = {Cited by: 0; Conference name: Joint REFSQ-2022 Workshops, Doctoral Symposium, and Posters and Tools Track, REFSQ-JP 2022; Conference date: 21 March 2022; Conference code: 178725},
	annote = {Cited by: 1; Conference name: Joint REFSQ-2022 Workshops, Doctoral Symposium, and Posters and Tools Track, REFSQ-JP 2022; Conference date: 21 March 2022; Conference code: 178725},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{shigyo_proposal_2020,
	title = {Proposal of an {Approach} to {Generate} {VDM}++ {Specifications} from {Natural} {Language} {Specification} by {Machine} {Learning}},
	isbn = {978-1-72819-802-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099372396&doi=10.1109%2fGCCE50665.2020.9292047&partnerID=40&md5=4dd4df1bb549713198642dd6d021f20a},
	doi = {10.1109/GCCE50665.2020.9292047},
	abstract = {A natural language contains ambiguous expressions. The VDM++ is one of the methodotogies on the formal methods to write the specification without ambiguity. It is difficult to write a VDM++ specification, because VDM++ is written by strict grammar. This research proposes an approach to automatically generate the VDM++ specification by machine learning. This approach defines four data structures and has four processes. In this paper, variables and only real type in the VDM++ specification are generated automatically by this approach. In order to generate the variables and real type, it is necessary to extract the noun corresponding to the variable from the natural language specification. Consequently, our proposed approach can generate a VDM++ specification and we have confirmed that the generated VDM++ specification is grammatically correct. © 2020 IEEE.},
	language = {English},
	booktitle = {2020 {IEEE} 9th {Global} {Conference} on {Consumer} {Electronics}, {GCCE} 2020},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Shigyo, Yasuhiro and Katayama, Tetsuro},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Formal specification, Natural languages, Machine learning, Natural language specifications},
	pages = {292 -- 296},
	annote = {Cited by: 2; Conference name: 9th IEEE Global Conference on Consumer Electronics, GCCE 2020; Conference date: 13 October 2020 through 16 October 2020; Conference code: 166035},
	annote = {Cited by: 2; Conference name: 9th IEEE Global Conference on Consumer Electronics, GCCE 2020; Conference date: 13 October 2020 through 16 October 2020; Conference code: 166035},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{wu_requirement_2021,
	title = {Requirement {Consistency} and {Integrity} {Verification} {Method} based on {Natural} {Language} {Processing}},
	volume = {1756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102400027&doi=10.1088%2f1742-6596%2f1756%2f1%2f012002&partnerID=40&md5=8a043c84bbd16ba015c284b184e675f5},
	doi = {10.1088/1742-6596/1756/1/012002},
	abstract = {In the iterative process of the update of the information service system, the continuous improvement of the system is restricted due to problems such as non-standard, incomplete, and strong ambiguity in the description of requirements. It makes it difficult to verify the consistency and integrity of requirements. In this paper, we focus on the huge requirements of complex information service system, and propose research on requirement itemized extraction and structured description technology based on natural language processing and requirement item keyword extraction and standardized expression technology. The library management system is used as the verification object to verify the effectiveness of the method proposed in this paper. © Published under licence by IOP Publishing Ltd.},
	language = {English},
	booktitle = {Journal of {Physics}: {Conference} {Series}},
	publisher = {IOP Publishing Ltd},
	author = {Wu, Chao and Huang, Zhong Hua and Yang, Yu Ting and Liu, Yue},
	year = {2021},
	note = {ISSN: 17426588
Issue: 1
Type: Conference paper},
	keywords = {Natural language processing systems, Extraction, Artificial intelligence, NAtural language processing, Big data, Iterative methods, Information services, Integrity verifications, Complex information, Continuous improvements, Information service systems, Iterative process, Keyword extraction, Library management},
	annote = {Cited by: 1; Conference name: 2020 International Conference on Industrial Applications of Big Data and Artificial Intelligence, BDAI 2020; Conference date: 26 November 2020 through 29 November 2020; Conference code: 167463; All Open Access, Bronze Open Access},
	annote = {Cited by: 2; Conference name: 2020 International Conference on Industrial Applications of Big Data and Artificial Intelligence, BDAI 2020; Conference date: 26 November 2020 through 29 November 2020; Conference code: 167463; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{wang_learning_2020,
	title = {Learning a natural-language to {LTL} executable semantic parser for grounded robotics},
	volume = {155},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168241969&partnerID=40&md5=6c3e5cd9fe6da29032fae93808c78a09},
	abstract = {Children acquire their native language with apparent ease by observing how language is used in context and attempting to use it themselves. They do so without laborious annotations, negative examples, or even direct corrections. We take a step toward robots that can do the same by training a grounded semantic parser, which discovers latent linguistic representations that can be used for the execution of natural-language commands. In particular, we focus on the difficult domain of commands with a temporal aspect, whose semantics we capture with Linear Temporal Logic, LTL. Our parser is trained with pairs of sentences and executions as well as an executor. At training time, the parser hypothesizes a meaning representation for the input as a formula in LTL. Three competing pressures allow the parser to discover meaning from language. First, any hypothesized meaning for a sentence must be permissive enough to reflect all the annotated execution trajectories. Second, the executor - a pretrained end-to-end LTL planner - must find that the observed trajectories are likely executions of the meaning. Finally, a generator, which reconstructs the original input, encourages the model to find representations that conserve knowledge about the command. Together these ensure that the meaning is neither too general nor too specific. Our model generalizes well, being able to parse and execute both machine-generated and human-generated commands, with near-equal accuracy, despite the fact that the human-generated sentences are much more varied and complex with an open lexicon. The approach presented here is not specific to LTL: it can be applied to any domain where sentence meanings can be hypothesized and an executor can verify these meanings, thus opening the door to many applications for robotic agents. © 2020 Proceedings of Machine Learning Research. All rights reserved.},
	language = {English},
	booktitle = {Proceedings of {Machine} {Learning} {Research}},
	publisher = {ML Research Press},
	author = {Wang, Christopher and Ross, Candace and Kuo, Yen-Ling and Katz, Boris and Barbu, Andrei},
	editor = {J, Kober and F, Ramos and C, Tomlin},
	year = {2020},
	note = {ISSN: 26403498
Type: Conference paper},
	keywords = {Natural languages, Semantics, Syntactics, Machine learning, Robotics, Semantic parsing, LTL, In contexts, Executable semantics, Linguistic representations, Native language, Negative examples, Temporal aspects, Weak supervision},
	pages = {1706 -- 1718},
	annote = {Cited by: 9; Conference name: 4th Conference on Robot Learning, CoRL 2020; Conference date: 16 November 2020 through 18 November 2020; Conference code: 193480},
	annote = {Cited by: 9; Conference name: 4th Conference on Robot Learning, CoRL 2020; Conference date: 16 November 2020 through 18 November 2020; Conference code: 193480},
	annote = {ISSN: 26403498 Type: Conference paper},
}


@inproceedings{hasanbeig_logically-constrained_2019,
	title = {Logically-constrained neural fitted {Q}-iteration},
	volume = {4},
	isbn = {978-1-5108-9200-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077028104&partnerID=40&md5=91caabb040c7cc52303a88f4e5d4157f},
	abstract = {We propose a model-free method for efficient training of Q-functions for continuous-state Markov Decision Processes (MDPs), such that the traces of the resulting policies satisfy a given Linear Temporal Logic (LTL) property. LTL, a modal logic, can express a wide range of time-dependent logical properties (including safety) that are quite similar to patterns in natural language. We convert the LTL property into a limit deterministic Buchi automaton and construct an on-the-fly synchronised product MDP. The control policy is then synthesised by defining an adaptive reward function and by applying a modified neural fitted Q-iteration algorithm to the synchronised structure, assuming that no prior knowledge is available from the original MDP (i.e., the method is model-free). The proposed method is evaluated in a numerical study to test the quality of the generated control policy and is compared with conventional methods for policy synthesis, including MDP abstraction (Voronoi quantizer) and approximate dynamic programming (fitted value iteration). © 2019 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.},
	language = {English},
	booktitle = {Proceedings of the {International} {Joint} {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}, {AAMAS}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)},
	author = {Hasanbeig, Mohammadhosein and Abate, Alessandro and Kroening, Daniel},
	year = {2019},
	note = {ISSN: 15488403
Type: Conference paper},
	keywords = {Dynamic programming, Natural languages, Quality control, Multi agent systems, Temporal logic, Linear temporal logic, Markov processes, Formal methods, Computer circuits, Autonomous agents, Iterative methods, Markov Decision Processes, Reinforcement learning, Accident prevention, reinforcement learning, Approximate dynamic programming, Conventional methods, Fitted value iteration, formal methods, Iteration algorithms, Logical properties, neural networks, Neural networks, Numerical methods, safety},
	pages = {2012 -- 2014},
	annote = {Cited by: 20; Conference name: 18th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2019; Conference date: 13 May 2019 through 17 May 2019; Conference code: 155776},
	annote = {Cited by: 20; Conference name: 18th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2019; Conference date: 13 May 2019 through 17 May 2019; Conference code: 155776},
	annote = {Cited by: 21; Conference name: 18th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2019; Conference date: 13 May 2019 through 17 May 2019; Conference code: 155776},
	annote = {event-place: Montreal QC, Canada},
	annote = {RELEVANT: NULL
},
}


@article{hassan_usability_2020,
	title = {Usability {Requirements} {Extraction} {Method} from {Software} {Document}},
	volume = {30},
	issn = {02181940},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082396047&doi=10.1142%2fS0218194020500084&partnerID=40&md5=1ee6ed01d51d181bc0f54f33f413d1ee},
	doi = {10.1142/S0218194020500084},
	abstract = {Extracting the usability requirements are crucial during requirements review and requirements validation for different purposes. Usability requirements are hard to be determined until the real user has experienced the software. It is even more challenging when these usability requirements are documented in natural language, which has an inconsistent and unrestricted structure. Automated requirements extraction has been widely studied to facilitate the process of requirements checking. Nevertheless, the accuracy of requirements extraction method still can be improved. Thus, this paper has presented the usability keywords repository that followed the ISO 9126 and ISO 25010 usability category and has gone through the expert validation process. The usability requirement extraction method is moreover enhanced with extra procedures in conforming the usability requirement statement. First, each statement in the requirement document is checked if there is a keyword usability, whereby the keywords used must match with the usability keyword repository. In order to ensure that the selected statement is a usability requirement, the corresponding usability keyword position should be after the fixed auxiliary verbs. The performance of the improved usability requirements extraction method is then evaluated using precision, recall and accuracy. © 2020 World Scientific Publishing Company.},
	language = {English},
	number = {2},
	journal = {International Journal of Software Engineering and Knowledge Engineering},
	author = {Hassan, Rohayanti and Fauzi, Noor Atikah Amira and Kasim, Shahreen and Omer, Herman Khalid},
	year = {2020},
	note = {Publisher: World Scientific Publishing Co. Pte Ltd
Type: Article},
	keywords = {Natural languages, Extraction, Requirements validation, usability, Usability engineering, Extraction method, Iso 9126, Usability requirements, Validation process},
	pages = {171 -- 189},
	annote = {Cited by: 1},
	annote = {Cited by: 2},
	annote = {RELEVANCE: not freely available
},
}


@article{pavita_using_2020,
	title = {Using {Formal} {Languages} to {Elicit} {Requirements} for {Healthcare} {Blockchain} {Applications}},
	volume = {1069},
	issn = {21945357},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075667723&doi=10.1007%2f978-3-030-32520-6_58&partnerID=40&md5=28eaf87a1ded9112b107905dd937cf01},
	doi = {10.1007/978-3-030-32520-6_58},
	abstract = {Specifying requirements for complex systems has an important role during software development. At times, the importance of the specification stage gets neglected by software engineers while developing software systems. Software engineering life cycle models are improved for better software quality and reliability. Even though powerful implementation strategies exist, if the requirements of a system to be developed are unclear and not specified properly, then the product can fail to satisfy user needs. Traditional methods use natural language for specifying the requirements of the software systems. The use of formal specifications to specify software systems remains a challenging research problem that needs to be addressed. In this research effort, several healthcare applications that are implemented using Blockchain are studied. Blockchain is a recent invention that uses the idea of decentralization to enforce security. Such applications come with complexity and specifying requirements for such systems using formal specification languages gets even more challenging. The challenges involved in writing formal specifications for such complex applications has been studied in this research effort. The Descartes specification language, a formal executable formal specification language, is used to specify the blockchain healthcare applications under study. Case study examples are used to illustrate the specification of Blockchain healthcare application requirements using the Descartes specification language. © 2020, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Advances in Intelligent Systems and Computing},
	author = {Pavita, Bella and Subburaj, Vinitha Hannah},
	editor = {K, Arai and R, Bhatia and S, Kapoor},
	year = {2020},
	note = {ISBN: 978-303032519-0
Publisher: Springer
Type: Conference paper},
	keywords = {Security, Computer software selection and evaluation, Formal specification, Natural languages, Software design, Software reliability, Specification languages, Life cycle, Health care, Complex applications, Blockchain, Specification stage, Executable formal specification, Health care application, Implementation strategies, Software engineering life-cycle},
	pages = {802 -- 815},
	annote = {Cited by: 0; Conference name: 4th Future Technologies Conference, FTC 2019; Conference date: 24 October 2019 through 25 October 2019; Conference code: 233129},
	annote = {Cited by: 0; Conference name: 4th Future Technologies Conference, FTC 2019; Conference date: 24 October 2019 through 25 October 2019; Conference code: 233129},
	annote = {RELEVANCE: LOW - but interesting
},
}


@article{garanina_verification-oriented_2019,
	title = {Verification-{Oriented} {Process} {Ontology}},
	volume = {53},
	issn = {01464116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080924043&doi=10.3103%2fS0146411619070058&partnerID=40&md5=d2e33ed9710e2b18c7e5301bcffac7a6},
	doi = {10.3103/S0146411619070058},
	abstract = {Abstract: This paper presents the ontology of the concurrent processes close to Hoare communicating sequential processes. It is a part of an intellectual system for supporting verification of behavioral properties of such processes. Our ontological representation of the processes is oriented both to the application of formal verification methods and to the extraction of information from technical documentation (by our previously developed system of information extraction from a natural language text). We describe the ontology classes and domains that define communicating concurrent processes. These processes are characterized by sets of local and shared variables, a list of actions on these variables which change their values, a list of channels for the process communication (which, in turn, are characterized by the type of reading messages, capacity, modes of writing and reading, and reliability), and also a list of communication actions for sending messages. In addition to the formal mathematical definition of classes and domains of the ontology, examples of descriptions of some ontological classes, as well as typical properties and axioms for them, are specified in the editor Protégé in the OWL language with the use of the inference rules in the SWRL language. We define the formal operational semantics of communicating processes for their ontological representation. This semantics is a labeled transition system. It is reduced to the local operational semantics of separate process instances in the interleaving model. We specialize several types of processes from the subject domain of automatic control systems that model the typical functional elements of the automatic control system (sensors, comparators and regulators), as well as their combinations. The concepts of the specialized ontology are illustrated by the example of a control part of a bottle-filling system. © 2019, Allerton Press, Inc.},
	language = {English},
	number = {7},
	journal = {Automatic Control and Computer Sciences},
	author = {Garanina, N.O. and Anureev, I.S. and Borovikova, O.I.},
	year = {2019},
	note = {Publisher: Pleiades Publishing
Type: Article},
	keywords = {Semantics, Ontology, Model checking, Communicating sequential process, Verification, Abstracting, Computer programming languages, Formal verification, Automation, Control systems, Process control, Concurrent process, Extraction of information, Bottles, Formal verification methods, Labeled transition systems, Mathematical definitions, Ontological representation, Technical documentations},
	pages = {584 -- 594},
	annote = {Cited by: 7; All Open Access, Green Open Access},
	annote = {Cited by: 7; All Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{rabinia_towards_2019,
	title = {Towards integrating the {FLG} framework with the {NLP} combinatory framework},
	volume = {2335},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063256698&partnerID=40&md5=d5d2e6f53281e0996c6a8ebbbc497af6},
	abstract = {Automatic modeling of privacy regulations is a highly demanded goal in requirements engineering. The FOL-based Legal-GRL (FLG) is a semi-automated goal-oriented modeling framework for extracting and representing the legal requirements of IT systems. One limitation of the FLG framework, however, is its manual requirements extraction process. Manual extraction of legal requirements is cumbersome, error-prone, and time-consuming. To overcome this shortcoming, we integrate this requirements modeling framework with another framework that combines several natural language processing (NLP) approaches. This Combinatory framework specifically exploits NLP techniques, such as Part-Of-Speech tagging and syntactic parsing, along with NLP tools, such as C\&C and Boxer, to propose an automated approach for extraction of rules from legal texts. This approach enables us to fully automate the FLG framework in order to propose a comprehensive framework for modeling privacy regulations and other legal requirements. This paper outlines the two frameworks and their integration process. Copyright © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Rabinia, Amin and Dragoni, Mauro and Ghanavati, Sepideh},
	editor = {N, Sadeh and K, Ghazinour and S, Wilson and S, Ghanavati},
	year = {2019},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Extraction, Artificial intelligence, NAtural language processing, Modeling languages, Automation, Syntactics, Requirements Models, Computational linguistics, Laws and legislation, Extraction process, Goal oriented modeling, Integration process, Legal requirements, Part of speech tagging, Privacy regulation},
	pages = {80 -- 82},
	annote = {Cited by: 0; Conference name: 2019 PAL: Privacy-Enhancing Artificial Intelligence and Language Technologies, PAL 2019; Conference date: 25 March 2019 through 27 March 2019; Conference code: 146046},
	annote = {Cited by: 0; Conference name: 2019 PAL: Privacy-Enhancing Artificial Intelligence and Language Technologies, PAL 2019; Conference date: 25 March 2019 through 27 March 2019; Conference code: 146046},
	annote = {RELEVANCE: HIGH - try to find a good version
},
}


@inproceedings{blasi_translating_2018,
	title = {Translating code comments to procedure specifications},
	isbn = {978-1-4503-5699-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051519685&doi=10.1145%2f3213846.3213872&partnerID=40&md5=173b5413dd042ae2139b2d4f3f31544c},
	doi = {10.1145/3213846.3213872},
	abstract = {Procedure specifications are useful in many software development tasks. As one example, in automatic test case generation they can guide testing, act as test oracles able to reveal bugs, and identify illegal inputs. Whereas formal specifications are seldom available in practice, it is standard practice for developers to document their code with semi-structured comments. These comments express the procedure specification with a mix of predefined tags and natural language. This paper presents Jdoctor, an approach that combines pattern, lexical, and semantic matching to translate Javadoc comments into executable procedure specifications written as Java expressions. In an empirical evaluation, Jdoctor achieved precision of 92\% and recall of 83\% in translating Javadoc into procedure specifications. We also supplied the Jdoctor-derived specifications to an automated test case generation tool, Randoop. The specifications enabled Randoop to generate test cases that produce fewer false alarms and reveal more defects. © 2018 Association for Computing Machinery.},
	language = {English},
	booktitle = {{ISSTA} 2018 - {Proceedings} of the 27th {ACM} {SIGSOFT} {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Blasi, Arianna and Goffi, Alberto and Kuznetsov, Konstantin and Gorla, Alessandra and Ernst, Michael D. and Pezze, Mauro and Castellanos, Sergio Delgado},
	editor = {E, Bodden and F, Tip},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Software design, Semantics, Software testing, Translation (languages), Automated test case generation, Automatic test-case generations, Empirical evaluations, Semantic matching, Specification inferences, Standard practices, Test oracles},
	pages = {242 -- 253},
	annote = {Cited by: 57; Conference name: 27th ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2018; Conference date: 16 July 2018 through 21 July 2018; Conference code: 138042},
	annote = {Cited by: 66; Conference name: 27th ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2018; Conference date: 16 July 2018 through 21 July 2018; Conference code: 138042},
	annote = {RELEVANCE: NULL but interesting

https://homes.cs.washington.edu/{\textasciitilde}mernst/pubs/comments-specs-issta2018.pdf
},
}


@article{reiher_recordflux_2020,
	title = {{RecordFlux}: {Formal} {Message} {Specification} and {Generation} of {Verifiable} {Binary} {Parsers}},
	volume = {12018 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080886493&doi=10.1007%2f978-3-030-40914-2_9&partnerID=40&md5=352ee32b6e73321e4636264282c8a0d9},
	doi = {10.1007/978-3-030-40914-2_9},
	abstract = {Various vulnerabilities have been found in message parsers of protocol implementations in the past. Even highly sensitive software components like TLS libraries are affected regularly. Resulting issues range from denial-of-service attacks to the extraction of sensitive information. The complexity of protocols and imprecise specifications in natural language are the core reasons for subtle bugs in implementations, which are hard to find. The lack of precise specifications impedes formal verification. In this paper, we propose a model and a corresponding domain-specific language to formally specify message formats of existing real-world binary protocols. A unique feature of the model is the capability to define invariants, which specify relations and dependencies between message fields. Furthermore, the model allows defining the relation of messages between different protocol layers and thus ensures correct interpretation of payload data. We present a technique to derive verifiable parsers based on the model, generate efficient code for their implementation, and automatically prove the absence of runtime errors. Examples of parser specifications for Ethernet and TLS demonstrate the applicability of our approach. © 2020, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Reiher, Tobias and Senier, Alexander and Castrillon, Jeronimo and Strufe, Thorsten},
	editor = {F, Arbab and S.-S, Jongmans},
	year = {2020},
	note = {ISBN: 978-303040913-5
Publisher: Springer
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Specifications, Domain specific languages, Problem oriented languages, Computer software, Computational linguistics, Software component, Binary protocols, Denial-of-service attack, Different protocols, Protocol implementation, Run-time errors, Sensitive informations},
	pages = {170 -- 190},
	annote = {Cited by: 2; Conference name: 16th International Conference on Formal Aspects of Component Software, FACS 2019; Conference date: 23 October 2019 through 25 October 2019; Conference code: 237649; All Open Access, Green Open Access},
}


@article{amendola_model-based_2020,
	title = {A {Model}-{Based} {Approach} to the {Design}, {Verification} and {Deployment} of {Railway} {Interlocking} {System}},
	volume = {12478 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096476300&doi=10.1007%2f978-3-030-61467-6_16&partnerID=40&md5=d5597845067f888ec6f83cf157763c99},
	doi = {10.1007/978-3-030-61467-6_16},
	abstract = {This paper describes a model-based flow for the development of Interlocking Systems. The flow starts from a set of specifications in Controlled Natural Language (CNL), that are close to the jargon adopted in by domain experts, but fully formal. From the CNL, a complete SysML specification is extracted, leveraging various forms of diagrams, and enabling automated code generation. Several formal verification methods are supported. A complementary part of the flow supports the extraction of formal properties from legacy Interlocking Systems designed as Relay circuits. The flow is implemented in a comprehensive toolset, and is currently used by railway experts. © 2020, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Amendola, Arturo and Becchi, Anna and Cavada, Roberto and Cimatti, Alessandro and Griggio, Alberto and Scaglione, Giuseppe and Susi, Angelo and Tacchella, Alberto and Tessi, Matteo},
	editor = {T, Margaria and B, Steffen},
	year = {2020},
	note = {ISBN: 978-303061466-9
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Specifications, Formal verification, Legacy systems, Controlled natural language, Railroads, Interlocking signals, Interlocking systems, Safety devices, Formal verification methods, Automated code generation, Formal properties, Model based approach, Railway interlocking system, SysML specification},
	pages = {240 -- 254},
	annote = {Cited by: 8; Conference name: 9th International Symposium on Leveraging Applications of Formal Methods, Verification and Validation, ISoLA 2020; Conference date: 20 October 2020 through 30 October 2020; Conference code: 250909},
}


@article{issad_scenario-oriented_2018,
	title = {Scenario-oriented reverse engineering of complex railway system specifications},
	volume = {21},
	issn = {10981241},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041211196&doi=10.1002%2fsys.21413&partnerID=40&md5=5e906f881c67af29e081c2cec5b24f89},
	doi = {10.1002/sys.21413},
	abstract = {In this article, we present a scenario-oriented modeling methodology dedicated to the analysis and the formalization of complex system specifications. The methodology relies on the SCOLA semiformal notation to describe scenarios and on a formal execution model described in the AltaRica 3.0 modeling language. We designed this methodology because we had to review thousands of pages of natural language specifications of a railway system in view of their validation with respect to safety constraints. We needed therefore some means to understand what the system was supposed to be and to do as well as to support a dialog with experts. This article aims at introducing the methodology and the modeling formalism that supports it as well as at discussing its application to the railway systems. © 2018 Wiley Periodicals, Inc.},
	language = {English},
	number = {2},
	journal = {Systems Engineering},
	author = {Issad, Melissa and Kloul, Leila and Rauzy, Antoine},
	year = {2018},
	note = {Publisher: John Wiley and Sons Inc.
Type: Article},
	keywords = {Formal specification, Specifications, Modeling languages, Systems engineering, Modeling formalisms, Natural language specifications, Transportation, Railroad transportation, Railroads, Reverse engineering, ITS applications, Modeling methodology, Railway system, Safety constraint, Semi-formal notations, System specification},
	pages = {91 -- 104},
	annote = {Cited by: 2},
	annote = {Cited by: 2},
	annote = {RELEVANCE: LOW
},
}


@article{sheth_systematic_2020,
	title = {Systematic problem-specification in innovation science using language},
	volume = {13},
	issn = {17572223},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100179065&doi=10.1108%2fIJIS-03-2020-0019&partnerID=40&md5=308eaa57301e805d014150f73ac18aac},
	doi = {10.1108/IJIS-03-2020-0019},
	abstract = {Purpose: Problem specification is a key front-end step in the innovation process. This paper aims to introduce ‘purpose-context’ – a conceptual framework to systematically explore problem-specification across mapped contexts. The framework’s logic is operationalized by the inherent structure of language – its syntax/grammar, which enables the systematic exploration of problem-specification. The method showcases two approaches to structurally explore the vast textual databases available to us today for problem-specification in innovation science, thereby furthering the pursuit of innovation through its foundational elements. Design/methodology/approach: The conceptualization of the purpose-context framework was guided by logic and the scholarship of integration applied to bodies of work including innovation, design and linguistics. Further, the key elements of the conceptual framework were unpacked and structured using the syntax of language. Two approaches to operationalize the method were developed to illustrate the systematicity of the process. The construct was then validated by using it to systematically specify problems in the technical context of Raman spectroscopy and in the socio-technical context of international development. Overall, this paper is a work of relational scholarship of integration that bridges academic-practitioner gaps. Findings: The purpose-context framework is well-suited for application in the innovation process with applicability across several abstraction levels. One key contribution is the recognition that a broader problem-specification exercise covering one-one, one-many, many-one, many-many problem-context mappings expands the range of potential solutions (innovations) to address the problem-space. Additionally, the work finds that it is possible to provide structure to the cognitive elements of the innovation process by drawing inspiration from the structure inherent in other cognitive processes such as language (e.g., parts-of-speech, phrase composition). Drawing from language is particularly appropriate as language mediates communication in any collective pursuit of the innovation process and furthermore because a large amount of information exists in textual form. Finally, this paper finds that there is merit in approaching innovation science from its foundational elements – i.e. data, information and knowledge. Research limitations/implications: While the purpose-context framework is broadly applicable, the methodical approach to provide structure to the front-end cognitive process is ‘one’ fruitful approach. We suspect other approaches exist. Practical implications: The purpose-context framework is simple in its framing yet provides innovators, scholars and thought leaders, the ability to specify the problem space with greater coverage and precision. Further, in the solution-space, it provides them the ability to choose the breadth of solution scope (e.g. targeted solution addressing a single problem, targeted solution addressing a set of problems, the combination of solutions addressing a single problem and combination of solutions addressing a combination of problems). In addition, by pairing the creative front-end innovation process with machine power, this study provides a formal method to scale-up the coverage of creativity (and potentially that of solutions to those problems) and reduces the chances of missed/blind-spots in problem-specification. Finally, evaluating purpose-contexts leads to ‘capability-contexts’ – a capability-oriented viewpoint informing capability development decisions such as the focus of R\&D programs and related resource allocation decisions. Originality/value: The paper uses logic to connect multiple bodies of research with a goal to provide systematicity to problem-specification – problem-specification, which is an under-addressed part of the innovation process. The use of data to systematically explore problem-space lends it systematicity (repeatability and measurability) and is therefore, valuable to innovation science. The proof-of-concept demonstrates the conversion of concept into a method for practical application. © 2020, Emerald Publishing Limited.},
	language = {English},
	number = {3},
	journal = {International Journal of Innovation Science},
	author = {Sheth, Ananya and Sinfield, Joseph Victor},
	year = {2020},
	note = {Publisher: Emerald Group Holdings Ltd.
Type: Article},
	keywords = {Formal specification, Computer circuits, Syntactics, Cognitive systems, Resource allocation decision, Capability development, Conceptual frameworks, Design/methodology/approach, Foundational elements, International development, Problem specification, Systematic exploration},
	pages = {314 -- 340},
	annote = {Cited by: 2},
	annote = {Cited by: 2},
	annote = {RELEVANCE: null
},
}


@article{konur_kpworkbench_2020,
	title = {{KPWORKBENCH}: {A} software suit for membrane systems},
	volume = {11},
	issn = {23527110},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078406347&doi=10.1016%2fj.softx.2020.100407&partnerID=40&md5=5eeb9a505a8eb42e2c50815ff0c9c4d9},
	doi = {10.1016/j.softx.2020.100407},
	abstract = {Membrane computing is a new natural computing paradigm inspired by the functioning and structure of biological cells, and has been successfully applied to many different areas, from biology to engineering. In this paper, we present KPWORKBENCH, a software framework developed to support membrane computing and its applications. KPWORKBENCH offers unique features, including modelling, simulation, agent-based high performance simulation and verification, which allow modelling and computational analysis of membrane systems. The KPWORKBENCH formal verification component provides the opportunity to analyse the behaviour of a model and validate that important system requirements are met and certain behaviours are observed. The platform also features a property language based on natural language statements to facilitate property specification. © 2020},
	language = {English},
	journal = {SoftwareX},
	author = {Konur, Savas and Mierlă, Laurenţiu and Ipate, Florentin and Gheorghe, Marian},
	year = {2020},
	note = {Publisher: Elsevier B.V.
Type: Article},
	keywords = {Simulation, Verification, Formal verification, System requirements, Application programs, Property Specification, Computer programming, Models, Bioinformatics, Computational analysis, Software frameworks, Agent based simulation, Cell engineering, High-performance simulation, Membrane computing, Membranes, Synthetic biology},
	annote = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{shigyo_proposal_2020-1,
	title = {Proposal of an algorithm to generate vdm++ by using words extracted from the natural language specification},
	volume = {2020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108796040&doi=10.5954%2fICAROB.2020.OS14-5&partnerID=40&md5=6aa2f98a9dc0ccb30d862bb33bbf78a7},
	doi = {10.5954/ICAROB.2020.OS14-5},
	abstract = {The natural language includes ambiguous expressions. VDM is one of methodology on the formal methods to write the specification without ambiguity. Because VDM++ is written by strict grammar, it is difficult to write a VDM++ specification. This research attempts to generate a VDM++ specification automatically from a natural language specification by machine learning. To generate a VDM++ specification, it is necessary to extract words which consist of predicate corresponding to the function and nouns corresponding to variable from the natural language specification. This paper proposes an approach to generate a VDM++ specification from the extracted words list. Identifiers are generated from the extracted words list, and then the VDM++ specification can be generated by converting them into VDM++ grammar. © The 2020 International Conference on Artificial Life and Robotics (ICAROB2020).},
	language = {English},
	booktitle = {Proceedings of {International} {Conference} on {Artificial} {Life} and {Robotics}},
	publisher = {ALife Robotics Corporation Ltd},
	author = {Shigyo, Yasuhiro and Katayama, Tetsuro and Kita, Yoshihiro and Yamaba, Hisaaki and Aburada, Kentaro and Okazaki, Naonobu},
	year = {2020},
	note = {ISSN: 24359157
Type: Conference paper},
	pages = {763 -- 766},
	annote = {Cited by: 0; Conference name: 25th International Conference on Artificial Life and Robotics, ICAROB 2020; Conference date: 13 January 2020 through 16 January 2020; Conference code: 257439},
	annote = {Cited by: 0; Conference name: 25th International Conference on Artificial Life and Robotics, ICAROB 2020; Conference date: 13 January 2020 through 16 January 2020; Conference code: 257439},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{listenmaa_testing_2018,
	title = {Testing {Natural} {Language} {Grammars}},
	isbn = {978-1-5386-5012-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048394075&doi=10.1109%2fICST.2018.00054&partnerID=40&md5=75727e2ac4ac5743b86648d2278398eb},
	doi = {10.1109/ICST.2018.00054},
	abstract = {Testing grammars has one big difference from testing software: Natural language has no formal specification, so ultimately we must involve a human oracle. However, we can automate many useful subtasks: Detect ambiguous constructions and contradictory grammar rules, as well as generate minimal and representative set of examples that cover all the constructions. Think of the whole grammar as a haystack, and we suspect there are a few needles-we cannot promise automatic needle-removal, but instead we help the human oracle to narrow down the search. © 2018 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2018 {IEEE} 11th {International} {Conference} on {Software} {Testing}, {Verification} and {Validation}, {ICST} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Listenmaa, Inari},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Software testing, Verification, Grammar analysis, Grammar rules, Natural language grammars, Needles, Subtasks, Symbolic evaluation, Test case generation, Testing software},
	pages = {428 -- 429},
	annote = {Cited by: 0; Conference name: 11th IEEE International Conference on Software Testing, Verification and Validation, ICST 2018; Conference date: 9 April 2018 through 13 April 2018; Conference code: 136754},
	annote = {Cited by: 0; Conference name: 11th IEEE International Conference on Software Testing, Verification and Validation, ICST 2018; Conference date: 9 April 2018 through 13 April 2018; Conference code: 136754},
	annote = {RELEVANCE: null
},
}


@article{qin_safety_2019,
	title = {Safety analysis for submarine torpedo launch control system based on {STPA}},
	volume = {39},
	issn = {10006788},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079319920&doi=10.12011%2f1000-6788-2019-0541-09&partnerID=40&md5=3699f59a426db7a32dfa37fc51d21aa4},
	doi = {10.12011/1000-6788-2019-0541-09},
	abstract = {In this paper, a safety analysis method based on system theoretic process analysis (STPA) is proposed for the submarine torpedo launch control system. One typical action of torpedo launching process, releasing the weapon brake is taken as an example for analysis with XSTAMPP safety engineering platform. Traditional STPA causal scenario analysis model is improved; refined system safety requirements are generated and the descriptions are standardized by linear temporal logic (LTL), the limitations of natural language descriptions used by traditional STPA analysis have been avoided, which provides theoretical support for further safety model verification and decision-making assistant for system operators. © 2019, Editorial Board of Journal of Systems Engineering Society of China. All right reserved.},
	language = {Chinese},
	number = {12},
	journal = {Xitong Gongcheng Lilun yu Shijian/System Engineering Theory and Practice},
	author = {Qin, Nan and Ma, Liang and Huang, Rui},
	year = {2019},
	note = {Publisher: Systems Engineering Society of China
Type: Article},
	keywords = {Decision making, Temporal logic, Linear temporal logic, Computer circuits, Safety engineering, Control systems, Process analysis, Causal analysis, Launch controls, Submarines, Torpedoes, XSTAMPP},
	pages = {3208 -- 3216},
	annote = {Cited by: 2},
	annote = {Cited by: 3},
	annote = {RELEVANCE: LOW
Complexity of NL text is avoided
},
}


@article{yanuarifiani_rule-based_2019,
	title = {Rule-based ontology framework ({ROF}) for auto-generating requirements specification: {A} case study},
	volume = {318},
	issn = {09226389},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082028546&doi=10.3233%2fFAIA190062&partnerID=40&md5=8c5fcc74443ca20036df322d0879133e},
	doi = {10.3233/FAIA190062},
	abstract = {Building requirements specification document in semi-formal notation and natural language needs great effort from users and developers. However, the current approach to the requirements engineering process is still lacking in auto-generating model and documentation. Most approaches only focusing in building UML use cases and a brief version of Software Requirements Specification (SRS), which are not enough as a basis for the code development process. A Rule-based Ontology Framework (ROF) for AutoGenerating Requirements Specification is proposed. It is used for auto-generating requirements specifications that consist of semi-formal modeling in Business Process Model Notation (BPMN) and natural language of Software Requirements Specification (SRS) in IEEE template. This paper discusses the implementation of ROF in a requirement engineering process in a University located in Indonesia. It is applied in Lecturer Workload Management (LWM) Application, an application that summarizes lecturer workload and calculates the scores as basis for generating salary. This application was developed by the Department of Information Systems (ISD). Existing requirements engineering process mostly depend on users' perspective which causes building the requirements documentation require much effort and do not represent the real needs of users. Thus, the requirements documents do not support the development process which causes project delay. Using ROF, the requirements engineering process becomes more effective by specifying functional requirements that represent user's needs and produce document that is feasible to be used as a reference for the development process. © 2019 The authors and IOS Press. All rights reserved.},
	language = {English},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Yanuarifiani, Amarilis Putri and Chua, Fang-Fang and Chan, Gaik-Yee},
	editor = {H, Fujita and A, Selamat},
	year = {2019},
	note = {ISBN: 978-164368012-5
Publisher: IOS Press BV
Type: Conference paper},
	keywords = {Business process modeling, Formal specification, Requirements engineering, Software requirements specifications, Ontology, Modeling languages, Requirements specifications, Compensation (personnel), Business Process Modeling Notation (BPMN), Ontology's, Modeling notation, Auto-generate BPMN, Requirement engineering process, Requirements documentations, Requirements engineering process, Requirements ontology, Auto-generate business process model notation, Auto-generate software requirement specification, Auto-generating, Rule based},
	pages = {347 -- 360},
	annote = {Cited by: 2; Conference name: 18th International Conference on New Trends in Intelligent Software Methodologies, Tools and Techniques, SoMeT 2019; Conference date: 23 September 2019 through 25 September 2019; Conference code: 158253},
	annote = {Cited by: 2; Conference name: 18th International Conference on New Trends in Intelligent Software Methodologies, Tools and Techniques, SoMeT 2019; Conference date: 23 September 2019 through 25 September 2019; Conference code: 158253},
	annote = {RELEVANCE: parece interesante pero no es gratis
},
}


@article{giantamidis_reform_2020,
	title = {{ReForm}: {A} {Tool} for {Rapid} {Requirements} {Formalization}},
	volume = {79},
	issn = {18632122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110647523&partnerID=40&md5=12db19d598cd0cbf29d7442f2f5391c6},
	abstract = {Formal methods practices can sometimes be challenging to adopt in industrial environments. On the other hand, the need for formalization and verification in the design of complex systems is now more evident than ever. To the end of easing integration of formal methods in industrial model based system engineering workflows, UTRC Ireland has developed a tool aiming to render requirements formalization as effortless as possible to the industrial engineer. The developed approach is an end-to-end solution, starting with natural language requirements as input and going all the way down to auto-generated monitors in MATLAB / Simulink. We employ natural language processing and machine learning techniques for (semi-)automatic pattern extraction from requirements, which drastically reduces the required formalization workload for both legacy and new requirements. For monitor generation, we provide our own approach which outperforms existing state-of-the-art tools by orders of magnitude in some cases © 2020, Electronic Communications of the EASST. All rights reserved.},
	language = {English},
	journal = {Electronic Communications of the EASST},
	author = {Giantamidis, Georgios and Papanikolaou, Georgios and Miranda, Marcelo and Salinas-Hernando, Gonzalo and Valverde-Alcalá, Juan and Veluru, Suresh and Basagiannis, Stylianos},
	year = {2020},
	note = {Publisher: Universitatsbibliothek TU Berlin
Type: Article},
	pages = {1 -- 9},
	annote = {Cited by: 1},
	annote = {Cited by: 1},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{kadebu_security_2018,
	title = {Security requirements extraction and classification: {A} survey},
	isbn = {978-1-5386-6894-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081129130&doi=10.1109%2fIC3I44769.2018.9007263&partnerID=40&md5=f6a3adba24eda0416ac7378623e87796},
	doi = {10.1109/IC3I44769.2018.9007263},
	abstract = {Security Requirements Engineering is a very important process in the Software Development Life Cycle (SDLC) with Security Engineering being given profound attention in the development of software. It is imperative to build security within a software product. This ensures that software that is deployed is secure and can withstand attack. The research work explores Security Requirements extraction and classification techniques and application of Machine to the process. Techniques such as Naïve Bayes Classifier, K-NN, Support Vector Machine (SVM), ANN among others have been applied to the various tasks embedded in the process. This research will pave a way to techniques that can aid in the process of Security Requirements extraction and classification. © 2018 IEEE.},
	language = {English},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Contemporary} {Computing} and {Informatics}, {IC3I} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Kadebu, Prudence and Thada, Vikas and Chiurunge, Panashe},
	editor = {P.B, Sharma and A, Rana and P, Singh and S.K, Khatri and A.K, Bhatnagar},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Software design, Extraction, NAtural language processing, Cryptography, Security requirements, Computer software, Learning algorithms, Engineering research, Life cycle, Support vector machines, Classification technique, Security engineering, Security requirements engineering, Software development life cycle, Software products, Software security},
	pages = {129 -- 134},
	annote = {Cited by: 0; Conference name: 3rd International Conference on Contemporary Computing and Informatics, IC3I 2018; Conference date: 10 October 2018 through 12 October 2018; Conference code: 158025},
	annote = {Cited by: 0; Conference name: 3rd International Conference on Contemporary Computing and Informatics, IC3I 2018; Conference date: 10 October 2018 through 12 October 2018; Conference code: 158025},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{noauthor_proceedings_2019,
	title = {Proceedings - {International} {Conference} on {Software} {Engineering}},
	volume = {2019-May},
	isbn = {978-1-72810-869-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072297797&partnerID=40&md5=e5ff0f0570660ff7e64ff3bcf5916ffa},
	abstract = {The proceedings contain 115 papers. The topics discussed include: why do episodic volunteers stay in FLOSS communities?; NL2Type: inferring JavaScript function types from natural language information; dockerizeme: automatic inference of environment dependencies for python code snippets; PIVOT: learning API-device correlations to facilitate android compatibility issue detection; AutoTap: synthesizing and repairing trigger-action programs using LTL properties; AutoTap: synthesizing and repairing trigger-action programs using LTL properties; test-driven code review: an empirical study; intention-based integration of software variants; automated reporting of anti-patterns and decay in continuous integration; and ActionNet: vision-based workflow action recognition from programming screencasts.},
	language = {English},
	booktitle = {Proceedings - {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Computer Society},
	year = {2019},
	note = {ISSN: 02705257
Type: Conference review},
	annote = {Cited by: 0; Conference name: 41st IEEE/ACM International Conference on Software Engineering, ICSE 2019; Conference date: 25 May 2019 through 31 May 2019; Conference code: 151191},
	annote = {Cited by: 0; Conference name: 41st IEEE/ACM International Conference on Software Engineering, ICSE 2019; Conference date: 25 May 2019 through 31 May 2019; Conference code: 151191},
	annote = {RELEVANCE:LOW - procedings
},
}


@inproceedings{priyadi_requirements_2019,
	title = {Requirements {Dependency} {Graph} {Modeling} on {Software} {Requirements} {Specification} {Using} {Text} {Analysis}},
	isbn = {978-1-72811-472-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074412789&doi=10.1109%2fICORIS.2019.8874920&partnerID=40&md5=28a7cebe183078561451cc733af7caa8},
	doi = {10.1109/ICORIS.2019.8874920},
	abstract = {Understanding interdependency among requirements is one of the success factors in software development. Information on requirements interdependency explicitly and implicitly resided various design artifacts or diagrams. A software requirements specification document is the artifact delivered in the early phase of development. It drives its following development processes. It also contains information on interdependencies among the requirements, such as similar, part-of, and elaborate. This study proposes an approach to model the requirement dependency graph for a software requirements specification document. There is an extraction process for Text Preprocessing, which includes of Tokenization, Stopword Removal, and Stemming. Besides, there is a process of measuring semantic similarity through WS4J (WordNet Similarity for Java). The results of the extraction process, combined with Greedy Algorithms as the optimum value solution approach. Besides, a method for calculating similarity was used through the practices of Wu Palmer and Levenshtein. At the end of this process, Reliability is performed using the Gwet's AC1 formula. © 2019 IEEE.},
	language = {English},
	booktitle = {2019 1st {International} {Conference} on {Cybernetics} and {Intelligent} {System}, {ICORIS} 2019},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Priyadi, Yudi and Djunaidy, Arif and Siahaan, Daniel},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Software design, Software requirements specifications, Extraction, Semantics, Software reliability, Intelligent systems, similarity, Reliability, dependency type, Requirements dependencies, Text preprocessing},
	pages = {221 -- 226},
	annote = {Cited by: 6; Conference name: 1st International Conference on Cybernetics and Intelligent System, ICORIS 2019; Conference date: 22 August 2019 through 23 August 2019; Conference code: 152983},
	annote = {Cited by: 7; Conference name: 1st International Conference on Cybernetics and Intelligent System, ICORIS 2019; Conference date: 22 August 2019 through 23 August 2019; Conference code: 152983},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{macbeth_towards_2019,
	title = {Towards modeling conceptual dependency primitives with image schema logic},
	volume = {2518},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077727937&partnerID=40&md5=5777616d6036e6fd56bd2b5f0e31c53c},
	abstract = {Conceptual Dependency (CD) primitives and Image Schemas (IS) share a common goal of grounding symbols of natural language in a representation that allows for automated semantic interpretation. Both seek to establish a connection between high-level conceptualizations in natural language and abstract cognitive building blocks. Some previous approaches have established a CD-IS correspondence. In this paper, we build on this correspondence in order to apply a logic designed for image schemas to selected CD primitives with the goal of formally taking account of the CD inventory. The logic draws from Region Connection Calculus (RCC-8), Qualitative Trajectory Calculus (QTC), Cardinal Directions and Linear Temporal Logic (LTL). One of the primary premises of CD is a minimalist approach to its inventory of primitives, that is, it seeks to express natural language contents in an abstract manner with as few primitives as possible. In a formal analysis of physical primitives of CD we found a potential reduction since some primitives can be expressed as special cases of others. Copyright © 2019 for this paper by its authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Macbeth, Jamie C. and Gromann, Dagmar},
	editor = {A, Barton and S, Seppala and D, Porello},
	year = {2019},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Semantics, Ontology, Temporal logic, Linear temporal logic, Calculations, Computer circuits, Formal model, Cardinal direction, Image schemas, Region connection calculus, High level languages, Conceptual Dependency, Potential reduction, Semantic interpretation},
	annote = {Cited by: 1; Conference name: 2019 Joint Ontology Workshops Episode V: The Styrian Autumn of Ontology, JOWO 2019; Conference date: 23 September 2019 through 25 September 2019; Conference code: 155856},
	annote = {Cited by: 2; Conference name: 2019 Joint Ontology Workshops Episode V: The Styrian Autumn of Ontology, JOWO 2019; Conference date: 23 September 2019 through 25 September 2019; Conference code: 155856},
	annote = {RELEVANCE: NULL
},
}


@article{irina_methodology_2020,
	title = {Methodology for development of event-driven software systems using ciao specification language; [МЕТОДИКА ПОСТРОЕНИЯ СОБЫТИЙНО-УПРАВЛЯЕМЫХ ПРОГРАММНЫХ СИСТЕМ С ИСПОЛЬЗОВАНИЕМ ЯЗЫКА СПЕЦИФИКАЦИИ {CIAO}]},
	volume = {19},
	issn = {20789181},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091136592&doi=10.15622%2fsp.2020.19.3.1&partnerID=40&md5=1f986ad547803917060db3e26b192980},
	doi = {10.15622/sp.2020.19.3.1},
	abstract = {Event-driven software systems, belonging to the class of systems with complex behavior in the scientific literature, are reactive systems, which react to the same input effect in different ways depending on their state and background. It is convenient to describe such systems using state-transition models utilizing special language tools, both graphical and textual. Methodology for automated development of systems with complex behavior using the designed CIAO language (Cooperative Interaction of Automata Objects), which allows formally specifying the required behavior based on an informal description of the reacting system, is presented. An informal description of a reacting system can be provided verbally in a natural language or in another way adopted in a specific domain. Further, according to this specification in the CIAO language, a software system for interacting automata in the C++ programming language is generated with a special system. The generated program implements a behavior guaranteed to correspond to a given specification and original informal description. CIAO provides both graphical and textual notation. Graphic notation is based on an extended notation of state machine diagrams and component diagrams of the unified modeling language UML, which are well established in describing the behavior of event-driven systems. The text syntax of the CIAO language is described by context-free grammar in regular form. Automatically generated C++ code allows using of both library and any external functions written manually. At the same time, the evident correspondence of the formal specification and the generated code is preserved on conditions that the external functions conform to their specifications. As an example, an original solution to D. Knut's problem of a responsive elevator control system is proposed. The effectiveness of the proposed methodology is demonstrated, since the automaton-converter generating the C++ code is presented as a responsive system, is specified in the CIAO language and implemented by the bootstrapping. The proposed methodology is compared with other well-known formal methods for describing systems with complex behavior. © 2020 St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences. All rights reserved.},
	language = {Russian},
	number = {3},
	journal = {SPIIRAS Proceedings},
	author = {Irina, Afanasieva and Fedor, Novikov and Ludmila, Fedorchenko},
	year = {2020},
	note = {Publisher: St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences
Type: Article},
	pages = {481 -- 514},
	annote = {Cited by: 0; All Open Access, Gold Open Access},
	annote = {Cited by: 1; All Open Access, Gold Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{kushiro_logic_2020,
	title = {Logic visualization algorithm in system specifications as companion tool for system designing and testing},
	volume = {176},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093361878&doi=10.1016%2fj.procs.2020.09.227&partnerID=40&md5=82ed20779053c2d1f7e1637a50103d74},
	doi = {10.1016/j.procs.2020.09.227},
	abstract = {Formal methods are introduced into system designing and testing for realizing high-reliability system. However, the use of these techniques still remain restrictive, due to their redundancies. Most engineers fulfill their activities with natural languages, the specifications described in a natural language are indispensable. For applying the formal method, the specifications in natural language should be translated into a formal language expressly. While, the specifications in the formal language should be re-translated once again in the natural language for execution tests using actual software and/or product. Those redundancies are reasons why the formal methods cannot penetrate into actual industries. To solve these redundancies, algorithms for converting sentences in specification documents into semi-formal descriptions automatically, and visualizing logical relations among semiformal descriptions are proposed in the paper. © 2020 The Authors. Published by Elsevier B.V.},
	language = {English},
	booktitle = {Procedia {Computer} {Science}},
	publisher = {Elsevier B.V.},
	author = {Kushiro, Noriyuki and Aoyama, Yusuke},
	editor = {M, Cristani and C, Toro and C, Zanni-Merk and R.J, Howlett and L.C, Jain and L.C, Jain},
	year = {2020},
	note = {ISSN: 18770509
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Formal languages, Software testing, Translation (languages), Knowledge based systems, Formal Description, Redundancy, Systems analysis, System specification, High-reliability systems, Logical relations, System designing, Visualization algorithms},
	pages = {1873 -- 1882},
	annote = {Cited by: 3; Conference name: 24th KES International Conference on Knowledge-Based and Intelligent Information and Engineering Systems, KES 2020; Conference date: 16 September 2020 through 18 September 2020; Conference code: 163593; All Open Access, Gold Open Access},
	annote = {Cited by: 3; Conference name: 24th KES International Conference on Knowledge-Based and Intelligent Information and Engineering Systems, KES 2020; Conference date: 16 September 2020 through 18 September 2020; Conference code: 163593; All Open Access, Gold Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{yadav_random_2020,
	title = {Random {Indexing} and {Centroid} {Based} {Technique} for {Multi} {Document} {Summarization}},
	volume = {601},
	issn = {18761100},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085503551&doi=10.1007%2f978-981-15-1420-3_26&partnerID=40&md5=35ca8733ae8210c2f519cd64aa74baec},
	doi = {10.1007/978-981-15-1420-3_26},
	abstract = {In the era of presence of multiple textual information about a particular topic, it becomes of immense importance to process these multiple documents and summarize them. This is the process of Multi-Document Summarization (MDS). One of the very famous technique for Multiple Document Summarization is Centroid based method which is used in a popular tool for MDS viz. MEAD. This research aims to fill the gap of developments taken in recent years and the technique of Centroid based summarization. Primarily, the centroid based technique works on vector space model of representation of sentence vectors. Recently, Random Indexing was proposed for efficient Single Document Summarization. This research aims to build a hybrid technique for MDS which utilizes the best of both techniques in one. The experimental results confirm not only a decrease in temporal requirement but also in efficiency measured in terms of ROUGE scores. The proposed work has been validated for generic multi document summarization using DUC2005 dataset. © 2020, Springer Nature Singapore Pte Ltd.},
	language = {English},
	journal = {Lecture Notes in Electrical Engineering},
	author = {Yadav, Nidhika and Aggarwal, Tanya and Chatterjee, Niladri},
	editor = {A, Kumar and M, Paprzycki and V.K, Gunjan},
	year = {2020},
	note = {ISBN: 978-981151419-7
Publisher: Springer
Type: Conference paper},
	keywords = {Natural language processing systems, Machine learning, Hybrid techniques, Indexing (of information), Multi-document summarization, Multiple documents, Random indexing, Single document summarization, Textual information, Vector space models, Vector spaces},
	pages = {246 -- 252},
	annote = {Cited by: 0; Conference name: 1st International Conference on Data Science, Machine Learning and Applications, 2019; Conference date: 29 March 2019 through 30 March 2019; Conference code: 240289},
	annote = {Cited by: 0; Conference name: 1st International Conference on Data Science, Machine Learning and Applications, 2019; Conference date: 29 March 2019 through 30 March 2019; Conference code: 240289},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{agarwal_ltl-ude_2020,
	title = {{LTL}-{UDE} at low-resource speech-to-text shared task: {Investigating} mozilla deepspeech in a low-resource setting},
	volume = {2624},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088409364&partnerID=40&md5=c47096bf8714a35f4e9b2c083515fe4a},
	abstract = {We describe our system participating in the SwissText/KONVENS shared task on low-resource speech-to-text (Plüss et al., 2020). We train an end-to-end neural model based on Mozilla DeepSpeech. We examine various methods to improve over the baseline results: transfer learning from standard German and English, data augmentation, and post-processing. Our best system achieves a somewhat disappointing WER of 58.9\% on the held-out test set, indicating that it is currently challenging to obtain good results with this approach in a low-resource setting. Copyright © 2020 for this paper by its authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Agarwal, Aashish and Zesch, Torsten},
	editor = {S, Ebling and D, Tuggener and M, Hurlimann and M, Cieliebak and M, Volk},
	year = {2020},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Text mining, Data augmentation, Transfer learning, End to end, Baseline results, Low-resource settings, Mozilla, Neural modeling, Post processing, Test sets},
	annote = {Cited by: 0; Conference name: 5th Swiss Text Analytics Conference and 16th Conference on Natural Language Processing, SWISSTEXT and KONVENS 2020; Conference date: 23 June 2020 through 25 June 2020; Conference code: 161235},
	annote = {Cited by: 0; Conference name: 5th Swiss Text Analytics Conference and 16th Conference on Natural Language Processing, SWISSTEXT and KONVENS 2020; Conference date: 23 June 2020 through 25 June 2020; Conference code: 161235},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{brunello_synthesis_2019,
	title = {Synthesis of {LTL} formulas from natural language texts: {State} of the art and research directions},
	volume = {147},
	isbn = {978-3-95977-127-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073529846&doi=10.4230%2fLIPIcs.TIME.2019.17&partnerID=40&md5=2a38c99621d79fcfd669488113caba70},
	doi = {10.4230/LIPIcs.TIME.2019.17},
	abstract = {Linear temporal logic (LTL) is commonly used in model checking tasks; moreover, it is well-suited for the formalization of technical requirements. However, the correct specification and interpretation of temporal logic formulas require a strong mathematical background and can hardly be done by domain experts, who, instead, tend to rely on a natural language description of the intended system behaviour. In such situations, a system that is able to automatically translate English sentences into LTL formulas, and vice versa, would be of great help. While the task of rendering an LTL formula into a more readable English sentence may be carried out in a relatively easy way by properly parsing the formula, the converse is still an open problem, due to the inherent difficulty of interpreting free, natural language texts. Although several partial solutions have been proposed in the past, the literature still lacks a critical assessment of the work done. We address such a shortcoming, presenting the current state of the art for what concerns the English-to-LTL translation problem, and outlining some possible research directions. © Michael H. Böhlen and Muhammad Saad;},
	language = {English},
	booktitle = {Leibniz {International} {Proceedings} in {Informatics}, {LIPIcs}},
	publisher = {Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing},
	author = {Brunello, Andrea and Montanari, Angelo and Reynolds, Mark},
	editor = {J, Gamper and S, Pinchinat and G, Sciavicco},
	year = {2019},
	note = {ISSN: 18688969
Type: Conference paper},
	keywords = {Evolutionary algorithms, Natural language processing systems, Natural language text, Semantics, Temporal logic, NAtural language processing, Linear temporal logic, Model checking, Computer circuits, Syntactics, Translation (languages), Machine learning, Learning algorithms, Context free grammars, Temporal logic formula, Technical requirement, Learning systems, Semantic parsing, Critical assessment, English sentences},
	pages = {171 -- 1719},
	annote = {Cited by: 29; Conference name: 26th International Symposium on Temporal Representation and Reasoning, TIME 2019; Conference date: 16 October 2019 through 19 October 2019; Conference code: 152384},
	annote = {Cited by: 34; Conference name: 26th International Symposium on Temporal Representation and Reasoning, TIME 2019; Conference date: 16 October 2019 through 19 October 2019; Conference code: 152384},
	annote = {RELEVANCE: HIGH
},
}


@article{mh_23rd_2019,
	title = {23rd {Symposium} on {Formal} {Methods}, {FM} 2019, in the form of the 3rd {World} {Congress} on {Formal} {Methods}, 2019},
	volume = {11800 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076102923&partnerID=40&md5=b1c470bc271eb541f323a15697c9a854},
	abstract = {The proceedings contain 46 papers. The special focus in this conference is on Symposium on Formal Methods, in the form of the World Congress on Formal Methods. The topics include: A parametric rely-guarantee reasoning framework for concurrent reactive systems; verifying correctness of persistent concurrent data structures; compositional verification of concurrent systems by combining bisimulations; towards a model-checker for circus; Circus2CSP: A tool for model-checking circus using FDR; how hard is finding shortest counter-example lassos in model checking?; From LTL to unambiguous büchi automata via disambiguation of alternating automata; generic partition refinement and weighted tree automata; equilibria-based probabilistic model checking for concurrent stochastic games; successes in deployed verified software (and insights on key social factors); abstract execution; Static analysis for detecting high-level races in RTOS kernels; parallel composition and modular verification of computer controlled systems in differential dynamic logic; an axiomatic approach to liveness for differential equations; local consistency check in synchronous dataflow models; gray-box monitoring of hyperproperties; quantitative verification of numerical stability for kalman filters; concolic testing heap-manipulating programs; Formal semantics extraction from natural language specifications for ARM; GOSPEL—providing OCaml with a formal specification language; provably correct floating-point implementation of a point-in-polygon algorithm; unification in matching logic; embedding high-level formal specifications into applications; value-dependent information-flow security on weak memory models; reasoning formally about database queries and updates; abstraction and subsumption in modular verification of C programs; IELE: A rigorously designed language and tool ecosystem for the blockchain; APML: An architecture proof modeling language; learning deterministic variable automata over infinite alphabets.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {M.H, ter Beek and A, McIver and J.N, Oliveira},
	year = {2019},
	note = {ISBN: 978-303030941-1
Publisher: Springer
Type: Conference review},
	annote = {Cited by: 0; Conference name: 23rd Symposium on Formal Methods, FM 2019, in the form of the 3rd World Congress on Formal Methods, 2019; Conference date: 7 October 2019 through 11 October 2019; Conference code: 232479},
	annote = {Cited by: 0; Conference name: 23rd Symposium on Formal Methods, FM 2019, in the form of the 3rd World Congress on Formal Methods, 2019; Conference date: 7 October 2019 through 11 October 2019; Conference code: 232479},
	annote = {RELEVANCE: NULL - procedings
},
}


@article{nardone_model_2019,
	title = {Model checking techniques applied to satellite operational mode management},
	volume = {13},
	issn = {19328184},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041525786&doi=10.1109%2fJSYST.2018.2793665&partnerID=40&md5=8bd5dd3df346c2b1a87cf7934c8e07c4},
	doi = {10.1109/JSYST.2018.2793665},
	abstract = {Satellites are nowadays complex systems and can be considered as components of larger mission-level systems of systems. The increasing complexity of space mission objectives is actually complicating the requirement engineering process. It is generally understood that space system engineers should translate system-level requirements (elaborated in natural language) into verifiable models, which can expose the design issues before the satellite manufacturing phase. This paper shows how the verification of complex system requirements can be performed via model checking. More specifically, a methodology is proposed which exploits the flexibility provided by the calculus of communicating systems to model complex system concurrent parts and their mutual interactions for verifying analytically their correctness, completeness, and consistency as prescribed by the system requirements. The proposed methodology is applied to the verification of a real satellite operational mode management specification. An abstraction reduction technique based on the selective mu-calculus logic is used to address the computational issues in model checking. It allows capturing and analyzing the parts of a satellite involved in the verification of a specific set of its system-level properties. © 2018 IEEE},
	language = {English},
	number = {1},
	journal = {IEEE Systems Journal},
	author = {Nardone, Vittoria and Santone, Antonella and Tipaldi, Massimo and Liuzza, Davide and Glielmo, Luigi},
	year = {2019},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.
Type: Article},
	keywords = {Requirements engineering, Temporal logic, Model checking, Systems engineering, Abstracting, Abstraction techniques, Analytical models, Calculations, Calculus, Calculus of communicating systems, Computer programming languages, Formal verification, Large scale systems, Operational modes, Satellites, Space applications, Space missions, Standards, System of systems, Systems of systems},
	pages = {1018 -- 1029},
	annote = {Cited by: 12},
	annote = {Cited by: 13},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{tosic_teaching_2018,
	title = {Teaching theoretical computer science and mathematical techniques to diverse undergraduate student populations},
	volume = {2018-June},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051226658&partnerID=40&md5=5fef6ec721e1994ba1797c10a3b1c8c4},
	abstract = {We share our experience and insights gained from teaching foundations of computer science courses to diverse groups of undergraduate (and at times, also graduate) students coming from a broad variety of educational and social backgrounds. Among all required courses of contemporary Computer Science (CS) curricula across the US and Canadian universities, at most institutions (except for the very top research universities), theoretical computer science courses tend to be among the least popular. The reasons behind these prevalent attitudes among CS college students (esp. the undergraduates) tend to fall into two categories: i) theoretical CS courses are "all math" requiring proofs and rigorous formal reasoning that many CS and other engineering students aren't (yet) comfortable with; and ii) "why do we need all this theory anyway" if our career goal is to become software engineers, develop the next cool mobile app, and similar. Yet, most research universities, as well as quite a few non-research colleges, require at least 1-2 semesters of core undergraduate coursework in theoretical or foundational CS. We summarize some interesting lessons learned from teaching theoretical CS to mostly undergraduate upperclassmen (as well as a few non-traditional students) at two prominent public research universities in the US Pacific Northwest, as well as at comparable institutions in Canada (specifically, British Columbia). While the academic and professional backgrounds of the two authors of this paper are considerably different, we also share quite a bit in common: in particular, both of us have spent several years in high-tech industry prior to returning to the academic world as Computer Science faculty. In particular, when teaching various CS courses, we try to relate concepts and techniques covered to the "real-world" applications, and in particular the recent and current technology challenges and R\&D done in industry. We have applied this general philosophy to virtually all courses we have taught, including the very theoretical ones ∼ such as those on Automata and Formal Languages. The goal is to get CS and other Engineering students intrigued by how, for example, finite automata or context-free grammars are used in compilers and interpreters (parsing, lexical analysis), or the formal specification of programming languages ∼ as well as to the more recently emerged technologies, such as computational/applied Natural Language Processing (NLP). Without sacrificing rigor, we try to present highly mathematical content in a manner that relates theoretical models and proofs of their properties to practical challenges in computer science and engineering. Some additional challenges we have encountered while teaching Theory of Computing courses stem from very diverse educational backgrounds of the students we have encountered: from graduate students overcoming true or perceived deficiencies in the CS foundations, to undergraduates transferring from local community colleges, many of whom still struggle with formulating a mathematical proof of any kind. This mix of students provides unique challenges, but also opportunities ∼ for example, to revisit teaching methodologies for the "mathematical side of computer science" curricula, how to best relate theory to practice (esp. in terms of technologies and applications these diverse students can most readily relate to), and how to best get students of broadly varying backgrounds actively engage in class discussions. © American Society for Engineering Education, 2018.},
	language = {English},
	booktitle = {{ASEE} {Annual} {Conference} and {Exposition}, {Conference} {Proceedings}},
	publisher = {American Society for Engineering Education},
	author = {Tosic, Predrag T. and Beeston, Julie},
	year = {2018},
	note = {ISSN: 21535965
Type: Conference paper},
	annote = {Cited by: 0; Conference name: 125th ASEE Annual Conference and Exposition; Conference date: 23 June 2018 through 27 December 2018; Conference code: 138114},
	annote = {Cited by: 0; Conference name: 125th ASEE Annual Conference and Exposition; Conference date: 23 June 2018 through 27 December 2018; Conference code: 138114},
	annote = {RELEVANCE: NULL
},
}


@inproceedings{welbl_towards_2020,
	title = {{TOWARDS} {VERIFIED} {ROBUSTNESS} {UNDER} {TEXT} {DELETION} {INTERVENTIONS}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093402997&partnerID=40&md5=4300d58fa2ec2926d79e1a74f4f28a0a},
	abstract = {Neural networks are widely used in Natural Language Processing, yet despite their empirical successes, their behaviour is brittle: they are both over-sensitive to small input changes, and under-sensitive to deletions of large fractions of input text. This paper aims to tackle under-sensitivity in the context of natural language inference by ensuring that models do not become more confident in their predictions as arbitrary subsets of words from the input text are deleted. We develop a novel technique for formal verification of this specification for models based on the popular decomposable attention mechanism by employing the efficient yet effective interval bound propagation (IBP) approach. Using this method we can efficiently prove, given a model, whether a particular sample is free from the under-sensitivity problem. We compare different training methods to address under-sensitivity, and compare metrics to measure it. In our experiments on the SNLI and MNLI datasets, we observe that IBP training leads to a significantly improved verified accuracy. On the SNLI test set, we can verify 18.4\% of samples, a substantial improvement over only 2.8\% using standard training. © 2020 8th International Conference on Learning Representations, ICLR 2020. All rights reserved.},
	language = {English},
	booktitle = {8th {International} {Conference} on {Learning} {Representations}, {ICLR} 2020},
	publisher = {International Conference on Learning Representations, ICLR},
	author = {Welbl, Johannes and Huang, Po-Sen and Stanforth, Robert and Gowal, Sven and Dvijotham, Krishnamurthy and Szummer, Martin and Kohli, Pushmeet},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Language processing, Neural-networks, Novel techniques, Model-based OPC, Arbitrary subsets, Attention mechanisms, Backpropagation, Interval bounds, Language inference, Small inputs},
	annote = {Cited by: 4; Conference name: 8th International Conference on Learning Representations, ICLR 2020; Conference date: 30 April 2020; Conference code: 186995},
	annote = {Cited by: 5; Conference name: 8th International Conference on Learning Representations, ICLR 2020; Conference date: 30 April 2020; Conference code: 186995},
	annote = {RELEVANCE: NULL - not related
},
}


@book{dghaym_systematic_2019,
	title = {Systematic verification and testing},
	isbn = {978-3-030-14628-3 978-3-030-14627-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085803450&doi=10.1007%2f978-3-030-14628-3_9&partnerID=40&md5=c6a63f44a666959d562a9a04e10a5d00},
	abstract = {In this chapter, we present a process pattern for model based specification, verification and testing. It combines concepts of behaviour driven development (BDD), graphical and formal, mathematical modelling, formal verification techniques, acceptance testing and model based testing. The rigorous approach helps to ensure that for highly dependable systems, dependability (e.g. safety) requirements are fulfilled and both the specified and the implemented behaviour are as desired. It helps bridging the gap between natural language or semi-formal requirements and mathematical abstraction. Furthermore, it addresses the issue that formal modelling expertise and domain knowledge are rarely held by the same set of people. © Springer Nature Switzerland AG 2020.},
	language = {English},
	publisher = {Springer International Publishing},
	author = {Dghaym, Dana and Fischer, Tomas and Hoang, Thai Son and Reichl, Klaus and Snook, Colin and Schlick, Rupert and Tummeltshammer, Peter},
	year = {2019},
	doi = {10.1007/978-3-030-14628-3_9},
	note = {Publication Title: Validation and Verification of Automated Systems: Results of the ENABLE-S3 Project
Type: Book chapter},
	annote = {Cited by: 1},
	annote = {Cited by: 1},
	annote = {RELEVANCE: NULL
},
}


@article{tsunoda_metrics_2019,
	title = {Metrics to predict future modifications and defects based on software requirements specifications},
	volume = {8},
	issn = {22875255},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068556066&doi=10.5573%2fIEIESPC.2019.8.3.210&partnerID=40&md5=ae44dd68bb6171160a99c90647ccf889},
	doi = {10.5573/IEIESPC.2019.8.3.210},
	abstract = {In software development, the quality of the upstream process greatly affects the quality of the downstream process. However, few studies have applied metrics to estimate quality, controlled the quality quantitatively, or have verified the relationship between specifications and software quality. One reason is that specifications are described in natural language, making it difficult to quantitatively evaluate software metrics, such as complexity. Although high-quality software requirements specifications (SRSs) lead to successful implementation, neither a simple quantitative evaluation nor an effective indicator to predict modification-prone SRSs exists. Herein, the effectiveness of two specification metrics is evaluated (the number of pages and the number of previous modifications) in order to predict software defects and future modifications of SRSs. We confirm that both specification quality measured by specification metrics and software quality measured by the number of defects are related. We also reveal that future modifications are correlated with the size of SRSs. © 2019 Institute of Electronics and Information Engineers. All rights reserved.},
	language = {English},
	number = {3},
	journal = {IEIE Transactions on Smart Processing and Computing},
	author = {Tsunoda, Taketo and Washizaki, Hironori and Fukazawa, Yosiaki and Inoue, Sakae and Hanai, Yoshiiku and Kanazawa, Masanobu},
	year = {2019},
	note = {Publisher: Institute of Electronics Engineers of Korea
Type: Article},
	keywords = {Computer software selection and evaluation, Defects, Downstream process, Empirical studies, Forecasting, Formal specification, High-quality software, Image quality, Metrics, Natural languages, Quality control, Quantitative evaluation, Requirements engineering, Software design, Software metrics, Software quality, Software requirements specifications},
	pages = {210 -- 218},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{gnesi_research_2018,
	title = {Research on {NLP} for {RE} at {CNR}-{ISTI}: {A} report},
	volume = {2075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045466444&partnerID=40&md5=0ff3222d0dafa5a0c6b52d93746d247c},
	abstract = {[Team Overview] The Formal Methods \& Tools (FMT) group of CNR-ISTI focuses on the study and development of formal methods and tools to support software development processes. [Past Research] FMT started working on requirements formalisation through natural language processing (NLP) at the end of the nineties. This stream of research evolved into requirements analysis and defect detection by means of NLP, with a focus on ambiguity, and resulted in the development and application of the QuARS tool for requirements analysis. More recently, the group started working on the analysis of requirements elicitation interviews, in which ambiguity in spoken natural language and other communication defects are studied. [Research Plan] In the upcoming years, FMT will devote its effort to the diffusion of a dataset for requirements analysis, to the usage of NLP in product line engineering, and to research in NLP techniques applied to the analysis of interviews. Copyright c 2018 by the paper's authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Gnesi, Stefania and Ferrari, Alessio},
	editor = {F, Dalpiaz and X, Franch and M, Kirikova and J, Ralyte and P, Spoletini and Y, Chisik and A, Ferrari and N, Madhavji and C, Palomares and M, Sabetzadeh and D, van der Linden and K, Schmid and E.B, Charrada and P, Sawyer and P, Forbrig and A, Zamansky},
	year = {2018},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Computer software selection and evaluation, Defects, Natural languages, Requirements engineering, Software design, Requirements elicitation, Defect detection, Development and applications, Formal methods, Product line engineering, Requirements analysis, Research plans, Software development process},
	annote = {Cited by: 0; Conference name: 24th Joint International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, REFSQ-JP 2018; Conference date: 19 March 2018; Conference code: 135277},
	annote = {Cited by: 0; Conference name: 24th Joint International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, REFSQ-JP 2018; Conference date: 19 March 2018; Conference code: 135277},
	annote = {RELEVANCE: MEDIUM
},
}


@article{t_21st_2018,
	title = {21st {Brazilian} {Symposium} on {Formal} {Methods}, {SBMF} 2018},
	volume = {11254 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057283314&partnerID=40&md5=402729e8afe928006bea585b4c2a0c4c},
	abstract = {The proceedings contain 16 papers. The special focus in this conference is on Formal Methods. The topics include: Automatic test case generation for concurrent features from natural language descriptions; A methodology for protocol verification applied to EMV® 1; analysing RoboChart with probabilities; timed scenarios: Consistency, equivalence and optimization; Safe and constructive design with UML components; formal modelling of environment restrictions from natural-language requirements; formal design of cloud computing systems in maude; source code analysis with a temporal extension of first-order logic; a type-directed algorithm to generate well-typed featherweight Java programs; programming language foundations in Agda; Formal verification of n-bit ALU using theorem proving; the Scallina grammar: Towards a scala extraction for Coq; VDM at large: Modelling the EMV® 2nd generation kernel; constraint reusing and k-induction for three-valued bounded model checking.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {T, Massoni and M.R, Mousavi},
	year = {2018},
	note = {ISBN: 978-303003043-8
Publisher: Springer Verlag
Type: Conference review},
	annote = {Cited by: 0; Conference name: 21st Brazilian Symposium on Formal Methods, SBMF 2018; Conference date: 26 November 2018 through 30 November 2018; Conference code: 221099},
	annote = {Cited by: 0; Conference name: 21st Brazilian Symposium on Formal Methods, SBMF 2018; Conference date: 26 November 2018 through 30 November 2018; Conference code: 221099},
	annote = {RELEVANCE: NULL - procedings
},
}


@article{montin_mechanizing_2018,
	title = {Mechanizing the denotational semantics of the clock constraint specification language},
	volume = {11163 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055840090&doi=10.1007%2f978-3-030-00856-7_26&partnerID=40&md5=3af9b3639065b9020fcd0d89a6387d83},
	doi = {10.1007/978-3-030-00856-7_26},
	abstract = {Domain Specific Modelling Languages provide the designers with appropriate languages for the task they must conduct. These dedicated languages play a key role in popular Model Driven Engineering (MDE) approaches. Their semantics are usually written in a semi-formal manner mixing natural language and mathematical notations. The mechanization of these semantics rely on formal specification languages. They are usually conducted in order to assess the correctness of verification and transformation tools for such languages. This contribution illustrates such a mechanization for the Clock Constraint Specification Language (CCSL). This language allows to model the timed concurrency concern in the MARTE UML profile and was designed to be easier to master than temporal logics for the system engineers. Its semantics has been defined in the usual semi-formal manner and implemented in the TimeSquare simulation tool. We discuss the interest of this mechanization and show how it allowed to prove properties about this language and ease the definition of a refinement relation for such models. This work relies on the Agda proof assistant and is presented accordingly. © Springer Nature Switzerland AG 2018.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Montin, Mathieu and Pantel, Marc},
	editor = {E.H, Abdelwahed and L, Bellatreche and M, Golfarelli and D, Méry and C, Ordonez},
	year = {2018},
	note = {ISBN: 978-303000855-0
Publisher: Springer Verlag
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Semantics, Specification languages, Modeling languages, Mathematical notations, Model-driven Engineering, Machinery, CCSL, Clocks, Denotational semantics, Domain-Specific Modelling Languages, DSML, Mechanization, Proof assistant, Transformation tools},
	pages = {385 -- 400},
	annote = {Cited by: 4; Conference name: 8th International Conference on Model and Data Engineering, MEDI 2018; Conference date: 24 October 2018 through 26 October 2018; Conference code: 219809},
	annote = {Cited by: 4; Conference name: 8th International Conference on Model and Data Engineering, MEDI 2018; Conference date: 24 October 2018 through 26 October 2018; Conference code: 219809},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{gopalan_sequence--sequence_2018,
	title = {Sequence-to-{Sequence} {Language} {Grounding} of {Non}-{Markovian} {Task} {Specifications}},
	isbn = {978-0-9923747-4-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071436152&doi=10.15607%2fRSS.2018.XIV.067&partnerID=40&md5=3835730af7a0620e7c74571dfc62694c},
	doi = {10.15607/RSS.2018.XIV.067},
	abstract = {Often times, natural language commands issued to robots not only specify a particular target configuration or goal state but also outline constraints on how the robot goes about its execution. That is, the path taken to achieving some goal state is given equal importance to the goal state itself. One example of this could be instructing a wheeled robot to “go to the living room but avoid the kitchen,” in order to avoid scuffing the floor. This class of behaviors poses a serious obstacle to existing language understanding for robotics approaches that map to either action sequences or goal state representations. Due to the non-Markovian nature of the objective, approaches in the former category must map to potentially unbounded action sequences whereas approaches in the latter category would require folding the entirety of a robot’s trajectory into a (traditionally Markovian) state representation, resulting in an intractable decision-making problem. To resolve this challenge, we use a recently introduced probabilistic variant of Linear Temporal Logic (LTL) as a goal specification language for a Markov Decision Process (MDP). While demonstrating that standard neural sequence-to-sequence learning models can successfully ground language to this semantic representation, we also provide analysis that highlights generalization to novel, unseen logical forms as an open problem for this class of model. We evaluate our system within two simulated robot domains as well as on a physical robot, demonstrating accurate language grounding alongside a significant expansion in the space of interpretable robot behaviors. © 2018, MIT Press Journals. All rights reserved.},
	language = {English},
	booktitle = {Robotics: {Science} and {Systems}},
	publisher = {MIT Press Journals},
	author = {Gopalan, Nakul and Arumugam, Dilip and Wong, Lawson L.S. and Tellex, Stefanie},
	editor = {H, Kress-Gazit and S.S, Srinivasa and T, Howard and N, Atanasov},
	year = {2018},
	note = {ISSN: 2330765X
Type: Conference paper},
	keywords = {Decision making, Natural languages, Semantics, Temporal logic, Action sequences, Behavioral research, Language grounding, Living room, Markov processes, Non-Markovian, Robots, Scuffings, Specification languages, Specifications, State representation, Target configurations, Task specifications, Wheeled robot},
	annote = {Cited by: 26; Conference name: 14th Robotics: Science and Systems, RSS 2018; Conference date: 26 June 2018 through 30 June 2018; Conference code: 275109; All Open Access, Bronze Open Access},
	annote = {Cited by: 31; Conference name: 14th Robotics: Science and Systems, RSS 2018; Conference date: 26 June 2018 through 30 June 2018; Conference code: 275109; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: MEDIUM

They introduce geometric LTL (GLTL)
},
}


@inproceedings{leeuwenberg_temporal_2018,
	title = {Temporal information extraction by predicting relative time-lines},
	isbn = {978-1-948087-84-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075460380&partnerID=40&md5=c7e9603e07c24a80b7665bc549c4ad14},
	abstract = {The current leading paradigm for temporal information extraction from text consists of three phases: (1) recognition of events and temporal expressions, (2) recognition of temporal relations among them, and (3) time-line construction from the temporal relations. In contrast to the first two phases, the last phase, time-line construction, received little attention and is the focus of this work. In this paper, we propose a new method to construct a linear time-line from a set of (extracted) temporal relations. But more importantly, we propose a novel paradigm in which we directly predict start and end-points for events from the text, constituting a time-line without going through the intermediate step of prediction of temporal relations as in earlier work. Within this paradigm, we propose two models that predict in linear complexity, and a new training loss using TimeML-style annotations, yielding promising results. © 2018 Association for Computational Linguistics},
	language = {English},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}, {EMNLP} 2018},
	publisher = {Association for Computational Linguistics},
	author = {Leeuwenberg, Artuur and Moens, Marie-Francine},
	editor = {E, Riloff and D, Chiang and J, Hockenmaier and J, Tsujii},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Forecasting, Temporal logic, Information retrieval, Temporal expressions, Temporal relation, Character recognition, End points, Linear complexity, Linear time, Relative time, Temporal information extraction, Three phasis},
	pages = {1237 -- 1246},
	annote = {Cited by: 25; Conference name: 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018; Conference date: 31 October 2018 through 4 November 2018; Conference code: 158085},
	annote = {Cited by: 28; Conference name: 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018; Conference date: 31 October 2018 through 4 November 2018; Conference code: 158085},
	annote = {RELEVANCE: HIGHFrom TLinks to Time-lines (TL2RTL)
},
}


@inproceedings{qin_voice_2018,
	title = {Voice of the customer oriented new product synthesis over knowledge graphs},
	volume = {1A-2018},
	isbn = {978-0-7918-5172-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056885168&doi=10.1115%2fDETC201885909&partnerID=40&md5=4609180e34b615dc17144397aa4a787f},
	doi = {10.1115/DETC201885909},
	abstract = {The online shopping has been much easier and popular, and meanwhile brings new challenges and opportunities to the field of product design and marketing sale. On one hand, product manufacturers find it challenging to produce new popularly accepted products to meet the customers’ needs; on the other hand, end customers usually feel it difficult to buy ideal goods that they really want, even if navigating a huge amount of commodities. There are indeed a’communication gap’ between the customers and manufacturers. As an effort to partially resolve the issue, this paper proposes a novel product synthesis approach from’voice of the customer’ over product knowledge graphs. Here the voice of customers mainly refer to the buyers’ product reviews from online shopping platforms or blogs, while the product knowledge graph is constructed containing professional hierarchical product knowledge on its properties based on ontological models. Using the technologies of natural language processing, we first extract the customs’ polarities on each specific aspect of a product, which are then transited to design requirements on the product’s design components. Based on the requirement extractions, and the pre-built product knowledge, semantic web and reasoning techniques are utilized to synthesize a novel product that meets more customer needs. Typical case studies on mobile phones from raw online data demonstrate the proposed approach’s performance. Copyright © 2018 ASME.},
	language = {English},
	booktitle = {Proceedings of the {ASME} {Design} {Engineering} {Technical} {Conference}},
	publisher = {American Society of Mechanical Engineers (ASME)},
	author = {Qin, Feiwei and Xu, Hairui and Zhang, Weicheng and Yuan, Lin and Li, Ming and Liu, Yusheng and Liu, Ying and Chen, Yong},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Communication gaps, Electronic commerce, Hierarchical product, Manufacture, Natural language processing systems, Ontological models, Product design, Product manufacturers, Product synthesis, Reasoning techniques, Sales, Voice of customer, Voice of the customer},
	annote = {Cited by: 1; Conference name: ASME 2018 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, IDETC/CIE 2018; Conference date: 26 August 2018 through 29 August 2018; Conference code: 141811},
	annote = {Cited by: 1; Conference name: ASME 2018 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, IDETC/CIE 2018; Conference date: 26 August 2018 through 29 August 2018; Conference code: 141811},
	annote = {RELEVANCE: NULL
},
}


@inproceedings{gordon_trustworthy_2023,
	title = {Trustworthy {Formal} {Natural} {Language} {Specifications}},
	isbn = {979-840070388-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178354766&doi=10.1145%2f3622758.3622890&partnerID=40&md5=849cfe83963b7b7dbc856e9655361d17},
	doi = {10.1145/3622758.3622890},
	abstract = {Interactive proof assistants are computer programs carefully constructed to check a human-designed proof of a mathematical claim with high confidence in the implementation. However, this only validates truth of a formal claim, which may have been mistranslated from a claim made in natural language. This is especially problematic when using proof assistants to formally verify the correctness of software with respect to a natural language specification. The translation from informal to formal remains a challenging, time-consuming process that is difficult to audit for correctness. This paper shows that it is possible to build support for specifications written in expressive subsets of natural language, within existing proof assistants, consistent with the principles used to establish trust and auditability in proof assistants themselves. We implement a means to provide specifications in a modularly extensible formal subset of English, and have them automatically translated into formal claims, entirely within the Lean proof assistant. Our approach is extensible (placing no permanent restrictions on grammatical structure), modular (allowing information about new words to be distributed alongside libraries), and produces proof certificates explaining how each word was interpreted and how the sentence's structure was used to compute the meaning. We apply our prototype to the translation of various English descriptions of formal specifications from a popular textbook into Lean formalizations; all can be translated correctly with a modest lexicon with only minor modifications related to lexicon size. © 2023 ACM.},
	language = {English},
	booktitle = {Onward! 2023 - {Proceedings} of the 2023 {ACM} {SIGPLAN} {International} {Symposium} on {New} {Ideas}, {New} {Paradigms}, and {Reflections} on {Programming} and {Software}, {Co}-located with: {SPLASH} 2023},
	publisher = {Association for Computing Machinery, Inc},
	author = {Gordon, Colin S. and Matskevich, Sergey},
	editor = {T, van der Storm and R, Hirschfeld},
	year = {2023},
	keywords = {Formal specification, Natural languages, Formal languages, Translation (languages), Formalisation, Natural language specifications, Proof assistant, Computational grammars, Categorial grammar, Grammatical structure, High confidence, Interactive proof assistants, Modulars, Sentence structures},
	pages = {50 -- 70},
	annote = {Cited by: 0; Conference name: 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, Onward! 2023, co-located with SPLASH 2023; Conference date: 25 October 2023 through 27 October 2023; Conference code: 193980},
	annote = {Cited by: 0; Conference name: 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, Onward! 2023, co-located with SPLASH 2023; Conference date: 25 October 2023 through 27 October 2023; Conference code: 193980},
	annote = {Type: Conference paper},
}


@inproceedings{fuggitti_nl2ltl_2023,
	title = {{NL2LTL} - {A} {Python} {Package} for {Converting} {Natural} {Language} ({NL}) {Instructions} to {Linear} {Temporal} {Logic} ({LTL}) {Formulas}},
	volume = {37},
	isbn = {978-1-57735-880-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162164607&partnerID=40&md5=e447cb9c369935ba15401c6d54471d1d},
	abstract = {This is a demonstration of our newly released Python package NL2LTL which leverages the latest in natural language understanding (NLU) and large language models (LLMs) to translate natural language instructions to linear temporal logic (LTL) formulas. This allows direct translation to formal languages that a reasoning system can use, while at the same time, allowing the end-user to provide inputs in natural language without having to understand any details of an underlying formal language. The package comes with support for a set of default LTL patterns, corresponding to popular DECLARE templates, but is also fully extensible to new formulas and user inputs. The package is open-source and is free to use for the AI community under the MIT license. Open Source: https://github.com/IBM/nl2ltl. Video Link: https://bit.ly/3dHW5b1. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	language = {English},
	booktitle = {Proceedings of the 37th {AAAI} {Conference} on {Artificial} {Intelligence}, {AAAI} 2023},
	publisher = {AAAI Press},
	author = {Fuggitti, Francesco and Chakraborti, Tathagata},
	editor = {B, Williams and Y, Chen and J, Neville},
	year = {2023},
	keywords = {Natural languages, Temporal logic, Artificial intelligence, Formal languages, Linear temporal logic, Computer circuits, Translation (languages), Temporal logic formula, Language model, Natural language understanding, End-users, High level languages, HTTP, Logic patterns, Open-source, Python, Reasoning system, User input},
	pages = {16428 -- 16430},
	annote = {Cited by: 1},
	annote = {Cited by: 1; Conference name: 37th AAAI Conference on Artificial Intelligence, AAAI 2023; Conference date: 7 February 2023 through 14 February 2023; Conference code: 190493},
	annote = {Cited by: 5; Conference name: 37th AAAI Conference on Artificial Intelligence, AAAI 2023; Conference date: 7 February 2023 through 14 February 2023; Conference code: 190493},
	annote = {Cited by: 5; Conference name: 37th AAAI Conference on Artificial Intelligence, AAAI 2023; Conference date: 7 February 2023 through 14 February 2023; Conference code: 190493},
	annote = {RELEVANCE: HIGH

https://bit.ly/3dHW5b1 -{\textgreater} video demo

it has industry appication

},
	annote = {Type: Conference paper},
}


@article{leong_translating_2024,
	title = {Translating meaning representations to behavioural interface specifications},
	volume = {211},
	issn = {01641212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186536924&doi=10.1016%2fj.jss.2024.112009&partnerID=40&md5=d1108134bcd27f0e08568c19613e5d45},
	doi = {10.1016/j.jss.2024.112009},
	abstract = {Higher-order logic can be used for meaning representation in natural language processing to encode the semantic relationships in text. Alternatively, using a formal specification language for meaning representation is more precise for specifying programs and widely supported by automatic theorem provers, while deductive verification based on higher order logic is less common for mainstream programming languages. This paper addresses the research question of translating higher-order logic meaning representations generated from method-level code comments into a formal specification language that extends first-order logic. Doing so requires resolving possible ambiguities in determining the appropriate semantics for predicates. This is an open challenge in the path toward using natural language processing with formal methods. To address this, the paper proposes an approach and constructs a compiler for translating meaning representations, generated from Java programs with method-level comments, into Java Modelling Language. We evaluate the compiler on a set of representative benchmarks, including programs and specifications from the Java API, by generating Java Modelling Language specifications and statically checking them with a theorem prover. Results show that in 94\% of the cases Java Modelling Language is accurately generated and in 97\% of those cases it can be automatically checked with a state-of-the-art theorem prover. © 2024 The Author(s)},
	language = {English},
	journal = {Journal of Systems and Software},
	author = {Leong, Iat Tou and Barbosa, Raul},
	year = {2024},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Semantics, Specification languages, Modeling languages, Formal verification, Computer circuits, Translation (languages), Formal specification language, Java Modeling Language, Java programming language, Language processing, Software verification, Formal logic, Theorem proving, Compiler, Program translators, Theorem provers, Behavioral interfaces, High order logic, Interface specification, Program compilers},
	annote = {All Open Access, Hybrid Gold Open Access},
	annote = {All Open Access, Hybrid Gold Open Access},
	annote = {All Open Access, Hybrid Gold Open Access},
	annote = {Publisher: Elsevier Inc. Type: Article},
}


@inproceedings{a_overlay_2023,
	title = {{OVERLAY} 2023 - {Short} {Paper} {Proceedings} of the 5th {Workshop} on {Artificial} {Intelligence} and {Formal} {Verification}, {Logic}, {Automata}, and {Synthesis}, hosted by the 22nd {International} {Conference} of the {Italian} {Association} for {Artificial} {Intelligence}, {AIxIA} 2023},
	volume = {3629},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184579648&partnerID=40&md5=00ee64993b08c2823422c4fe9a2b695e},
	abstract = {The proceedings contain 15 papers. The topics discussed include: formal design of cyber-physical systems with learning-enabled components; on challenges and opportunities in the translation of deep neural networks into finite automata; towards machine learning enhanced LTL monitoring; towards large language model architectures for knowledge acquisition and strategy synthesis; ODD-based health monitoring and predictive maintenance of degrading vehicle functionality; a first-order interval temporal logic for adjacent variables temporal data; heuristic minimization modulo theory of modal decision trees class-formulas; revisiting formal verification in VeriSolid: an analysis and enhancements; towards compliance of smart contracts with the European union data act; and tree kernels to support formal methods-based testing of evolving specifications.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	editor = {A, Brunello and A, Gianola and F, Mogavero},
	year = {2023},
	annote = {Conference name: 5th Workshop on Artificial Intelligence and Formal Verification, Logic, Automata, and Synthesis, OVERLAY 2023; Conference date: 7 November 2023; Conference code: 196746},
	annote = {Conference name: 5th Workshop on Artificial Intelligence and Formal Verification, Logic, Automata, and Synthesis, OVERLAY 2023; Conference date: 7 November 2023; Conference code: 196746},
	annote = {ISSN: 16130073 Type: Conference review},
}


@article{belzner_large_2024,
	title = {Large {Language} {Model} {Assisted} {Software} {Engineering}: {Prospects}, {Challenges}, and a {Case} {Study}},
	volume = {14380 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180630873&doi=10.1007%2f978-3-031-46002-9_23&partnerID=40&md5=317aeedef81c776751800c5f7caa7a52},
	doi = {10.1007/978-3-031-46002-9_23},
	abstract = {Large language models such as OpenAI’s GPT and Google’s Bard offer new opportunities for supporting software engineering processes. Large language model assisted software engineering promises to support developers in a conversational way with expert knowledge over the whole software lifecycle. Current applications range from requirements extraction, ambiguity resolution, code and test case generation, code review and translation to verification and repair of software vulnerabilities. In this paper we present our position on the potential benefits and challenges associated with the adoption of language models in software engineering. In particular, we focus on the possible applications of large language models for requirements engineering, system design, code and test generation, code quality reviews, and software process management. We also give a short review of the state-of-the-art of large language model support for software construction and illustrate our position by a case study on the object-oriented development of a simple “search and rescue” scenario. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Belzner, Lenz and Gabor, Thomas and Wirsing, Martin},
	editor = {B, Steffen},
	year = {2024},
	keywords = {Requirements engineering, Software testing, Modeling languages, Verification, Case-studies, Object oriented programming, Application programs, Life cycle, Requirement, Language model, Validation, Design, Computational linguistics, State of the art, GPT, Large language model, Bard, Challenge, LLM-assisted},
	pages = {355 -- 374},
	annote = {Cited by: 2; Conference name: 1st International Conference on Bridging the Gap between AI and Reality, AISoLA 2023; Conference date: 23 October 2023 through 28 October 2023; Conference code: 305199},
	annote = {Cited by: 2; Conference name: 1st International Conference on Bridging the Gap between AI and Reality, AISoLA 2023; Conference date: 23 October 2023 through 28 October 2023; Conference code: 305199},
	annote = {ISBN: 978-303146001-2 Publisher: Springer Science and Business Media Deutschland GmbH Type: Conference paper},
}


@article{b_1st_2024,
	title = {1st {International} {Conference} on {Bridging} the {Gap} between {AI} and {Reality}, {AISoLA} 2023},
	volume = {14380 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180623143&partnerID=40&md5=2b35aeac86d4e269319ddb61b49bb31f},
	abstract = {The proceedings contain 27 papers. The special focus in this conference is on Bridging the Gap between AI and Reality. The topics include: Towards a Formal Account on Negative Latency; Track C1: Safety Verification of Deep Neural Networks (DNNs); formal Verification of a Neural Network Based Prognostics System for Aircraft Equipment; the Inverse Problem for Neural Networks; continuous Engineering for Trustworthy Learning-Enabled Autonomous Systems; benchmarks: Semantic Segmentation Neural Network Verification and Objection Detection Neural Network Verification in Perceptions Tasks of Autonomous Driving; benchmark: Neural Network Malware Classification; benchmark: Remaining Useful Life Predictor for Aircraft Equipment; benchmark: Object Detection for Maritime Search and Rescue; Welcome Remarks from AISoLA 2023/Track C2 Chairs; benchmark: Formal Verification of Semantic Segmentation Neural Networks; empirical Analysis of Benchmark Generation for the Verification of Neural Network Image Classifiers; AI Assisted Programming: (AISoLA 2023 Track Introduction); large Language Model Assisted Software Engineering: Prospects, Challenges, and a Case Study; ChatGPT in the Loop: A Natural Language Extension for Domain-Specific Modeling Languages; what Can Large Language Models Do for Theorem Proving and Formal Methods?; integrating Distributed Component-Based Systems Through Deep Reinforcement Learning; Safe AI in Autonomous Vehicles: Track at AISoLA 2023; shielded Reinforcement Learning for Hybrid Systems; what, Indeed, is an Achievable Provable Guarantee for Learning-Enabled Safety-Critical Systems; deepAbstraction++: Enhancing Test Prioritization Performance via Combined Parameterized Boxes; shielded Learning for Resilience and Performance Based on Statistical Model Checking in Simulink; Formal XAI via Syntax-Guided Synthesis; Differential Safety Testing of Deep RL Agents Enabled by Automata Learning; gRoMA: A Tool for Measuring the Global Robustness of Deep Neural Networks.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	editor = {B, Steffen},
	year = {2024},
	annote = {Cited by: 0; Conference name: 1st International Conference on Bridging the Gap between AI and Reality, AISoLA 2023; Conference date: 23 October 2023 through 28 October 2023; Conference code: 305199},
	annote = {Cited by: 0; Conference name: 1st International Conference on Bridging the Gap between AI and Reality, AISoLA 2023; Conference date: 23 October 2023 through 28 October 2023; Conference code: 305199},
	annote = {ISBN: 978-303146001-2 Publisher: Springer Science and Business Media Deutschland GmbH Type: Conference review},
}


@article{dong_neuron_2024,
	title = {Neuron importance based verification of neural networks via divide and conquer},
	volume = {565},
	issn = {09252312},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175817337&doi=10.1016%2fj.neucom.2023.126995&partnerID=40&md5=331edc03fd727a5494d1bf5ac9733d51},
	doi = {10.1016/j.neucom.2023.126995},
	abstract = {Neural networks are widely used in various applications such as image classification, speech recognition and natural language processing. As intelligent systems often rely on neural networks to make critical decisions, it is crucial to ensure that the behavior of a neural network is trustworthy. Along with the increase in the scale and complexity of neural networks, it becomes a challenging problem to verify their safety, since the large-scale state space may make the verification of safety properties infeasible or unsolvable. In order to achieve efficient safety verification of neural networks, this paper proposes a divide-and-conquer verification method based on neuron importance analysis. The method converts the safety constraints to be verified into an optimization problem composed of output neurons, and recursively measures the influence of neurons in the network on the final objective function to calculate their importance. The neurons with the greatest importance are split to refine the constraints, so that the original verification problem is transformed into a set of sub-problems for solution. The method is implemented as a tool named NIAVerify, which is evaluated through experiments of property verification on ReLU-based fully-connected benchmark networks trained on two classic datasets. Experimental results show that NIAVerify can achieve significant state space reduction and the verification efficiency is 44.80\% higher than the existing verification method. © 2023 Elsevier B.V.},
	language = {English},
	journal = {Neurocomputing},
	author = {Dong, Yansong and Liu, Yuehao and Zhao, Liang and Tian, Cong and Duan, Zhenhua},
	year = {2024},
	keywords = {Natural language processing systems, Natural languages, Formal verification, Learning algorithms, Intelligent systems, Language processing, Verification method, Neural-networks, Neural networks, Speech recognition, Neurons, human, article, Large-scales, Divide-and-conquer, Images classification, Model abstraction, nerve cell, nerve cell network, Neuron importance, Speech recognition languages},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Publisher: Elsevier B.V. Type: Article},
}


@inproceedings{nelaturu_natural_2023,
	title = {Natural {Language}-{Based} {Model}-{Checking} {Framework} for {Move} {Smart} {Contracts}},
	isbn = {979-835038223-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180370431&doi=10.1109%2fSDS59856.2023.10328964&partnerID=40&md5=b40b693285ff19c1eb87adff2814030e},
	doi = {10.1109/SDS59856.2023.10328964},
	abstract = {Significant efforts have been dedicated to employing model-checking as a formal verification approach in the context of smart contracts. The utilization of these tools necessitates an in-depth knowledge on the part of the developer regarding both the programming language and the implementation of model-checking techniques. To provide accessibility to developers with basic language proficiency, we present a technique for developing a conversational application framework that can be seamlessly linked with any model-checking tool for the purpose of creating a smart contract. This architecture offers a robust and effective approach to the development of safe and dependable smart contracts. The utilization of natural language processing techniques in conjunction with neural networks is employed for this objective. Using this methodology, a prototype implementation for Move smart contracts has been created and is used with the VeriMove model-checking tool. Using the offered graphical user interface, we were able to successfully build, compile and test Move smart contracts across four different classes of smart contracts. This strategy effectively decreases the amount of time and effort needed for manual coding and debugging. In addition, the use of the VeriMove model-checking tool guarantees that the smart contracts produced are devoid of any potential vulnerabilities and flaws. © 2023 IEEE.},
	language = {English},
	booktitle = {2023 10th {International} {Conference} on {Software} {Defined} {Systems}, {SDS} 2023},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Nelaturu, Keerthi and Keilty, Eric and Veneris, Andreas},
	editor = {M, Quwaider and Y, Jararweh and E, Benkhelifa and J, Lloret Mauri},
	year = {2023},
	keywords = {Natural language processing systems, Natural languages, Model checking, Models checking, Neural networks, Sentiment analysis, Predictive models, Graphical user interfaces, smart contracts, Prototypes, NLP, Smart contract, model-checking, Application frameworks, Effective approaches, Manuals, Model-checking techniques, Model checking tools, In-depth knowledge, Language proficiency, Move, Robust approaches, Smart contracts, move, Oral communication},
	pages = {89 -- 94},
	annote = {Cited by: 0; Conference name: 10th International Conference on Software Defined Systems, SDS 2023; Conference date: 23 October 2023 through 25 October 2023; Conference code: 195047},
	annote = {Cited by: 0; Conference name: 10th International Conference on Software Defined Systems, SDS 2023; Conference date: 23 October 2023 through 25 October 2023; Conference code: 195047},
	annote = {Type: Conference paper},
}


@inproceedings{giorgini_towards_2023,
	title = {Towards {Large} {Language} {Model} {Architectures} for {Knowledge} {Acquisition} and {Strategy} {Synthesis}},
	volume = {3629},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184520918&partnerID=40&md5=bc31a8a712c0d0ad8c029992bc0750d5},
	abstract = {To address the bottlenecks of knowledge acquisition and strategy synthesis, in the development of autonomous AI agents capable of reasoning and planning about dynamic environments, we propose an architecture that combines large language model (LLM) functionalities with formal verification modules. Concerning knowledge acquisition, we focus on the problem of learning description logic concepts to separate data instances, whereas, in a process mining setting, we propose to leverage LLMs to extract linear temporal logic specifications from event logs. Finally, in a strategy synthesis context, we illustrate how LLMs can be employed to address realisability problems in linear temporal logic on finite traces. © 2023 CEUR-WS. All rights reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Giorgini, Paolo and Mazzullo, Andrea and Robol, Marco and Roveri, Marco},
	editor = {A, Brunello and A, Gianola and F, Mogavero},
	year = {2023},
	keywords = {Process mining, Temporal logic, Formal languages, Linear temporal logic, Computer circuits, Language model, Learning systems, Linear temporal logic specifications, Knowledge management, Dynamic environments, Knowledge acquisition, Computational linguistics, Data description, Description logic, Large language model, Learning from examples, Modeling architecture, Strategy synthesis},
	pages = {61 -- 66},
	annote = {Cited by: 0; Conference name: 5th Workshop on Artificial Intelligence and Formal Verification, Logic, Automata, and Synthesis, OVERLAY 2023; Conference date: 7 November 2023; Conference code: 196746},
	annote = {Cited by: 0; Conference name: 5th Workshop on Artificial Intelligence and Formal Verification, Logic, Automata, and Synthesis, OVERLAY 2023; Conference date: 7 November 2023; Conference code: 196746},
	annote = {ISSN: 16130073 Type: Conference paper},
}


@inproceedings{altiero_tree_2023,
	title = {Tree {Kernels} to {Support} {Formal} {Methods}-{Based} {Testing} of {Evolving} {Specifications}},
	volume = {3629},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184519495&partnerID=40&md5=12fde308a5e5d4a91a4a676a3b1339e1},
	abstract = {Tree Kernels (TKs) are a family of functions measuring the similarity between two tree-structured objects. TKs have been successfully employed in several fields of AI, including Natural Language Processing and Software Engineering (e.g.: software testing and code clone detection). A recent research line has proved that the information about source code changes captured by TKs can fruitfully be applied to select and prioritize test cases in Regression Testing, a crucial activity in modern software development processes. We suggest that a similar approach can be adopted also in the field of formal specification of safety-critical systems, whenever a structured language (e.g., a variant of Statecharts, hierarchical automata or the Promela description language) is adopted for the specification task and test cases are (semi-)automatically generated from the specifications. In evolutionary approaches to specification development, the information on changes between two consecutive versions of the specification can aid in focusing the activity of test generation and their execution on the specification modules that were mainly affected by the specification changes. © 2023 CEUR-WS. All rights reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Altiero, Francesco and Corazza, Anna and Martino, Sergio Di and Peron, Adriano and Lucio Starace, Luigi Libero},
	editor = {A, Brunello and A, Gianola and F, Mogavero},
	year = {2023},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Software design, Software testing, Formal verification, Safety engineering, Language processing, Hierarchical systems, Test case, Software testings, Change-driven testing, Code clone detection, Recent researches, Software codes, Tree kernels, Tree-structured},
	pages = {31 -- 36},
	annote = {Cited by: 0; Conference name: 5th Workshop on Artificial Intelligence and Formal Verification, Logic, Automata, and Synthesis, OVERLAY 2023; Conference date: 7 November 2023; Conference code: 196746},
	annote = {Cited by: 0; Conference name: 5th Workshop on Artificial Intelligence and Formal Verification, Logic, Automata, and Synthesis, OVERLAY 2023; Conference date: 7 November 2023; Conference code: 196746},
	annote = {ISSN: 16130073 Type: Conference paper},
}


@inproceedings{xia_plastic_2023,
	title = {The {Plastic} {Surgery} {Hypothesis} in the {Era} of {Large} {Language} {Models}},
	isbn = {979-835032996-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179011197&doi=10.1109%2fASE56229.2023.00047&partnerID=40&md5=2fd8c88596d302ac441c4842b8f35541},
	doi = {10.1109/ASE56229.2023.00047},
	abstract = {Automated Program Repair (APR) aspires to automatically generate patches for an input buggy program. Traditional APR tools typically focus on specific bug types and fixes through the use of templates, heuristics, and formal specifications. However, these techniques are limited in terms of the bug types and patch variety they can produce. As such, researchers have designed various learning-based APR tools with recent work focused on directly using Large Language Models (LLMs) for APR. While LLM-based APR tools are able to achieve state-of-the-art performance on many repair datasets, the LLMs used for direct repair are not fully aware of the project-specific information such as unique variable or method names. The plastic surgery hypothesis is a well-known insight for APR, which states that the code ingredients to fix the bug usually already exist within the same project. Traditional APR tools have largely leveraged the plastic surgery hypothesis by designing manual or heuristic-based approaches to exploit such existing code ingredients. However, as recent APR research starts focusing on LLM-based approaches, the plastic surgery hypothesis has been largely ignored. In this paper, we ask the following question: How useful is the plastic surgery hypothesis in the era of LLMs? Interestingly, LLM-based APR presents a unique opportunity to fully automate the plastic surgery hypothesis via fine-tuning (training on the buggy project) and prompting (directly providing valuable code ingredients as hints to the LLM). To this end, we propose FitRepair, which combines the direct usage of LLMs with two domain-specific fine-tuning strategies and one prompting strategy (via information retrieval and static analysis) for more powerful APR. While traditional APR techniques require intensive manual efforts in both generating patches based on the plastic surgery hypothesis and guaranteeing patch validity, our approach is fully automated and general. Moreover, while it is very challenging to manually design heuristics/patterns for effectively leveraging the hypothesis, due to the power of LLMs in code vectorization/understanding, even partial/imprecise project-specific information can still guide LLMs in generating correct patches! Our experiments on the widely studied Defects4j 1.2 and 2.0 datasets show that FitRepair fixes 89 and 44 bugs (substantially outperforming baseline techniques by 15 and 8), respectively, demonstrating a promising future of the plastic surgery hypothesis in the era of LLMs. © 2023 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2023 38th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering}, {ASE} 2023},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Xia, Chunqiu Steven and Ding, Yifeng and Zhang, Lingming},
	year = {2023},
	keywords = {Language model, Surgery, Computational linguistics, Model-based OPC, Repair, Domain specific, Model based approach, Fine tuning, Plastic surgery, Repair tools, Specific information, State-of-the-art performance, Static analysis, Two domains},
	pages = {522 -- 534},
	annote = {Cited by: 0; Conference name: 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023; Conference date: 11 September 2023 through 15 September 2023; Conference code: 194295},
	annote = {Cited by: 0; Conference name: 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023; Conference date: 11 September 2023 through 15 September 2023; Conference code: 194295},
	annote = {Type: Conference paper},
}


@inproceedings{noauthor_proceedings_2023,
	title = {Proceedings - 2023 {IEEE} 34th {International} {Symposium} on {Software} {Reliability} {Engineering} {Workshop}, {ISSREW} 2023},
	isbn = {979-835031956-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178195708&partnerID=40&md5=1b3a9542d344f2a493eace6bcf730b32},
	abstract = {The proceedings contain 45 papers. The topics discussed include: towards human-centric software complexity metrics: a neuroscience-based approach; on the efficacy of smart contract analysis tools; poisoning programs by un-repairing code: security concerns of ai-generated code; toward an efficient end-to-end test suite execution; towards predicting source code changes based on natural language processing models: an empirical evaluation; bridging the gap between system architecture and software design using model transformation; semantics-based, automated preparation of exploratory data analysis for complex systems; enhancing white-box search-based testing of RESTful APIs; and a fault injection and formal verification framework based on UML sequence diagrams.},
	language = {English},
	booktitle = {Proceedings - 2023 {IEEE} 34th {International} {Symposium} on {Software} {Reliability} {Engineering} {Workshop}, {ISSREW} 2023},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	year = {2023},
	annote = {Cited by: 0; Conference name: 34th IEEE International Symposium on Software Reliability Engineering Workshop, ISSREW 2023; Conference date: 9 October 2023 through 12 October 2023; Conference code: 194254},
	annote = {Cited by: 0; Conference name: 34th IEEE International Symposium on Software Reliability Engineering Workshop, ISSREW 2023; Conference date: 9 October 2023 through 12 October 2023; Conference code: 194254},
	annote = {Type: Conference review},
}


@inproceedings{bai_ssgcn_2023,
	title = {{SSGCN}: a graph convolutional neural network model based on syntactic structure and similarity features for relation extraction in shipbuilding industry},
	volume = {12943},
	isbn = {978-1-5106-7192-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180152539&doi=10.1117%2f12.3014256&partnerID=40&md5=b656bf486ea0980ee5619e38befa5d08},
	doi = {10.1117/12.3014256},
	abstract = {The construction of the standard knowledge graph is to realize the reorganization of the internal knowledge of the traditional standard texts and achieve the purpose of innovating knowledge storage and the practice of knowledge supply. Technical requirement extraction is a typical relation extraction task in the construction process of a standard knowledge graph. However, the existing relation extraction models can not achieve ideal performance due to standard texts' unique organizational forms and special writing characteristics. Therefore, This paper proposes a Graph Convolutional Neural Network model based on Syntactic structure and Similarity features (SSGCN), integrating expert knowledge in syntactic pruning, dynamically interfering with the weight matrix by the pruning strategy based on attention, and making full use of supervised relation label semantic similarity features. The experiment in this paper compares the large language models (LLMs) such as GPT-3, and our model achieves better experimental performance than other relation extraction models on specialized datasets in the field, providing a related solution for standard technical requirement extraction tasks. © 2023 SPIE.},
	language = {English},
	booktitle = {Proceedings of {SPIE} - {The} {International} {Society} for {Optical} {Engineering}},
	publisher = {SPIE},
	author = {Bai, Chuanyang and Zheng, Jiaming and Hu, Jiexin and Zhou, Linna and Chen, Jiabin and Yang, Hongjie},
	editor = {Y, Yue},
	year = {2023},
	keywords = {Extraction, Semantics, Syntactics, Large dataset, Knowledge graph, Convolution, Convolutional neural networks, Graph neural networks, Graph convolutional neural network, Model-based OPC, Convolutional neural network, Knowledge graphs, Llms, Neural network model, Neural network models, Relation extraction, Standard knowledge graph, Syntactic pruning, Syntactic similarities},
	annote = {Cited by: 0; Conference name: 2023 International Workshop on Signal Processing and Machine Learning, WSPML 2023; Conference date: 22 September 2023 through 24 September 2023; Conference code: 195236},
	annote = {Cited by: 0; Conference name: 2023 International Workshop on Signal Processing and Machine Learning, WSPML 2023; Conference date: 22 September 2023 through 24 September 2023; Conference code: 195236},
	annote = {ISSN: 0277786X Type: Conference paper},
}


@article{wan_semantic_2024,
	title = {Semantic {Consistency} and {Correctness} {Verification} of {Digital} {Traffic} {Rules}},
	issn = {20958099},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184618357&doi=10.1016%2fj.eng.2023.04.016&partnerID=40&md5=be85d90243d8b2c254b7d5991d76abfa},
	doi = {10.1016/j.eng.2023.04.016},
	abstract = {The consensus of the automotive industry and traffic management authorities is that autonomous vehicles must follow the same traffic laws as human drivers. Using formal or digital methods, natural language traffic rules can be translated into machine language and used by autonomous vehicles. In this paper, a translation flow is designed. Beyond the translation, a deeper examination is required, because the semantics of natural languages are rich and complex, and frequently contain hidden assumptions. The issue of how to ensure that digital rules are accurate and consistent with the original intent of the traffic rules they represent is both significant and unresolved. In response, we propose a method of formal verification that combines equivalence verification with model checking. Reasonable and reassuring digital traffic rules can be obtained by utilizing the proposed traffic rule digitization flow and verification method. In addition, we offer a number of simulation applications that employ digital traffic rules to assess vehicle violations. The experimental findings indicate that our digital rules utilizing metric temporal logic (MTL) can be easily incorporated into simulation platforms and autonomous driving systems (ADS). © 2023},
	language = {English},
	journal = {Engineering},
	author = {Wan, Lei and Wang, Changjun and Luo, Daxin and Liu, Hang and Ma, Sha and Hu, Weichao},
	year = {2024},
	keywords = {Semantics, Model checking, Formal verification, Translation (languages), Formalisation, Accident prevention, Autonomous vehicles, Traffic laws, Traffic rules, Simulation platform, Consistency verifications, Autonomous Vehicles, Autonomous driving, Automotive industry, Correctness verifications, Digitisation, Semantic consistency, Traffic management},
	annote = {All Open Access, Gold Open Access},
	annote = {All Open Access, Gold Open Access},
	annote = {All Open Access, Gold Open Access},
	annote = {Publisher: Elsevier Ltd Type: Article},
}


@inproceedings{bharadwaj_transforming_2023,
	title = {Transforming {Natural} {Language} {Requirements} into {Petri} {Nets} - {A} {Semi}-{Automated} {Approach}},
	volume = {2023-June},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174415416&partnerID=40&md5=88c458332485b32dd085cd36be25b116},
	abstract = {Software requirements are mostly specified in natural language (say English) and may contain errors. To prevent such errors, the requirements need to be transformed using formal methods, as analysis, identification and subsequent removal of errors are easier. But expression of requirements using formal methods is laborious. We propose a simple, semi-automated methodology that transforms natural language requirements into Petri nets. Petri nets allow better modeling and analysis of the requirements and hence have been chosen as the target method. A practical example of Automated Teller Machine has been used to demonstrate our approach. A tool NLTOPNGEN to implement this approach has been developed. © Grenze Scientific Society, 2023.},
	language = {English},
	booktitle = {14th {International} {Conference} on {Advances} in {Computing}, {Control}, and {Telecommunication} {Technologies}, {ACT} 2023},
	publisher = {Grenze Scientific Society},
	author = {Bharadwaj, A. Keshav and Agrawal, V.K. and Jayashree, R.},
	editor = {J, Stephen and P, Sharma and Y, Chaba and K.U, Abraham and P.K, Anooj and N, Mohammad and Universiti Kebangsaan Malaysia, 43600 UKM, Bangi Selangor and G, Thomas and S, Srikiran},
	year = {2023},
	keywords = {Petri nets, Natural language processing systems, Formal specification, Natural languages, Natural language requirements, Software requirements, Modeling languages, Automation, Requirements specifications, Language processing, Natural language processing, Errors, Modeling, Automated approach, Simple++, Consistency},
	pages = {2176 -- 2188},
	annote = {Cited by: 0; Conference name: 14th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2023; Conference date: 15 June 2023 through 16 June 2023; Conference code: 192282},
	annote = {Cited by: 0; Conference name: 14th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2023; Conference date: 15 June 2023 through 16 June 2023; Conference code: 192282},
	annote = {Type: Conference paper},
}


@inproceedings{sun_textverifier_2023,
	title = {{TextVerifier}: {Robustness} {Verification} for {Textual} {Classifiers} with {Certifiable} {Guarantees}},
	isbn = {978-1-959429-62-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175481974&partnerID=40&md5=f7f42845004e4e89a3897144d3962b46},
	abstract = {When textual classifiers are deployed in safety-critical workflows, they must withstand the onslaught of AI-enabled model confusion caused by adversarial examples with minor alterations. In this paper, the main objective is to provide a formal verification framework, called TextVerifier, with certifiable guarantees on deep neural networks in natural language processing against word-level alteration attacks. We aim to provide an approximation of the maximal safe radius by deriving provable bounds both mathematically and automatically, where a minimum word-level L0 distance is quantified as a guarantee for the classification invariance of victim models. Here, we illustrate three strengths of our strategy: i) certifiable guarantee: effective verification with convergence to ensure approximation of maximal safe radius with tight bounds ultimately; ii) high-efficiency: it yields an efficient speed edge by a novel parallelization strategy that can process a set of candidate texts simultaneously on GPUs; and iii) reliable anytime estimation: the verification can return intermediate bounds, and robustness estimates that are gradually, but strictly, improved as the computation proceeds. Furthermore, experiments are conducted on text classification on four datasets over three victim models to demonstrate the validity of tightening bounds. Our tool TextVerifier is available at https://github.com/TrustAI/TextVerifer. © 2023 Association for Computational Linguistics.},
	language = {English},
	booktitle = {Proceedings of the {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics (ACL)},
	author = {Sun, Siqi and Ruan, Wenjie},
	year = {2023},
	keywords = {Natural language processing systems, Natural languages, Verification framework, Formal verification, Safety engineering, Classification (of information), Text classification, Text processing, Language processing, Deep neural networks, Work-flows, Parallelization strategies, Computational linguistics, Program processors, Higher efficiency, Tight bound, Word level},
	pages = {4362 -- 4380},
	annote = {Cited by: 0; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867},
	annote = {Cited by: 0; Conference name: 61st Annual Meeting of the Association for Computational Linguistics, ACL 2023; Conference date: 9 July 2023 through 14 July 2023; Conference code: 192867},
	annote = {ISSN: 0736587X Type: Conference paper},
}


@inproceedings{vt_splash_2023,
	title = {{SPLASH} {Companion} 2023 - {Companion} {Proceedings} of the 2023 {ACM} {SIGPLAN} {International} {Conference} on {Systems}, {Programming}, {Languages}, and {Applications}: {Software} for {Humanity}},
	isbn = {979-840070384-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178327583&partnerID=40&md5=4f788049cee9788937a949d25f1f9f1d},
	abstract = {The proceedings contain 26 papers. The topics discussed include: remote just-in-time compilation for dynamic languages; scaling up program synthesis to efficient algorithms; large language models for automated program repair; transforming ideas into code: visual sketching for ml development; semantic versioning for python programs; reusing single-language analyses for static analysis of multi-language programs; a pragmatic approach to syntax repair; partial gradual dependent type theory; synthesizing recursive programs through dataflow constraints; modular educational languages; historiographer: strongly-consistent distributed reactive programming with minimal locking; clearing the trail: motivations for maintenance work in open source; towards the formal verification of Wigderson’s algorithm; and involving users in design of a widely used language: a case of ECMAScript (JavaScript) standardization.},
	language = {English},
	booktitle = {{SPLASH} {Companion} 2023 - {Companion} {Proceedings} of the 2023 {ACM} {SIGPLAN} {International} {Conference} on {Systems}, {Programming}, {Languages}, and {Applications}: {Software} for {Humanity}},
	publisher = {Association for Computing Machinery, Inc},
	editor = {V.T, Vasconcelos},
	year = {2023},
	annote = {Cited by: 0; Conference name: 38th ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity, SPLASH 2023; Conference date: 22 October 2023 through 27 October 2023; Conference code: 193976},
	annote = {Cited by: 0; Conference name: 38th ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity, SPLASH 2023; Conference date: 22 October 2023 through 27 October 2023; Conference code: 193976},
	annote = {Type: Conference review},
}


@inproceedings{elbarbari_ltlf-based_2021,
	title = {{LTLf}-based {Reward} {Shaping} for {Reinforcement} {Learning}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132965901&partnerID=40&md5=69ab5cf4b58f38988a5e4540547a8d63},
	abstract = {Reinforcement Learning usually does not scale up well to large problems. It typically takes a Reinforcement Learning agent many trials until it can reach a satisfying policy. A main contributing factor to this problem is the fact that Reinforcement Learning is often used for learning exclusively by means of trial and error. There has been much work that addresses incorporating domain knowledge in Reinforcement Learning to allow more efficient learning. Reward shaping is a well-established method to incorporate domain knowledge in Reinforcement Learning by providing the learning agent with a supplementary reward. In this work we propose a novel methodology that automatically generates reward shaping functions from user-provided Linear Temporal Logic formulas. Linear Temporal Logic in our work serves as a rich, yet compact, language that allows the user to express the domain knowledge with minimum effort. Linear Temporal Logic is also rather easy to be expressed in natural language which makes it easier for non-expert users. We use the flag collection domain to demonstrate empirically the increase in both the convergence speed and the quality of the learned policy despite the minimum domain knowledge provided. © 2021 Association for Computing Machinery.},
	language = {English},
	booktitle = {{ALA} 2021 - {Adaptive} and {Learning} {Agents} {Workshop} at {AAMAS} 2021},
	publisher = {AAMAS},
	author = {Elbarbari, Mahmoud and Efthymiadis, Kyriakos and Vanderborght, Bram and Nowé, Ann},
	year = {2021},
	keywords = {Temporal logic, Linear temporal logic, Computer circuits, Reinforcement learning, Reinforcement learnings, Domain knowledge, Reinforcement learning agent, Finite traces, Domain Knowledge, Contributing factor, Large problems, Linear temporal logic on finite trace, Reward shaping, Scale-up},
	annote = {Cited by: 1; Conference name: Adaptive and Learning Agents Workshop, ALA 2021 at AAMAS 2021; Conference date: 3 May 2021 through 4 May 2021; Conference code: 192414},
	annote = {Cited by: 1; Conference name: Adaptive and Learning Agents Workshop, ALA 2021 at AAMAS 2021; Conference date: 3 May 2021 through 4 May 2021; Conference code: 192414},
	annote = {Type: Conference paper},
}


@inproceedings{osama_srcm_2021,
	title = {{SRCM}: {A} semi formal requirements representation model enabling system visualisation and quality checking},
	isbn = {978-989-758-487-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102993010&partnerID=40&md5=685b81f6c5ade4beaa8ac5f08ebed484},
	abstract = {Requirements engineering is pivotal to the successful development of any given system. The core artifact for such phase is the requirements specification document. Requirements can be specified in informal, semi-formal, and formal notations. The majority of the requirements across many fields and domains are written natural language. However, natural language is inherently ambiguous and imprecise and the requirements cannot be automatically validated. Formal notations on the other hand enable automated testing and validation but is only comprehensible by experts and requires rewriting the requirements. Semi-formal notations strikes a good balance between comprehension and checking for several systems. However, the majority of the existing representation models mandates the requirements to be (re)written to adhere to certain templates. They also do not support automated checking. In this paper, we present SRCM –a semi-formal requirements representation model based on a comprehensive requirements capturing model (RCM) that does not enforce much limitations on how the requirements can be written. We also provide an automated approach to construct SRCM from RCM. In addition to providing a unified visualisation of the system entities and relations between the requirements key components, SRCM also enables automated quality checking on the requirements. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	language = {English},
	booktitle = {{MODELSWARD} 2021 - {Proceedings} of the 9th {International} {Conference} on {Model}-{Driven} {Engineering} and {Software} {Development}},
	publisher = {SciTePress},
	author = {Osama, Mohamed and Zaki-Ismail, Aya and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {S, Hammoudi and L.F, Pires and E, Seidewitz and R, Soley},
	year = {2021},
	keywords = {Visualization, Natural languages, Software design, Automation, Requirements specifications, Formal notations, Representation model, Semi-formal notations, Automated approach, Automated testing},
	pages = {278 -- 285},
	annote = {Cited by: 0; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 300849; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 0; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 300849; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 3; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 167487},
	annote = {Cited by: 3; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 167487},
	annote = {Cited by: 3; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 167487},
	annote = {ISSN: 21844348 Type: Conference paper},
	annote = {RELEVANCE: LOW
},
	annote = {Type: Conference paper},
}


@inproceedings{e_9th_2021,
	title = {9th {International} {Conference} on {Model}-{Driven} {Engineering} and {Software} {Development}, {MODELSWARD} 2021},
	isbn = {978-989-758-487-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173911600&partnerID=40&md5=f8f8582466764a91e8c2def857f73c68},
	abstract = {The proceedings contain 38 papers. The special focus in this conference is on International Conference on Model-Driven Engineering and Software Development. The topics include: SeGa4Biz: Model-Driven Framework for Developing Serious Games for Business Processes; transpLanMeta: A Metamodel for TranspLan Modeling Language; addressing Industrial Needs with the Fulib Modeling Library; An MDE Method for Improving Deep Learning Dataset Requirements Engineering using Alloy and UML; multi-view-Model Risk Assessment in Cyber-Physical Production Systems Engineering; reusing (Safety-oriented) Compliance Artifacts while Recertifying; Process Digitalization using Blockchain: EU Parliament Elections Case Study; textual Approach for Designing Database Conceptual Models: A Focus Group; performance Aspects of Correctness-oriented Synthesis Flows; improving Digital Twin Experience Reports; towards a Model Transformation based Code Renovation Tool; from Quantities in Software Models to Implementation; transforming Data Flow Diagrams for Privacy Compliance; Direct Model-checking of SysML Models; interfacing Digital and Analog Models for Fast Simulation and Virtual Prototyping; a Modeling Workbench for the Development of Situation-specific Test Co-migration Methods; integrating Kahn Process Networks as a Model of Computation in an Extendable Model-based Design Framework; HERO vs. Zombie: Identifying Zombie Guests in a Virtual Machine Environment; Empirical and Theoretical Evaluation of USE and OCLE Tools; characterization of Software Design and Collaborative Modeling in Open Source Projects; A Model-driven Implementation of PSCS Specification for C++; Model-based Analysis Support for Dependable Complex Systems in CHESS; RCM: Requirement Capturing Model for Automated Requirements Formalisation; RCM-Extractor: Automated Extraction of a Semi Formal Representation Model from Natural Language Requirements; a Framework for Projectional Multi-variant Model Editors.},
	language = {English},
	booktitle = {International {Conference} on {Model}-{Driven} {Engineering} and {Software} {Development}},
	publisher = {Science and Technology Publications, Lda},
	editor = {E, Seidewitz and L, Ferreira Pires and S, Hammoudi},
	year = {2021},
	annote = {Cited by: 0; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 300849},
	annote = {Cited by: 0; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 300849},
	annote = {ISSN: 21844348 Type: Conference review},
}


@article{mohanan_natural_2018,
	title = {Natural {Language} {Processing} {Approach} for {UML} {Class} {Model} {Generation} from {Software} {Requirement} {Specifications} via {SBVR}},
	volume = {27},
	issn = {02182130},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054319545&doi=10.1142%2fS0218213018500276&partnerID=40&md5=e2364ba79be26c866389cbd7a8ab22e9},
	doi = {10.1142/S0218213018500276},
	abstract = {The user's software requirements are represented in natural language or speech language such as English. Translating these requirements into the object oriented models is a tough process for the designers. This paper proposes a neoteric approach to generate Unified Modeling Language (UML) class models instantly from software requirement specifications (SRS). Here we make use of the Open Natural language processing tool (OpenNLP) for lexical analysis and to generate the necessary parts of speech (POS) tags from these requirement specifications. Then Semantics of Business Vocabulary and Rules (SBVR) standard is used to extract the object oriented elements from the natural language (NL) processed SRS. From this, we generate the UML class models. Our prototype tool can generate accurate models in less time. This automated system for designing object oriented models from SRS reduces the cost and budget for both the designers and the users. © 2018 World Scientific Publishing Company.},
	language = {English},
	number = {6},
	journal = {International Journal on Artificial Intelligence Tools},
	author = {Mohanan, Murali and Samuel, Philip},
	year = {2018},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Semantics, Software requirements, Unified Modeling Language, Software requirement specification, Automation, Object oriented programming, Syntactics, Requirement analysis, Automated systems, Requirement specification, Budget control, Business vocabulary, Object oriented model, UML class diagrams},
	annote = {Cited by: 5},
	annote = {Cited by: 5},
	annote = {Publisher: World Scientific Publishing Co. Pte Ltd Type: Retracted},
}


@inproceedings{spaulding_darpa_2020,
	title = {The {DARPA} {Wikidata} {Overlay}: {Wikidata} as an ontology for natural language processing},
	isbn = {978-1-959429-66-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184817758&partnerID=40&md5=cd86c3ab3bd9a2a68d6c25d609bc1c12},
	abstract = {With 102,530,067 items currently in its crowd-sourced knowledge base, Wikidata provides NLP practitioners a unique and powerful resource for inference and reasoning over real-world entities. However, because Wikidata is very entity focused, events and actions are often labeled with eventive nouns (e.g., the process of diagnosing a person’s illness is labeled “diagnosis”), and the typical participants in an event are not described or linked to that event concept (e.g., the medical professional or patient). Motivated by a need for an adaptable, comprehensive, domain-flexible ontology for information extraction, including identifying the roles entities are playing in an event, we present a curated subset of Wikidata in which events have been enriched with PropBank roles. To enable richer narrative understanding between events from Wikidata concepts, we have also provided a comprehensive mapping from temporal Qnodes and Pnodes to the Allen Interval Temporal Logic relations. © 2023 Association for Computational Linguistics.},
	language = {English},
	booktitle = {{ISA} 2023 - 19th {Joint} {ACL} - {ISO} {Workshop} on {Interoperable} {Semantic} {Annotation}, {Proceedings} of the {Workshop}},
	publisher = {Association for Computational Linguistics (ACL)},
	author = {Spaulding, Elizabeth and Conger, Kathryn and Gershman, Anatole and Uceda-Sosa, Rosario and Brown, Susan Windisch and Pustejovsky, James and Anick, Peter and Palmer, Martha},
	editor = {H, Bunt},
	year = {2020},
	keywords = {Natural language processing systems, Natural languages, Ontology, Knowledge based systems, Language processing, Diagnosis, Ontology's, Real-world entities, Interval temporal logic, Medical professionals},
	pages = {1 -- 10},
	annote = {Cited by: 1; Conference name: 19th Joint ACL - ISO Workshop on Interoperable Semantic Annotation, ISA 2023; Conference date: 20 June 2023; Conference code: 196594},
	annote = {Cited by: 1; Conference name: 19th Joint ACL - ISO Workshop on Interoperable Semantic Annotation, ISA 2023; Conference date: 20 June 2023; Conference code: 196594},
	annote = {Type: Conference paper},
}


@inproceedings{bunt_compositional_2020,
	title = {The compositional semantics of {QuantML} annotations},
	isbn = {978-1-959429-66-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184989081&partnerID=40&md5=7f8112ec1f4fb677ce40e2b271aae290},
	abstract = {This paper discusses some issues in the semantic annotation of quantification phenomena in general, and in particular in the markup language QuantML, which has been proposed to form part of an ISO standard annotation scheme for quantification in natural language data. QuantML annotations have been claimed to have a compositional semantic interpretation, but the formal specification of QuantML in the official ISO documentation does not provide sufficient detail to judge this. This paper aims to fill this gap. © 2023 Association for Computational Linguistics.},
	language = {English},
	booktitle = {{ISA} 2023 - 19th {Joint} {ACL} - {ISO} {Workshop} on {Interoperable} {Semantic} {Annotation}, {Proceedings} of the {Workshop}},
	publisher = {Association for Computational Linguistics (ACL)},
	author = {Bunt, Harry},
	editor = {H, Bunt},
	year = {2020},
	keywords = {Natural languages, Semantics, Markup languages, Semantic interpretation, Semantic annotations, ISO Standards, Annotation scheme, Compositional semantics, ISO standards},
	pages = {56 -- 65},
	annote = {Conference name: 19th Joint ACL - ISO Workshop on Interoperable Semantic Annotation, ISA 2023; Conference date: 20 June 2023; Conference code: 196594},
	annote = {Conference name: 19th Joint ACL - ISO Workshop on Interoperable Semantic Annotation, ISA 2023; Conference date: 20 June 2023; Conference code: 196594},
	annote = {Type: Conference paper},
}


@inproceedings{chen_semantic_2019,
	title = {Semantic {Inference} for {Cyber}-{Physical} {Systems} with {Signal} {Temporal} {Logic}},
	url = {https://doi.org/10.1109/CDC40024.2019.9030138},
	doi = {10.1109/CDC40024.2019.9030138},
	abstract = {Formal specification plays crucial roles in the rigorous verification and design of cyber-physical systems (CPS). The challenge of getting high-quality formal specifications is well documented. This challenge is further exacerbated in CPS with artificial-intelligence- or machine-learning-based components. This paper presents a problem called ‘semantic inference’, the goal of which is to automatically translate the behavior of a CPS to a formal specification written in signal temporal logic (STL). To reduce the potential combinatorial explosion inherent to the problem, this paper adopts a search strategy called agenda-based computation, which is inspired by natural language processing. Based on such a strategy, the semantic inference problem can be formulated as a Markov decision process (MDP) and then solved using reinforcement learning (RL). The obtained formal specification can be viewed as an interpretable classifier, which, on the one hand, can classify desirable and undesirable behaviors, and, on the other hand, is expressed in a human-understandable form. The performance of the proposed method is demonstrated with a case study.},
	booktitle = {2019 {IEEE} 58th {Conference} on {Decision} and {Control} ({CDC})},
	publisher = {IEEE Press},
	author = {Chen, Gang and Liu, Mei and Kong, Zhaodan},
	year = {2019},
	note = {Place: Nice, France},
	keywords = {Natural language processing systems, Formal specification, Semantics, Temporal logic, NAtural language processing, Markov processes, Computer circuits, Cyber Physical System, Embedded systems, Combinatorial explosion, Cyber-physical systems (CPS), High quality, Learning systems, Markov Decision Processes, Reinforcement learning, Search strategies, Semantic inference},
	pages = {6269--6274},
	annote = {Cited by: 1; Conference name: 58th IEEE Conference on Decision and Control, CDC 2019; Conference date: 11 December 2019 through 13 December 2019; Conference code: 158431},
	annote = {Cited by: 1; Conference name: 58th IEEE Conference on Decision and Control, CDC 2019; Conference date: 11 December 2019 through 13 December 2019; Conference code: 158431},
	annote = {RELEVANCE: LOW  - STL

again signal temporal logic
},
}


@inproceedings{chen_semantic_2018,
	address = {New York, NY, USA},
	series = {{IOT} '18},
	title = {Semantic parsing of automobile steering systems},
	isbn = {978-1-4503-6564-2},
	url = {https://doi.org/10.1145/3277593.3277629},
	doi = {10.1145/3277593.3277629},
	abstract = {Formal specification plays crucial roles in the rigorous verification and design of automobile steering systems. The challenge of getting high-quality formal specifications is well documented. This paper presents a problem called 'semantic parsing', the goal of which is to automatically translate the behavior of an automobile steering system to a formal specification written in signal temporal logic (STL) with human-in-the loop manner. To tackle the combinatorial explosion inherent to the problem, this paper adopts a search strategy called agenda-based parsing, which is inspired by natural language processing. Based on such a strategy, the semantic parsing problem can be formulated as a Markov decision process (MDP) and then solved using reinforcement learning. The obtained formal specification can be viewed as an interpretable classifier, which, on the one hand, can classify desirable and undesirable behaviors, and, on the other hand, is expressed in a human-understandable form. The performance of the proposed method is demonstrated with study.},
	booktitle = {Proceedings of the 8th {International} {Conference} on the {Internet} of {Things}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Gang and Sabato, Zachary and Kong, Zhaodan},
	year = {2018},
	note = {event-place: Santa Barbara, California, USA},
	keywords = {Natural language processing systems, Semantics, Temporal logic, Markov processes, Computer circuits, Internet of things, Learning algorithms, Combinatorial explosion, Markov Decision Processes, Reinforcement learning, Search strategies, signal temporal logic, Automobile steering, Automobiles, Formal specication, formal specification, Human-in-the-loop, reinforcement learning, semantic parsing, Semantic parsing, steering systems, Steering systems},
	annote = {Cited by: 0; Conference name: 8th International Conference on the Internet of Things, IoT 2018; Conference date: 15 October 2018 through 18 October 2018; Conference code: 140996},
	annote = {Cited by: 0; Conference name: 8th International Conference on the Internet of Things, IoT 2018; Conference date: 15 October 2018 through 18 October 2018; Conference code: 140996},
	annote = {RELEVANCE: LOW  - STL

They do not consider QTCR
},
}


@inproceedings{nan_safety_2019,
	title = {Safety {Requirements} {Analysis} for a {Launching} {Control} {System} {Based} on {STPA}},
	isbn = {978-1-72811-698-3},
	url = {https://doi.org/10.1109/ICMA.2019.8816630},
	doi = {10.1109/ICMA.2019.8816630},
	abstract = {In this paper, system theory process analysis (STPA) method is used as a new safety analysis approach for a launching control system. One typical control action of the launching process, release the brake is taken as an example for analysis. With XSTAMPP safety engineering platform, the unsafe control actions of the system are analyzed, refined system safety requirements are generated and the descriptions are standardized by linear temporal logic (LTL), the limitations of natural language descriptions used by traditional STPA analysis have been avoided, which provides theoretical support for further safety model verification.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Mechatronics} and {Automation} ({ICMA})},
	publisher = {IEEE Press},
	author = {Nan, Qin and Liang, Ma},
	year = {2019},
	note = {Place: Tianjin, China},
	keywords = {Natural languages, Temporal logic, Linear temporal logic, Computer circuits, Safety engineering, Control systems, Control actions, Launching, Process analysis, Safety analysis, Safety modeling, Safety requirements, System safety requirements},
	pages = {1201--1205},
	annote = {Cited by: 4; Conference name: 16th IEEE International Conference on Mechatronics and Automation, ICMA 2019; Conference date: 4 August 2019 through 7 August 2019; Conference code: 151420},
	annote = {Cited by: 4; Conference name: 16th IEEE International Conference on Mechatronics and Automation, ICMA 2019; Conference date: 4 August 2019 through 7 August 2019; Conference code: 151420},
	annote = {RELEVANCE: LOW

system theory process analysis (STPA)

identify casual scenarios that lead to unsafe control actions

specification of safety requirements 



},
}


@inproceedings{bernaerts_validating_2021,
	series = {{MODELS} '19},
	title = {Validating industrial requirements with a contract-based approach},
	isbn = {978-1-72815-125-0},
	url = {https://doi.org/10.1109/MODELS-C.2019.00010},
	doi = {10.1109/MODELS-C.2019.00010},
	abstract = {This paper presents our contract-based design technique for formalizing requirements during the design phase of a complicated and safety-critical automotive component. In our approach, contracts are created using property specification patterns to eliminate ambiguous unstructured natural language requirements, which could lead to misinterpretations or mismatched interfaces in the integration phases of the design process.These patterns are then automatically transformed into Signal Temporal Logic (STL) formulas. The STL formulas are verified on a modeled system of the component, utilizing the Matlab® toolbox Breach. This approach validates the industrial requirements described in the contracts, and can help achieve the requirement-based testing demanded by automotive safety standard ISO 26262.},
	booktitle = {Proceedings of the 22nd {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}},
	publisher = {IEEE Press},
	author = {Bernaerts, Matthias and Oakes, Bentley James and Vanherpen, Ken and Aelvoet, Bjorn and Vangheluwe, Hans and Denil, Joachim},
	year = {2021},
	note = {Place: Munich, Germany},
	keywords = {Natural language processing systems, Temporal logic, Specifications, C (programming language), Verification, Computer circuits, Safety testing, Property Specification, Accident prevention, automotive, Automotive, contract-based design, Contract-based designs, formalizing requirements, Formalizing Requirements, property specification patterns, requirement validation, Requirement Validation, signal temporal logic},
	pages = {18--27},
	annote = {Cited by: 8; Conference name: 22nd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion, MODELS-C 2019; Conference date: 15 September 2019 through 20 September 2019; Conference code: 154915},
	annote = {Cited by: 10; Conference name: 22nd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion, MODELS-C 2019; Conference date: 15 September 2019 through 20 September 2019; Conference code: 154915},
	annote = {RELEVANCE: LOW but interestings
By using the EARS templates, requirements in an unstructured natural language are forced into a simple structure, which reduces the complexity for many requirements.

Functional Safety Formal Model.

Verification of Signal Temporal Logic (SLT)
From requirements to validated constracts
They mention max. and min. duration of a process. 
},
}


@article{ye_probabilistic_2022,
	title = {Probabilistic modelling and verification using {RoboChart} and {PRISM}},
	volume = {21},
	issn = {1619-1366},
	url = {https://doi.org/10.1007/s10270-021-00916-8},
	doi = {10.1007/s10270-021-00916-8},
	abstract = {RoboChart is a timed domain-specific language for robotics, distinctive in its support for automated verification by model checking and theorem proving. Since uncertainty is an essential part of robotic systems, we present here an extension to RoboChart to model uncertainty using probabilism. The extension enriches RoboChart state machines with probability through a new construct: probabilistic junctions as the source of transitions with a probability value. RoboChart has an accompanying tool, called RoboTool, for modelling and verification of functional and real-time behaviour. We present here also an automatic technique, implemented in RoboTool, to transform a RoboChart model into a PRISM model for verification. We have extended the property language of RoboTool so that probabilistic properties expressed in temporal logic can be written using controlled natural language.},
	number = {2},
	journal = {Softw. Syst. Model.},
	author = {Ye, Kangfeng and Cavalcanti, Ana and Foster, Simon and Miyazawa, Alvaro and Woodcock, Jim},
	month = apr,
	year = {2022},
	note = {Place: Berlin, Heidelberg
Publisher: Springer-Verlag},
	keywords = {Semantics, Formal Semantics, Model checking, Formal methods, Modeling languages, Problem oriented languages, Automated verification, Domain-specific language for robotic, Domain-specific language for robotics, Formal semantics, Model transformation, Modeling and verifications, PRISM, Prisms, Probabilistic model checking, Probabilistic model-checking, Probabilistic models, Probabilistic verification, Robotics, State machines, State-machine, Uncertainty analysis},
	pages = {667--716},
	annote = {Cited by: 8; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 12; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE: MEDIUM - just for the idea

Since uncertainty is an essential part of robotic systems, we present here an extension to RoboChart to model uncertainty using probabilistic.
},
}


@inproceedings{lin_road_2022,
	title = {Road {Traffic} {Law} {Adaptive} {Decision}-making for {Self}-{Driving} {Vehicles}},
	url = {https://doi.org/10.1109/ITSC55140.2022.9922208},
	doi = {10.1109/ITSC55140.2022.9922208},
	abstract = {Self-driving vehicles have their own intelligence to drive on open roads. However, vehicle managers, e.g., government or industrial companies, still need a way to tell these self-driving vehicles what behaviors are encouraged or forbidden. Unlike human drivers, current self-driving vehicles cannot understand the traffic laws, and thus rely on the programmers manually writing the corresponding principles into the driving systems. It would be less efficient and hard to adapt some temporary traffic laws, especially when the vehicles use data-driven decision-making algorithms. Besides, current self-driving vehicle systems rarely take traffic law modification into consideration. This work aims to design a road traffic law adaptive decision-making method. The decision-making algorithm is designed based on reinforcement learning, in which the traffic rules are usually implicitly coded in deep neural networks. The main idea is to supply the adaptability to traffic laws of self-driving vehicles by a law-adaptive backup policy. In this work, the natural language-based traffic laws are first translated into a logical expression by the Linear Temporal Logic method. Then, the system will try to monitor in advance whether the self-driving vehicle may break the traffic laws by designing a long-term RL action space. Finally, a sample-based planning method will re-plan the trajectory when the vehicle may break the traffic rules. The method is validated in a Beijing Winter Olympic Lane scenario and an overtaking case, built in CARLA simulator. The results show that by adopting this method, self-driving vehicles can comply with new issued or updated traffic laws effectively. This method helps self-driving vehicles governed by digital traffic laws, which is necessary for the wide adoption of autonomous driving.},
	booktitle = {2022 {IEEE} 25th {International} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC})},
	publisher = {IEEE Press},
	author = {Lin, Jiaxin and Zhou, Wenhui and Wang, Hong and Cao, Zhong and Yu, Wenhao and Zhao, Chengxiang and Zhao, Ding and Yang, Diange and Li, Jun},
	year = {2022},
	note = {Place: Macau, China},
	keywords = {Decision making, 'current, Roads and streets, Reinforcement learning, Adaptive decision making, Autonomous vehicles, Decision-making algorithms, Decisions makings, Deep neural networks, Digital storage, Highway planning, Reinforcement learnings, Road traffic, Road vehicles, Self drivings, Self-driving vehicle, Traffic laws, Traffic rules},
	pages = {2034--2041},
	annote = {Cited by: 1; Conference name: 25th IEEE International Conference on Intelligent Transportation Systems, ITSC 2022; Conference date: 8 October 2022 through 12 October 2022; Conference code: 183941; All Open Access, Green Open Access},
	annote = {Cited by: 7; Conference name: 25th IEEE International Conference on Intelligent Transportation Systems, ITSC 2022; Conference date: 8 October 2022 through 12 October 2022; Conference code: 183941; All Open Access, Green Open Access},
	annote = {RELEVANCE: MEDIUM

How can self driving vehicles automatically comply with the temporary road traffic laws, e.g. exclusive winter olympic lane?


Road Traffic Law-Adaptive Decision Making



Traffic Law Digitization using Linear Temporal Logic

aw-violence Forecaster

if max speed of road is 40 km hora y ha recorrido 100km en 1 hora, ha violado temporal constraint?

CARLA simulation

compliance vs violation place


},
}


@inproceedings{osman_partakable_2018,
	series = {{IJCAI}'18},
	title = {Partakable technology},
	isbn = {978-0-9992411-2-7},
	abstract = {This paper proposes a shift in how technology is currently being developed by giving people, the users, control over their technology. We argue that users should have a say in the behaviour of the technologies that mediate their online interactions and control their private data. We propose 'partakable technologies', technologies where users can come together to discuss and agree on its features and functionalities. To achieve this, we base our proposal on a number of existing technologies in the fields of agreement technologies, natural language processing, normative systems, and formal verification. As an IJCAI early career spotlight paper, the paper provides an overview of the author's expertise in these different areas.},
	booktitle = {Proceedings of the 27th {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {AAAI Press},
	author = {Osman, Nardine},
	year = {2018},
	note = {Place: Stockholm, Sweden},
	keywords = {Natural language processing systems, Artificial intelligence, NAtural language processing, Agreement technologies, Normative system, On-line interactions, Private data},
	pages = {5714--5718},
	annote = {Cited by: 0; Conference name: 27th International Joint Conference on Artificial Intelligence, IJCAI 2018; Conference date: 13 July 2018 through 19 July 2018; Conference code: 140653; All Open Access, Bronze Open Access},
	annote = {Cited by: 0; Conference name: 27th International Joint Conference on Artificial Intelligence, IJCAI 2018; Conference date: 13 July 2018 through 19 July 2018; Conference code: 140653; All Open Access, Bronze Open Access},
	annote = {Cited by: 0; Conference name: 27th International Joint Conference on Artificial Intelligence, IJCAI 2018; Conference date: 13 July 2018 through 19 July 2018; Conference code: 140653; All Open Access, Bronze Open Access},
	annote = {Cited by: 0; Conference name: 27th International Joint Conference on Artificial Intelligence, IJCAI 2018; Conference date: 13 July 2018 through 19 July 2018; Conference code: 140653; All Open Access, Bronze Open Access},
	annote = {ISSN: 10450823 Type: Conference paper},
	annote = {Place: Stockholm, Sweden},
	annote = {RELEVANCE: NULL
Not available

https://dl.acm.org/doi/10.5555/3304652.3304831
},
}


@inproceedings{wiecher_scenarios_2020,
	address = {New York, NY, USA},
	series = {{MODELS} '20},
	title = {Scenarios in the {Loop}: {Integrated} {Requirements} {Analysis} and {Automotive} {System} {Validation}},
	isbn = {978-1-4503-8135-2},
	url = {https://doi.org/10.1145/3417990.3421264},
	doi = {10.1145/3417990.3421264},
	abstract = {The development of safety-relevant systems in the automotive industry requires the definition of high-quality requirements and tests for the coordination and monitoring of development activities in an agile development environment. In this paper we describe a Scenarios in the Loop (SCIL) approach. SCIL combines (1) natural language requirements specification based on Behavior-Driven Development (BDD) with (2) formal and test-driven requirements modeling and analysis, and (3) integrates discipline-specific tools for software and system validation during development. A central element of SCIL is a flexible and executable scenario-based modeling language, the Scenario Modeling Language for Kotlin (SMLK). SMLK allows for an intuitive requirements formalization, and supports engineers to move iteratively, and continuously aided by automated checks, from stakeholder requirements to the validation of the implemented system. We evaluated the approach using a real example from the field of e-mobility.},
	booktitle = {Proceedings of the 23rd {ACM}/{IEEE} {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}: {Companion} {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Wiecher, Carsten and Japs, Sergej and Kaiser, Lydia and Greenyer, Joel and Dumitrescu, Roman and Wolff, Carsten},
	year = {2020},
	keywords = {Natural language processing systems, Requirements engineering, Natural language requirements, Formal methods, Software testing, Modeling languages, Requirements formalizations, Requirements Models, Accident prevention, Agile development environments, automotive systems engineering, BizDevOps, Development activity, Integrated requirements, requirements analysis, Safety relevant systems, Scenario-based modeling, system validation},
	annote = {Cited by: 12; Conference name: 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020; Conference date: 16 October 2020 through 23 October 2020; Conference code: 164397},
	annote = {Cited by: 12; Conference name: 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020; Conference date: 16 October 2020 through 23 October 2020; Conference code: 164397},
	annote = {Cited by: 12; Conference name: 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020; Conference date: 16 October 2020 through 23 October 2020; Conference code: 164397},
	annote = {Cited by: 12; Conference name: 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020; Conference date: 16 October 2020 through 23 October 2020; Conference code: 164397},
	annote = {Cited by: 12; Conference name: 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020; Conference date: 16 October 2020 through 23 October 2020; Conference code: 164397},
	annote = {event-place: Virtual Event, Canada},
	annote = {event-place: Virtual Event, Canada},
	annote = {event-place: Virtual Event, Canada},
	annote = {RELEVANCE: LOW - but nice ideas….

Scenarios in the Loop (SCIL) SCIL combines 
(1) natural language requirements specification based on Behavior-DrivenDevelopment (BDD) with 
(2) formal and test-driven requirements modeling and analysis, and 
(3) integrates discipline-specific tools for software and system validation during development

automotive systems engineering : The basisfor the development of often safety-critical systems are differentstandards (e.g. ISO26262 [ 20 ], ISO/SAE 21434 [ 32 ]). These must betaken into account by the stakeholders involved in the development,which leads to extensive process implementations in the companiesparticipating.

Vague requirements: At the start of the software imple-mentation, requirements were available in an under-specifiedform. In the course of the implementation it turned out thata number of constraints, error cases, etc. were not takeninto account and were only further elaborated during theimplementation phase

Manual requirements analysis: Scenarios were also usedhere to further concretise the behavior. There is currently alarge number of scenarios and there are still contradictionsbetween requirements that were not noticed during the doc-umentation and manual analysis of the requirements andonly became clear in the implementation phase
},
}


@inproceedings{awan_seamless_2022,
	title = {Seamless {Runtime} {Transformations} from {Natural} {Language} to {Formal} {Methods} – {A} {Usecase} of {Z}-{Notation}},
	url = {https://doi.org/10.1109/SOSE55472.2022.9812644},
	doi = {10.1109/SOSE55472.2022.9812644},
	abstract = {Requirements specification in a crucial activity in Software Development Life Cycle (SDLC). Traditional requirements specification in Natural Language (NL) is error prone activity which may leads to project failure. This scenario is more critical in Systems of Systems (SOS) domain as different stakeholder have different perspectives and requirements. Hence formal requirements specification is a popular domain since many years. This is because formal methods guarantees that the software must meet the standards by clear and unambiguous specification of requirements. However, formal methods are complex and not easy to implement. Therefore, we have proposed a comprehensive automated framework which takes requirements in natural language and provides their seamless transformation in the respective formal language. This paper aims to reduce the overhead of specifying requirements in formal methods and at the same time helps to reap maximum benefits offered by formal methods. We have validated the proposed framework by implementing a popular Z-Notation case study. We have used xtext framework to write a Domain Specific Language (DSL) and provided a luxurious interface for writing requirements in NL and then provided the seamless side-by-side transformation in Z-Notation.},
	booktitle = {2022 17th {Annual} {System} of {Systems} {Engineering} {Conference} ({SOSE})},
	publisher = {IEEE Press},
	author = {Awan, Misbah Mehboob and Butt, Wasi Haider and Anwar, Muhammad Waseem and Azam, Farooque},
	year = {2022},
	keywords = {Natural languages, Software design, Specification languages, Formal methods, Problem oriented languages, Systems engineering, Requirements specifications, Life cycle, Error prones, MDSE, POS tagging, Project failures, Runtimes, Software development life-cycle, System domain, System-of-systems},
	pages = {375--380},
	annote = {Cited by: 0; Conference name: 17th Annual System of Systems Engineering Conference, SOSE 2022; Conference date: 7 June 2022 through 11 June 2022; Conference code: 180662},
	annote = {Cited by: 0; Conference name: 17th Annual System of Systems Engineering Conference, SOSE 2022; Conference date: 7 June 2022 through 11 June 2022; Conference code: 180662},
	annote = {Cited by: 0; Conference name: 17th Annual System of Systems Engineering Conference, SOSE 2022; Conference date: 7 June 2022 through 11 June 2022; Conference code: 180662},
	annote = {Cited by: 0; Conference name: 17th Annual System of Systems Engineering Conference, SOSE 2022; Conference date: 7 June 2022 through 11 June 2022; Conference code: 180662},
	annote = {Cited by: 0; Conference name: 17th Annual System of Systems Engineering Conference, SOSE 2022; Conference date: 7 June 2022 through 11 June 2022; Conference code: 180662},
	annote = {Place: Rochester, NY, USA},
	annote = {Place: Rochester, NY, USA},
	annote = {Place: Rochester, NY, USA},
	annote = {RELEVANCE: LOW - SHORT

Software Development Life Cycle (SDLC)


},
}


@article{zaki-ismail_rcm-extractor_2022,
	title = {{RCM}-{Extractor}: {An} {Automated} {NLP}-{Based} {Approach} for {Extracting} a {Semi} {Formal} {Representation} {Model} from {Natural} {Language} {Requirements}},
	volume = {29},
	issn = {0928-8910},
	url = {https://doi.org/10.1007/s10515-021-00312-y},
	doi = {10.1007/s10515-021-00312-y},
	abstract = {Most existing (semi-)automated requirements formalisation techniques assume requirements to be specified in predefined templates. They also employ template-specific transformation rules to provide the corresponding formal representation. Hence, such techniques have limited expressiveness and more importantly require system engineers to re-write their system requirements following defined templates for maintenance and evolution. In this paper, we introduce an automated requirements extraction technique (RCM-Extractor) to automatically extract the key constructs of a comprehensive and formalisable semi-formal representation model from textual requirements. This avoids the expressiveness issues affecting the existing requirement specification templates, and eliminates the need to rewriting the requirements to match the structure of such templates. We evaluated RCM-Extractor on a dataset of 162 requirements curated from several papers in the literature. RCM-Extractor achieved 87\% precision, 98\% recall, 92\% F-measure, and 86\% accuracy. In addition, we evaluated the capabilities of RCM-Extractor to extract requirements on a dataset of 15,000 automatically synthesised requirements that are constructed specifically to evaluate our approach. This dataset has a complete coverage of the possible structures and arrangements of the properties that can exist in system requirements. Our approach achieved 57\%, 92\% and 100\% accuracy for un-corrected, partially-corrected and fully-corrected Stanford typed-dependencies representations of the synthesised requirements, respectively.},
	number = {1},
	journal = {Automated Software Engg.},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	month = may,
	year = {2022},
	keywords = {Natural language processing systems, Natural languages, Requirements engineering, Extraction, Natural language requirements, Requirements formalizations, Automation, System requirements, Requirement extraction, Requirements formalization, Natural-language extraction, Representation model, Requirements extraction, Semi-formal representations, Synthesised, Transformation rules},
	annote = {Cited by: 4},
	annote = {Cited by: 4},
	annote = {Cited by: 4},
	annote = {Cited by: 4},
	annote = {Cited by: 5},
	annote = {Place: USA Publisher: Kluwer Academic Publishers},
	annote = {Place: USA Publisher: Kluwer Academic Publishers},
	annote = {Place: USA Publisher: Kluwer Academic Publishers},
	annote = {RELEVANCE: HIGH


"Can a semi-formal representation be sufficient?"


"Should NLT be reformatted to a version that can be formalized?"



intro pana y figure

The introduce the concept of valid time to quantify the time constraints, also pre elapsed time and in between time


First, they add an overhead burden on the system engineers to re-write their requirements to con-form to the used template(s) even if the requirements are well written (i.e., haveno quality issues). Second, the user needs guidance to phrase the requirements incompliance with the defined format(s). Third, they reduce the expressiveness powerof the writing. Finally, the format might be so restricted that it becomes irritating touse.

which other semiformal representation exists?

what to do when you consider documents from different domains?
Zaki-Ismail et al. (2021b), we introduced an automated requirements extrac-tion technique (RCM-Extractor)

Additionally, we also utilised a new dataset of 15,000 automatically synthesised requirements covering all the possible structures of the requirement properties to assess the robustness of the developed approaches.

TODO: check out their dataset

ARSENAL first reduces the complexity of the input sentence through term replacement
},
}


@inproceedings{tihanyi_formai_2023,
	address = {New York, NY, USA},
	series = {{PROMISE} 2023},
	title = {The {FormAI} {Dataset}: {Generative} {AI} in {Software} {Security} through the {Lens} of {Formal} {Verification}},
	isbn = {9798400703751},
	url = {https://doi.org/10.1145/3617555.3617874},
	doi = {10.1145/3617555.3617874},
	abstract = {This paper presents the FormAI dataset, a large collection of 112,000 AI-generated compilable and independent C programs with vulnerability classification. We introduce a dynamic zero-shot prompting technique constructed to spawn diverse programs utilizing Large Language Models (LLMs). The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity. Some programs handle complicated tasks like network management, table games, or encryption, while others deal with simpler tasks like string manipulation. Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name. This is accomplished by employing a formal verification method using the Efficient SMT-based Bounded Model Checker (ESBMC), which uses model checking, abstract interpretation, constraint programming, and satisfiability modulo theories to reason over safety/security properties in programs. This approach definitively detects vulnerabilities and offers a formal model known as a counterexample, thus eliminating the possibility of generating false positive reports. We have associated the identified vulnerabilities with Common Weakness Enumeration (CWE) numbers. We make the source code available for the 112,000 programs, accompanied by a separate file containing the vulnerabilities detected in each program, making the dataset ideal for training LLMs and machine learning algorithms. Our study unveiled that according to ESBMC, 51.24\% of the programs generated by GPT-3.5 contained vulnerabilities, thereby presenting considerable risks to software safety and security.},
	booktitle = {Proceedings of the 19th {International} {Conference} on {Predictive} {Models} and {Data} {Analytics} in {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Tihanyi, Norbert and Bisztray, Tamas and Jain, Ridhi and Ferrag, Mohamed Amine and Cordeiro, Lucas C. and Mavroeidis, Vasileios},
	year = {2023},
	keywords = {Computer software selection and evaluation, Semantics, Model checking, C (programming language), Formal verification, Cryptography, Learning algorithms, Classification (of information), Codes (symbols), Language model, Large dataset, Constraint programming, Constraint theory, Artificial Intelligence, Software security, Computational linguistics, Formal Verification, Large language model, Zero-shot learning, Source codes, Bounded model checkers, C programs, Dataset, Networks management, Through the lens, Vulnerability classifications, Large Language Models, Software Security, Vulnerability Classification},
	pages = {33--43},
	annote = {Cited by: 2; Conference name: 19th International Conference on Predictive Models and Data Analytics in Software Engineering, Co-located with: ESEC/FSE 2023; Conference date: 8 December 2023; Conference code: 195221; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 2; Conference name: 19th International Conference on Predictive Models and Data Analytics in Software Engineering, Co-located with: ESEC/FSE 2023; Conference date: 8 December 2023; Conference code: 195221; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {event-place: {\textbackslash}textlessconf-loc{\textbackslash}textgreater, {\textbackslash}textlesscity{\textbackslash}textgreaterSan Francisco{\textbackslash}textless/city{\textbackslash}textgreater, {\textbackslash}textlessstate{\textbackslash}textgreaterCA{\textbackslash}textless/state{\textbackslash}textgreater, {\textbackslash}textlesscountry{\textbackslash}textgreaterUSA{\textbackslash}textless/country{\textbackslash}textgreater, {\textbackslash}textless/conf-loc{\textbackslash}textgreater},
	annote = {event-place: {\textbackslash}textlessconf-loc{\textbackslash}textgreater, {\textbackslash}textlesscity{\textbackslash}textgreaterSan Francisco{\textbackslash}textless/city{\textbackslash}textgreater, {\textbackslash}textlessstate{\textbackslash}textgreaterCA{\textbackslash}textless/state{\textbackslash}textgreater, {\textbackslash}textlesscountry{\textbackslash}textgreaterUSA{\textbackslash}textless/country{\textbackslash}textgreater, {\textbackslash}textless/conf-loc{\textbackslash}textgreater},
	annote = {Type: Conference paper},
}


@inproceedings{leong_translating_2023,
	title = {Translating {Natural} {Language} {Requirements} to {Formal} {Specifications}: {A} {Study} on {GPT} and {Symbolic} {NLP}},
	doi = {10.1109/DSN-W58399.2023.00065},
	abstract = {Software verification is essential to ensure dependability and that a system or component fulfils its specified requirements. Natural language is the most common way of specifying requirements, although many verification techniques such as theorem proving depend upon requirements being written in formal specification languages. Automatically translating requirements into a formal specification language is a relevant and challenging research question, because developers often lack the necessary expertise. In our work we consider the application of natural language processing (NLP) to address that research question. This paper considers two distinct approaches to formalise natural language requirements: a symbolic method and a GPT-based method. The two methods are evaluated with respect to their ability to generate accurate Java Modeling Language (JML) from textual requirements, and the results show good promise for automatic formalisation of requirements.},
	booktitle = {2023 53rd {Annual} {IEEE}/{IFIP} {International} {Conference} on {Dependable} {Systems} and {Networks} {Workshops} ({DSN}-{W})},
	author = {Leong, Iat Tou and Barbosa, Raul},
	month = jun,
	year = {2023},
	note = {ISSN: 2325-6664},
	keywords = {Conferences, Natural language processing systems, Formal specification, Natural languages, Natural language requirements, Modeling languages, Verification, Translation (languages), Formalisation, Verification techniques, Software engineering, Formal specification language, Java Modeling Language, Java programming language, Language processing, Research questions, Software verification, Symbolic methods, Natural language processing, Formal specifications, Software, Organizations, Costs, Java},
	pages = {259--262},
	annote = {Cited by: 0; Conference name: 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops Volume, DSN-W 2023; Conference date: 27 June 2023 through 30 June 2023; Conference code: 191633},
	annote = {Cited by: 0; Conference name: 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops Volume, DSN-W 2023; Conference date: 27 June 2023 through 30 June 2023; Conference code: 191633},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{gnezdilova_towards_2023,
	title = {Towards {Controlled} {Natural} {Language} for {Event}-{Driven} {Temporal} {Requirements}},
	doi = {10.1109/EDM58354.2023.10225047},
	abstract = {Currently, requirements for control software written in natural language are often formulated ambiguously and incompletely. Controlled natural languages (CNLs) can solve this problem, at the same time maintaining flexibility for writing and conveying requirements in an intuitive and common way. The creation of domain-specific controlled natural languages nowadays is under active development. In this paper, we suggest CNL which is based on event-driven semantics. This language is intended for describing the temporal properties of cyber-physical systems. We develop our CNL using a number of natural language patterns build for classes of requirements expressed in Event-Driven Temporal Logic formalism (EDTL). Due to formal semantics of EDTL, the suggested CNL is also unambiguous and can be translated into logic formulas. As a result, the proposed CNL provides an auxiliary tool to improve communication quality between different participants in the industrial system development process: customers, requirements engineers, developers, and others. Therefore, the solution helps to reduce the number of errors in the formulation of requirements at earlier stages of development.},
	booktitle = {2023 {IEEE} 24th {International} {Conference} of {Young} {Professionals} in {Electron} {Devices} and {Materials} ({EDM})},
	author = {Gnezdilova, Anna V. and Garanina, Natalia O. and Staroletov, Sergey M. and Zyubin, Vladimir E.},
	month = jun,
	year = {2023},
	note = {ISSN: 2325-419X},
	keywords = {Natural languages, Semantics, Software systems, Temporal logic, Linear temporal logic, Formal methods, Computer circuits, Cyber Physical System, Embedded systems, Control systems, Control software, Event-driven, Requirement, Controlled natural language, Cybe-physical systems, Cyber-physical systems, Event-driven temporal logic, Logic formalism, cyber-physical system, Planning, requirements, Prototypes, linear temporal logic, controlled natural language, event-driven temporal logic},
	pages = {1860--1865},
	annote = {Cited by: 0; Conference name: 24th IEEE International Conference of Young Professionals in Electron Devices and Materials, EDM 2023; Conference date: 29 June 2023 through 3 July 2023; Conference code: 192147},
	annote = {Cited by: 0; Conference name: 24th IEEE International Conference of Young Professionals in Electron Devices and Materials, EDM 2023; Conference date: 29 June 2023 through 3 July 2023; Conference code: 192147},
	annote = {RELEVANCE: HIGH - but i dont like it
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=\&arnumber=10225047
},
}


@inproceedings{rosser_resolving_2023,
	title = {Resolving {Ambiguity} via {Dialogue} to {Correct} {Unsynthesizable} {Controllers} for {Free}-{Flying} {Robots}},
	doi = {10.1109/AERO55745.2023.10115982},
	abstract = {For human-robot teams that operate in space, safety and robustness are paramount. In situations such as habitat construction, station inspection, or cooperative exploration, incorrect assumptions about the environment or task across the team could lead to mission failure. Thus it is important to resolve any ambiguity about the mission between teammates before embarking on a commanded task. The safeguards guaranteed by formal methods can be used to synthesize correct-by-construction reactive controllers for a robot using Linear Temporal Logic. If a robot fails to synthesize a controller given an instruction, it is clear that there exists a logical inconsistency in the environmental assumptions and/or described interactions. These specifications however are typically crafted in a language unique to the verification framework, requiring the human collaborator to be fluent in the software tool used to construct it. Furthermore, if the controller fails to synthesize, it may prove difficult to easily repair the specification. Language is a natural medium to generate these specifications using modern symbol grounding techniques. Using language empowers non-expert humans to describe tasks to robot teammates while retaining the benefits of formal verification. Additionally, dialogue could be used to inform robots about the environment and/or resolve any ambiguities before mission execution. This paper introduces an architecture for natural language interaction using a symbolic representation that informs the construction of a specification in Linear Temporal Logic. The novel aspect of this approach is that it provides a mechanism for resolving synthesis failure by hypothesizing corrections to the specification that are verified through human-robot dialogue. Experiments involving the proposed architecture are demonstrated using a simulation of an Astrobee robot navigating in the International Space Station.},
	booktitle = {2023 {IEEE} {Aerospace} {Conference}},
	author = {Rosser, Joshua and Arkin, Jacob and Patki, Siddharth and Howard, Thomas M.},
	month = mar,
	year = {2023},
	note = {ISSN: 1095-323X},
	keywords = {Formal specification, Semantics, Temporal logic, Linear temporal logic, Robots, Verification framework, Formal verification, Computer circuits, Correct-by-construction, Controllers, Computer aided software engineering, Cooperative exploration, Fluents, Free-flying robots, Human-robot-team, Resolving ambiguities, Software-tools, Space safety, Space stations, Computer architecture, Pipelines, Maintenance engineering, Inspection, Navigation, Symbols},
	pages = {1--11},
	annote = {Cited by: 0; Conference name: 2023 IEEE Aerospace Conference, AERO 2023; Conference date: 4 March 2023 through 11 March 2023; Conference code: 188722; All Open Access, Green Open Access},
	annote = {Cited by: 0; Conference name: 2023 IEEE Aerospace Conference, AERO 2023; Conference date: 4 March 2023 through 11 March 2023; Conference code: 188722; All Open Access, Green Open Access},
	annote = {RELEVANCE: LOW
},
}


@inproceedings{irvine_structured_2023,
	title = {Structured {Natural} {Language} for expressing {Rules} of the {Road} for {Automated} {Driving} {Systems}},
	doi = {10.1109/IV55152.2023.10186664},
	abstract = {Automated Driving Systems (ADSs), like human drivers, must be compliant with the rules of the road. However, current rules of the road are not well defined. They use inconsistent and ambiguous language. As a result, they are not sufficiently formal for machine interpretability, a necessity for applications of verification and validation (V\&V) of ADSs. Rules must be defined in a way that make them usable to a variety of stakeholders. While first-order and temporal logic forms of rules of the road are needed for monitoring and verification during simulation and testing, a structured natural language for these rules is necessary for consistent definition. They must also adhering to standard vocabulary taxonomies of Operational Design Domain (ODD) and behaviour. This paper contributes a structured natural language based on formal logic, that allows rules of the road to be defined in a natural, yet precise manner, using concepts of ODD and behaviour, making them usable in the V\&V of ADSs. We evaluate the effectiveness of the language on a selection of rules from the Vienna Convention on Road Traffic and the UK Highway Code.},
	booktitle = {2023 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Irvine, Patrick and Da Costa, Antonio A. Bruto and Zhang, Xizhe and Khastgir, Siddartha and Jennings, Paul},
	month = jun,
	year = {2023},
	note = {ISSN: 2642-7214},
	keywords = {Natural languages, Computer circuits, Automation, Automated driving systems, Computer simulation languages, Design behaviours, Design domains, Formal logic, Human drivers, Logic, Operational design, Roads and streets, Rule of the road, Scenario, Verification-and-validation, Road traffic, Roads, Taxonomy, Safety, Vocabulary, natural language, Codes, logic, scenarios, automated driving systems, rules of the road},
	pages = {1--8},
	annote = {Cited by: 0; Conference name: 34th IEEE Intelligent Vehicles Symposium, IV 2023; Conference date: 4 June 2023 through 7 June 2023; Conference code: 191161},
	annote = {Cited by: 0; Conference name: 34th IEEE Intelligent Vehicles Symposium, IV 2023; Conference date: 4 June 2023 through 7 June 2023; Conference code: 191161; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{ferro_simplifying_2023,
	title = {Simplifying {Requirements} {Formalization} for {Resource}-{Constrained} {Mission}-{Critical} {Software}},
	doi = {10.1109/DSN-W58399.2023.00066},
	abstract = {Developing critical software requires adherence to rigorous software development practices, such as formal requirement specification and verification. Despite their importance, such practices are often considered as complex and challenging tasks that require a strong formal methods background. In this paper, we present our work on simplifying the formal requirements specification experience for resource-constrained mission critical software through the use of structured natural language. To this end, we connect NASA’s FRET, a formal requirement elicitation and authoring tool with the Shelley model checking framework for MicroPython code. We report our experience on using these tools to specify requirements and analyze code from the NASA Ames PHALANX exploration concept.},
	booktitle = {2023 53rd {Annual} {IEEE}/{IFIP} {International} {Conference} on {Dependable} {Systems} and {Networks} {Workshops} ({DSN}-{W})},
	author = {Ferro, Carlos Mão de and Mavridou, Anastasia and Dille, Michael and Martins, Francisco},
	month = jun,
	year = {2023},
	note = {ISSN: 2325-6664},
	keywords = {Conferences, Formal specification, Natural languages, Requirements engineering, Software design, Model checking, Formal verification, Requirements formalizations, NASA, Software development practices, Codes (symbols), Requirement, Critical codes, Critical software, Formal requirement specifications, Mission critical, Mission critical softwares, Mission-critical code, Requirement verifications, requirements, Codes, verification, Authoring systems, Mission critical systems, mission-critical code},
	pages = {263--266},
	annote = {Cited by: 0; Conference name: 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops Volume, DSN-W 2023; Conference date: 27 June 2023 through 30 June 2023; Conference code: 191633},
	annote = {Cited by: 0; Conference name: 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops Volume, DSN-W 2023; Conference date: 27 June 2023 through 30 June 2023; Conference code: 191633},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{ruan_requirements_2023,
	title = {Requirements {Modeling} {Aided} by {ChatGPT}: {An} {Experience} in {Embedded} {Systems}},
	doi = {10.1109/REW57809.2023.00035},
	abstract = {Requirements modeling is a crucial tool for requirements analysis and has been demonstrated to aid in the comprehension and analysis of requirements. However, constructing requirements models from natural language descriptions in user requirements documents can be a time-consuming task. With the growing attention given to large language models, they have become an integral component of natural language processing. Consequently, utilizing large language models to facilitate the construction of high-quality requirement models is appealing. This paper presents an automated framework for requirement model generation that incorporates ChatGPT-based zero-shot learning to extract requirement models from requirement texts and subsequently compose them using predefined rules. The framework defines the requirement extraction task of ChatGPT by designing appropriate prompt, and it generates requirement models by employing composition rules. Furthermore, a case study on a digital home system is conducted to validate the feasibility of the framework in assisting requirements modeling.},
	booktitle = {2023 {IEEE} 31st {International} {Requirements} {Engineering} {Conference} {Workshops} ({REW})},
	author = {Ruan, Kun and Chen, Xiaohong and Jin, Zhi},
	month = sep,
	year = {2023},
	note = {ISSN: 2770-6834},
	keywords = {Conferences, Natural language processing systems, Natural languages, Requirements engineering, Semantics, User requirements, Analytical models, Embedded systems, Requirement analysis, Language model, Requirements document, Chatbots, Task analysis, Digital devices, Computational linguistics, Requirements modeling, Language description, ChatGPT, Embedded-system, Problem Frames approach, Zero-shot learning, Embedded system, Problem Frames Approach, Requirements Modeling},
	pages = {170--177},
	annote = {Cited by: 0; Conference name: 31st IEEE International Requirements Engineering Conference Workshops, REW 2023; Conference date: 4 September 2023 through 8 September 2023; Conference code: 193031},
	annote = {Cited by: 0; Conference name: 31st IEEE International Requirements Engineering Conference Workshops, REW 2023; Conference date: 4 September 2023 through 8 September 2023; Conference code: 193031},
	annote = {RELEVANCE: HIGH
https://rulemining.org/
conformance checking

},
	annote = {Type: Conference paper},
}


@article{yang_toward_2024,
	title = {Toward {Auto}-{Modeling} of {Formal} {Verification} for {NextG} {Protocols}: {A} {Multimodal} {Cross}- and {Self}-{Attention} {Large} {Language} {Model} {Approach}},
	volume = {12},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2024.3366803},
	abstract = {This paper introduces Auto-modeling of Formal Verification with Real-world Prompting for 5G and NextG protocols (AVRE), a novel system designed for the formal verification of Next Generation (NextG) communication protocols, addressing the increasing complexity and scalability challenges in network protocol design and verification. Utilizing Large Language Models (LLMs), AVRE transforms protocol descriptions into dependency graphs and formal models, efficiently resolving ambiguities and capturing design intent. The system integrates a transformer model with LLMs to autonomously establish quantifiable dependency relationships through cross- and self-attention mechanisms. Enhanced by iterative feedback from the HyFuzz experimental platform, AVRE significantly advances the accuracy and relevance of formal verification in complex communication protocols, offering a groundbreaking approach to validating sophisticated communication systems. We compare CAL’s performance with state-of-the-art LLM-based models and traditional time sequence models, demonstrating its superiority in accuracy and robustness, achieving an accuracy of 95.94\% and an AUC of 0.98. This NLP-based approach enables, for the first time, the creation of exploits directly from design documents, making remarkable progress in scalable system verification and validation.},
	journal = {IEEE Access},
	author = {Yang, Jingda and Wang, Ying},
	year = {2024},
	keywords = {Natural language processing systems, Natural languages, Modeling languages, Formal verification, Iterative methods, Natural language processing, Complexity theory, Protocols, Complex networks, Network protocols, 5G mobile communication, Flow graphs, Computational linguistics, Transformers, 5g mobile communication, 5G mobile communication systems, Cross-attention, Flow-graphs, Formal flow graph, Mobile communications, Natural language protocol, Self-attention, Transformer, cross-attention, formal flow graph, natural language protocol, self-attention},
	pages = {27858--27869},
	annote = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access},
	annote = {Publisher: Institute of Electrical and Electronics Engineers Inc. Type: Article},
}


@inproceedings{joshi_smart_2023,
	title = {Smart {Contract} {Vulnerability} detection using {Natural} {Language} {Processing}},
	doi = {10.1109/ICRASET59632.2023.10420108},
	abstract = {The smart agreement is one of the most utilized makes use of blockchain and an important issue of the blockchain ecosystem. The blockchain-based totally credit device suffers from common smart contract safety troubles, which additionally reason for big monetary losses. As an end result, smart contract’s security and dependability are of exquisite interest to researchers from all over the international. First, the use of the three levels of this survey—the Solidity code layer, the EVM execution layer, and the Block dependency layer—not unusual kinds and standard instances of smart contract vulnerabilities are explained. The nation of the artwork on this difficulty is likewise evaluated, and the existing equivalents are divided into five companies: formal verification, symbolic execution, fuzzing detection, intermediate illustration, and deep getting to know.},
	booktitle = {2023 {International} {Conference} on {Recent} {Advances} in {Science} and {Engineering} {Technology} ({ICRASET})},
	author = {Joshi, Deepali and Patil, Sangam and Chauhan, Sayee and Baware, Tanuj and Thakur, Rohit and Naik, Sameer},
	month = nov,
	year = {2023},
	keywords = {Security, Natural language processing systems, Natural languages, Language processing, Natural language processing, Scalability, Research and development, Blockchain, Smart contract, Ecosystems, Block-chain, Blockchains, Bitcoin, Vulnerability detection, Symbolic execution, Three-level, Vulnerability, Smart contracts, Smart Contracts},
	pages = {1--6},
	annote = {Cited by: 0; Conference name: 2023 International Conference on Recent Advances in Science and Engineering Technology, ICRASET 2023; Conference date: 23 November 2023 through 24 November 2023; Conference code: 197160},
	annote = {Cited by: 0; Conference name: 2023 International Conference on Recent Advances in Science and Engineering Technology, ICRASET 2023; Conference date: 23 November 2023 through 24 November 2023; Conference code: 197160},
	annote = {Type: Conference paper},
}


@article{kande_security_2024,
	title = {({Security}) {Assertions} by {Large} {Language} {Models}},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2024.3372809},
	abstract = {The security of computer systems typically relies on a hardware root of trust. As vulnerabilities in hardware can have severe implications on a system, there is a need for techniques to support security verification activities. Assertion-based verification is a popular verification technique that involves capturing design intent in a set of assertions that can be used in formal verification or testing-based checking. However, writing security-centric assertions is a challenging task. In this work, we investigate the use of emerging large language models (LLMs) for code generation in hardware assertion generation for security, where primarily natural language prompts, such as those one would see as code comments in assertion files, are used to produce SystemVerilog assertions. We focus our attention on a popular LLM and characterize its ability to write assertions out of the box, given varying levels of detail in the prompt. We design an evaluation framework that generates a variety of prompts, and we create a benchmark suite comprising real-world hardware designs and corresponding golden reference assertions that we want to generate with the LLM.},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Kande, Rahul and Pearce, Hammond and Tan, Benjamin and Dolan-Gavitt, Brendan and Thakur, Shailja and Karri, Ramesh and Rajendran, Jeyavijayan},
	year = {2024},
	keywords = {Security, Network security, Formal verification, Assertion generations, Codes (symbols), Language model, Task analysis, Job analysis, Hardware, Benchmark testing, AI, Computer hardware, Code, Codes, Writing, Large language model, ChatGPT, Codex, Source-coding, Vulnerability detection, Source coding, assertion generation, hardware, hardware security, LLM, vulnerability detection},
	pages = {1--1},
	annote = {Publisher: Institute of Electrical and Electronics Engineers Inc. Type: Article},
}


