@inproceedings{dave_identifying_2022,
	title = {Identifying {Functional} and {Non}-functional {Software} {Requirements} from {User} {App} {Reviews}},
	isbn = {978-1-66548-684-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133840756&doi=10.1109%2fIEMTRONICS55184.2022.9795770&partnerID=40&md5=1c2a464458ba3d79df13b99c99127002},
	doi = {10.1109/IEMTRONICS55184.2022.9795770},
	abstract = {Mobile app developers are always looking for ways to use the reviews (provided by their app's users) to improve their application (e.g., adding a new functionality in the app that a user mentioned in their review). Usually, there are thousands of user reviews that are available for each mobile app and isolating software requirements manually from such as big dataset can be difficult and time-consuming. The primary objective of the current research is to automate the process of extracting functional requirements and filtering out non-requirements from user app reviews to help app developers better meet the wants and needs of their users. This paper proposes and evaluates machine learning based models to identify and classify software requirements from both, formal Software Requirements Specifications (SRS) documents and Mobile App Reviews (written by users) using machine learning (ML) algorithms combined with natural language processing (NLP) techniques. Initial evaluation of our ML-based models show that they can help classify user app reviews and software requirements as Functional Requirements (FR), Non-Functional Requirements (NFR), or Non-Requirements (NR). © 2022 IEEE.},
	language = {English},
	booktitle = {2022 {IEEE} {International} {IOT}, {Electronics} and {Mechatronics} {Conference}, {IEMTRONICS} 2022},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Dave, Dev and Anu, Vaibhav},
	editor = {S, Chakrabarti and R, Paul and B, Gill and M, Gangopadhyay and S, Poddar},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Software requirements, Machine learning, Learning algorithms, Classification (of information), Application programs, Language processing, Requirement, Machine-learning, Natural language processing, Functional requirement, Learning Based Models, Mobile app, Non-functional},
	annote = {Cited by: 1; Conference name: 2022 IEEE International IOT, Electronics and Mechatronics Conference, IEMTRONICS 2022; Conference date: 1 June 2022 through 4 June 2022; Conference code: 180242},
	annote = {Cited by: 3; Conference name: 2022 IEEE International IOT, Electronics and Mechatronics Conference, IEMTRONICS 2022; Conference date: 1 June 2022 through 4 June 2022; Conference code: 180242},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{conrad_compositional_2022,
	address = {New York, NY, USA},
	series = {{CPP} 2022},
	title = {A {Compositional} {Proof} {Framework} for {FRETish} {Requirements}},
	isbn = {978-1-4503-9182-5},
	url = {https://doi.org/10.1145/3497775.3503685},
	doi = {10.1145/3497775.3503685},
	abstract = {Structured natural languages provide a trade space between ambiguous natural languages that make up most written requirements, and mathematical formal specifications such as Linear Temporal Logic. FRETish is a structured natural language for the elicitation of system requirements developed at NASA. The related open-source tool Fret provides support for translating FRETish requirements into temporal logic formulas that can be input to several verification and analysis tools. In the context of safety-critical systems, it is crucial to ensure that a generated formula captures the semantics of the corresponding FRETish requirement precisely. This paper presents a rigorous formalization of the FRETish language including a new denotational semantics and a proof of semantic equivalence between FRETish specifications and their temporal logic counterparts computed by Fret. The complete formalization and the proof have been developed in the Prototype Verification System (PVS) theorem prover.},
	booktitle = {Proceedings of the 11th {ACM} {SIGPLAN} {International} {Conference} on {Certified} {Programs} and {Proofs}},
	publisher = {Association for Computing Machinery},
	author = {Conrad, Esther and Titolo, Laura and Giannakopoulou, Dimitra and Pressburger, Thomas and Dutle, Aaron},
	year = {2022},
	note = {event-place: Philadelphia, PA, USA},
	keywords = {Formal specification, Natural languages, Semantics, Temporal logic, Linear temporal logic, Model checking, Formal verification, Computer circuits, Safety engineering, Formalisation, NASA, Requirement, Formal proofs, Formal Proofs, Metric temporal logic, Metric Temporal Logic, Open systems, Prototype verification systems, PVS, Requirements, Space between, Structured natural language, Structured Natural Language, Trade space},
	pages = {68--81},
	annote = {Cited by: 4; Conference name: 11th ACM SIGPLAN International Conference on Certified Programs and Proofs, CPP 2022 - co-located with POPL 2022; Conference date: 17 January 2022 through 18 January 2022; Conference code: 176264; All Open Access, Green Open Access},
	annote = {Cited by: 6; Conference name: 11th ACM SIGPLAN International Conference on Certified Programs and Proofs, CPP 2022 - co-located with POPL 2022; Conference date: 17 January 2022 through 18 January 2022; Conference code: 176264; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{maiko_onishishinpei_ogatakozo_okanodaisuke_bekki_method_2023,
	title = {A {Method} for {Matching} {Patterns} {Based} on {Event} {Semantics} with {Requirements}},
	url = {{http://link.springer.com/chapter/10.1007/978-3-031-17583-1_14}},
	doi = {10.1007/978-3-031-17583-1_14},
	journal = {Knowledge-Based Software Engineering: 2022},
	author = {{Maiko OnishiShinpei OgataKozo OkanoDaisuke Bekki}},
	year = {2023},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Semantics, Model checking, Pattern matching, Requirement engineering, Syntactics, Systems specification, Language processing, Natural language processing, Semantic parsing, Event semantics, Matching methods, Matching patterns, Pattern-matching},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Publisher: Springer Nature Type: Book chapter},
	annote = {RELEVANCE: LOW

},
}


@inproceedings{alman_declo_2020,
	title = {Declo: {A} chatbot for user-friendly specification of declarative process models},
	volume = {2673},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092663333&partnerID=40&md5=706df84041da39d7d158d04cd9c176b8},
	abstract = {Proposed approaches for modeling knowledge-intensive pro- cesses include declarative, constraint-based solutions, which meet halfway between support and exibility. A noteworthy example is the Declare framework, which is equipped with a graphical declarative lan- guage whose semantics can be expressed with multiple logic-based for- malisms. So far, the practical use of Declare constraints has been mostly hampered by the difficulty of modeling them: the formal notation of De- clare represents a steep learning curve for users lacking an understanding of temporal logic, while the graphical notation has proven to be unin- tuitive. This work presents Declo, a chatbot that allows users to easily define declarative constraints using natural language statements provided in the form of vocal or textual input. The supported constraints cover the entire Multi-Perspective extension of Declare (MP-Declare), comple- menting control- ow constraints with data and temporal perspectives. Copyright © 2020 for this paper by its authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Alman, Anti and Balder, Karl Johannes and Maggi, Fabrizio Maria and Van Der Aa, Han},
	editor = {W.M.P, van der Aalst and J, vom Brocke and M, Comuzzi and C, Di Ciccio and F, Garcia and A, Kumar and J, Mendling and B, Pentland and L, Pufahl and M, Reichert and M, Weske},
	year = {2020},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural languages, Semantics, Computer circuits, Declarative process models, Graphical notation, Formal notations, Multi-perspective, Constraint-based, Declarative constraints, Steep learning curve},
	pages = {122 -- 126},
	annote = {Cited by: 3; Conference name: 2020 Best Dissertation Award, Doctoral Consortium, and Demonstration and Resources Track at BPM, BPM-D 2020; Conference date: 13 September 2020 through 18 September 2020; Conference code: 163020},
	annote = {Cited by: 4; Conference name: 2020 Best Dissertation Award, Doctoral Consortium, and Demonstration and Resources Track at BPM, BPM-D 2020; Conference date: 13 September 2020 through 18 September 2020; Conference code: 163020},
	annote = {RELEVANCE: HIGH
},
}


@article{wang_automatic_2021,
	title = {Automatic {Generation} of {Specification} from {Natural} {Language} {Based} on {Temporal} {Logic}},
	volume = {12723 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111149251&doi=10.1007%2f978-3-030-77474-5_11&partnerID=40&md5=a3ae38ee79be193921eff0b48fd59cfe},
	doi = {10.1007/978-3-030-77474-5_11},
	abstract = {Formal specifications are usually used for describing safety system properties and play an important role in formal verification. In order to improve the effectiveness of formal specification generation and formal verification, this paper proposes a framework for automatic conversion from natural language describing properties to temporal logic formulas, and implements a tool PPTLGenerator (Propositional Projection Temporal Logic formula Generator) for the conversion. First, PPTLGenerator is developed based on JavaCC for automatic conversion from natural language to PPTL. Then, the satisfiability of a PPTL formula generated by PPTLGenerator is checked by a tool PPTLSAT. Finally, to illustrate the principle and effectiveness of the framework, a case study of the safety property of Level 3 autonomous car is provided. © 2021, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Wang, Xiaobing and Li, Ge and Li, Chunyi and Zhao, Liang and Shu, Xinfeng},
	editor = {J, Xue and F, Nagoya and S, Liu and Z, Duan},
	year = {2021},
	note = {ISBN: 978-303077473-8
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Temporal logic, Formal languages, Formal verification, Computer circuits, Temporal logic formula, Automatic Generation, Automatic conversion, Safety property, Satisfiability, Specification generations, System property},
	pages = {154 -- 171},
	annote = {Cited by: 0; Conference name: International Workshop on Structured Object-Oriented Formal Language and Method, SOFL+MSVL 2020; Conference date: 1 March 2021 through 1 March 2021; Conference code: 260819},
	annote = {RELEVANCE: HIGH see fig 1
},
}


@inproceedings{soavi_legal_2021,
	title = {From {Legal} {Contracts} to {Formal} {Specifications}: {A} {Progress} {Report}},
	volume = {2857},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105560078&partnerID=40&md5=e7179eff8bdfebad88fcd92f4f311f86},
	abstract = {Smart contracts are software systems that partially automate, monitor and control the execution of legal contracts. The requirements of such systems consist of a formal specification of the legal contract whose execution is to be monitored and controlled. Legal contracts are always available as text expressed in natural language. We have been working on the translation of such text documents into formal specifications. Our translation process consists of four steps that (a) Semantic annotation of text identifying obligations, powers, contracting parties and assets, (b) Identification of relationships among the concepts identified in (a), (c) Generation of a domain model for terms used in the contract, as well as identification of parameters and local variables for the contract, (d) Generation of formal expressions that formalize the constituents of obligations and powers. This paper reports on the status of the project and the results that have been achieved. © 2021 CEUR-WS. All rights reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Soavi, Michele and Zeni, Nicola and Mylopoulos, John and Mich, Luisa},
	editor = {F.B, Aydemir and C, Gralha and M, Daneva and E.C, Groen and A, Herrmann and P, Mennig and S, Abualhaija and A, Ferrari and J, Guo and R, Guizzardi and J, Horkoff and A, Perini and A, Susi and T, Breaux and X, Franch and N, Ernst and E, Paja and N, Seyff},
	year = {2021},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Computer software selection and evaluation, Formal specification, Natural languages, Requirements engineering, Semantics, Software systems, Formal expressions, Local variables, Monitor and control, Progress report, Semantic annotations, Translation process},
	annote = {Cited by: 0; Conference name: Joint Workshops of the 27th International Conference on Requirements Engineering, REFSQ 2021 - OpenRE, Posters and Tools Track, and Doctoral Symposium; Conference date: 12 April 2021; Conference code: 168710},
	annote = {Cited by: 0; Conference name: Joint Workshops of the 27th International Conference on Requirements Engineering, REFSQ 2021 - OpenRE, Posters and Tools Track, and Doctoral Symposium; Conference date: 12 April 2021; Conference code: 168710},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{kaiser_ai4rfq_2021,
	title = {{AI4RFQ}: {Exploiting} {User} {Annotations} towards {Automating} the {Extraction} of {Information} and {Requirements} from {Specification} {Documents}},
	volume = {2905},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110416507&partnerID=40&md5=1a781dfa01e1ab3e8000a3372bd908ea},
	abstract = {A common task in business-to-business relationships is the analysis of specification documents within a request for quotation (RFQ) process. For non-standard products or services, one company with a need provides detailed specifications to potential suppliers and invites them to make an offer. In order to create an offer that fits with the specification, a supplier company needs to carefully inspect the documents to extract any requirements that are relevant for designing the contents of this offer and calculating its price. In a research effort focusing on HCI and natural language processing aspects, we seek methods and technology to support such RFQ processes. We have created a software tool that supports the reading and requirements identification process with a set of intelligent features that are expected to speed up the process significantly. Whenever users are extracting information, they are asked to annotate all text passages that contain relevant information. This annotation data is used to train machine learning models that provide suggestions in the future. The degree of automation increases continuously as more example data is collected. We strive to participate in the 'Automation Experience at the Workplace' workshop to discuss this change in work practice for our target users in terms of a technical as well as a user experience dimension. We would like to especially reflect on users' motivation to cooperate with the system and provide useful annotations (sharing their precious work expertise), the question of responsibility when dealing with automatic suggestions, as well as the fear of being replaced by 'an Artificial Intelligence' in the near future. Copyright © 2021 for this paper by its authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Kaiser, Rene and Stern, Hermann},
	editor = {M, Baldauf and P, Frohlich and S, Sadeghian and P, Palanque and V, Roto and W, Ju and L, Baillie and M, Tscheligi and M, Tscheligi},
	year = {2021},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Artificial intelligence, NAtural language processing, Specifications, Automation, Machine learning models, Identification process, Administrative data processing, User experience, Extracting information, Business to business, Degree of automation, Extraction of information, Request for quotations},
	annote = {Cited by: 0; Conference name: 2021 Workshop on Automation Experience at the Workplace, AutomationXP 2021; Conference date: 7 May 2021; Conference code: 170007},
	annote = {Cited by: 0; Conference name: 2021 Workshop on Automation Experience at the Workplace, AutomationXP 2021; Conference date: 7 May 2021; Conference code: 170007},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{dutle_requirements_2020,
	title = {From requirements to autonomous flight: {An} overview of the monitoring {ICAROUS} project},
	volume = {329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101067660&doi=10.4204%2fEPTCS.329.3&partnerID=40&md5=40b509794247255a013c620bd4ee096e},
	doi = {10.4204/EPTCS.329.3},
	abstract = {The Independent Configurable Architecture for Reliable Operations of Unmanned Systems (ICAROUS) is a software architecture incorporating a set of algorithms to enable autonomous operations of unmanned aircraft applications. This paper provides an overview of Monitoring ICAROUS, a project whose objective is to provide a formal approach to generating runtime monitors for autonomous systems from requirements written in a structured natural language. This approach integrates FRET, a formal requirement elicitation and authoring tool, and Copilot, a runtime verification framework. FRET is used to specify formal requirements in structured natural language. These requirements are translated into temporal logic formulae. Copilot is then used to generate executable runtime monitors from these temporal logic specifications. The generated monitors are directly integrated into ICAROUS to perform runtime verification during flight. © 2020 Open Publishing Association. All rights reserved.},
	language = {English},
	booktitle = {Electronic {Proceedings} in {Theoretical} {Computer} {Science}, {EPTCS}},
	publisher = {Open Publishing Association},
	author = {Dutle, Aaron and Titolo, Laura and Giannakopoulou, Dimitra and Muñoz, César and Perez, Ivan and Mavridou, Anastasia and Conrad, Esther and Balachandran, Swee and Pressburger, Thomas and Goodloe, Alwyn},
	editor = {M, Luckcuck and M, Farrell},
	year = {2020},
	note = {ISSN: 20752180
Type: Conference paper},
	keywords = {Temporal logic, Requirement elicitation, Formal methods, Computer circuits, Application programs, Temporal logic specifications, Autonomous systems, Autonomous operations, Configurable architectures, Forster resonance energy transfer, Reliable operation, Run-time verification, Unmanned aircrafts},
	pages = {23 -- 30},
	annote = {Cited by: 8; Conference name: 2nd Workshop on Formal Methods for Autonomous Systems, FMAS 2020; Conference date: 7 December 2020; Conference code: 166772; All Open Access, Gold Open Access},
	annote = {Cited by: 10; Conference name: 2nd Workshop on Formal Methods for Autonomous Systems, FMAS 2020; Conference date: 7 December 2020; Conference code: 166772; All Open Access, Gold Open Access},
	annote = {RELEVANCE: MEDIUM
},
}


@article{giannakopoulou_generation_2020,
	title = {Generation of {Formal} {Requirements} from {Structured} {Natural} {Language}},
	volume = {12045 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083986430&doi=10.1007%2f978-3-030-44429-7_2&partnerID=40&md5=dea1255499debd812d6eb1daa54cd5cb},
	doi = {10.1007/978-3-030-44429-7_2},
	abstract = {[Motivation] The use of structured natural languages to capture requirements provides a reasonable trade-off between ambiguous natural language and unintuitive formal notations. [Problem] There are two major challenges in making structured natural language amenable to formal analysis: (1) associating requirements with formulas that can be processed by analysis tools and (2) ensuring that the formulas conform to the language semantics. [Results] FRETISH is a structured natural language that incorporates features from existing research and from NASA applications. Even though FRETISH is quite expressive, its underlying semantics is determined by the types of four fields: scope, condition, timing, and response. Each combination of field types defines a template with Real-Time Graphical Interval Logic (RTGIL) semantics. We present an approach that constructs future and past-time metric temporal logic formulas for each template compositionally, from its fields. To establish correctness of our approach we have developed a framework which, for each template: (1) extensively tests the generated formulas against the template semantics and (2) proves equivalence between its past-time and future-time formulas. Our approach has been used to capture and analyze requirements for a Lockheed Martin Cyber-Physical System challenge. [Contribution] To the best of our knowledge, this is the first approach to generate pure past-time and pure future-time formalizations to accommodate a variety of analysis tools. The compositional nature of our algorithms facilitates maintenance and extensibility, and our extensive verification framework establishes trust in the produced formalizations. Our approach is available through the open-source tool fret. © 2020, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Giannakopoulou, Dimitra and Pressburger, Thomas and Mavridou, Anastasia and Schumann, Johann},
	editor = {N, Madhavji and L, Pasquale},
	year = {2020},
	note = {ISBN: 978-303044428-0
Publisher: Springer
Type: Conference paper},
	keywords = {Computer software selection and evaluation, Natural languages, Requirements engineering, Semantics, Verification framework, Computer circuits, Embedded systems, NASA, Formal notations, Formal analysis, Metric temporal logic, Open source software, Economic and social effects, Language semantics, Open source tools, Template semantics},
	pages = {19 -- 35},
	annote = {Cited by: 21; Conference name: 26th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2020; Conference date: 24 March 2020 through 27 March 2020; Conference code: 239239},
	annote = {RELEVANCE: MEDIUM
},
}


@article{shaaban_automated_2019,
	title = {An automated tool for detection and tutoring of sources of ambiguities in requirements documents},
	volume = {8},
	issn = {22773878},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073561031&doi=10.35940%2fijrte.C4660.098319&partnerID=40&md5=0cf76d058ee0e642105db1d8806e373e},
	doi = {10.35940/ijrte.C4660.098319},
	abstract = {Software Engineering (SE) is the application of essentials to deal with the analysis, design, development, testing, deployment and management-Software Development Life Cycle (SDLC)-of software systems. Requirements Engineering (RE) is responsible for the most critical task in the SDLC; which is transforming the requirements and wishes of the software users into complete, accurate and formal specifications. One of the main responsibilities of RE is the creation of a software requirements document that exactly, reliably, and totally defines the functional and non-functional properties of the system to be developed. At some point through the RE process, the requirements are written using a Natural Language (NL). On one hand, NLs are flexible, common, and popular. On the other hand, NLs are recognized widely as inherently ambiguous. Ambiguity is noticed in a requirement document when a piece of text is interpreted in distinct ways. This may lead to erroneous software that is too expensive to correct in later phases of the SDLC. Many tools have been developed in the literature to detect ambiguities in requirements documents. Best practices for writing requirements have also been proposed to help avoid ambiguities in the first place. The goal of this paper is to combine features from both approaches by developing the Ambiguity Checker Tutor (ACTutor), which not only detects ambiguities, but also aids in tutoring requirements engineers to apply best practices while writing requirements (rather than merely listing them). The paper is mainly concerned with proving the tutoring effectiveness of ACTutor through empirical evaluation. © BEIESP.},
	language = {English},
	number = {3},
	journal = {International Journal of Recent Technology and Engineering},
	author = {Shaaban, Ayat and Elazhary, Hanan and Hassanein, Ehab},
	year = {2019},
	note = {Publisher: Blue Eyes Intelligence Engineering and Sciences Publication
Type: Article},
	pages = {2371 -- 2375},
	annote = {Cited by: 0; All Open Access, Bronze Open Access},
	annote = {Cited by: 0; All Open Access, Bronze Open Access},
	annote = {RELEVANCE:  MEDIUM
},
}


@inproceedings{haris_automated_2020,
	title = {Automated requirement sentences extraction from software requirement specification document},
	isbn = {978-1-4503-7605-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099014527&doi=10.1145%2f3427423.3427450&partnerID=40&md5=6124c65a2d66449817de3958512a1dbf},
	doi = {10.1145/3427423.3427450},
	abstract = {In the requirement reuse and natural language document-based Software Product Line (SPL) domain analysis, requirement sentences of the requirement document are the primary concern. Most studies conducted in this research area have document preprocessing stage in their methods that is a manual process to separate requirement sentences and non-requirement sentences from the document. This manual labor process might be tedious and error-prone since it will need much time and expert intervention to make this process completely done. In this paper, we present a method to automate requirement sentence extraction from the Software Requirement Specification (SRS) document by leveraging Natural Language Processing (NLP) approach and requirement boilerplate sentence patterns. Conducted experiments in this research show this method has such accuracy from 64\% to 100\% on precision value and recall value in the range of 64\% to 89\%. © 2020 ACM.},
	language = {English},
	booktitle = {{ACM} {International} {Conference} {Proceeding} {Series}},
	publisher = {Association for Computing Machinery},
	author = {Haris, M Syauqi and Kurniawan, Tri Astoto},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Extraction, NAtural language processing, Software requirement specification, Sentence extraction, Computer software reusability, Document pre-processing, Domain analysis, Manual process, Software product lines},
	pages = {142 -- 147},
	annote = {Cited by: 2; Conference name: 5th International Conference on Sustainable Information Engineering and Technology, SIET 2020; Conference date: 16 November 2020 through 17 November 2020; Conference code: 166157},
	annote = {Cited by: 4; Conference name: 5th International Conference on Sustainable Information Engineering and Technology, SIET 2020; Conference date: 16 November 2020 through 17 November 2020; Conference code: 166157},
	annote = {RELEVANCE: MEDIUM
},
}


@article{cherukuri_towards_2022,
	title = {Towards {Explainable} {Formal} {Methods}: {From} {LTL} to {Natural} {Language} with {Neural} {Machine} {Translation}},
	volume = {13216 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127071136&doi=10.1007%2f978-3-030-98464-9_7&partnerID=40&md5=ba5bdc952cd20a8ad2688192f2dc504c},
	doi = {10.1007/978-3-030-98464-9_7},
	abstract = {[Context and motivation] Requirements formalisation facilitates reasoning about inconsistencies, detection of ambiguities, and identification critical issues in system models. Temporal logic formulae are the natural choice when it comes to formalise requirements associated to desired system behaviours. [Question/problem] Understanding and mastering temporal logic requires a formal background. Means are therefore needed to make temporal logic formulae interpretable by engineers, domain experts and other stakeholders involved in the development process. [Principal ideas/results] In this paper, we propose to use a neural machine translation tool, named OpenNMT, to translate Linear Temporal Logic (LTL) formulae into corresponding natural language descriptions. Our results show that the translation system achieves an average BLEU (BiLingual Evaluation Understudy) score of 93.53\%, which corresponds to high-quality translations. [Contribution] Our neural model can be applied to assess if requirements have been correctly formalised. This can be useful to requirements analysts, who may have limited confidence with LTL, and to other stakeholders involved in the requirements verification process. Overall, our research preview contributes to bridging the gap between formal methods and requirements engineering, and opens to further research in explainable formal methods. © 2022, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Cherukuri, Himaja and Ferrari, Alessio and Spoletini, Paola},
	editor = {V, Gervasi and A, Vogelsang},
	year = {2022},
	note = {ISBN: 978-303098463-2
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Temporal logic, Linear temporal logic, Computer circuits, Requirements formalizations, Requirement engineering, Temporal logic formula, Neural-networks, System models, Computational linguistics, Computer aided language translation, Critical issues, Inconsistency detection, Machine translation, System behaviors},
	pages = {79 -- 86},
	annote = {Cited by: 4; Conference name: 28th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2022; Conference date: 21 March 2022 through 24 March 2022; Conference code: 274709},
	annote = {RELEVANCE: HIGH
https://www.researchgate.net/publication/359102190\_Towards\_Explainable\_Formal\_Methods\_From\_LTL\_to\_Natural\_Language\_with\_Neural\_Machine\_Translation
},
}


@article{mustroph_verifying_2023,
	title = {Verifying {Resource} {Compliance} {Requirements} from {Natural} {Language} {Text} over {Event} {Logs}},
	volume = {14159 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172192425&doi=10.1007%2f978-3-031-41620-0_15&partnerID=40&md5=73b277bcc783f7c96eb873c5325927b2},
	doi = {10.1007/978-3-031-41620-0_15},
	abstract = {Process compliance aims to ensure that processes adhere to requirements imposed by natural language texts such as regulatory documents. Existing approaches assume that requirements are available in a formalized manner using, e.g., linear temporal logic, leaving the question open of how to automatically extract and formalize them for verification. Especially with the constantly growing amount of regulatory documents and their frequent updates, it can be preferable to provide an approach that enables the verification of processes with requirements in natural language text instead of formalized requirements. To this end, this paper presents an approach that copes with the verification of resource compliance requirements, e.g., which resource shall perform which activity, in natural language over event logs. The approach relies on a comprehensive literature analysis to identify resource compliance patterns. It then contrasts these patterns with resource patterns reflecting the process perspective, while considering the natural language perspective. We combine the state-of-the-art GPT-4 technology for pre-processing the natural language text with a customized compliance verification component to identify and verify resource compliance requirements. Thereby, the approach distinguishes different resource patterns including multiple organizational perspectives. The approach is evaluated based on a set of well-established process descriptions and synthesized event logs generated by a process execution engine as well as the BPIC 2020 dataset. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Mustroph, Henryk and Barrientos, Marisol and Winter, Karolin and Rinderle-Ma, Stefanie},
	editor = {C, Di Francescomarino and A, Burattin and C, Janiesch and S, Sadiq},
	year = {2023},
	note = {ISBN: 978-303141619-4
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Event logs, Natural languages, Requirements engineering, Regulatory compliance, Regulatory documents, Temporal logic, Linear temporal logic, Compliance control, Requirement verifications, Compliance requirement verification, Literature analysis, Natural languages texts, Process descriptions, Resources minings},
	pages = {249 -- 265},
	annote = {Cited by: 0; Conference name: Proceedings of the 21st International Conference on Business Process Management , BPM 2023; Conference date: 11 September 2023 through 15 September 2023; Conference code: 300169},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{gropler_automated_2022,
	title = {Automated {Requirement} {Formalization} {Using} {Product} {Design} {Specifications}},
	volume = {3122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128715774&partnerID=40&md5=6e87b52c6b3aaa7186831eb9b0d81717},
	abstract = {Assuring the quality of complex and highly configurable software systems is a demanding and time-consuming process. Especially for safety-critical systems, extensive testing based on requirements is necessary. Methods for model-based test automation in agile software development offer the possibility to overcome these difficulties. However, it is still a major effort to create formal models from functional requirements in natural language on a large scale. In this paper, we present and evaluate automated support for the requirements formalization process to reduce cost and effort. We present a new approach based on Natural Language Processing (NLP) and textual similarity using requirements and product design specifications to generate human- and machine-readable models. The method is evaluated on an industrial use case from the railway domain. The recommended requirement models for the considered propulsion system show an average accuracy of more than 90\% and an exact match of the entire models of about 55\%. These results show that our approach can support the requirements formalization process, which can be further used for test case generation and execution, as well as for requirements and design verification. © 2022 Copyright for this paper by its authors},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Gröpler, Robin and Kutty, Libin and Sudhi, Viju and Smalley, Daran},
	editor = {J, Fischbach and N, Condori-Fernandez and N, Condori-Fernandez and J, Doerr and M, Ruiz and J.-P, Steghofer and L, Pasquale and A, Zisman and R, Guizzardi and J, Horkoff and A, Perini and A, Susi and M, Daneva and A, Herrmann and K, Schneider and P, Mennig and F, Dalpiaz and D, Dell�Anna and S, Kopczynska and L, Montgomery and A.G, Darby and P, Sawyer},
	year = {2022},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Product design, Requirements engineering, Software design, Model checking, Specifications, Software testing, Modeling languages, Requirements formalizations, Automation, Safety engineering, Safety testing, Requirement engineering, Software-systems, Safety critical systems, Propulsion, Requirements modeling, Design specification, Extensive testing, Model-based test, Test Automation, Textual similarities},
	annote = {Cited by: 0; Conference name: Joint REFSQ-2022 Workshops, Doctoral Symposium, and Posters and Tools Track, REFSQ-JP 2022; Conference date: 21 March 2022; Conference code: 178725},
	annote = {Cited by: 0; Conference name: Joint REFSQ-2022 Workshops, Doctoral Symposium, and Posters and Tools Track, REFSQ-JP 2022; Conference date: 21 March 2022; Conference code: 178725},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{wu_autoformalization_2022,
	title = {Autoformalization with {Large} {Language} {Models}},
	volume = {35},
	isbn = {978-1-71387-108-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144992805&partnerID=40&md5=6ef93aef894d2abaf7d32df8436b037b},
	abstract = {Autoformalization is the process of automatically translating from natural language mathematics to formal specifications and proofs. A successful autoformalization system could advance the fields of formal verification, program synthesis, and artificial intelligence. While the long-term goal of autoformalization seemed elusive for a long time, we show large language models provide new prospects towards this goal. We make the surprising observation that LLMs can correctly translate a significant portion (25.3\%) of mathematical competition problems perfectly to formal specifications in Isabelle/HOL. We demonstrate the usefulness of this process by improving a previously introduced neural theorem prover via training on these autoformalized theorems. Our methodology results in a new state-of-the-art result on the MiniF2F theorem proving benchmark, improving the proof rate from 29.6\% to 35.2\%. © 2022 Neural information processing systems foundation. All rights reserved.},
	language = {English},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Neural information processing systems foundation},
	author = {Wu, Yuhuai and Jiang, Albert Q. and Li, Wenda and Rabe, Markus N. and Staats, Charles and Jamnik, Mateja and Szegedy, Christian},
	editor = {S, Koyejo and S, Mohamed and A, Agarwal and D, Belgrave and K, Cho and A, Oh},
	year = {2022},
	note = {ISSN: 10495258
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Translation (languages), Language model, Theorem proving, Computational linguistics, State of the art, Program synthesis, Isabelle, Long-term goals, Theorem provers, Verification programs},
	annote = {Cited by: 4; Conference name: 36th Conference on Neural Information Processing Systems, NeurIPS 2022; Conference date: 28 November 2022 through 9 December 2022; Conference code: 189185},
	annote = {Cited by: 11; Conference name: 36th Conference on Neural Information Processing Systems, NeurIPS 2022; Conference date: 28 November 2022 through 9 December 2022; Conference code: 189185},
	annote = {RELEVANCE: HIGH
},
}


@article{giannakopoulou_automated_2021,
	title = {Automated formalization of structured natural language requirements},
	volume = {137},
	issn = {09505849},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110475677&doi=10.1016%2fj.infsof.2021.106590&partnerID=40&md5=026ddfe572f5a6ad835456a709fe95f0},
	doi = {10.1016/j.infsof.2021.106590},
	abstract = {The use of structured natural languages to capture requirements provides a reasonable trade-off between ambiguous natural language and unintuitive formal notations. There are two major challenges in making structured natural language amenable to formal analysis: (1) formalizing requirements as formulas that can be processed by analysis tools and (2) ensuring that the formulas conform to the semantics of the structured natural language. FRETISH is a structured natural language that incorporates features from existing research and from NASA applications. Even though FRETISH is quite expressive, its underlying semantics is determined by the types of four fields: scope, condition, timing, and response. Each combination of field types defines a template with Real-Time Graphical Interval Logic (RTGIL) semantics. We have developed a framework that constructs temporal logic formulas for each template compositionally, from its fields. The compositional nature of our algorithms facilitates maintenance and extensibility. Our goal is to be inclusive not only in terms of language expressivity, but also in terms of requirements analysis tools that we can interface with. For this reason we generate metric-temporal logic formulas with (1) exclusively future-time operators, over both finite and infinite traces, and (2) exclusively past-time operators. To establish trust in the produced formalizations for each template, our framework: (1) extensively tests the generated formulas against the template semantics and (2) proves equivalence between its past-time and future-time formulas. Our approach is available through the open-source tool FRET and has been used to capture and analyze requirements for a Lockheed Martin Cyber–Physical System challenge. © 2021},
	language = {English},
	journal = {Information and Software Technology},
	author = {Giannakopoulou, Dimitra and Pressburger, Thomas and Mavridou, Anastasia and Schumann, Johann},
	year = {2021},
	note = {Publisher: Elsevier B.V.
Type: Article},
	keywords = {Natural language processing systems, Natural languages, Semantics, Temporal logic, Natural language requirements, Computer circuits, NASA, Formal notations, Temporal logic formula, Metric temporal logic, Open systems, Economic and social effects, Open source tools, Template semantics, Requirements analysis tools},
	annote = {Cited by: 19; All Open Access, Bronze Open Access},
	annote = {Cited by: 20; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: MEDIUM
},
}


@article{barrientos_verification_2023,
	title = {Verification of {Quantitative} {Temporal} {Compliance} {Requirements} in {Process} {Descriptions} {Over} {Event} {Logs}},
	volume = {13901 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163923412&doi=10.1007%2f978-3-031-34560-9_25&partnerID=40&md5=353e9e058a5ab256b57b8f55ddc0861b},
	doi = {10.1007/978-3-031-34560-9_25},
	abstract = {Process compliance verification ensures that processes adhere to a set of given regulatory requirements which are typically assumed to be available in a formalized way using, e.g., LTL. However, formalized requirements are rarely available in practice, but rather embedded in regulatory documents such as the GDPR, requiring extraction and formalization by experts. Due to the vast amount and frequent changes in regulatory documents, it is almost impossible to keep formalized requirements up to date in a manual way. Therefore, this paper presents an approach towards compliance verification between natural language text and event logs without the need for requirements formalization. This enables humans to cope with an increasingly complex environment. The approach focuses on quantitative temporal requirements (QTCR) and consists of multiple steps. First, we identify clauses with temporal expressions from process descriptions. Second, we generate a set of QTCR by mapping the retrieved clauses to event log activities. Finally, in the third step, we verify that the event log is compliant with the QTCR. The approach is evaluated based on process descriptions and synthesized event logs. For the latter, we implement time shifting as a concept for simulating real-life logs with varying temporal challenges. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Barrientos, Marisol and Winter, Karolin and Mangler, Juergen and Rinderle-Ma, Stefanie},
	editor = {M, Indulska and I, Reinhartz-Berger and C, Cetina and O, Pastor},
	year = {2023},
	note = {ISBN: 978-303134559-3
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Event logs, Regulatory compliance, Regulatory documents, Compliance control, Requirements formalizations, Compliance verification, Formalisation, In-process, Natural languages texts, Process descriptions, Regulatory requirements, Temporal compliance requirement},
	pages = {417 -- 433},
	annote = {Cited by: 1; Conference name: 35th International Conference on Advanced Information Systems Engineering, CAiSE 2023; Conference date: 12 June 2023 through 16 June 2023; Conference code: 296279},
	annote = {RELEVANCE: HIGH
},
}


@article{adam_natural_2023,
	title = {From {Natural} {Language} {Requirements} to the {Verification} of {Programmable} {Logic} {Controllers}: {Integrating} {FRET} into {PLCverif}},
	volume = {13903 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163948676&doi=10.1007%2f978-3-031-33170-1_21&partnerID=40&md5=207888e33fec3c7c7a700b62dcc3a711},
	doi = {10.1007/978-3-031-33170-1_21},
	abstract = {PLCverif is an actively developed project at CERN, enabling the formal verification of Programmable Logic Controller (PLC) programs in critical systems. In this paper, we present our work on improving the formal requirements specification experience in PLCverif through the use of natural language. To this end, we integrate NASA’s FRET, a formal requirement elicitation and authoring tool, into PLCverif. FRET is used to specify formal requirements in structured natural language, which automatically translates into temporal logic formulae. FRET’s output is then directly used by PLCverif for verification purposes. We discuss practical challenges that PLCverif users face when authoring requirements and the FRET features that help alleviate these problems. We present the new requirement formalization workflow and report our experience using it on two critical CERN case studies. © 2023, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Ádám, Zsófia and Lopez-Miguel, Ignacio D. and Mavridou, Anastasia and Pressburger, Thomas and Bęś, Marcin and Blanco Viñuela, Enrique and Katis, Andreas and Tournier, Jean-Charles and Trinh, Khanh V. and Fernández Adiego, Borja},
	editor = {K.Y, Rozier and S, Chaudhuri},
	year = {2023},
	note = {ISBN: 978-303133169-5
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Natural language requirements, Requirements elicitation, Formal verification, Computer circuits, Requirements formalizations, NASA, Controllers, Temporal logic formula, Programmable logic controllers, Formal requirement specifications, Work-flows, Critical systems, Forster resonance energy transfer, Authoring tool, Controller programs},
	pages = {353 -- 360},
	annote = {Cited by: 0; Conference name: 15th International Symposium on NASA Formal Methods, NFM 2023; Conference date: 16 May 2023 through 18 May 2023; Conference code: 296139},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{masmoudi_adopting_2022,
	title = {Adopting formal methods on requirements verification and validation for cyber-physical systems: {A} systematic literature review},
	volume = {55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144507475&doi=10.1016%2fj.ifacol.2022.10.131&partnerID=40&md5=42604e9eea9d6342c2ce87407e970246},
	doi = {10.1016/j.ifacol.2022.10.131},
	abstract = {Requirements engineering is a critical activity in developing complex cyber-physical systems. Requirements are usually expressed using natural language, which may be ambiguous, inconsistent, or incomplete. These issues in requirements qualities may introduce errors in system design that lead to high project cost overruns. Hence it is essential to verify the qualities of requirements early. Since formal methods have demonstrated their ability to verify system designs and are increasingly adopted to support requirements engineering for software systems, a question arises about adapting formal methods to account for specific properties of cyber-physical systems. Even if there are many literature reviews concerning requirements engineering, there is a lack of a global view on the reviews that specifically address the issues related to validation and verification (V\&V) of requirements. This paper aims to provide an overview of literature reviews related to requirements V\&V and mainly investigates the use of formal approaches and models for preventing, detecting, or correcting errors occurring in requirements and identifies the main challenges of adopting formal methods on requirements engineering for cyber-physical systems. Copyright © 2022 The Authors. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0/)},
	language = {English},
	booktitle = {{IFAC}-{PapersOnLine}},
	publisher = {Elsevier B.V.},
	author = {Masmoudi, Chedhli and Marange, Pascale and Bonjour, Eric and Levrat, Eric and Kerbrat, Alain},
	editor = {A, Bernard and A, Dolgui and H.H, Benderbal and D, Ivanov and D, Lemoine and F, Sgarbossa},
	year = {2022},
	note = {ISSN: 24058963
Issue: 10
Type: Conference paper},
	keywords = {Requirements engineering, Formal verification, Cyber Physical System, Embedded systems, Requirement engineering, Requirements validation, Verification-and-validation, Cybe-physical systems, Cyber-physical systems, Requirement verifications, Systematic literature review, Literature reviews, Systems analysis, Critical activities, Validation and verification},
	pages = {3274 -- 3279},
	annote = {Cited by: 0; Conference name: 10th IFAC Conference on Manufacturing Modelling, Management and Control, MIM 2022; Conference date: 22 June 2022 through 24 June 2022; Conference code: 148818; All Open Access, Bronze Open Access},
	annote = {Cited by: 0; Conference name: 10th IFAC Conference on Manufacturing Modelling, Management and Control, MIM 2022; Conference date: 22 June 2022 through 24 June 2022; Conference code: 148818; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: MEDIUM check
},
}


@inproceedings{ghosh_specnfs_2022,
	title = {{SpecNFS}: {A} {Challenge} {Dataset} {Towards} {Extracting} {Formal} {Models} from {Natural} {Language} {Specifications}},
	isbn = {979-10-95546-72-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144467883&partnerID=40&md5=35a4545cd8f0c8214404491a13793849},
	abstract = {Can NLP assist in building formal models for verifying complex systems? We study this challenge in the context of parsing Network File System (NFS) specifications. We define a semantic-dependency problem over SpecIR, a representation language we introduce to model sentences appearing in NFS specification documents (RFCs) as semantic dependency structures, and present an annotated dataset of 1,198 sentences. We develop and evaluate semantic-dependency parsing systems for this problem. Evaluations show that even when using a state-of-the-art language model, there is significant room for improvement, with the best models achieving an F1 score of only 60.5 and 33.3 in the named-entity-recognition and dependency-link-prediction sub-tasks, respectively. We also release additional unlabeled data and other domain-related texts. Experiments show that these additional resources increase the F1 measure when used for simple domain-adaption and transfer-learning-based approaches, suggesting fruitful directions for further research. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.},
	language = {English},
	booktitle = {2022 {Language} {Resources} and {Evaluation} {Conference}, {LREC} 2022},
	publisher = {European Language Resources Association (ELRA)},
	author = {Ghosh, Sayontan and Singh, Amanpreet and Merenstein, Alex and Su, Wei and Smolka, Scott A. and Zadok, Erez and Balasubramanian, Niranjan},
	editor = {N, Calzolari and F, Bechet and P, Blache and K, Choukri and C, Cieri and T, Declerck and S, Goggi and H, Isahara and B, Maegaard and J, Mariani and H, Mazo and J, Odijk and S, Piperidis},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Semantics, Specifications, Formal verification, Syntactics, Natural language specifications, Systems specification, Formal modeling, Dependency parsing, In-buildings, Network file system, Representation languages, Semantic dependency, Semantic dependency parsing, Specification dataset},
	pages = {2166 -- 2176},
	annote = {Cited by: 0; Conference name: 13th International Conference on Language Resources and Evaluation Conference, LREC 2022; Conference date: 20 June 2022 through 25 June 2022; Conference code: 184830},
	annote = {Cited by: 0; Conference name: 13th International Conference on Language Resources and Evaluation Conference, LREC 2022; Conference date: 20 June 2022 through 25 June 2022; Conference code: 184830},
	annote = {RELEVANCE: HIGH
},
}


@article{cosler_nl2spec_2023,
	title = {nl2spec: {Interactively} {Translating} {Unstructured} {Natural} {Language} to {Temporal} {Logics} with {Large} {Language} {Models}},
	volume = {13965 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172279049&doi=10.1007%2f978-3-031-37703-7_18&partnerID=40&md5=da4ca72272ab67781d4b7a02d3bf8273},
	doi = {10.1007/978-3-031-37703-7_18},
	abstract = {A rigorous formalization of desired system requirements is indispensable when performing any verification task. This often limits the application of verification techniques, as writing formal specifications is an error-prone and time-consuming manual task. To facilitate this, we present nl2spec, a framework for applying Large Language Models (LLMs) to derive formal specifications (in temporal logics) from unstructured natural language. In particular, we introduce a new methodology to detect and resolve the inherent ambiguity of system requirements in natural language: we utilize LLMs to map subformulas of the formalization back to the corresponding natural language fragments of the input. Users iteratively add, delete, and edit these sub-translations to amend erroneous formalizations, which is easier than manually redrafting the entire formalization. The framework is agnostic to specific application domains and can be extended to similar specification languages and new neural models. We perform a user study to obtain a challenging dataset, which we use to run experiments on the quality of translations. We provide an open-source implementation, including a web-based frontend. © 2023, The Author(s).},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Cosler, Matthias and Hahn, Christopher and Mendoza, Daniel and Schmitt, Frederik and Trippel, Caroline},
	year = {2023},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Requirements engineering, Temporal logic, Specification languages, System requirements, Translation (languages), Formalisation, Verification techniques, Iterative methods, Language model, Error prones, Applications domains, Subformulas, Unstructured natural language, Verification task},
	pages = {383 -- 396},
	annote = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{chhabra_formalizing_2018,
	title = {Formalizing and verifying natural language system requirements using petri nets and context based reasoning},
	volume = {2134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050472945&partnerID=40&md5=64df7203c36657fbf8bb9d210f284593},
	abstract = {Natural language descriptions are generally used to describe requirements in reactive systems. Translating the natural language requirements to a more formal specification is a challenging task. One possible approach to handle complex natural language requirements is to convert them to an intermediary formal representation. This intermediate representation is further converted into a more formal representation such as EDT (Expressive Decision Tables). In this paper, we use Petri nets in combination with domain based context reasoning as a tool to model natural language requirements. We have also built a tool, NatEDT, to generate EDT specifications. In a case study, consisting of natural language requirements across three domains, our experimental results show that Petri nets provide an efficient way of formalizing natural language requirements. © 2018 CEUR-WS. All Rights Reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Chhabra, Aishwarya and Sangroya, Amit and Anantaram, C.},
	editor = {J, Cassens and A, Kofod-Petersen and R, Wegener and A, Kofod-Petersen and R, Wegener},
	year = {2018},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Petri nets, Natural language processing systems, Formal specification, Natural languages, Artificial intelligence, Context reasoning, Context-based reasoning, Decision tables, Formal representations, Intermediate representations, Natural language requirements, Natural language systems, Reactive system},
	pages = {64 -- 71},
	annote = {Cited by: 4; Conference name: 10th International Workshop Modelling and Reasoning in Context, MRC 2018; Conference date: 13 July 2018; Conference code: 137772},
	annote = {Cited by: 5; Conference name: 10th International Workshop Modelling and Reasoning in Context, MRC 2018; Conference date: 13 July 2018; Conference code: 137772},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{friesen_cordula_2018,
	title = {{CORDULA}: {Software} requirements extraction utilizing chatbot as communication interface},
	volume = {2075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045428517&partnerID=40&md5=d4b4abace7d7289b989dbb84feab5d57},
	abstract = {Natural language requirement descriptions are often unstructured, contradictory and incomplete and are therefore challenging for automatic processing. Although many of these deficits can be compensated by means of natural language processing, there still remain cases where interaction with end-users is necessary for clarification. In this vision paper, we present CORDULA, a system using chatbot technology to establish end-user communication in order to support the requirement elicitation and partial compensation of deficits in user requirements. Copyright c 2018 by the paper's authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Friesen, Edwin and Bäumer, Frederik S. and Geierhos, Michaela},
	editor = {F, Dalpiaz and X, Franch and M, Kirikova and J, Ralyte and P, Spoletini and Y, Chisik and A, Ferrari and N, Madhavji and C, Palomares and M, Sabetzadeh and D, van der Linden and K, Schmid and E.B, Charrada and P, Sawyer and P, Forbrig and A, Zamansky},
	year = {2018},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Computer software selection and evaluation, Requirements engineering, Natural language requirements, Automatic processing, Communication interface, End users, Partial compensation, Requirement elicitation, Software requirements, User requirements},
	annote = {Cited by: 7; Conference name: 24th Joint International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, REFSQ-JP 2018; Conference date: 19 March 2018; Conference code: 135277},
	annote = {Cited by: 7; Conference name: 24th Joint International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, REFSQ-JP 2018; Conference date: 19 March 2018; Conference code: 135277},
	annote = {RELEVANCE: HIGH
},
}


@article{mokammel_automatic_2018,
	title = {Automatic requirements extraction, analysis, and graph representation using an approach derived from computational linguistics},
	volume = {21},
	issn = {10981241},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051070662&doi=10.1002%2fsys.21461&partnerID=40&md5=3eda877d27e29b86325972739debf3d8},
	doi = {10.1002/sys.21461},
	abstract = {The quality of requirements is fundamental in engineering projects. Requirements are usually expressed partly or totally in a natural language (NL) format and come from different documents. Their qualities are difficult to analyze manually, especially when hundreds of thousands of them have to be considered. The assistance of software tools is becoming a necessity. In this article, the goal was to develop a set of metrics supported by NL processing (NLP) methods supporting different types of analysis of requirements and especially the dependencies between requirements. An NLP approach is used to extract requirements from text; to analyze their quality, links, similarities, and contradictions; and to cluster them automatically. The analysis framework includes different combinations of methods such as cosine similarity, singular value decomposition, and K-means clustering. One objective is to assess the possible combinations and their impacts on detections to establish optimal metrics. Three case studies exemplify and support the validation of the work. Graphs are used to represent the automatically clustered requirements, as well as similarities and contradictions. A new contradiction analysis process that includes a rules-based approach is proposed. Finally, the combined results are presented as graphs, which unveil the semantic relationships between requirements. Subsection 4.8 compares the results provided by the tool and the results obtained from experts. The proposed methodology and network presentation not only support the understanding of the semantics of the requirements but also help requirements engineers to review the interconnections and consistency of requirements systems and manage traceability. The approach is valuable during the early phases of projects when requirements are evolving dynamically and rapidly. © 2018 Wiley Periodicals, Inc.},
	language = {English},
	number = {6},
	journal = {Systems Engineering},
	author = {Mokammel, Faisal and Coatanéa, Eric and Coatanéa, Joonas and Nenchev, Vladislav and Blanco, Eric and Pietola, Matti},
	year = {2018},
	note = {Publisher: John Wiley and Sons Inc.
Type: Article},
	keywords = {Natural language processing systems, Requirements engineering, Semantics, Contradiction analysis, Contradictions analysis, Graph representation, Network representation, Requirements management, Rules-based approaches, Semantic relationships, Similarity, Singular value decomposition},
	pages = {555 -- 575},
	annote = {Cited by: 8},
	annote = {Cited by: 11},
	annote = {RELEVANCE: MEDIUM
},
}


@article{naumchev_vercors_2019,
	title = {{VERCORS}: {Hardware} and {Software} {Complex} for {Intelligent} {Round}-{Trip} {Formalized} {Verification} of {Dependable} {Cyber}-{Physical} {Systems} in a {Digital} {Twin} {Environment} ({Position} {Paper})},
	volume = {11771 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075682305&doi=10.1007%2f978-3-030-29852-4_30&partnerID=40&md5=ddfd9800bc60ff99a1848056e7a50e0b},
	doi = {10.1007/978-3-030-29852-4_30},
	abstract = {Formal specification, model checking and model-based testing are recommended techniques for engineering of mission-critical systems. In the meantime, those techniques struggle to obtain wide adoption due to inherent learning barrier, i.e. it is considered difficult to use those methods. There is also a common difficulty in translating the specifications in natural language, a common practice nowadays, to formal specifications. In this position paper we discuss the concept of an end-to-end methodology that helps identify specifications from various sources, automatically create formal specifications and apply them to verification of cyber-physical systems. Thus, we intent to address the challenges of creation of formal specifications in an efficient automated and tool-supported manner. The novelty of the approach is analyzed through a survey of state of the art. It is currently planned to implement this concept and evaluate it with industrial case studies. © 2019, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Naumchev, Alexandr and Sadovykh, Andrey and Ivanov, Vladimir},
	editor = {M, Mazzara and B, Meyer and J.-M, Bruel and A, Petrenko},
	year = {2019},
	note = {ISBN: 978-303029851-7
Publisher: Springer
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Model checking, Modeling languages, Verification, Cyber Physical System, Embedded systems, Language processing, Computer simulation languages, Cyber-physical systems (CPS), Traceability, Digital twin, Multi-modelling, Cosimulation, Model based testing, Natural},
	pages = {351 -- 363},
	annote = {Cited by: 3; Conference name: 51st International Conference on Software Technology: Methods and Tools, TOOLS 2019; Conference date: 15 October 2019 through 17 October 2019; Conference code: 233059},
	annote = {RELEVANCE: HIGH
https://link.springer.com/chapter/10.1007/978-3-030-29852-4\_30
},
}


@inproceedings{zhai_c2s_2020,
	title = {{C2S}: {Translating} natural language comments to formal program specifications},
	isbn = {978-1-4503-7043-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097166035&doi=10.1145%2f3368089.3409716&partnerID=40&md5=c247b0b8e31798c15801c9734b79dbd4},
	doi = {10.1145/3368089.3409716},
	abstract = {Formal program specifications are essential for various software engineering tasks, such as program verification, program synthesis, code debugging and software testing. However, manually inferring formal program specifications is not only time-consuming but also error-prone. In addition, it requires substantial expertise. Natural language comments contain rich semantics about behaviors of code, making it feasible to infer program specifications from comments. Inspired by this, we develop a tool, named C2S, to automate the specification synthesis task by translating natural language comments into formal program specifications. Our approach firstly constructs alignments between natural language word and specification tokens from existing comments and their corresponding specifications. Then for a given method comment, our approach assembles tokens that are associated with words in the comment from the alignments into specifications guided by specification syntax and the context of the target method. Our tool successfully synthesizes 1,145 specifications for 511 methods of 64 classes in 5 different projects, substantially outperforming the state-of-the-art. The generated specifications are also used to improve a number of software engineering tasks like static taint analysis, which demonstrates the high quality of the specifications. © 2020 ACM.},
	language = {English},
	booktitle = {{ESEC}/{FSE} 2020 - {Proceedings} of the 28th {ACM} {Joint} {Meeting} {European} {Software} {Engineering} {Conference} and {Symposium} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Zhai, Juan and Shi, Yu and Pan, Minxue and Zhou, Guian and Liu, Yongxiang and Fang, Chunrong and Ma, Shiqing and Tan, Lin and Zhang, Xiangyu},
	editor = {P, Devanbu and M, Cohen and T, Zimmermann},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Natural languages, Semantics, Specifications, Software testing, Verification, Program debugging, Translation (languages), High quality, Alignment, State of the art, Code debugging, Formal programs, Program specification, Program synthesis, Program translators, Program Verification},
	pages = {25 -- 37},
	annote = {Cited by: 15; Conference name: 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2020; Conference date: 8 November 2020 through 13 November 2020; Conference code: 164831},
	annote = {Cited by: 17; Conference name: 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2020; Conference date: 8 November 2020 through 13 November 2020; Conference code: 164831},
	annote = {RELEVANCE: MEDIUM
},
}


@article{pi_automated_2019,
	title = {Automated {Mining} and {Checking} of {Formal} {Properties} in {Natural} {Language} {Requirements}},
	volume = {11776 LNAI},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077116773&doi=10.1007%2f978-3-030-29563-9_8&partnerID=40&md5=0f073f51cf59b3fbaed8a1dc3eedecec},
	doi = {10.1007/978-3-030-29563-9_8},
	abstract = {Bridging the gap between natural language requirements (NLR) and precise formal specifications is a crucial task of knowledge engineering. Software system development has become more complex in recent years, and it includes many requirements in different domains that users need to understand. Many of these requirements are expressed in natural language, which may be incomplete and ambiguous. However, the formal language with its rigorous semantics may accurately represent certain temporal logic properties and allow for automatic validation analysis. It is difficult for software engineers to understand the formal temporal logic from numerous requirements. In this paper, we propose a novel method to automatically mine the linear temporal logic (LTL) from the natural language requirements and check the consistency among different formal properties. We use natural language processing (NLP) to parse requirement sentences and map syntactic dependencies to LTL formulas by using our extraction rules. Also, we apply the automata-based model checking to assess the correctness and consistency of the extracted properties. Through implementation and case studies, we demonstrate that our approach is well suited to deal with the temporal logic requirements upon which the natural language is based. © 2019, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Pi, Xingxing and Shi, Jianqi and Huang, Yanhong and Wei, Hansheng},
	editor = {C, Douligeris and D, Apostolou and D, Karagiannis},
	year = {2019},
	note = {ISBN: 978-303029562-2
Publisher: Springer
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Semantics, Temporal logic, Natural language requirements, NAtural language processing, Formal languages, Linear temporal logic, Model checking, Computer circuits, Automata-based model, Automatic validation, Syntactic dependencies, Temporal logic properties},
	pages = {75 -- 87},
	annote = {Cited by: 0; Conference name: 12th International Conference on Knowledge Science, Engineering and Management, KSEM 2019; Conference date: 28 August 2019 through 30 August 2019; Conference code: 230379},
	annote = {RELEVANCE: MEDIUM
},
}


@article{gervasi_ambiguity_2019,
	title = {Ambiguity in {Requirements} {Engineering}: {Towards} a {Unifying} {Framework}},
	volume = {11865 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073690565&doi=10.1007%2f978-3-030-30985-5_12&partnerID=40&md5=815e14d66c5950d2e94db73481135335},
	doi = {10.1007/978-3-030-30985-5_12},
	abstract = {A long stream of research in RE has been devoted to analyzing the occurrences and consequences of ambiguity in requirements documents. Ambiguity often occurs in documents, most often in natural language (NL) ones, but occasionally also in formal specifications, be it because of abstraction, or of imprecise designation of which real-world entities are denotated by certain expressions. In many of those studies, ambiguity has been considered a defect to be avoided. In this paper, we investigate the nature of ambiguity, and advocate that the simplistic view of ambiguity as merely a defect in the document does not do justice to the complexity of this phenomenon. We offer a more extensive analysis, based on the multiple linguistic sources of ambiguity, and present a list of real-world cases, both in written matter and in oral interviews, that we analyze based on our framework. We hope that a better understanding of the phenomenon can help in the analysis of practical experiences and in the design of more effective methods to detect, mark and handle ambiguity. © 2019, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Gervasi, Vincenzo and Ferrari, Alessio and Zowghi, Didar and Spoletini, Paola},
	year = {2019},
	note = {Publisher: Springer Verlag
Type: Book chapter},
	keywords = {Defects, Natural languages, Artificial intelligence, Requirements document, Computer science, Real-world, Computers, Practical experience, Real-world entities},
	pages = {191 -- 210},
	annote = {Cited by: 11; All Open Access, Green Open Access},
	annote = {Cited by: 12; All Open Access, Green Open Access},
	annote = {RELEVANCE: MEDIUM

},
}


@article{luo_generating_2020,
	title = {Generating {Linear} {Temporal} {Logics} {Based} on {Property} {Specification} {Templates}},
	volume = {850},
	issn = {1860949X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071605507&doi=10.1007%2f978-3-030-26428-4_1&partnerID=40&md5=049deb5fcd11d1578865925e76542ed5},
	doi = {10.1007/978-3-030-26428-4_1},
	abstract = {Temporal logics are widely used in software verification such as model checking. However, creating temporal logics such as linear temporal logics (LTLs) based on property specifications written in a natural language is difficult due to practitioners’ unfamiliarity with property specifications and notations of temporal logics. Although property specification patterns have been introduced to help write correct temporal logics, creating temporal logics using property specification patterns requires an understanding of the pattern system. Since some patterns are difficult to understand, especially for beginners, and the final temporal logics are usually complicated, creating temporal logics using pattern systems is time consuming and error-prone. Here, we introduce a method to create LTLs based on property specification patterns. We experimentally compare the required time and accuracy of our approach to those using property specification patterns. Our approach can improve the creation of LTLs in terms of speed and accuracy. Although our experiment is implemented in Japanese, the results should be applicable to other languages such as English. We also provide a visualization scheme so that practitioners can understand the generated LTLs and confirm that they are correct. © 2020, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Studies in Computational Intelligence},
	author = {Luo, Weibin and Washizaki, Hironori and Fukazawa, Yoshiaki},
	year = {2020},
	note = {Publisher: Springer Verlag
Type: Book chapter},
	pages = {1 -- 15},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{habib_detecting_2021,
	title = {Detecting {Requirements} {Smells} {With} {Deep} {Learning}: {Experiences}, {Challenges} and {Future} {Work}},
	doi = {10.1109/REW53955.2021.00027},
	abstract = {Requirements Engineering (RE) is one of the initial phases when building a software system. The success or failure of a software project is firmly tied to this phase, based on communication among stakeholders using natural language. The problem with natural language is that it can easily lead to different understandings if it is not expressed precisely by the stakeholders involved. This results in building a product which is different from the expected one. Previous work proposed to enhance the quality of the software requirements by detecting language errors based on ISO 29148 requirements language criteria. The existing solutions apply classical Natural Language Processing (NLP) to detect them. NLP has some limitations, such as domain dependability which results in poor generalization capability. Therefore, this work aims to improve the previous work by creating a manually labeled dataset and using ensemble learning, Deep Learning (DL), and techniques such as word embeddings and transfer learning to overcome the generalization problem that is tied with classical NLP and improve precision and recall metrics using a manually labeled dataset. The current findings show that the dataset is unbalanced and which class examples should be added more. It is tempting to train algorithms even if the dataset is not considerably representative. Whence, the results show that models are overfitting; in Machine Learning this issue is adressed by adding more instances to the dataset, improving label quality, removing noise, and reducing the learning algorithms complexity, which is planned for this research.},
	booktitle = {2021 {IEEE} 29th {International} {Requirements} {Engineering} {Conference} {Workshops} ({REW})},
	author = {Habib, Mohammad Kasra and Wagner, Stefan and Graziotin, Daniel},
	month = sep,
	year = {2021},
	pages = {153--156},
	annote = {medium
},
}


@inproceedings{ye_natural_2022,
	title = {A {Natural} {Language} {Instruction} {Disambiguation} {Method} for {Robot} {Grasping}},
	url = {https://doi.org/10.1109/ROBIO54168.2021.9739456},
	doi = {10.1109/ROBIO54168.2021.9739456},
	abstract = {Robot grasping under the instruction of natural language has attracted increasing attention in various applications for its advantages in enabling natural and smooth human-robot interaction. At present, mainstream algorithms mainly solve problems of utilizing simple natural language instructions to guide the robot arm to perform some specific grasping. However, for two natural language instructions with different temporal logic and the same semantics, it is usually difficult for the robot to achieve semantic disambiguation, which further leads to the failure of the grasping task. In order to address this problem, we propose a new natural language instruction disambiguation method for robot grasping by combining sentence vector similarity calculation model and sentence temporal logic model. Firstly, the word vector is obtained through the Skip-gram model in Word2vec and a sentence vector is constructed. The semantic similarity of the sentence is then calculated by using the proposed cost function. Based on the semantic similarity of the sentence, the correct temporal logic form of the sentence is then extracted according to the temporal adverbial priority to further guide the grabbing process of the robot arm. The experimental results show that our method can successfully realize the semantic disambiguation for natural language instructions with different temporal logics and the same semantics, and further guide the robot arm to complete more complicated tasks than previous tasks.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Biomimetics} ({ROBIO})},
	publisher = {IEEE Press},
	author = {Ye, Rongguang and Xu, Qingchuan and Liu, Jie and Hong, Yang and Sun, Chengfeng and Chi, Wenzheng and Sun, Lining},
	year = {2022},
	note = {Place: Sanya, China},
	keywords = {Natural languages, Semantics, Temporal logic, Calculations, Computer circuits, Cost functions, Human robot interaction, Robotics, Disambiguation method, Natural language instruction, Robot arms, Robot grasping, Robotic arms, Semantic disambiguation, Semantic similarity, Sentence vector similarity calculation, Similarity calculation, Vector similarity, Vectors},
	pages = {601--606},
	annote = {Cited by: 1; Conference name: 2021 IEEE International Conference on Robotics and Biomimetics, ROBIO 2021; Conference date: 27 December 2021 through 31 December 2021; Conference code: 178223},
	annote = {Cited by: 1; Conference name: 2021 IEEE International Conference on Robotics and Biomimetics, ROBIO 2021; Conference date: 27 December 2021 through 31 December 2021; Conference code: 178223},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{bugayenko_combining_2021,
	address = {New York, NY, USA},
	series = {{BCNC} 2021},
	title = {Combining {Object}-{Oriented} {Paradigm} and {Controlled} {Natural} {Language} for {Requirements} {Specification}},
	isbn = {978-1-4503-9125-2},
	url = {https://doi.org/10.1145/3486949.3486963},
	doi = {10.1145/3486949.3486963},
	abstract = {Natural language is the dominant form of writing software requirements. Its essential ambiguity causes inconsistency of requirements, which leads to scope creep. On the other hand, formal requirements specification notations such as Z, Petri Nets, SysML, and others are difficult to understand by non-technical project stakeholders. They often become a barrier between developers and requirements providers. The article presents a controlled natural language that looks like English but is a strongly typed object-oriented language compiled to UML/XMI. Thus, it is easily understood, at the same time, by non-technical people, programmers, and computers. Moreover, it is formally verifiable and testable. It was designed, developed, and tested in three commercial software projects in order to validate the assumption that object-oriented design can be applied to requirements engineering at the level of specifications writing. The article outlines key features of the language and summarizes the experience obtained during its practical application.},
	booktitle = {Proceedings of the 1st {ACM} {SIGPLAN} {International} {Workshop} on {Beyond} {Code}: {No} {Code}},
	publisher = {Association for Computing Machinery},
	author = {Bugayenko, Yegor},
	year = {2021},
	note = {event-place: Chicago, IL, USA},
	keywords = {Petri nets, Natural language processing systems, Natural languages, Requirements engineering, Software requirements, Specifications, Software testing, Requirements specifications, Object oriented programming, Requirement, Controlled natural language, Formal requirement specifications, Requirements, Natural Language Processing, Object-oriented languages, Object-oriented paradigm, Project stakeholders, Technical programme},
	pages = {11--17},
	annote = {Cited by: 1; Conference name: 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, BCNC 2021, co-located with SPLASH 2021; Conference date: 17 October 2021; Conference code: 172642},
	annote = {Cited by: 1; Conference name: 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, BCNC 2021, co-located with SPLASH 2021; Conference date: 17 October 2021; Conference code: 172642},
	annote = {Cited by: 1; Conference name: 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, BCNC 2021, co-located with SPLASH 2021; Conference date: 17 October 2021; Conference code: 172642},
	annote = {Cited by: 1; Conference name: 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, BCNC 2021, co-located with SPLASH 2021; Conference date: 17 October 2021; Conference code: 172642},
	annote = {Cited by: 1; Conference name: 1st ACM SIGPLAN International Workshop on Beyond Code: No Code, BCNC 2021, co-located with SPLASH 2021; Conference date: 17 October 2021; Conference code: 172642},
	annote = {event-place: Chicago, IL, USA},
	annote = {event-place: Chicago, IL, USA},
	annote = {event-place: Chicago, IL, USA},
	annote = {RELEVANCE: MEDIUM

Controlled natural language

},
}


@inproceedings{a_abdelnabi_algorithmic_2021,
	address = {New York, NY, USA},
	series = {{ICEMIS}'21},
	title = {An {Algorithmic} {Approach} for {Generating} {Behavioral} {UML} {Models} {Using} {Natural} {Language} {Processing}},
	isbn = {978-1-4503-9044-6},
	url = {https://doi.org/10.1145/3492547.3492612},
	doi = {10.1145/3492547.3492612},
	abstract = {The process of transformation from informal requirements stated in natural language into a formal specification such as Unified Modeling Language (UML) is an important challenge. User requirements that are expressed in natural language can be very problematic, which makes the requirements analysis a difficult task. In this paper, we propose a method to analyze the natural language requirements and generate sequence and collaboration diagrams from these requirements, which are commonly used to describe the behavior of software systems. A case study was accomplished to compare the diagrams generated by the proposed approach to the diagrams produced by other approaches. The results showed that the elements of the sequence and collaboration diagrams extracted through our approach are very satisfactory and they would be acceptable as initial analysis models.},
	booktitle = {The 7th {International} {Conference} on {Engineering} \&amp; {MIS} 2021},
	publisher = {Association for Computing Machinery},
	author = {A. Abdelnabi, Esra and M. Maatuk, Abdelsalam and M. Abdelaziz, Tawfig},
	year = {2021},
	note = {event-place: Almaty, Kazakhstan},
	keywords = {Natural language processing systems, Natural languages, User requirements, Unified Modeling Language, Requirement analysis, Language model, Algorithmic approach, Algorithmic languages, Collaboration diagram, Graphic methods, Informal requirements, NLP tools, Sequence and Collaboration diagrams, Sequence diagrams, UML diagrams, Unified modeling language diagrams},
	annote = {Cited by: 3; Conference name: 7th International Conference on Engineering and MIS, ICEMIS 2021; Conference date: 11 October 2021 through 13 October 2021; Conference code: 175544},
	annote = {Cited by: 4; Conference name: 7th International Conference on Engineering and MIS, ICEMIS 2021; Conference date: 11 October 2021 through 13 October 2021; Conference code: 175544},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{zhang_automated_2020,
	address = {San Jose, CA, USA},
	series = {{DATE} '20},
	title = {Automated {Generation} of {LTL} {Specifications} for {Smart} {Home} {IoT} {Using} {Natural} {Language}},
	isbn = {978-3-9819263-4-7},
	abstract = {Ordinary users can build their smart home automation system easily nowadays, but such user-customized systems could be error-prone. Using formal verification to prove the correctness of such systems is necessary. However, to conduct formal proof, formal specifications such as Linear Temporal Logic (LTL) formulas have to be provided, but ordinary users cannot author LTL formulas but only natural language.To address this problem, this paper presents a novel approach that can automatically generate formal LTL specifications from natural language requirements based on domain knowledge and our proposed ambiguity refining techniques. Experimental results show that our approach can achieve a high correctness rate of 95.4\% in converting natural language sentences into LTL formulas from 481 requirements of real examples.},
	booktitle = {Proceedings of the 23rd {Conference} on {Design}, {Automation} and {Test} in {Europe}},
	publisher = {EDA Consortium},
	author = {Zhang, Shiyu and Zhai, Juan and Bu, Lei and Chen, Mingsong and Wang, Linzhang and Li, Xuandong},
	year = {2020},
	note = {event-place: Grenoble, France},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Temporal logic, Natural language requirements, Linear temporal logic, Internet of things, Automated generation, Automation, Formal proofs, Correctness rates, Domain knowledge, Real example},
	pages = {622--625},
	annote = {Cited by: 8; Conference name: 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020; Conference date: 9 March 2020 through 13 March 2020; Conference code: 161220},
	annote = {Cited by: 8; Conference name: 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020; Conference date: 9 March 2020 through 13 March 2020; Conference code: 161220},
	annote = {Cited by: 12; Conference name: 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020; Conference date: 9 March 2020 through 13 March 2020; Conference code: 161220},
	annote = {Cited by: 12; Conference name: 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020; Conference date: 9 March 2020 through 13 March 2020; Conference code: 161220},
	annote = {event-place: Grenoble, France},
	annote = {RELEVANCE: HIGH
},
	annote = {Type: Conference paper},
}


@inproceedings{ye_components_2020,
	address = {New York, NY, USA},
	series = {{WSSE} '20},
	title = {Components {Interaction} {Safety} {Analysis} {Method} {Based} on {STAMP} and {Formal} {Verification}},
	isbn = {978-1-4503-8787-3},
	url = {https://doi.org/10.1145/3425329.3425390},
	doi = {10.1145/3425329.3425390},
	abstract = {The traditional safety analysis method is based on the event chain theory, which is not suitable for analyzing the accident caused by components interaction problems of complex system. However, the System Theoretic Accident Model and Process(STAMP) can overcome this difficulty. There are some shortcomings in the current research on STAMP, such as describing the model with natural language and relying on manual analysis. Therefore, this paper proposes a components interaction safety analysis method based on STAMP and formal verification. Taking the aero-engine control system as an example, the root cause of system hazard is obtained and the feasibility of the proposed method is verified.},
	booktitle = {Proceedings of the 2nd {World} {Symposium} on {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Ye, Nan and Zhang, Jianguo and Wu, Jie},
	year = {2020},
	note = {event-place: Chengdu, China},
	keywords = {Natural languages, Formal verification, Aircraft engines, Safety analysis, Accident models, Accidents, Aero-engine, aero-engine control system, Chain theory, Components interaction, Manual analysis, model checking, STAMP, System hazards, system safety analysis},
	pages = {46--50},
	annote = {Cited by: 0; Conference name: 2nd World Symposium on Software Engineering, WSSE 2020; Conference date: 25 September 2020 through 27 September 2020; Conference code: 165162},
	annote = {Cited by: 0; Conference name: 2nd World Symposium on Software Engineering, WSSE 2020; Conference date: 25 September 2020 through 27 September 2020; Conference code: 165162},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{wein_fully_2021,
	title = {A {Fully} {Automated} {Approach} to {Requirement} {Extraction} from {Design} {Documents}},
	volume = {2021-March},
	isbn = {978-1-72817-436-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111403199&doi=10.1109%2fAERO50100.2021.9438170&partnerID=40&md5=28e38fdf40c788256a15d42ee52109d3},
	doi = {10.1109/AERO50100.2021.9438170},
	abstract = {Design documents are intended to outline the goals of a system or project, which are utilized in the creation of specific software requirements. At the NASA Jet Propulsion Laboratory, California Institute of Technology, Functional Design Description (FDD) documents describe the scope of the project and reflect the design and implementation of the system. The specifications in the document are not explicitly written as requirements, though these guidelines must be reflected in the official software requirements. In this work we present a fully automatic approach to extracting software requirements from design documents as well as comparing the extracted requirements to those that exist in the official software requirement database. We do this through (1) sentence extraction from the design document, (2) the incorporation of coreferent text, and (3) aligning the extracted text to the official software requirements. Via natural language processing and information retrieval techniques, our system results in an automated process that ensures that the specifications in the design document result in official software requirements. We find that extraction of imperatives results in a recall rate of 0.73 and the TF-IDF cosine similarity metric is shown to be a useful and successful way to compare requirements. Though there has been recent work investigating the usefulness of natural language processing techniques in requirement engineering, this has not been made use of in the aerospace industry. Aerospace requirement engineering is a field particularly ripe for this type of innovation because these techniques can both automate some of needlessly manual work and contribute to aerospace safety practices by identifying issues that a human may miss. We present the first fully automated approach that extracts requirements from a design document and compares them to a database, and use these findings as encouragement for future work that makes use of natural language processing techniques in aerospace requirement engineering. © 2021 IEEE.},
	language = {English},
	booktitle = {{IEEE} {Aerospace} {Conference} {Proceedings}},
	publisher = {IEEE Computer Society},
	author = {Wein, Shira and Briggs, Paul},
	year = {2021},
	note = {ISSN: 1095323X
Type: Conference paper},
	keywords = {Natural language processing systems, Requirements engineering, Extraction, NAtural language processing, Software requirements, Specifications, Automation, Requirement engineering, Aerospace engineering, Aerospace industry, Automatic approaches, California Institute of Technology, Cosine similarity metric, Design and implementations, NASA, Search engines, Sentence extraction},
	annote = {Cited by: 3; Conference name: 2021 IEEE Aerospace Conference, AERO 2021; Conference date: 6 March 2021 through 13 March 2021; Conference code: 170491},
	annote = {Cited by: 4; Conference name: 2021 IEEE Aerospace Conference, AERO 2021; Conference date: 6 March 2021 through 13 March 2021; Conference code: 170491},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{pogodin_use_2021,
	title = {The {Use} of {Model}-{Theoretical} {Methods} for {Automated} {Knowledge} {Extraction} from {Medical} {Texts}},
	volume = {2021-June},
	isbn = {978-1-66541-498-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113540901&doi=10.1109%2fEDM52169.2021.9507606&partnerID=40&md5=8ffa62f464302049483ed4aaa229d535},
	doi = {10.1109/EDM52169.2021.9507606},
	abstract = {The paper is devoted to the application of model-theoretical methods for extraction of knowledge from medical texts and documents and its formal representation. The aim of the work is to automate the filling of knowledge bases of the IACPaaS platform using knowledge from texts of disease descriptions. IACPaaS is a cloud platform for the development, management and remote use of intelligent cloud services. The peculiarities of disease description texts are the presence of medical word terms (such as 'blood pressure') and the abundance of sentences with clauses and homogeneous sentence members. To solve the problem of knowledge extraction, methods of transforming natural language sentences into quantifier-free formulas of the first-order predicate logic are used. Knowledge extracted from texts is formalized in the form of sets of atomic sentences that form fragments of atomic diagrams of algebraic systems. Further, a knowledge tree is built from the fragments of atomic diagrams, which serves as an intermediate representation of knowledge for subsequent translation into the format of IACPaaS information resources. The software system allows medical workers to fill knowledge bases with descriptions of diseases in shorter time, and gives the opportunity to check the consistency of the obtained formal specifications automatically. © 2021 IEEE.},
	language = {English},
	booktitle = {International {Conference} of {Young} {Specialists} on {Micro}/{Nanotechnologies} and {Electron} {Devices}, {EDM}},
	publisher = {IEEE Computer Society},
	author = {Pogodin, Ruslan S. and Palchunov, Dmitry},
	year = {2021},
	note = {ISSN: 23254173
Type: Conference paper},
	keywords = {Natural languages, Data mining, Extraction, Software systems, Formal representations, Intermediate representations, Algebraic system, Atoms, Blood pressure, Electron devices, Information resource, Knowledge extraction, Theoretical methods},
	pages = {555 -- 560},
	annote = {Cited by: 0; Conference name: 22nd IEEE International Conference of Young Professionals in Electron Devices and Materials, EDM 2021; Conference date: 30 June 2021 through 4 July 2021; Conference code: 171291},
	annote = {RELEVANCE: MEDIUM
https://ieeexplore.ieee.org/abstract/document/9507606
},
}


@inproceedings{osama_enhancing_2021,
	title = {Enhancing {NL} {Requirements} {Formalisation} {Using} a {Quality} {Checking} {Model}},
	isbn = {978-1-66542-856-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123199170&doi=10.1109%2fRE51729.2021.00064&partnerID=40&md5=fb7e14a8d605ba964f0167d995428138},
	doi = {10.1109/RE51729.2021.00064},
	abstract = {The formalisation of natural language (NL) requirements is a challenging problem because NL is inherently vague and imprecise. Existing formalisation approaches only support requirements adhering to specific boilerplates or templates, and are affected by the requirements quality issues. Several quality models are developed to assess the quality of NL requirements. However, they do not focus on the quality issues affecting the formalisability of requirements. Such issues can greatly compromise the operation of complex systems and even lead to catastrophic consequences or loss of life (in case of critical systems). In this paper, we propose a requirements quality checking approach utilising natural language processing (NLP) analysis. The approach assesses the quality of the requirements against a quality model that we developed to enhance the formalisability of NL requirements. We evaluate the effectiveness of our approach by comparing the formalisation efficiency of a recent automatic formalisation technique before and after utilising our approach. The results show an increase of approximately 15\% in the F-measure (from 83.8\% to 98\%). © 2021 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Requirements} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Osama, Mohamed and Zaki-Ismail, Aya and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {A, Moreira and K, Schneider and M, Vierhauser and J, Cleland-Huang},
	year = {2021},
	note = {ISSN: 1090705X
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Quality control, Requirements engineering, Natural language requirements, Requirements formalizations, Requirements specifications, Formalisation, Quality analyse, Quality issues, Quality modeling, Requirement analysis, Support requirements},
	pages = {448 -- 449},
	annote = {Cited by: 1; Conference name: 29th IEEE International Requirements Engineering Conference, RE 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 174516},
	annote = {Cited by: 1; Conference name: 29th IEEE International Requirements Engineering Conference, RE 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 174516},
	annote = {RELEVANCE: MEDIUM

},
}


@inproceedings{mishra_survey_2021,
	title = {A {Survey} on {Formal} {Specification} of {Security} {Requirements}},
	isbn = {978-1-66543-811-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126935073&doi=10.1109%2fICAC3N53548.2021.9725779&partnerID=40&md5=27397a787675136ecb401bfb3d15d085},
	doi = {10.1109/ICAC3N53548.2021.9725779},
	abstract = {Formalization of security requirements ensures the correctness of any safety-critical system, software system, and web applications through specification and verification. Although there is a gap between security requirements expressed in natural language and formal language. Formal language is a more powerful tool based on higher-order mathematics to express unambiguous and concise security requirements.it remains an active research challenge to express precise, concrete, and correct security requirements. Identification of security requirements is also a challenging task because requirement inherent in the software changes frequently. Specification through formal methods is possible only after fixing the security requirements. In this study, we propose a formal specification software process model (FSSPM). The proposed model indicates the use of formal specification at the early phase of software development is cost-effective, time saving, and reduces the possibility of error at the later phase of software development. © 2021 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2021 3rd {International} {Conference} on {Advances} in {Computing}, {Communication} {Control} and {Networking}, {ICAC3N} 2021},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Mishra, Aditya Dev and Mustafa, Khurram},
	editor = {V, Sharma and R, Srivastava and M, Singh},
	year = {2021},
	note = {Type: Conference paper},
	keywords = {Formal specification, Software design, Formal languages, Formal verification, Cryptography, Security requirements, Safety engineering, Formalisation, Software-systems, Security properties, Application programs, Cost effectiveness, Safety critical systems, Specification and verification, System applications, System softwares, WEB application, Web applications},
	pages = {1453 -- 1456},
	annote = {Cited by: 0; Conference name: 3rd International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2021; Conference date: 17 December 2021 through 18 December 2021; Conference code: 177627},
	annote = {Cited by: 2; Conference name: 3rd International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2021; Conference date: 17 December 2021 through 18 December 2021; Conference code: 177627},
	annote = {RELEVANCE: MEDIUM check
},
}


@inproceedings{koscinski_natural_2021,
	title = {A {Natural} {Language} {Processing} {Technique} for {Formalization} of {Systems} {Requirement} {Specifications}},
	volume = {2021-September},
	isbn = {978-1-66541-898-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118422069&doi=10.1109%2fREW53955.2021.00062&partnerID=40&md5=279e4d6dd34f6250d402fd03fc69ac44},
	doi = {10.1109/REW53955.2021.00062},
	abstract = {Natural language processing techniques have proven to be useful for analysis of technical specifications documents. One such technique, information extraction (IE), can help automate the analysis of software systems requirement specifications (SysRS) by extracting structured information from unstructured or semi-structured natural language data, allowing for requirements to be converted into formal logic. Current IE techniques are not designed for SysRS data, and often do not extract the information needed for requirements formalization. In this work, we introduce an IE method specifically designed for SysRS data. We provide a description of our approach, analysis of the technique on a set of real requirements, example of how information obtained using our technique can be converted into a formal logic representation, and discussion of our technique and its benefits in automated SysRS analysis tasks. © 2021 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Requirements} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Koscinski, Viktoria and Gambardella, Celeste and Gerstner, Estey and Zappavigna, Mark and Cassetti, Jennifer and Mirakhorli, Mehdi},
	editor = {T, Yue and M, Mirakhorli},
	year = {2021},
	note = {ISSN: 1090705X
Type: Conference paper},
	keywords = {Natural language processing systems, Requirements engineering, Data mining, Artificial intelligence, Information retrieval, Computer circuits, Requirements formalizations, Semi-structured, Language processing techniques, Formalisation, Requirement analysis, Software-systems, Formal logic, Specifications document, Structured information, System requirements specifications, Technical specifications},
	pages = {350 -- 356},
	annote = {Cited by: 5; Conference name: 29th IEEE International Requirements Engineering Conference Workshops, REW 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 173221},
	annote = {Cited by: 5; Conference name: 29th IEEE International Requirements Engineering Conference Workshops, REW 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 173221},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{trakhtenbrot_approach_2019,
	title = {An approach to validation of combined natural language and formal requirements for control systems},
	isbn = {978-1-72815-165-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078019988&doi=10.1109%2fREW.2019.00025&partnerID=40&md5=999f0266012e9da0e731864cee90c46e},
	doi = {10.1109/REW.2019.00025},
	abstract = {The paper presents a novel approach to validation of behavioral requirements for control systems. A requirement is specified by a natural language pattern and its expression in Linear Temporal Logic (LTL). This way flexibility and understandability of natural language is combined with advantages of formalization that is a basis for various stages of system development, testing and verification. Still, validity of the requirements remains a major challenge. The paper considers application of mutation analysis for capturing of correct behavioral requirements. Generation and exploration of mutants supports a better understanding of requirements, The novelty of the approach is that the suggested mutations are semantic-based, as opposed to the more common syntax-based mutation analysis. A significant advantage of the approach is that it allows to focus only on plausible potential faults in understanding of the required system behavior, and to avoid generation of a vast amount of mutants that are irrelevant to the intended meaning of the requirements. Moreover, in many cases the effect of semantic-based mutations just can not be achieved by usual syntax-based mutations of LTL formulas associated with requirements. The approach is illustrated using a rail cross control example. © 2019 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2019 {IEEE} 27th {International} {Requirements} {Engineering} {Conference} {Workshops}, {REW} 2019},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Trakhtenbrot, Mark},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Natural languages, Requirements engineering, Semantics, Temporal logic, Linear temporal logic, Software testing, Syntactics, Control system analysis, Control systems, Mutation analysis, Natural language patterns, Potential faults, Requirements validation, System development, Understandability},
	pages = {110 -- 115},
	annote = {Cited by: 0; Conference name: 27th IEEE International Requirements Engineering Conference Workshops, REW 2019; Conference date: 23 September 2019 through 27 September 2019; Conference code: 156154},
	annote = {Cited by: 0; Conference name: 27th IEEE International Requirements Engineering Conference Workshops, REW 2019; Conference date: 23 September 2019 through 27 September 2019; Conference code: 156154},
	annote = {RELEVANCE: MEDIUM
},
}


@article{zinovia_stefanidiasterios_leonidismargherita_antona_multi-stage_2019,
	title = {A {Multi}-stage {Approach} to {Facilitate} {Interaction} with {Intelligent} {Environments} via {Natural} {Language}},
	url = {{http://link.springer.com/chapter/10.1007/978-3-030-30712-7_9}},
	doi = {10.1007/978-3-030-30712-7_9},
	journal = {HCI International 2019 – Late Breaking Posters},
	author = {{Zinovia StefanidiAsterios LeonidisMargherita Antona}},
	year = {2019},
	keywords = {Natural language processing systems, NAtural language processing, Internet of things, Chatbot, Intelligent agents, Human computer interaction, Conversational agents, Home automation, Intelligent environment, Intelligent home},
	annote = {Cited by: 3; Conference name: 21st International Conference on Human Computer Interaction, HCII 2019; Conference date: 26 July 2019 through 31 July 2019; Conference code: 232579},
	annote = {Cited by: 3; Conference name: 21st International Conference on Human Computer Interaction, HCII 2019; Conference date: 26 July 2019 through 31 July 2019; Conference code: 232579},
	annote = {RELEVANCE: MEDUM
},
}


@article{moitra_automating_2019,
	title = {Automating {Requirements} {Analysis} and {Test} {Case} {Generation}},
	volume = {24},
	issn = {0947-3602},
	url = {https://doi.org/10.1007/s00766-019-00316-x},
	doi = {10.1007/s00766-019-00316-x},
	abstract = {Writing clear and unambiguous requirements that are conflict-free and complete is no easy task. Incorrect requirements lead to errors being introduced early in the design process. The longer the gap between error introduction and error discovery, the higher the cost associated with the error. To address the growing cost of system development, we introduce a tool called Analysis of Semantic Specifications and Efficient generation of Requirements-based Tests (ASSERT™) for capturing requirements, backed by a formal requirements analysis engine. ASSERT also automatically generates a complete set of requirements-based test cases. The requirements are captured in a structured natural language that is both human- and machine-readable. Formal analysis of these requirements with an automated theorem prover identifies errors as soon as requirements are written. It also addresses the historical problem that analysis engines are hard to use and understand for someone without formal methods expertise and analysis results are often difficult for the end-user to understand and make actionable. ASSERT's major contribution is to bring powerful requirements capture and analysis capability to the domain of the end-user. We provide explainable and automated formal analysis, something we found important for a tool's adoptability in industry. Automating test case generation in ASSERT also provides clear and measurable productivity gains in system development.},
	number = {3},
	journal = {Requir. Eng.},
	author = {Moitra, Abha and Siu, Kit and Crapo, Andrew W. and Durling, Michael and Li, Meng and Manolios, Panagiotis and Meiners, Michael and Mcmillan, Craig},
	month = sep,
	year = {2019},
	note = {Place: Berlin, Heidelberg
Publisher: Springer-Verlag},
	keywords = {Testing, Requirements engineering, Semantics, Ontology, Formal methods, Requirements analysis, Requirements formalizations, Automation, Engines, Analysis capabilities, Automated formal analysis, Automated requirements-based test generation, Automated theorem prover, Cost benefit analysis, Errors, Formal analysis, Formal analysis of requirements, Productivity, Requirements formalization, Semantic specification, Test generations},
	pages = {341--364},
	annote = {Cited by: 11},
	annote = {Cited by: 11},
	annote = {Cited by: 11},
	annote = {Cited by: 11},
	annote = {Cited by: 13},
	annote = {Place: Berlin, Heidelberg Publisher: Springer-Verlag},
	annote = {Place: Berlin, Heidelberg Publisher: Springer-Verlag},
	annote = {Place: Berlin, Heidelberg Publisher: Springer-Verlag},
	annote = {RELEVANCE: HIGH

Until 2018, NLP techniques were barely used: Transformation techniques Fig. 8
},
}


@inproceedings{janpitak_information_2019,
	title = {Information security requirement extraction from regulatory documents using {GATE}/{ANNIC}},
	isbn = {978-1-72810-729-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077960723&doi=10.1109%2fiEECON45304.2019.8938899&partnerID=40&md5=4aa23ad714e5626c1b441451cc21dcb9},
	doi = {10.1109/iEECON45304.2019.8938899},
	abstract = {Compliance is a concept of acting in accordance with established laws, regulations, etc. In order to judge that an organization is following the given rules or not, a compliance auditing is required. A compliance checking is an important activity of compliance auditing which require the extraction of compliance requirement from legal documents. There have been a more and more research challenges to automate the extraction of compliance requirements from the legal documents. This is because most legal documents are embodied in natural language which cannot be understood by the traditional computer system. Though a regulatory document comprises thousands of words, not every word is required in the automation of compliance checking requirement. Extracting only the essential content from the regulatory document can help to shorten the process of compliance requirement retrieving. This paper presents a methodology to extract the compliance requirements in term of goals (subject, object, target, action) which is the essential contents from the legal or regulatory documents by using GATE. GATE is a widely used tool for language engineering to support the machine to process the information extraction (IE) for queries and reasoning. Most researchers proposed to use the readymade application named ANNIE in GATE to extract the essential statements from any target documents. In our proposed method, we add the ANNIC which is a plug-in tool in GATE to help in searching for annotations, visualizing them and inspecting features. Using ANNIC can extract more detail from the ANNIE outcomes which is still in form of unstructured text into structured data such as table. © 2019 IEEE.},
	language = {English},
	booktitle = {{iEECON} 2019 - 7th {International} {Electrical} {Engineering} {Congress}, {Proceedings}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Janpitak, Nanta and Sathitwiriyawong, Chanboon and Pipatthanaudomdee, Phatwarat},
	year = {2019},
	note = {Type: Conference paper},
	keywords = {Regulatory compliance, ANNIC, ANNIE, Authentication, Compliance checking, Compliance control, GATE, Information retrieval, ISO27002, Legal documents},
	annote = {Cited by: 4; Conference name: 7th International Electrical Engineering Congress, iEECON 2019; Conference date: 6 March 2019 through 8 March 2019; Conference code: 156205},
	annote = {Cited by: 5; Conference name: 7th International Electrical Engineering Congress, iEECON 2019; Conference date: 6 March 2019 through 8 March 2019; Conference code: 156205},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{buzhinsky_formalization_2019,
	title = {Formalization of natural language requirements into temporal logics: {A} survey},
	volume = {2019-July},
	isbn = {978-1-72812-927-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079053792&doi=10.1109%2fINDIN41052.2019.8972130&partnerID=40&md5=d98fe5baa7407ebcf859e1c8630898b6},
	doi = {10.1109/INDIN41052.2019.8972130},
	abstract = {One of the challenges of requirements engineering is the fact that requirements are often formulated in natural language. This represents difficulty if requirements must be processed by formal approaches, especially if these approaches are intended to check the requirements. In model checking, a formal technique of verification by exhaustive state space exploration, requirements must be stated in formal languages (most commonly, temporal logics) which are essentially supersets of the Boolean propositional logic. Translation of natural language requirements to these languages is a process which requires much knowledge and expertise in model checking as well the ability to correctly understand these requirements, and hence automating this process is desirable. This paper reviews existing approaches of requirements formalization that are applicable for, or at least can be adapted to generation of discrete time temporal logic requirements. Based on the review, conclusions are made regarding the practical applicability of these approaches for the considered problem. © 2019 IEEE.},
	language = {English},
	booktitle = {{IEEE} {International} {Conference} on {Industrial} {Informatics} ({INDIN})},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Buzhinsky, Igor},
	year = {2019},
	note = {ISSN: 19354576
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Temporal logic, Natural language requirements, Formal languages, Model checking, Boolean functions, Computer circuits, Discrete time, Formal approach, Formal techniques, Industrial informatics, Propositional logic, Requirements formalizations, Space research, State space exploration},
	pages = {400 -- 406},
	annote = {Cited by: 17; Conference name: 17th IEEE International Conference on Industrial Informatics, INDIN 2019; Conference date: 22 July 2019 through 25 July 2019; Conference code: 157260},
	annote = {Cited by: 22; Conference name: 17th IEEE International Conference on Industrial Informatics, INDIN 2019; Conference date: 22 July 2019 through 25 July 2019; Conference code: 157260},
	annote = {RELEVANCE: HIGH
},
}


@article{winter_detecting_2018,
	title = {Detecting {Constraints} and {Their} {Relations} from {Regulatory} {Documents} {Using} {NLP} {Techniques}},
	volume = {11229 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055833260&doi=10.1007%2f978-3-030-02610-3_15&partnerID=40&md5=037bbecf4bd88af57b6643fd3290a881},
	doi = {10.1007/978-3-030-02610-3_15},
	abstract = {Extracting constraints and process models from natural language text is an ongoing challenge. While the focus of current research is merely on the extraction itself, this paper presents a three step approach to group constraints as well as to detect and display relations between constraints in order to ease their implementation. For this, the approach uses NLP techniques to extract sentences containing constraints, group them by, e.g., stakeholders or topics, and detect redundant, subsuming, and conflicting pairs of constraints. These relations are displayed using network maps. The approach is prototypically implemented and evaluated based on regulatory documents from the financial sector as well as expert interviews. © 2018, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Winter, Karolin and Rinderle-Ma, Stefanie},
	editor = {H.A, Proper and R, Meersman and C.A, Ardagna and H, Panetto and C, Debruyne and D, Roman},
	year = {2018},
	note = {ISBN: 978-303002609-7
Publisher: Springer Verlag
Type: Conference paper},
	keywords = {Compliance, Natural language processing systems, Data mining, Distributed computer systems, Extraction, Financial sectors, Group constraints, Multi agent systems, Natural language text, Nlp techniques, Regulatory compliance, Regulatory documents, Semantics, Text mining, Three-step approach},
	pages = {261 -- 278},
	annote = {Cited by: 15; Conference name: Confederated International Conferences: Cooperative Information Systems, CoopIS 2018, Ontologies, Databases, and Applications of Semantics, ODBASE 2018, and Cloud and Trusted Computing, C and TC, held as part of OTM 2018; Conference date: 22 October 2018 through 26 October 2018; Conference code: 219839},
	annote = {RELEVANCE: MEDIUM

},
}


@inproceedings{hsiung_generalizing_2022,
	title = {Generalizing to {New} {Domains} by {Mapping} {Natural} {Language} to {Lifted} {LTL}},
	url = {https://doi.org/10.1109/ICRA46639.2022.9812169},
	doi = {10.1109/ICRA46639.2022.9812169},
	abstract = {Recent work on using natural language to specify commands to robots has grounded that language to LTL. However, mapping natural language task specifications to LTL task specifications using language models require probability distributions over finite vocabulary. Existing state-of-the-art methods have extended this finite vocabulary to include unseen terms from the input sequence to improve output generalization. However, novel out-of-vocabulary atomic propositions cannot be generated using these methods. To overcome this, we introduce an intermediate contextual query representation which can be learned from single positive task specification examples, associating a contextual query with an LTL template. We demonstrate that this intermediate representation allows for generalization over unseen object references, assuming accurate groundings are available. We compare our method of mapping natural language task specifications to intermediate contextual queries against state-of-the-art CopyNet models capable of translating natural language to LTL, by evaluating whether correct LTL for manipulation and navigation task specifications can be output, and show that our method outperforms the CopyNet model on unseen object references. We demonstrate that the grounded LTL our method outputs can be used for planning in a simulated OO-MDP environment. Finally, we discuss some common failure modes encountered when translating natural language task specifications to grounded LTL.},
	booktitle = {2022 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE Press},
	author = {Hsiung, Eric and Mehta, Hiloni and Chu, Junchi and Liu, Xinyu and Patel, Roma and Tellex, Stefanie and Konidaris, George},
	year = {2022},
	note = {Place: Philadelphia, PA, USA},
	keywords = {Natural languages, Mapping, Specifications, Task specifications, Translation (languages), Language model, Atomic propositions, Generalisation, Input sequence, Linearization, Object reference, Probability distributions, Probability: distributions, Query representations, State-of-the-art methods},
	pages = {3624--3630},
	annote = {Cited by: 3; Conference name: 39th IEEE International Conference on Robotics and Automation, ICRA 2022; Conference date: 23 May 2022 through 27 May 2022; Conference code: 180851; All Open Access, Green Open Access},
	annote = {Cited by: 3; Conference name: 39th IEEE International Conference on Robotics and Automation, ICRA 2022; Conference date: 23 May 2022 through 27 May 2022; Conference code: 180851; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH

},
}


@inproceedings{luckcuck_methodology_2022,
	title = {A {Methodology} for {Developing} a {Verifiable} {Aircraft} {Engine} {Controller} from {Formal} {Requirements}},
	volume = {2022-March},
	isbn = {978-1-66543-760-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123429477&doi=10.1109%2fAERO53065.2022.9843589&partnerID=40&md5=7493b05faada29438601fb8c15d30b60},
	doi = {10.1109/AERO53065.2022.9843589},
	abstract = {Verification of complex, safety-critical systems is a significant challenge. Manual testing and simulations are often used, but are only capable of exploring a subset of the system's reachable states. Formal methods are mathematically-based techniques for the specification and development of software, which can provide proofs of properties and exhaustive checks over a system's state space. In this paper, we present a formal requirements-driven methodology, applied to a model of an aircraft engine controller that has been provided by our industrial partner. Our methodology begins by formalising the controller's natural-language requirements using the (pre-existing) Formal Requirements Elicitation Tool (FRET), iteratively, in consultation with our industry partner. Once formalised, FRET can automatically translate the requirements to enable their verification alongside a Simulink model of the aircraft engine controller; the requirements can also guide formal verification using other approaches. These two parallel streams in our methodology seek to combine the results from formal requirements elicitation, classical verification approaches, and runtime verification; to support the verification of aerospace systems modelled in Simulink, from the requirements phase through to execution. Our methodology harnesses the power of formal methods in a way that complements existing verification techniques, and supports the traceability of requirements throughout the verification process. This methodology streamlines the process of developing verifiable aircraft engine controllers, by ensuring that the requirements are formalised up-front and useable during development. In this paper we give an overview of FRET, describe our methodology and work to-date on the formalisation and verification of the requirements, and outline future work using our methodology. © 2022 IEEE.},
	language = {English},
	booktitle = {{IEEE} {Aerospace} {Conference} {Proceedings}},
	publisher = {IEEE Computer Society},
	author = {Luckcuck, Matt and Farrell, Marie and Sheridan, Oisin and Monahan, Rosemary},
	year = {2022},
	note = {ISSN: 1095323X
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural language requirements, Requirements elicitation, Formal verification, Safety engineering, Safety critical systems, Aircraft engines, Controllers, Engine controller, Engines, Industrial partners, Iterative methods, Manual testing, Property, Requirement-driven, State-space, System state},
	annote = {Cited by: 3; Conference name: 2022 IEEE Aerospace Conference, AERO 2022; Conference date: 5 March 2022 through 12 March 2022; Conference code: 181782; All Open Access, Green Open Access},
	annote = {Cited by: 3; Conference name: 2022 IEEE Aerospace Conference, AERO 2022; Conference date: 5 March 2022 through 12 March 2022; Conference code: 181782; All Open Access, Green Open Access},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{neider_expanding_2022,
	title = {Expanding the {Horizon} of {Linear} {Temporal} {Logic} {Inference} for {Explainability}},
	isbn = {978-1-66546-000-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142270653&doi=10.1109%2fREW56159.2022.00026&partnerID=40&md5=d0b451e3b1393227b80c40085342e543},
	doi = {10.1109/REW56159.2022.00026},
	abstract = {Linear Temporal Logic (LTL), a logical formalism originally developed for the verification of reactive systems, has emerged as a popular model for explaining the behavior of complex systems. The popularity of LTL as explanations can mainly be attributed to its similarity to natural language and its ease of use owing to its simple syntax and semantics. To aid the explanations using LTL, a task commonly known as inference of Linear Temporal Logic formulas, or LTL inference in short, has been of growing interest in recent years. Roughly, this task asks to infer succinct LTL formulas that describe a system based on its recorded observations. Inferring LTL formulas from a given set of positive and negative examples is a well-studied setting, with a number of competing approaches to tackle it. However, for the widespread applicability of LTL as explanations, we argue that one still needs to consider a number of different settings. In this vision paper, we, thus, discuss different problem settings of LTL inference and highlight how one can expand the horizon of LTL inference by investigating these settings. © 2022 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Requirements} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Neider, Daniel and Roy, Rajarshi},
	editor = {E, Knauss and G, Mussbacher and C, Arora and M, Bano and J.-G, Schneider},
	year = {2022},
	note = {ISSN: 1090705X
Type: Conference paper},
	keywords = {Natural languages, Semantics, Temporal logic, Reactive system, Linear temporal logic, Computer circuits, Temporal logic formula, Constraint satisfiability, Ease-of-use, Linear temporal logic constraint satisfiability explainable AI, Logic constraints, Logic inferences, Logical formalism},
	pages = {103 -- 107},
	annote = {Cited by: 0; Conference name: 30th IEEE International Requirements Engineering Conference Workshops, REW 2022; Conference date: 15 August 2022 through 19 August 2022; Conference code: 183744},
	annote = {Cited by: 1; Conference name: 30th IEEE International Requirements Engineering Conference Workshops, REW 2022; Conference date: 15 August 2022 through 19 August 2022; Conference code: 183744},
	annote = {RELEVANCE: MEDIUM
},
}


@article{nayak_req2spec_2022,
	title = {{Req2Spec}: {Transforming} {Software} {Requirements} into {Formal} {Specifications} {Using} {Natural} {Language} {Processing}},
	volume = {13216 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127033698&doi=10.1007%2f978-3-030-98464-9_8&partnerID=40&md5=41b06868600570e3f0f0b3e53ce5c111},
	doi = {10.1007/978-3-030-98464-9_8},
	abstract = {[Context and motivation] Requirement analysis and Test specification generation are critical activities in the Software Development Life Cycle (SDLC), which if not done correctly can lead to defects in the software system. Manually performing these tasks on Natural Language Requirements (NLR) is time consuming and error prone. [Question/problem] The problem is to facilitate the automation of these activities by transforming the NLR into Formal Specifications. [Principal ideas/results] In this paper we present Req2Spec, a Natural Language Processing (NLP) based pipeline that performs syntactic and semantic analysis on NLR to generate formal specifications that can be readily consumed by HANFOR, an industry scale Requirements analysis and Test specification generation tool. We considered 222 automotive domain software requirements at BOSCH, 71\% of which were correctly formalized. [Contribution] Req2Spec will be an aid to stakeholders of the SDLC as it seamlessly integrates with HANFOR enabling automation. © 2022, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Nayak, Anmol and Timmapathini, Hari Prasad and Murali, Vidhya and Ponnalagu, Karthikeyan and Venkoparao, Vijendran Gopalan and Post, Amalinda},
	editor = {V, Gervasi and A, Vogelsang},
	year = {2022},
	note = {ISBN: 978-303098463-2
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Software design, Semantics, Natural language requirements, Software requirements, Software testing, Requirements formalizations, Requirement analysis, Software-systems, Life cycle, Language model, Error prones, Software development life-cycle, Critical activities, Test specification generation},
	pages = {87 -- 95},
	annote = {Cited by: 3; Conference name: 28th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2022; Conference date: 21 March 2022 through 24 March 2022; Conference code: 274709},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{zaki-ismail_arf_2021,
	title = {{ARF}: {Automatic} {Requirements} {Formalisation} {Tool}},
	isbn = {978-1-66542-856-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123207416&doi=10.1109%2fRE51729.2021.00060&partnerID=40&md5=7eab04396607347c04259a0968dae2a2},
	doi = {10.1109/RE51729.2021.00060},
	abstract = {Formal verification techniques enable the detection of complex quality issues within system specifications. However, the majority of system requirements are usually specified in natural language (NL). Manual formalisation of NL requirements is an error-prone and labour-intensive process requiring strong mathematical expertise, and can be infeasible for large numbers of requirements. Existing automatic formalisation techniques usually support heavily constrained natural language relying on requirement boilerplates or templates. In this paper, we introduce ARF: Automatic Requirements Formalisation Tool. ARF can automatically transform free-format natural language requirements into temporal logic based formal notations. This is achieved through two steps: 1) extraction of key requirement attributes into an intermediate representation (RCM: Requirement Capturing Model), and 2) transformation rules that convert requirements from the RCM format to formal notations. © 2021 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Requirements} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {A, Moreira and K, Schneider and M, Vierhauser and J, Cleland-Huang},
	year = {2021},
	note = {ISSN: 1090705X
Type: Conference paper},
	keywords = {Natural language processing systems, Requirements engineering, Extraction, Natural language requirements, Specifications, Formal verification, Requirements formalizations, Requirement engineering, System requirements, Formalisation, Quality issues, Formal notations, Requirement extraction, Systems specification, Verification techniques},
	pages = {440 -- 441},
	annote = {Cited by: 1; Conference name: 29th IEEE International Requirements Engineering Conference, RE 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 174516},
	annote = {Cited by: 1; Conference name: 29th IEEE International Requirements Engineering Conference, RE 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 174516},
	annote = {RELEVANCE: HIGH
},
}


@article{soavi_contract_2020,
	title = {{ContracT} – from {Legal} {Contracts} to {Formal} {Specifications}: {Preliminary} {Results}},
	volume = {400},
	issn = {18651348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097073162&doi=10.1007%2f978-3-030-63479-7_9&partnerID=40&md5=ca9e5259305d86e56588fa22f6934f30},
	doi = {10.1007/978-3-030-63479-7_9},
	abstract = {We are interested in semi-automating the process of generating a formal specification from a legal contract in natural language text form. Towards this end, we present a tool, named ContracT, that annotates legal contract text using an ontology for legal contracts. In the last part of the paper, we present results from a preliminary empirical evaluation of the tool that provided encouraging results in identifying contract concepts in text and discuss critical points to be tackled in future studies. © 2020, IFIP International Federation for Information Processing.},
	language = {English},
	journal = {Lecture Notes in Business Information Processing},
	author = {Soavi, Michele and Zeni, Nicola and Mylopoulos, John and Mich, Luisa},
	editor = {J, Grabis and D, Bork},
	year = {2020},
	note = {ISBN: 978-303063478-0
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Formal specification, Natural language text, Data processing, Empirical evaluations, Legal contracts},
	pages = {124 -- 137},
	annote = {Cited by: 3; Conference name: 13th IFIP Working Conference on the Practice of Enterprise Modeling, PoEM 2020; Conference date: 25 November 2020 through 27 November 2020; Conference code: 251829; All Open Access, Green Open Access},
	annote = {Cited by: 3; Conference name: 13th IFIP Working Conference on the Practice of Enterprise Modeling, PoEM 2020; Conference date: 25 November 2020 through 27 November 2020; Conference code: 251829; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@book{harris_generation_2020,
	title = {Generation of verification artifacts from natural language descriptions},
	isbn = {978-3-030-52273-5 978-3-030-52271-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148547855&doi=10.1007%2f978-3-030-52273-5_3&partnerID=40&md5=ddd23ce069f3d91f899db13661255e16},
	abstract = {This chapter describes the generation of formal verification artifacts from natural language (NL) hardware specifications. Difficulties in the formalization process are described, including the linguistic variation problem which causes the mapping from NL to formal artifacts to be many-to-one. The use of semantic parsers is described as an approach which can map NL to formal models while addressing problems including linguistic variation. This chapter presents two approaches which use semantic parsing to generate formal models. The first approach uses an attribute grammar to generate SystemVerilog properties, and the second approach generates bus transactors which can be used as golden models of bus behavior. © Springer Nature Switzerland AG 2020.},
	language = {English},
	publisher = {Springer International Publishing},
	author = {Harris, Ian G. and Harris, Christopher B.},
	year = {2020},
	doi = {10.1007/978-3-030-52273-5_3},
	note = {Publication Title: Natural Language Processing for Electronic Design Automation
Type: Book chapter},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {Publication Title: Natural Language Processing for Electronic Design Automation Type: Book},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{hu_constructing_2020,
	title = {Constructing formal specification models from domain specific natural language requirements},
	isbn = {978-0-7381-0497-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098324503&doi=10.1109%2fISSSR51244.2020.00017&partnerID=40&md5=a89cd94768651813a00341752759776d},
	doi = {10.1109/ISSSR51244.2020.00017},
	abstract = {One important way to improve the quality of safety-critical software is to produce a good software requirement satisfying several key properties, such as: integrity, consistency, and well organized, etc. Our work is based on airborne software domain, and propose a framework to translate the software requirements, which are itemized with domain natural language in avionics, effectively into a formal specification model VRM (Variable Relation Model), which has table-style structures with formal semantics. Firstly, considering avionics domain characteristics, a domain concept library is established including different types of variables and concepts. Then, a set of domain-oriented requirements templates are defined, such as: general event/condition, display event/condition, etc. According to VRM model element semantics, three types model construction algorithms are designed to complete the translation automatically. And in the case study, the Engine Indication and Crew Warning System (EICAS) was selected to show how to construct formal models from natural language requirements. © 2020 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2020 6th {International} {Symposium} on {System} and {Software} {Reliability}, {ISSSR} 2020},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Hu, Jun and Hu, Jiancheng and Wang, Wenxuan and Kang, Jiexiang and Wang, Hui and Gao, Zhongjie},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Requirements engineering, Semantics, Natural language requirements, Software requirements, Safety engineering, Avionics, Domain template library, Engine indication and crew warning system, Model transition, Relation models, Safety critical software, Specification models, Template libraries, Translation (languages), Variable relation model},
	pages = {52 -- 60},
	annote = {Cited by: 6; Conference name: 6th International Symposium on System and Software Reliability, ISSSR 2020; Conference date: 24 October 2020 through 25 October 2020; Conference code: 165486},
	annote = {Cited by: 8; Conference name: 6th International Symposium on System and Software Reliability, ISSSR 2020; Conference date: 24 October 2020 through 25 October 2020; Conference code: 165486},
	annote = {RELEVANCE: HIGH
},
}


@article{han_van_der_aakarl_johannes_balderfabrizio_maria_maggialexander_nolte_say_2020,
	title = {Say {It} in {Your} {Own} {Words}: {Defining} {Declarative} {Process} {Models} {Using} {Speech} {Recognition}},
	url = {{http://link.springer.com/chapter/10.1007/978-3-030-58638-6_4}},
	doi = {10.1007/978-3-030-58638-6_4},
	journal = {Business Process Management Forum},
	author = {{Han van der AaKarl Johannes BalderFabrizio Maria MaggiAlexander Nolte}},
	year = {2020},
	keywords = {Semantics, Computer circuits, Declarative process models, Graphical notation, Declarative Languages, Speech recognition, Enterprise resource management, Business process model, Multi-perspective, Analysis toolkits, Logic based formalism, Recognition mechanism},
	annote = {Cited by: 4; Conference name: 18th International Conference on Business Process Management, BPM 2020; Conference date: 13 September 2020 through 18 September 2020; Conference code: 244799},
	annote = {RELEVANCE: HIGH

DECLARE
},
}


@article{gavran_interactive_2020,
	title = {Interactive {Synthesis} of {Temporal} {Specifications} from {Examples} and {Natural} {Language}},
	volume = {4},
	url = {https://doi.org/10.1145/3428269},
	doi = {10.1145/3428269},
	abstract = {Motivated by applications in robotics, we consider the task of synthesizing linear temporal logic (LTL) specifications based on examples and natural language descriptions. While LTL is a flexible, expressive, and unambiguous language to describe robotic tasks, it is often challenging for non-expert users. In this paper, we present an interactive method for synthesizing LTL specifications from a single example trace and a natural language description. The interaction is limited to showing a small number of behavioral examples to the user who decides whether or not they exhibit the original intent. Our approach generates candidate LTL specifications and distinguishing examples using an encoding into optimization modulo theories problems. Additionally, we use a grammar extension mechanism and a semantic parser to generalize synthesized specifications to parametric task descriptions for subsequent use. Our implementation in the tool LtlTalk starts with a domain-specific language that maps to a fragment of LTL and expands it through example-based user interactions, thus enabling natural language-like robot programming, while maintaining the expressive power and precision of a formal language. Our experiments show that the synthesis method is precise, quick, and asks only a few questions to the users, and we demonstrate in a case study how LtlTalk generalizes from the synthesized tasks to other, yet unseen, tasks.},
	number = {OOPSLA},
	journal = {Proc. ACM Program. Lang.},
	author = {Gavran, Ivan and Darulova, Eva and Majumdar, Rupak},
	month = nov,
	year = {2020},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {natural language processing, Natural language processing systems, Natural languages, Semantics, Temporal logic, Formal languages, Specifications, Domain specific languages, Problem oriented languages, Robotics, End effectors, Expressive power, Extension mechanisms, Interactive methods, Linear temporal logic specifications, LTL, program synthesis, Robot programming, robots, specification, Synthesis method, Temporal specification},
	annote = {Cited by: 6; All Open Access, Bronze Open Access},
	annote = {Cited by: 7; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: HIGH

They present LTLtalk

In this paper, we present an interactive method for synthesizing LTL specifications from a single example trace and a natural language description.
LTL provides a flexible, expressive, and unambiguous mechanism to describe complex task. Unfortunately, specifying tasks in LTL is challenging for untrained users

First, a synthesis procedure that takes a natural language description of a task and an example execution trace from the user and generates a set of candidate LTL specifications. Second, an interactive loop that uses distinguishing examples to identify the correct LTL specification. Third, a generalization step that eventually learns a parameterized LTL specification. The three components ensure the following properties.

Natural Language Interfaces for Robotics. In an attempt to provide a more natural specificationlanguage for robotics, but keep the precision of a formal language, Kress-Gazit et al. [2008] proposea controlled, natural looking language that matches a fragment of LTL.

cited in:

Learning Linear Temporal Properties for Autonomous Robotic Systems
Differentiable Inference of Temporal Logic Formulas
Formal Specifications from Natural Language

},
}


@inproceedings{frederiksen_automated_2020,
	title = {Automated {Assertion} {Generation} from {Natural} {Language} {Specifications}},
	volume = {2020-November},
	isbn = {978-1-72819-113-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100202487&doi=10.1109%2fITC44778.2020.9325264&partnerID=40&md5=b0c5018ea8d5d4176bf1c4f53d5ad711},
	doi = {10.1109/ITC44778.2020.9325264},
	abstract = {We explore contemporary natural language processing (NLP) techniques for converting NL specifications found in design documents directly to an temporal logic-like intermediate representation (IR). Generally, attempts to use NLP for assertion generation have relied on restrictive sentence formats and grammars as well as being difficult to handle new sentence formats. We tackle these issues by first implementing a system that uses commonsense mappings to process input sentences into a normalized form. Then we use frame semantics to convert the normalized sentences into an IR based on the information and context contained in the Frames. Through this we are able to handle a large number of sentences from real datasheets allowing for complex formats using temporal conditions, property statements, and compound statements; all order agnostic. Our system can also be easy extended by modifying an external, rather than internal, commonsense knowledge-base to handle new sentence formats without requiring code changes or intimate knowledge of the algorithms used. © 2020 IEEE.},
	language = {English},
	booktitle = {Proceedings - {International} {Test} {Conference}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Frederiksen, Steven J. and Aromando, John and Hsiao, Michael S.},
	year = {2020},
	note = {ISSN: 10893539
Type: Conference paper},
	keywords = {Natural language processing systems, Semantics, Intermediate representations, NAtural language processing, Specifications, Natural language specifications, Assertion generations, Commonsense knowledge base, Design documents, Frame semantics, Knowledge based systems, Process inputs},
	annote = {Cited by: 1; Conference name: 2020 IEEE International Test Conference, ITC 2020; Conference date: 1 November 2020 through 6 November 2020; Conference code: 166654},
	annote = {Cited by: 2; Conference name: 2020 IEEE International Test Conference, ITC 2020; Conference date: 1 November 2020 through 6 November 2020; Conference code: 166654},
	annote = {RELEVANCE:  MEDIUM
},
}


@article{osama_comprehensive_2022,
	title = {A {Comprehensive} {Requirement} {Capturing} {Model} {Enabling} the {Automated} {Formalisation} of {NL} {Requirements}},
	volume = {4},
	url = {https://doi.org/10.1007/s42979-022-01449-7},
	doi = {10.1007/s42979-022-01449-7},
	abstract = {Formalising natural language (NL) requirements is essential to have formal specifications that enable formal checking and improve the quality of requirements. However, the existing formalisation techniques require engineers to (re)write the system requirements using a set of requirements templates with predefined and limited structure and semantics. The main drawback of using such templates, usually with a fixed format, is the inability to capture diverse requirements outside the scope of the template structure. To address this limitation, a comprehensive reference model is needed to enable capturing key requirement properties regardless of their format, order, or structure. NLP technique can then be used to convert unrestricted NL requirements into the reference model. Using a set of transformation rules, the reference model representing the requirements can be transformed into the target formal notation. In this paper, we introduce requirement capturing model (RCM) to represent NL requirements by adapting to their key properties and without imposing constraints on how the requirements are written. We also implemented a requirements formalisation approach that supports transforming RCM into temporal logic (TL). In addition, we developed an automated similarity checking approach to check the correctness of the constructed RCM structures against the source NL requirements. We carried out extensive evaluation of RCM by comparing it against 15 existing requirements representation approaches on a dataset of 162 requirement sentences. The results show that RCM supports a much wider range of requirements formats compared to any of the existing approaches.},
	number = {1},
	journal = {SN Comput. Sci.},
	author = {Osama, Mohamed and Zaki-Ismail, Aya and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	month = nov,
	year = {2022},
	note = {Place: Berlin, Heidelberg
Publisher: Springer-Verlag},
	keywords = {Requirement engineering, Requirement formalisation, Requirement modelling, Requirement representation},
	annote = {Cited by: 0},
	annote = {Cited by: 1},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{pan_data-efficient_2023,
	title = {Data-{Efficient} {Learning} of {Natural} {Language} to {Linear} {Temporal} {Logic} {Translators} for {Robot} {Task} {Specification}},
	volume = {2023-May},
	isbn = {979-835032365-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168663890&doi=10.1109%2fICRA48891.2023.10161125&partnerID=40&md5=5329f8f8d7fb1f2a3e74425517d4e2e2},
	doi = {10.1109/ICRA48891.2023.10161125},
	abstract = {To make robots accessible to a broad audience, it is critical to endow them with the ability to take universal modes of communication, like commands given in natural language, and extract a concrete desired task specification, defined using a formal language like linear temporal logic (LTL). In this paper, we present a learning-based approach for translating from natural language commands to LTL specifications with very limited human-labeled training data. This is in stark contrast to existing natural-language to LTL translators, which require large human-labeled datasets, often in the form of labeled pairs of LTL formulas and natural language commands, to train the translator. To reduce reliance on human data, our approach generates a large synthetic training dataset through algorithmic generation of LTL formulas, conversion to structured English, and then exploiting the paraphrasing capabilities of modern large language models (LLMs) to synthesize a diverse corpus of natural language commands corresponding to the LTL formu-las. We use this generated data to finetune an LLM and apply a constrained decoding procedure at inference time to ensure the returned LTL formula is syntactically correct. We evaluate our approach on three existing LTL/natural language datasets and show that we can translate natural language commands at 75\% accuracy with far less human data (≤12 annotations). Moreover, when training on large human-annotated datasets, our method achieves higher test accuracy (95\% on average) than prior work. Finally, we show the translated formulas can be used to plan long-horizon, multi-stage tasks on a 12D quadrotor. © 2023 IEEE.},
	language = {English},
	booktitle = {Proceedings - {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Pan, Jiayi and Chou, Glen and Berenson, Dmitry},
	year = {2023},
	note = {ISSN: 10504729
Type: Conference paper},
	keywords = {Natural languages, Temporal logic, Formal languages, Linear temporal logic, Specifications, Task specifications, Computer circuits, Automation, Translation (languages), Temporal logic formula, Efficient learning, Human data, Language model, Large dataset, Learning-based approach, Natural extracts, Robot tasks, Data models, Training, Decoding, Training data},
	pages = {11554 -- 11561},
	annote = {Cited by: 0; Conference name: 2023 IEEE International Conference on Robotics and Automation, ICRA 2023; Conference date: 29 May 2023 through 2 June 2023; Conference code: 190430; All Open Access, Green Open Access},
	annote = {Cited by: 1; Conference name: 2023 IEEE International Conference on Robotics and Automation, ICRA 2023; Conference date: 29 May 2023 through 2 June 2023; Conference code: 190430; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{soavi_legal_2022,
	title = {From {Legal} {Contracts} to {Formal} {Specifications}: {A} {Systematic} {Literature} {Review}},
	volume = {3},
	url = {https://doi.org/10.1007/s42979-022-01228-4},
	doi = {10.1007/s42979-022-01228-4},
	abstract = {The opportunity to automate and monitor the execution of legal contracts is gaining increasing interest in Business and Academia, thanks to the advent of smart contracts, blockchain technologies, and the Internet of Things. A critical issue in developing smart contract systems is the formalization of legal contracts, which are traditionally expressed in natural language with all the pitfalls that this entails. This paper presents a systematic literature review of papers for the main steps related to the transformation of a legal contract expressed in natural language into a formal specification. Key research studies have been identified, classified, and analyzed according to a four-step transformation process: (a) structural and semantic annotation to identify legal concepts in text, (b) identification of relationships among concepts, (c) contract domain modeling, and (d) generation of a formal specification. Each one of these steps poses serious research challenges that have been the subject of research for decades. The systematic review offers an overview of the most relevant research efforts undertaken to address each step and identifies promising approaches, best practices, and existing gaps in the literature.},
	number = {5},
	journal = {SN Comput. Sci.},
	author = {Soavi, Michele and Zeni, Nicola and Mylopoulos, John and Mich, Luisa},
	month = jun,
	year = {2022},
	note = {Place: Berlin, Heidelberg
Publisher: Springer-Verlag},
	keywords = {Requirement, Conceptual model, Legal contract, Semantic annotation, Specification, Systematic literature review},
	annote = {Cited by: 4; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 6; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{soavi_contratto_2022,
	title = {Contratto – {A} {Method} for {Transforming} {Legal} {Contracts} into {Formal} {Specifications}},
	volume = {446 LNBIP},
	issn = {18651348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130940713&doi=10.1007%2f978-3-031-05760-1_20&partnerID=40&md5=9ac2508c4cf1c3835e5b5fc77d541178},
	doi = {10.1007/978-3-031-05760-1_20},
	abstract = {Legal contracts have been used for millennia to conduct business transactions world-wide. Such contracts are expressed in natural language, and usually come in written form. We are interested in producing formal specifications from such legal text that can be used to formally analyze contracts, also serve as launching pad for generating smart contracts, information systems that partially automate, monitor and control the execution of legal contracts. We have been developing a method for transforming legal contract documents into specifications, adopting a semantic approach where transformation is treated as a text classification, rather than a natural language processing problem. The method consists of five steps that (a) Identify domain terms in the contract and manually disambiguate them when necessary, in consultation with stakeholders; (b) Semantically annotate text identifying obligations, powers, contracting parties, assets and situations; (c) Identify relationships among the concepts mined in (b); (d) Generate a domain model based on the terms identified in (a), as well as parameters and local variables for the contract; (e) Generate expressions that formalize the conditions of obligations and powers using terms identified in earlier steps in a contract specification language. This paper presents the method through an illustrative example, also reports on a prototype implementation of an environment that supports the method. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Business Information Processing},
	author = {Soavi, Michele and Zeni, Nicola and Mylopoulos, John and Mich, Luisa},
	editor = {R, Guizzardi and J, Ralyté and X, Franch},
	year = {2022},
	note = {ISBN: 978-303105759-5
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Semantics, Specification languages, Classification (of information), Text processing, Smart contract, Ontology's, Information retrieval systems, Monitor and control, Semantic annotations, Legal contracts, Business transaction, Contract document, Domain model, Legal texts, Power},
	pages = {338 -- 353},
	annote = {Cited by: 1; Conference name: 16th International Conference on Research Challenges in Information Science, RCIS 2022; Conference date: 17 May 2022 through 20 May 2022; Conference code: 277829},
	annote = {Cited by: 1; Conference name: 16th International Conference on Research Challenges in Information Science, RCIS 2022; Conference date: 17 May 2022 through 20 May 2022; Conference code: 277829},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{madala_comprehensive_2023,
	title = {A {Comprehensive} {Analysis} of {Methods} to {Write} {Requirements} for {Machine} {Learning} {Components} used in {Autonomous} {Vehicles}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160730652&doi=10.4271%2f2023-01-0866&partnerID=40&md5=eef0dcb38b52d09bc0673a1db803e589},
	doi = {10.4271/2023-01-0866},
	abstract = {Machine learning components are widely used in autonomous vehicles for implementing functionalities related to perception and planning. To verify if the vehicle-level functionalities are as specified, one of the widely used approaches is requirements-based testing. However, writing testable requirements for machine learning components can be challenging since the machine learning outcomes are seldom known in advance. Nevertheless, it is important to have a specification that details the expected behavior from machine learning components. In this paper, we discuss different approaches to write a specification for machine learning algorithms that are used in autonomous vehicles. These approaches include natural language requirements, user stories, use case specifications, behavioral diagrams, data as requirements, and formal specification methods. We also propose a tabular specification method for specifying requirements of machine learning algorithms. We use a sample operational design domain (ODD) and system architecture to discuss the advantages and disadvantages of each of the techniques. We also discuss which approaches can aid with testing as well as error analysis of the model generated using the machine learning algorithms. © 2023 SAE International. All Rights Reserved.},
	booktitle = {{SAE} {Technical} {Papers}},
	author = {Madala, Kaushik and Krishnamoorthy, Jayalekshmi and Gil Batres, Andrea and Avalos Gonzalez, Carlos and Chang, Melody},
	year = {2023},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural language requirements, Use case specifications, Machine learning, Learning algorithms, Machine-learning, Well testing, Autonomous vehicles, Machine learning algorithms, Machine components, User stories, Autonomous Vehicles, Behavioral diagrams, Comprehensive analysis, Formal specification method, Learning outcome},
	annote = {Cited by: 0},
	annote = {Cited by: 0; Conference name: SAE 2023 World Congress Experience, WCX 2023; Conference date: 18 April 2023 through 20 April 2023; Conference code: 187990},
	annote = {Cited by: 0; Conference name: SAE 2023 World Congress Experience, WCX 2023; Conference date: 18 April 2023 through 20 April 2023; Conference code: 187990},
	annote = {RELEVANCE: MEDIUM

},
}


@article{hu_deploying_2024,
	title = {Deploying and {Evaluating} {LLMs} to {Program} {Service} {Mobile} {Robots}},
	volume = {9},
	issn = {23773766},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184339520&doi=10.1109%2fLRA.2024.3360020&partnerID=40&md5=5d19a1c212d9481a8e5052da1f046aae},
	doi = {10.1109/LRA.2024.3360020},
	abstract = {Recent advancements in large language models (LLMs) have spurred interest in using them for generating robot programs from natural language, with promising initial results. We investigate the use of LLMs to generate programs for service mobile robots leveraging mobility, perception, and human interaction skills, and where accurate sequencing and ordering of actions is crucial for success. We contribute CodeBotler, an open-source robot-agnostic tool to program service mobile robots from natural language, and RoboEval, a benchmark for evaluating LLMs' capabilities of generating programs to complete service robot tasks. CodeBotler performs program generation via few-shot prompting of LLMs with an embedded domain-specific language (eDSL) in Python, and leverages skill abstractions to deploy generated programs on any general-purpose mobile robot. RoboEval evaluates the correctness of generated programs by checking execution traces starting with multiple initial states, and checking whether the traces satisfy temporal logic properties that encode correctness for each task. RoboEval also includes multiple prompts per task to test for the robustness of program generation. We evaluate several popular state-of-the-art LLMs with the RoboEval benchmark, and perform a thorough analysis of the modes of failures, resulting in a taxonomy that highlights common pitfalls of LLMs at generating robot programs. © 2016 IEEE.},
	language = {English},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Hu, Zichao and Lucchetti, Francesca and Schlesinger, Claire and Saxena, Yash and Freeman, Anders and Modak, Sadanand and Guha, Arjun and Biswas, Joydeep},
	year = {2024},
	note = {Publisher: Institute of Electrical and Electronics Engineers Inc.
Type: Article},
	keywords = {Natural languages, Robots, Software testing, Problem oriented languages, Software-tools, Benchmarking, Human robot interaction, Robot programming, Python, Task analysis, Job analysis, Open source software, Benchmark testing, Service robots, Mobile robots, Human centered robotics, Reproducibilities, Service robotics, Social HRI, Software tool for benchmarking and reproducibility, Software tool for robot programming, human-centered robotics, service robotics, social HRI, Software tools for benchmarking and reproducibility, software tools for robot programming},
	pages = {2853 -- 2860},
	annote = {Cited by: 0; All Open Access, Green Open Access},
	annote = {Cited by: 0; All Open Access, Green Open Access},
	annote = {Cited by: 0; All Open Access, Green Open Access},
	annote = {Publisher: Institute of Electrical and Electronics Engineers Inc. Type: Article},
}


@inproceedings{ge_automtlspec_2023,
	title = {{AutoMTLSpec}: {Learning} to {Generate} {MTL} {Specifications} from {Natural} {Language} {Contracts}},
	isbn = {979-835034004-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179523728&doi=10.1109%2fICECCS59891.2023.00018&partnerID=40&md5=0232781811239fea834036e9ecaf463f},
	doi = {10.1109/ICECCS59891.2023.00018},
	abstract = {A smart legal contract is a legally binding contract in which some or all of the contractual obligations are defined and performed automatically by a computer program. As its software requirement, the legal contract is composed of legal clauses expressing the execution logic and time constraints between events in natural language. When formally verifying a smart legal contract to ensure the requirements' conformance, it is necessary to translate the time-constrained functional requirements (TFRs) into property specifications like Metric temporal logic (MTL) as the input of a model checker. Instead of costly and error-prone manual writing, this work automates the TFR detection and the specification generation using deep learning, named AutoMTL-Spec. We separate the MTL specification generation approach into four tasks: TFR detection, intermediate representation structure extraction, event sequence/time point extraction, and MTL generation, respectively. We construct a dataset including 43 contracts of four categories, 4608 terms, and 277 TFRs. The experimental results showed that all three models significantly outperform the baselines. Most of the indicators of the three learning tasks reached near to or more than 90\%. © 2023 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Engineering} of {Complex} {Computer} {Systems}, {ICECCS}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Ge, Ning and Yang, Jinwen and Yu, Tianyu and Liu, Wei},
	year = {2023},
	note = {ISSN: 27708527
Type: Conference paper},
	keywords = {Measurement, Formal specification, Natural languages, Extraction, Temporal logic, Model checking, Computer circuits, Functional requirement, Temporal property, Metric temporal logic, deep learning, Deep learning, Software, Writing, Manuals, Specification generations, Legal contracts, Law, Formal specification generation, Metric temporal property, Smart legal contract, Time-constrained functional requirement, formal specification generation, metric temporal property, smart legal contract, time-constrained functional requirements},
	pages = {71 -- 80},
	annote = {Cited by: 0; Conference name: 27th International Conference on Engineering of Complex Computer Systems, ICECCS 2023; Conference date: 14 June 2023 through 16 June 2023; Conference code: 194655},
	annote = {Cited by: 0; Conference name: 27th International Conference on Engineering of Complex Computer Systems, ICECCS 2023; Conference date: 14 June 2023 through 16 June 2023; Conference code: 194655},
	annote = {ISSN: 27708527 Type: Conference paper},
}


@inproceedings{chen_nl2tl_2023,
	title = {{NL2TL}: {Transforming} {Natural} {Languages} to {Temporal} {Logics} using {Large} {Language} {Models}},
	isbn = {979-889176060-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184819932&partnerID=40&md5=89d5356accb387e971dc9083e6cc3a3c},
	abstract = {Temporal Logic (TL) can be used to rigorously specify complex high-level specification for systems in many engineering applications. The translation between natural language (NL) and TL has been under-explored due to the lack of dataset and generalizable model across different application domains. In this paper, we propose an accurate and generalizable transformation framework of English instructions from NL to TL, exploring the use of Large Language Models (LLMs) at multiple stages. Our contributions are twofold. First, we develop a framework to create a dataset of NL-TL pairs combining LLMs and human annotation. We publish a dataset with 28K NL-TL pairs. Then, we finetune T5 models on the lifted versions (i.e., the specific Atomic Propositions (AP) are hidden) of the NL and TL. The enhanced generalizability originates from two aspects: 1) Usage of lifted NL-TL characterizes common logical structures, without constraints of specific domains. 2) Application of LLMs in dataset creation largely enhances corpus richness. We test the generalization of trained models on five varied domains. To achieve full NL-TL transformation, we either combine the lifted model with AP recognition task or do the further finetuning on each specific domain. During the further finetuning, our model achieves higher accuracy ({\textgreater}95\%) using only {\textless}10\% training data, compared with the baseline sequence to sequence (Seq2Seq) model. ©2023 Association for Computational Linguistics.},
	language = {English},
	booktitle = {{EMNLP} 2023 - 2023 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}, {Proceedings}},
	publisher = {Association for Computational Linguistics (ACL)},
	author = {Chen, Yongchao and Gandhi, Rujul and Zhang, Yang and Fan, Chuchu},
	editor = {H, Bouamor and J, Pino and K, Bali},
	year = {2023},
	note = {Type: Conference paper},
	keywords = {Natural languages, Temporal logic, Computer circuits, Language model, Atomic propositions, Generalisation, Computational linguistics, Applications domains, Human annotations, Engineering applications, High level specification, Logical structure, Multiple stages},
	pages = {15880 -- 15903},
	annote = {Cited by: 0; Conference name: 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196512},
	annote = {Cited by: 0; Conference name: 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023; Conference date: 6 December 2023 through 10 December 2023; Conference code: 196512},
	annote = {Type: Conference paper},
}


@article{ozkaya_practitioners_2023,
	title = {Practitioners’ {Perspectives} towards {Requirements} {Engineering}: {A} {Survey}},
	volume = {11},
	issn = {20798954},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149217529&doi=10.3390%2fsystems11020065&partnerID=40&md5=f7c55d939577b75b596c10e48cf69c16},
	doi = {10.3390/systems11020065},
	abstract = {In this paper, we discuss the results of our survey among 84 practitioners in order to understand practitioners’ perspectives towards requirements engineering. We asked 28 questions to learn the practitioners’ motivations, the techniques and technologies used for different activities, practitioners’ experiences with customer involvement, and any challenges encountered. Some important results are as follows: the practitioners’ top motivations are the precise communication of requirements and analyzing the requirements to detect issues. Most practitioners (i) insist on using natural languages, (ii) specify requirements as the use case and scenario descriptions, (iii) neglect using/transforming requirements for making high-level decisions and reasoning about requirements, (iv) neglect the specifications of quality requirements and their reasoning while considering quality requirements important, and (v) neglect any technologies for facilitating requirements engineering (e.g., meta-modeling technologies, formal verification tools, and advanced tools). Practitioners are challenged by the cost and effort spent in specifying requirements, the omissions of errors, misinterpretations of requirements and their incorrect (manual) transformations, and customers’ lack of technical knowledge. With the survey results, practitioners can gain an awareness on the general perspectives, academics can trigger new research addressing the observed issues, and tool vendors can improve their tools with regard to the weaknesses determined. © 2023 by the authors.},
	language = {English},
	number = {2},
	journal = {Systems},
	author = {Ozkaya, Mert and Akdur, Deniz and Toptani, Etem Cetin and Kocak, Burak and Kardas, Geylani},
	year = {2023},
	note = {Publisher: MDPI
Type: Article},
	annote = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{nistala_towards_2022,
	title = {Towards digitalization of requirements: generating context-sensitive user stories from diverse specifications},
	volume = {29},
	issn = {09288910},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125628911&doi=10.1007%2fs10515-022-00324-2&partnerID=40&md5=bceef0abdc4b94d8a51b0373a4938e51},
	doi = {10.1007/s10515-022-00324-2},
	abstract = {Requirements Engineering in the industry is expertise-driven, heavily manual, and centered around various types of requirement specification documents being prepared and maintained. These specification documents are in diverse formats and vary depending on whether it is a business requirement document, functional specification, interface specification, client specification, and so on. These diverse specification documents embed crucial product knowledge such as functional decomposition of the domain into features, feature hierarchy, feature types and their specific feature characteristics, dependencies, business context, etc. Moreover, in a product development scenario, thousands of pages of requirement specification documentation is created over the years. Comprehending functionality and its associated context from large volumes of specification documents is a highly complex task. To address this problem, we propose to digitalize the requirement specification documents into processable models. This paper discusses the salient aspects involved in the digitalization of requirements knowledge from diverse requirement specification documents. It proposes an AI engine for the automatic transformation of diverse text-based requirement specifications into machine-processable models using NLP techniques and the generation of context-sensitive user stories. The paper describes the key requirement abstractions and concepts essential in an industrial scenario, the conceptual meta-model, and DizReq engine (AI engine for digitalizing requirements) implementation for automatically transforming diverse requirement specifications into user stories embedding the business context. The evaluation results from digitalizing specifications of an IT product suite are discussed: mean feature extraction efficiency is 40 features/file, mean user story extraction efficiency is 71 user stories/file, feature extraction accuracy is 94\%, and requirement extraction accuracy is 98\%. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	language = {English},
	number = {1},
	journal = {Automated Software Engineering},
	author = {Nistala, Padmalata V. and Rajbhoj, Asha and Kulkarni, Vinay and Soni, Shivani and Nori, Kesav V. and Reddy, Raghu},
	year = {2022},
	note = {Publisher: Springer
Type: Article},
	keywords = {Natural language processing systems, Extraction, Specifications, Requirements specifications, Engines, Feature extraction, Efficiency, Meta model, Metamodeling, User stories, Feature classification, Feature models, Model extraction, NLP4RE, Product context, Requirement digitalization, Requirement meta-model},
	annote = {Cited by: 1},
	annote = {Cited by: 5},
	annote = {RELEVANCE: HIGH
https://link.springer.com/content/pdf/10.1007/s10515-022-00324-2.pdf?pdf=button
},
}


@inproceedings{zhao_digitization_2023,
	title = {Digitization of {Traffic} {Laws}: {Methodologies} and {Usage} for {Monitoring} {Driving} {Compliance}},
	isbn = {979-835039946-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186531733&doi=10.1109%2fITSC57777.2023.10422600&partnerID=40&md5=0066f42dd627bb319cf9d3e66231dbec},
	doi = {10.1109/ITSC57777.2023.10422600},
	abstract = {Autonomous Vehicles (AVs) must adhere to traffic laws designed for human-driven vehicles. However, since current traffic laws are expressed in natural language and are inherently ambiguous, AVs encounter challenges in comprehending these laws. Therefore, digitizing traffic laws into a format that AVs can understand is crucial for safe and efficient driving. In this paper, a process for digitizing regulations is proposed, where each regulation is digitized into a temporal logic expression composed of computable atomic propositions. Based on this process, a vehicle-side online violation monitoring architecture is established. These works make AVs understand traffic laws easily. Several common but important regulations are used as examples to illustrate our work and are deployed on an AV for verification. The results demonstrate that the proposed monitoring architecture can monitor ego vehicle's illegal behavior in real-time and provide compliance suggestions, thereby helping AVs operate more safely. © 2023 IEEE.},
	language = {English},
	booktitle = {{IEEE} {Conference} on {Intelligent} {Transportation} {Systems}, {Proceedings}, {ITSC}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Zhao, Chengxiang and Yu, Wenhao and Ma, Xiaohan and Zhao, Yuzhuang and Li, Boqi and Wang, Weida and Hu, Jia and Wang, Hong and Zhao, Ding},
	year = {2023},
	note = {ISSN: 21530009
Type: Conference paper},
	keywords = {Natural languages, 'current, Real-time systems, Autonomous vehicles, Traffic laws, Atomic propositions, Monitoring, Regulation, Computer architecture, Trajectory, Real- time, Vehicles, Laws and legislation, Behavioral sciences, Autonomous Vehicles, Digitisation, Logic expressions, Monitoring architecture},
	pages = {2376 -- 2383},
	annote = {Conference name: 26th IEEE International Conference on Intelligent Transportation Systems, ITSC 2023; Conference date: 24 September 2023 through 28 September 2023; Conference code: 197273},
	annote = {Conference name: 26th IEEE International Conference on Intelligent Transportation Systems, ITSC 2023; Conference date: 24 September 2023 through 28 September 2023; Conference code: 197273},
	annote = {ISSN: 21530009 Type: Conference paper},
}


@article{soavi_semantic_2022,
	title = {Semantic {Annotation} of {Legal} {Contracts} with {ContrattoA}},
	volume = {9},
	issn = {22279709},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144672537&doi=10.3390%2finformatics9040072&partnerID=40&md5=979eb3f6f5a0ef291c140037150d9b9f},
	doi = {10.3390/informatics9040072},
	abstract = {The aim of the research is to semi-automate the process of generating formal specifications from legal contracts in natural language text form. Towards this end, the paper presents a tool, named ContrattoA, that semi-automatically conducts semantic annotation of legal contract text using an ontology for legal contracts. ContrattoA was developed through two iterations where lexical patterns were defined for legal concepts and their effectiveness was evaluated with experiments. The first iteration was based on a handful of sample contracts and resulted in defining lexical patterns for recognizing concepts in the ontology; these were evaluated with an empirical study where one group of subjects was asked to annotate legal text manually, while a second group edited the annotations generated by ContrattoA. The second iteration focused on the lexical patterns for the core contract concepts of obligation and power where results of the first iteration were mixed. On the basis of an extended set of sample contracts, new lexical patterns were derived and those were shown to substantially improve the performance of ContrattoA, nearing in quality the performance of experts. The experiments suggest that good quality annotations can be generated for a broad range of contracts with minor refinements to the lexical patterns. © 2022 by the authors.},
	language = {English},
	number = {4},
	journal = {Informatics},
	author = {Soavi, Michele and Zeni, Nicola and Mylopoulos, John and Mich, Luisa},
	year = {2022},
	note = {Publisher: MDPI
Type: Article},
	annote = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{liu_grounding_2023,
	title = {Grounding {Complex} {Natural} {Language} {Commands} for {Temporal} {Tasks} in {Unseen} {Environments}},
	volume = {229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184348122&partnerID=40&md5=399947535998ac88d4712acb7c0a19e3},
	abstract = {Grounding navigational commands to linear temporal logic (LTL) leverages its unambiguous semantics for reasoning about long-horizon tasks and verifying the satisfaction of temporal constraints. Existing approaches require training data from the specific environment and landmarks that will be used in natural language to understand commands in those environments. We propose Lang2LTL, a modular system and a software package that leverages large language models (LLMs) to ground temporal navigational commands to LTL specifications in environments without prior language data. We comprehensively evaluate Lang2LTL for five well-defined generalization behaviors. Lang2LTL demonstrates the state-of-the-art ability of a single model to ground navigational commands to diverse temporal specifications in 21 city-scaled environments. Finally, we demonstrate a physical robot using Lang2LTL can follow 52 semantically diverse navigational commands in two indoor environments. © 2023 Proceedings of Machine Learning Research. All Rights Reserved.},
	language = {English},
	booktitle = {Proceedings of {Machine} {Learning} {Research}},
	publisher = {ML Research Press},
	author = {Liu, Jason Xinyu and Yang, Ziyi and Idrees, Ifrah and Liang, Sam and Schornstein, Benjamin and Tellex, Stefanie and Shah, Ankit},
	editor = {J, Tan and M, Toussaint and K, Darvish},
	year = {2023},
	note = {ISSN: 26403498
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Semantics, Temporal logic, Linear temporal logic, Language grounding, Robots, Machine learning, Language model, Linear temporal logic specifications, Generalisation, Temporal constraints, Training data, Modular system, Navigation, Robot navigation},
	annote = {Cited by: 0; Conference name: 7th Conference on Robot Learning, CoRL 2023; Conference date: 6 November 2023 through 9 November 2023; Conference code: 196640},
	annote = {Cited by: 0; Conference name: 7th Conference on Robot Learning, CoRL 2023; Conference date: 6 November 2023 through 9 November 2023; Conference code: 196640},
	annote = {ISSN: 26403498 Type: Conference paper},
}


@inproceedings{lukacs_transformation_2022,
	title = {Transformation domain requirements specification into computation tree logic language},
	isbn = {978-1-66547-631-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160439746&doi=10.1109%2fCogMob55547.2022.10117911&partnerID=40&md5=898480f829fb72546c3298a48483a367},
	doi = {10.1109/CogMob55547.2022.10117911},
	abstract = {The requirements specification languages are frequently challenged in every domain - including the safety aspects of cognitive mobility. The correct formalization and communication of the expectations related to the systems is a decisively important step (i.e. the intra cognitive mobility aspect of this early design step) because the effects of the mistakes made during the development and analysis of the requirements are magnified in the later phases of the development life cycle. Formal description and modeling of the requirements become even more imperative with the increasing level of automation in transport as there is gradually less human supervision and intervention in case of undesired/erroneous behavior. For this reason, regulations and standards recommend the use of semi-formal and formal requirement description languages during the development of systems. However, it can be difficult for experts of a specific field to use a field-independent, completely formal method, partly due to their lack of necessary background knowledge, and partly because formal descriptions are difficult to read. It is, therefore worthwhile to strive for a compromise, and to develop a formalism that fits the specific field and is a little closer to natural language. This paper presents a possible methodology (transformation process) for developing and applying of such an intermediate language. The constructed intermediate language (we call it 'restricted textual template') provides an easy-to-apply, practice-oriented language compared to currently available solutions. We aim to support the work of the transportation engineers who work in the development of industrial control systems. © 2022 IEEE.},
	language = {English},
	booktitle = {2022 {IEEE} 1st {International} {Conference} on {Cognitive} {Mobility}, {CogMob} 2022},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Lukacs, Gabor and Bartha, Tamas},
	year = {2022},
	note = {Type: Conference paper},
	keywords = {Formal specification, Temporal logic, Model checking, Specification languages, Computer circuits, Requirements specifications, Cognitive systems, Formal Description, Computation tree logic, Domain requirements, Intermediate languages, Life cycle, Logic languages, Models checking, Requirements specification language, Safety aspects, Transformation domain},
	pages = {73 -- 78},
	annote = {Cited by: 0; Conference name: 1st IEEE International Conference on Cognitive Mobility, CogMob 2022; Conference date: 12 October 2022 through 13 October 2022; Conference code: 188685},
	annote = {Cited by: 0; Conference name: 1st IEEE International Conference on Cognitive Mobility, CogMob 2022; Conference date: 12 October 2022 through 13 October 2022; Conference code: 188685},
	annote = {RELEVANCE: HIGH
https://ieeexplore.ieee.org/document/10117911
},
}


@article{wang_requirement_2023,
	title = {Requirement specification extraction and analysis based on propositional projection temporal logic},
	issn = {20477481},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150895714&doi=10.1002%2fsmr.2558&partnerID=40&md5=d57ddd6c9d5323fd9d0605497391ca43},
	doi = {10.1002/smr.2558},
	abstract = {At present, formal methods significantly facilitate the specification and verification of security requirements in requirement engineering, which can reduce requirement errors in the early stage of system development. Extracting formal specifications from security requirements and then evaluating the quality of the requirements are regarded as a promising solution to ensure software quality. Propositional projection temporal logic (PPTL) with a strong mathematical basis and full regular expressiveness is a suitable language for formal specifications. Inspired by natural language processing and text mining techniques, this paper designs and implements a tool, namely, NL2PPTL, to generate formal coarse-grained and fine-grained specifications in terms of PPTL formulas automatically. In specific, the grammatical production rules are defined to construct the syntax tree, and then, the formula is obtained by post-order traversal of the tree. The satisfiability of the PPTL specifications can be checked utilizing PPTLSAT. In addition, the state transformation model is constructed from fine-grained specifications, so as to discover scope conflicts and verify the security properties of the requirement case. © 2023 John Wiley \& Sons Ltd.},
	language = {English},
	journal = {Journal of Software: Evolution and Process},
	author = {Wang, Xiaobing and Li, Chunyi and Zhao, Liang},
	year = {2023},
	note = {Publisher: John Wiley and Sons Ltd
Type: Article},
	keywords = {Natural language processing systems, Computer software selection and evaluation, Formal specification, Temporal logic, Computer circuits, Cryptography, Security requirements, Requirements specifications, Requirement engineering, System development, Specification and verification, Propositional projection temporal logic, Trees (mathematics), Fine grained, Mathematical basis, Requirement errors, Software Quality},
	annote = {Cited by: 0},
	annote = {Cited by: 0},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{sharma_instructing_2023,
	title = {Instructing {Robots} with {Natural} {Language} via {Bi}-{RNNs} for {Temporal} {Logic} {Translation}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184383465&partnerID=40&md5=9a09f07a3d2022b763a0a17f7d14289d},
	abstract = {We consider the problem of planning trajectories that satisfy natural language instruction. We explore translating natural language commands to temporal logic formulae to resolve ambiguities for planning. Our main contribution is a new bi-directional recurrent neural network (Bi-RNN) architecture for this translation task. We experimentally show that the proposed Bi-RNN architecture achieves 1.6\% better accuracy, 20\% faster inference time, and 98\% faster training time compared to leading models owing to bidirectional processing. The overall system, including a planning algorithm, exhibits useful diverse behaviours that satisfy given instructions. © 2023 Australasian Robotics and Automation Association. All rights reserved.},
	language = {English},
	booktitle = {Australasian {Conference} on {Robotics} and {Automation}, {ACRA}},
	publisher = {Australasian Robotics and Automation Association},
	author = {Sharma, Suryansh and Brian Lee, Ki Myung and Brown, Mason and Best, Graeme},
	year = {2023},
	note = {ISSN: 14482053
Type: Conference paper},
	keywords = {Natural languages, Temporal logic, Computer circuits, Translation (languages), Temporal logic formula, Robotics, Recurrent neural networks, Network architecture, Bi-directional, Bidirectional processing, Fast inference, Leading models, Planning algorithms, Recurrent neural network architectures, Training time},
	annote = {Conference name: 2023 Australasian Conference on Robotics and Automation, ACRA 2023; Conference date: 4 December 2023 through 6 December 2023; Conference code: 196740},
	annote = {Conference name: 2023 Australasian Conference on Robotics and Automation, ACRA 2023; Conference date: 4 December 2023 through 6 December 2023; Conference code: 196740},
	annote = {ISSN: 14482053 Type: Conference paper},
}


@article{korel_text--ontology_2023,
	title = {Text-to-{Ontology} {Mapping} via {Natural} {Language} {Processing} with {Application} to {Search} for {Relevant} {Ontologies} in {Catalysis} †},
	volume = {12},
	issn = {2073431X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146810459&doi=10.3390%2fcomputers12010014&partnerID=40&md5=2cb5d123a804a5861652a5337e14b843},
	doi = {10.3390/computers12010014},
	abstract = {The paper presents a machine-learning based approach to text-to-ontology mapping. We explore a possibility of matching texts to the relevant ontologies using a combination of artificial neural networks and classifiers. Ontologies are formal specifications of the shared conceptualizations of application domains. While describing the same domain, different ontologies might be created by different domain experts. To enhance the reasoning and data handling of concepts in scientific papers, finding the best fitting ontology regarding description of the concepts contained in a text corpus. The approach presented in this work attempts to solve this by selection of a representative text paragraph from a set of scientific papers, which are used as data set. Then, using a pre-trained and fine-tuned Transformer, the paragraph is embedded into a vector space. Finally, the embedded vector becomes classified with respect to its relevance regarding a selected target ontology. To construct representative embeddings, we experiment with different training pipelines for natural language processing models. Those embeddings in turn are later used in the task of matching text to ontology. Finally, the result is assessed by compressing and visualizing the latent space and exploring the mappings between text fragments from a database and the set of chosen ontologies. To confirm the differences in behavior of the proposed ontology mapper models, we test five statistical hypotheses about their relative performance on ontology classification. To categorize the output from the Transformer, different classifiers are considered. These classifiers are, in detail, the Support Vector Machine (SVM), k-Nearest Neighbor, Gaussian Process, Random Forest, and Multilayer Perceptron. Application of these classifiers in a domain of scientific texts concerning catalysis research and respective ontologies, the suitability of the classifiers is evaluated, where the best result was achieved by the SVM classifier. © 2023 by the authors.},
	language = {English},
	number = {1},
	journal = {Computers},
	author = {Korel, Lukáš and Yorsh, Uladzislau and Behr, Alexander S. and Kockmann, Norbert and Holeňa, Martin},
	year = {2023},
	note = {Publisher: MDPI
Type: Article},
	annote = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access},
	annote = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{sudhi_natural_2023,
	title = {Natural {Language} {Processing} for {Requirements} {Formalization}: {How} to {Derive} {New} {Approaches}?},
	volume = {1091 SCI},
	issn = {1860949X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163377601&doi=10.1007%2f978-3-031-26651-5_1&partnerID=40&md5=59946197913f204f8e38fa1596520c70},
	doi = {10.1007/978-3-031-26651-5_1},
	abstract = {It is a long-standing desire of industry and research to automate the software development and testing process as much as possible. Model-based design and testing methods have been developed to automate several process steps and handle the growing complexity and variability of software systems. However, major effort is still required to create specification models from a large set of functional requirements provided in natural language. Numerous approaches based on natural language processing (NLP) have been proposed in the literature to generate requirements models using mainly syntactic properties. Recent advances in NLP show that semantic quantities can also be identified and used to provide better assistance in the requirements formalization process. In this work, we present and discuss principal ideas and state-of-the-art methodologies from the field of NLP in order to guide the readers on how to derive new requirements formalization approaches according to their specific use case and needs. We demonstrate our approaches on two industrial use cases from the automotive and railway domains and show that the use of current pre-trained NLP models requires less effort to adapt to a specific use case. Furthermore, we outline findings and shortcomings of this research area and propose some promising future developments. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Studies in Computational Intelligence},
	author = {Sudhi, Viju and Kutty, Libin and Gröpler, Robin},
	editor = {B, Schlingloff and T, Vogel and A, Skowron},
	year = {2023},
	note = {ISBN: 978-303126650-8
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	pages = {1 -- 27},
	annote = {Cited by: 0; Conference name: 29th International Workshop on Concurrency, Specification and Programming, CS and P 2021; Conference date: 27 September 2021 through 28 September 2021; Conference code: 294419; All Open Access, Green Open Access},
	annote = {Cited by: 0; Conference name: 29th International Workshop on Concurrency, Specification and Programming, CS and P 2021; Conference date: 27 September 2021 through 28 September 2021; Conference code: 294419; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@article{bombieri_mapping_2023,
	title = {Mapping natural language procedures descriptions to linear temporal logic templates: an application in the surgical robotic domain},
	volume = {53},
	issn = {0924669X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168563884&doi=10.1007%2fs10489-023-04882-0&partnerID=40&md5=ca7b984a2effef53e105490cf558f48a},
	doi = {10.1007/s10489-023-04882-0},
	abstract = {Natural language annotations and manuals can provide useful procedural information and relations for the highly specialized scenario of autonomous robotic task planning. In this paper, we propose and publicly release AUTOMATE, a pipeline for automatic task knowledge extraction from expert-written domain texts. AUTOMATE integrates semantic sentence classification, semantic role labeling, and identification of procedural connectors, in order to extract templates of Linear Temporal Logic (LTL) relations that can be directly implemented in any sufficiently expressive logic programming formalism for autonomous reasoning, assuming some low-level commonsense and domain-independent knowledge is available. This is the first work that bridges natural language descriptions of complex LTL relations and the automation of full robotic tasks. Unlike most recent similar works that assume strict language constraints in substantially simplified domains, we test our pipeline on texts that reflect the expressiveness of natural language used in available textbooks and manuals. In fact, we test AUTOMATE in the surgical robotic scenario, defining realistic language constraints based on a publicly available dataset. In the context of two benchmark training tasks with texts constrained as above, we show that automatically extracted LTL templates, after translation to a suitable logic programming paradigm, achieve comparable planning success in reduced time, with respect to logic programs written by expert programmers. © 2023, The Author(s).},
	language = {English},
	number = {22},
	journal = {Applied Intelligence},
	author = {Bombieri, Marco and Meli, Daniele and Dall’Alba, Diego and Rospocher, Marco and Fiorini, Paolo},
	year = {2023},
	note = {Publisher: Springer
Type: Article},
	keywords = {Natural language processing systems, Natural languages, Semantics, Temporal logic, Linear temporal logic, Computer circuits, Translation (languages), Logic programming, Language processing, Natural language processing, Statistical tests, Robot programming, Pipelines, Program translators, Autonomous planning, Autonomous robotics, Logic-programming, Robotic surgery, Robotic tasks, Surgical robotics, Task planning},
	pages = {26351 -- 26363},
	annote = {Cited by: 0; All Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 0; All Open Access, Hybrid Gold Open Access},
	annote = {Place: USA Publisher: Kluwer Academic Publishers},
	annote = {Place: USA Publisher: Kluwer Academic Publishers},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{hains_machine_2023,
	title = {Machine {Learning} {Pseudo}-{Natural} {Language} for {Temporal} {Logic} {Requirements} of {Embedded} {Systems}},
	isbn = {979-835032974-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178520056&doi=10.1109%2fKSE59128.2023.10299468&partnerID=40&md5=9923076b0db1afb9d8e849603a3fbf4e},
	doi = {10.1109/KSE59128.2023.10299468},
	abstract = {Requirements formalization is a critical part of any verification methodology for embedded systems like those in the automotive industry. There is a strong tension between techniques that enter requirements as logic- or code-like formal expressions and others that use natural language. The former are much safer but require user training and have low productivity. As a compromise we proposed a context-free grammar for entering real-time system requirements and translating them to temporal logic (TL) unambiously and reversibly. It has been demonstrated on hundreds of examples and became validated by a recent patent. But building or extending the grammar itself requires a precise understanding of the translation rules. To aleviate this new hurdle we have found that neural nets inspired by NLP can learn and then replace the pseudo-English-to-TL translation, and allow extending it without the explicit use of a grammar. The paper explains how we mixed real-life and synthetic datasets and overcame the initial limitations of the neural nets. © 2023 IEEE.},
	language = {English},
	booktitle = {Proceedings - {International} {Conference} on {Knowledge} and {Systems} {Engineering}, {KSE}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Hains, Gaetan and Fenek, Ouarda},
	editor = {H.T.T, Binh and V.T, Hoang and L.M, Nguyen and S.V, Le and T.D, Vu and D.T, Pham},
	year = {2023},
	note = {ISSN: 26944804
Type: Conference paper},
	keywords = {natural language processing, Natural language processing systems, Natural languages, Requirements engineering, Temporal logic, Computer circuits, Requirements formalizations, Safety engineering, Embedded systems, Translation (languages), Machine learning, Real time systems, Learning algorithms, Software engineering, Safety critical systems, Language processing, Natural language processing, Learning systems, Interactive computer systems, Real-time systems, Productivity, Requirements formalization, Neural networks, deep learning, Deep learning, Training, Adaptation models, Real-time embedded systems, Automotive industry, Embedded-system, Engineering productivity, Software engineering productivity, real-time embedded systems, safety-critical systems, software engineering productivity},
	annote = {Cited by: 0; Conference name: 15th International Conference on Knowledge and Systems Engineering, KSE 2023; Conference date: 18 October 2023 through 20 October 2023; Conference code: 194303},
	annote = {Cited by: 0; Conference name: 15th International Conference on Knowledge and Systems Engineering, KSE 2023; Conference date: 18 October 2023 through 20 October 2023; Conference code: 194303},
	annote = {ISSN: 26944804 Type: Conference paper},
}


@inproceedings{alman_rule_2020,
	title = {Rule mining with {RuM}},
	isbn = {978-1-72819-832-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094822179&doi=10.1109%2fICPM49681.2020.00027&partnerID=40&md5=88689bb1f14c791a3e3fe876ecb34018},
	doi = {10.1109/ICPM49681.2020.00027},
	abstract = {Declarative process modeling languages are especially suitable to model loosely-structured, unpredictable business processes. One of the most prominent of these languages is Declare. The Declare language can be used for all process mining branches and a plethora of techniques have been implemented to support process mining with Declare. However, using these techniques can become cumbersome in practical situations where different techniques need to be combined for analysis. In addition, the use of Declare constraints in practice is often hampered by the difficulty of modeling them: The formal expression of Declare is difficult to understand for users without a background in temporal logics, whereas its graphical notation has been shown to be unintuitive. In this paper, we present RuM, a novel application for rule mining that addresses the abovementioned issues by integrating multiple Declare-based process mining methods into a single unified application. The process mining techniques provided in RuM strongly rely on the use of Declare models expressed in natural language, which has the potential of mitigating the barriers of the language bias. The application has been evaluated by conducting a qualitative user evaluation with eight process analysts. © 2020 IEEE.},
	language = {English},
	booktitle = {Proceedings - 2020 2nd {International} {Conference} on {Process} {Mining}, {ICPM} 2020},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Alman, Anti and Ciccio, Claudio Di and Haas, Dominik and Maggi, Fabrizio Maria and Nolte, Alexander},
	editor = {B, van Dongen and M, Montali and M.T, Wynn},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Business Process, Process mining, Natural languages, Data mining, Modeling languages, Declarative process models, Formal expressions, Graphical notation, Mining, Novel applications, User evaluations},
	pages = {121 -- 128},
	annote = {Cited by: 17; Conference name: 2nd International Conference on Process Mining, ICPM 2020; Conference date: 4 October 2020 through 9 October 2020; Conference code: 164352; All Open Access, Green Open Access},
	annote = {Cited by: 22; Conference name: 2nd International Conference on Process Mining, ICPM 2020; Conference date: 4 October 2020 through 9 October 2020; Conference code: 164352; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
https://rulemining.org/
conformance checking

},
}


@inproceedings{de_brock_nlg4re_2022,
	title = {{NLG4RE}: {How} {NL} {Generation} {Can} {Support} {Validation} in {RE}},
	volume = {3122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128777167&partnerID=40&md5=c7f586d6766f6bad13b0bab16d420729},
	abstract = {Context and motivation: All too frequently functional requirements (FRs) for a (software) system are unclear. Written in natural language, FRs are underspecified for software developers; when written in formal language, FRs are insufficiently comprehensible for users. This is a well-known problem in RE. As long as this either/or dichotomy exists, FRs cannot be a “basis for common agreement among all parties involved”, as Barry Boehm puts it. Question/problem: On the one hand, FRs should unambiguously specify the functional behaviour of the system to be written or adapted, and on the other hand be fully understandable by the customer that must agree with them. What is required to achieve this goal? Principal ideas/results: A specification must describe the Statics as well as the Dynamics. In our approach it consists of a Conceptual Data Model (the data structure, i.e., the Statics) plus a set of System Sequence Descriptions (SSDs) representing the processes (i.e., the Dynamics). SSDs schematically depict the interactions between the primary actor (user), the system (as a black box), and other actors (if any), including the messages between them. We provide a set of rules to generate natural language expressions from both the Conceptual Data Model and the SSDs that are understandable by the user ('Informalisation of formal requirements'). Generating understandable representations of a specification is relevant for requirements validation tasks. Contribution to validation: We introduce a form of Natural Language Generation (the NLG in the title) by defining a grammar and mapping rules to precise and unambiguous expressions in natural language, in order to improve understandability of the FRs and the data model by the user community. © 2022 Copyright for this paper by its authors},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {de Brock, Bert and Suurmond, Coen},
	editor = {J, Fischbach and N, Condori-Fernandez and N, Condori-Fernandez and J, Doerr and M, Ruiz and J.-P, Steghofer and L, Pasquale and A, Zisman and R, Guizzardi and J, Horkoff and A, Perini and A, Susi and M, Daneva and A, Herrmann and K, Schneider and P, Mennig and F, Dalpiaz and D, Dell�Anna and S, Kopczynska and L, Montgomery and A.G, Darby and P, Sawyer},
	year = {2022},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Requirements engineering, Formal languages, Mapping, Specifications, Functional requirement, Validation, Grammar, Conceptual data models, Explainability, Support validations, Syntax-directed mapping, System sequence description, Use case},
	annote = {Cited by: 0; Conference name: Joint REFSQ-2022 Workshops, Doctoral Symposium, and Posters and Tools Track, REFSQ-JP 2022; Conference date: 21 March 2022; Conference code: 178725},
	annote = {Cited by: 0; Conference name: Joint REFSQ-2022 Workshops, Doctoral Symposium, and Posters and Tools Track, REFSQ-JP 2022; Conference date: 21 March 2022; Conference code: 178725},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{germiniani_mist_2020,
	title = {{MIST}: {Monitor} generation from informal specifications for firmware verification},
	volume = {2020-October},
	isbn = {978-1-72815-409-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101080043&doi=10.1109%2fVLSI-SOC46417.2020.9344072&partnerID=40&md5=301a8b5d12762bab24892f155e33ab29},
	doi = {10.1109/VLSI-SOC46417.2020.9344072},
	abstract = {This paper presents MIST, an all-in-one tool capable of generating a complete environment to verify C/C++ firmwares starting from informal specifications. Given a set of specifications written in natural language, the tool guides the user in translating each specification into an XML formal description, capturing a temporal behavior that must hold in the design. Our XML format guarantees the same expressiveness of linear temporal logic, but it is designed to be used by designers that are not familiar with formal methods. Once each behavior is formalized, MIST automatically generates the corresponding test-bench and checker to stimulate and verify the design. In order to guide the verification process, MIST employs a clustering procedure that classifies the internal states of the firmware. Such classification aims at finding an effective ordering to check the expected behaviors and to advise for possible specification holes. MIST has been fully integrated into the IAR System Embedded Workbench. Its effectiveness and efficiency have been evaluated to formalize and check a complex test-plan for an industrial firmware. © 2020 IEEE.},
	language = {English},
	booktitle = {{IEEE}/{IFIP} {International} {Conference} on {VLSI} and {System}-on-{Chip}, {VLSI}-{SoC}},
	publisher = {IEEE Computer Society},
	author = {Germiniani, Samuele and Bragaglio, Moreno and Pravadelli, Graziano},
	year = {2020},
	note = {ISSN: 23248432
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Linear temporal logic, Formal verification, XML, C++ (programming language), Clustering procedure, Effectiveness and efficiencies, Firmware, Formal Description, Fully integrated, Temporal behavior, Verification process, VLSI circuits},
	pages = {111 -- 116},
	annote = {Cited by: 0; Conference name: 28th IFIP/IEEE International Conference on Very Large Scale Integration, VLSI-SOC 2020; Conference date: 5 October 2020 through 7 October 2020; Conference code: 167075},
	annote = {Cited by: 0; Conference name: 28th IFIP/IEEE International Conference on Very Large Scale Integration, VLSI-SOC 2020; Conference date: 5 October 2020 through 7 October 2020; Conference code: 167075},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{peng_itemization_2022,
	title = {Itemization {Framework} of {Requirements} using {Machine} {Reading} {Comprehension}},
	volume = {12451},
	isbn = {978-1-5106-6007-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142053006&doi=10.1117%2f12.2656629&partnerID=40&md5=5dbc5195c4e09c9734266e978171ce10},
	doi = {10.1117/12.2656629},
	abstract = {In practice, it is very important to determine the requirements items of the proposed software system from the requirements document. However, due to the problems of ambiguity, redundancy, ambiguity, and difficulty in traceability of changes in the requirements documents described in natural language, the estimation results are subject to a certain degree, and the process is labor-intensive and cost-intensive. In this paper, we propose a new method to automatically extract requirement entries from requirement text by leveraging a set of natural language processing techniques and machine learning models. Our method is inspired by imitating the process of expert extraction of itemized requirements, which usually consists of three main processes: locating requirement locations and boundaries, building models, and extracting fine-grained requirement semantics. We performed evaluations in the field of military arguments, and the results showed that our model was nearly 80 percent accurate. Our approach can provide sound advice to help industry practitioners extract requirements items faster and easier. © 2022 SPIE.},
	language = {English},
	booktitle = {Proceedings of {SPIE} - {The} {International} {Society} for {Optical} {Engineering}},
	publisher = {SPIE},
	author = {Peng, Siyu and Xu, Luo and Jiang, Wei},
	editor = {F, Zhao},
	year = {2022},
	note = {ISSN: 0277786X
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Requirements engineering, Extraction, Semantics, Requirement engineering, Learning algorithms, Software-systems, Requirement extraction, Requirements document, Attention mechanisms, Estimation results, Machine reading comprehension, Reading comprehension, Semantic Computing},
	annote = {Cited by: 0; Conference name: 5th International Conference on Computer Information Science and Application Technology, CISAT 2022; Conference date: 29 July 2022 through 31 July 2022; Conference code: 183755},
	annote = {Cited by: 0; Conference name: 5th International Conference on Computer Information Science and Application Technology, CISAT 2022; Conference date: 29 July 2022 through 31 July 2022; Conference code: 183755},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{zaki-ismail_rcm_2021,
	title = {{RCM}: {Requirement} capturing model for automated requirements formalisation},
	isbn = {978-989-758-487-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102991179&partnerID=40&md5=6141617e81ee4382b5d40b7d3c19ad96},
	abstract = {Most existing automated requirements formalisation techniques require system engineers to (re)write their requirements using a set of predefined requirement templates with a fixed structure and known semantics to simplify the formalisation process. However, these techniques require understanding and memorising requirement templates, which are usually fixed format, limit requirements captured, and do not allow capture of more diverse requirements. To address these limitations, we need a reference model that captures key requirement details regardless of their structure, format or order. Then, using NLP techniques we can transform textual requirements into the reference model. Finally, using a suite of transformation rules we can then convert these requirements into formal notations. In this paper, we introduce the first and key step in this process, a Requirement Capturing Model (RCM) - as a reference model - to model the key elements of a system requirement regardless of their format, or order. We evaluated the robustness of the RCM model compared to 15 existing requirements representation approaches and a benchmark of 162 requirements. Our evaluation shows that RCM breakdowns support a wider range of requirements formats compared to the existing approaches. We also implemented a suite of transformation rules that transforms RCM-based requirements into temporal logic(s). In the future, we will develop NLP-based RCM extraction technique to provide end-to-end solution. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	language = {English},
	booktitle = {{MODELSWARD} 2021 - {Proceedings} of the 9th {International} {Conference} on {Model}-{Driven} {Engineering} and {Software} {Development}},
	publisher = {SciTePress},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {S, Hammoudi and L.F, Pires and E, Seidewitz and R, Soley},
	year = {2021},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Software design, Semantics, System requirements, Formal notations, Transformation rules, End-to-end solutions, Extraction techniques, Reference modeling, Requirement capturing, System engineers},
	pages = {110 -- 121},
	annote = {Cited by: 4; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 167487},
	annote = {Cited by: 4; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 167487},
	annote = {RELEVANCE: MEDIUM
},
}


@article{rahman_semantic_2021,
	title = {Semantic {Annotations} in {Clinical} {Guidelines}},
	volume = {12611 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103556106&doi=10.1007%2f978-3-030-70650-0_12&partnerID=40&md5=4644b43d36e07823e9fa0f560c4cb040},
	doi = {10.1007/978-3-030-70650-0_12},
	abstract = {Clinical guidelines are evidence-based recommendations developed to assist practitioners in their decisions on appropriate care for patients with specific clinical circumstances. They provide succinct instructions such as what drugs should be given or taken for a particular condition, how long such treatment should be given, what tests should be conducted, or other situational clinical circumstances for certain diseases. However, as they are described in natural language, they are prone to problems such as variability and ambiguity. In this paper, we propose an approach to automatically infer the main components in clinical guideline sentences. Knowing the key concepts in the sentences, we can then feed them to model checkers to validate their correctness. We adapt semantic role labelling approach to mark the key entities in our problem domain. We also implement the technique used for Named-Entity Recognition (NER) task and compare the results. The aim of our work is to build a reasoning framework that combines the information gained from real patient data and clinical practice, with clinical guidelines to give more suitable personalised recommendations for treating patients. © 2021, Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Rahman, Fahrurrozi and Bowles, Juliana},
	editor = {J, Bowles and G, Broccia and M, Nanni},
	year = {2021},
	note = {ISBN: 978-303070649-4
Publisher: Springer Science and Business Media Deutschland GmbH
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Semantics, Model checking, Hospital data processing, Clinical guideline, Named entity recognition, Semantic annotations, Clinical practices, Particular condition, Personalised recommendations, Reasoning framework},
	pages = {190 -- 205},
	annote = {Cited by: 0; Conference name: 9th International Symposium on From Data Models and Back, DataMod 2020; Conference date: 20 October 2020 through 20 October 2020; Conference code: 256199; All Open Access, Green Open Access},
	annote = {Cited by: 0; Conference name: 9th International Symposium on From Data Models and Back, DataMod 2020; Conference date: 20 October 2020 through 20 October 2020; Conference code: 256199; All Open Access, Green Open Access},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{anderson_pyforel_2022,
	title = {{PyFoReL}: {A} {Domain}-{Specific} {Language} for {Formal} {Requirements} in {Temporal} {Logic}},
	volume = {2022-August},
	isbn = {978-1-66547-000-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133885496&doi=10.1109%2fRE54965.2022.00037&partnerID=40&md5=2ed4dd0e4e02455d8e8704e4cba5915a},
	doi = {10.1109/RE54965.2022.00037},
	abstract = {Temporal Logic (TL) bridges the gap between natural language and formal reasoning in the field of complex systems verification. However, in order to leverage the expressivity entailed by TL, the syntax and semantics must first be understood - a large task in itself. This significant knowledge gap leads to several issues: (1) the likelihood of adopting a TL-based verification method is decreased, and (2) the chance of poorly written and inaccurate requirements is increased. In this ongoing work, we present the Pythonic Formal Requirements Language (PyFoReL) tool: a Domain-Specific Language inspired by the programming language Python to simplify the elicitation of TL-based requirements for engineers and non-experts. © 2022 IEEE.},
	language = {English},
	booktitle = {Proceedings of the {IEEE} {International} {Conference} on {Requirements} {Engineering}},
	publisher = {IEEE Computer Society},
	author = {Anderson, Jacob and Hekmatnejad, Mohammad and Fainekos, Georgios},
	editor = {E, Knauss and G, Mussbacher and C, Arora and M, Bano and J.-G, Schneider},
	year = {2022},
	note = {ISSN: 1090705X
Type: Conference paper},
	keywords = {Natural languages, Semantics, Temporal logic, Problem oriented languages, Computer circuits, Domains specific languages, Formal reasoning, Formal requirement, Knowledge gaps, Language tools, Requirement languages, Requirement-based testing, System verifications, Verification method},
	pages = {266 -- 267},
	annote = {Cited by: 0; Conference name: 30th IEEE International Requirements Engineering Conference, RE 2022; Conference date: 15 August 2022 through 19 August 2022; Conference code: 183667},
	annote = {Cited by: 1; Conference name: 30th IEEE International Requirements Engineering Conference, RE 2022; Conference date: 15 August 2022 through 19 August 2022; Conference code: 183667},
	annote = {RELEVANCE: HIGH - check code

https://par.nsf.gov/servlets/purl/10392510
},
}


@article{sanchez-ferreres_unleashing_2021,
	title = {Unleashing textual descriptions of business processes},
	volume = {20},
	issn = {16191366},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106476225&doi=10.1007%2fs10270-021-00886-x&partnerID=40&md5=336f1f9c3ab33facad7cc6001f8e8290},
	doi = {10.1007/s10270-021-00886-x},
	abstract = {Textual descriptions of processes are ubiquitous in organizations, so that documentation of the important processes can be accessible to anyone involved. Unfortunately, the value of this rich data source is hampered by the challenge of analyzing unstructured information. In this paper we propose a framework to overcome the current limitations on dealing with textual descriptions of processes. This framework considers extraction and analysis and connects to process mining via simulation. The framework is grounded in the notion of annotated textual descriptions of processes, which represents a middle-ground between formalization and accessibility, and which accounts for different modeling styles, ranging from purely imperative to purely declarative. The contributions of this paper are implemented in several tools, and case studies are highlighted. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	language = {English},
	number = {6},
	journal = {Software and Systems Modeling},
	author = {Sànchez-Ferreres, Josep and Burattin, Andrea and Carmona, Josep and Montali, Marco and Padró, Lluís and Quishpi, Luís},
	year = {2021},
	note = {Publisher: Springer Science and Business Media Deutschland GmbH
Type: Article},
	keywords = {Business Process, Process mining, Case-studies, Software engineering, Computer simulation, Data-source, Current limitation, Textual description},
	pages = {2131 -- 2153},
	annote = {Cited by: 4; All Open Access, Green Open Access},
	annote = {Cited by: 6; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{perera_transformation_2020,
	title = {Transformation of contract descriptions in a domain specific language to solidity assembly},
	isbn = {978-1-72818-653-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100488359&doi=10.1109%2fICTer51097.2020.9325490&partnerID=40&md5=5562e246f15ab00b50c9b51cc1090a2d},
	doi = {10.1109/ICTer51097.2020.9325490},
	abstract = {There are a variety of contracts being traded in the financial markets. To eliminate the ambiguities imposed by the financial contracts written in natural languages, Peyton Jones and co-researchers proposed a contract definition language for standard representation of the financial contracts and a combinator library embedded in Haskell programming language to define financial contracts. Further, a special purpose compiler which is an extension to this work has been already proposed by exploiting major advancements such as autonomous contract execution and elimination of central counterparty in contemporary smart contracts, to transform contracts written in Peyton Jones' Contract Descriptive Language to Solidity which is the scripting language used in Ethereum smart contract platform. However, we have noticed that the cost related to the execution of contracts in Ethereum platform curtails the benefits received through the transformation of those contracts. Hence, we propose a novel approach to reduce the cost using different optimization techniques and it involves the direct transformation of the Peyton Jones' Contract Descriptive language to Solidity (inline) Assembly language which enables the manipulation of data locations in the Ethereum Virtual Machine. A formal verification is provided by verifying the semantic equivalence between the Peyton Jones' Contract Descriptive language and the proposed solution to ensure the correctness of the proposed approach is preserved while it is being optimized. © 2020 IEEE.},
	language = {English},
	booktitle = {20th {International} {Conference} on {Advances} in {ICT} for {Emerging} {Regions}, {ICTer} 2020 - {Proceedings}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Perera, K.S.M. and Gunawardana, K.G. and Keppitiyagama, C.I.},
	year = {2020},
	note = {Type: Conference paper},
	keywords = {Semantics, Domain specific languages, Problem oriented languages, Combinator library, Contract execution, Ethereum, Finance, Financial contracts, Haskell programming language, Metadata, Optimization techniques, Scripting languages, Semantic equivalences},
	pages = {89 -- 94},
	annote = {Cited by: 0; Conference name: 20th International Conference on Advances in ICT for Emerging Regions, ICTer 2020; Conference date: 5 November 2020 through 6 November 2020; Conference code: 166665},
	annote = {Cited by: 0; Conference name: 20th International Conference on Advances in ICT for Emerging Regions, ICTer 2020; Conference date: 5 November 2020 through 6 November 2020; Conference code: 166665},
	annote = {RELEVANCE: MEDIUM interesting

what is PeytonJones’ Contract Descriptive Language?
},
}


@inproceedings{gropler_nlp-based_2021,
	title = {{NLP}-based requirements formalization for automatic test case generation},
	volume = {2951},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115828064&partnerID=40&md5=04bc8919eac2d0d5edc5e50694938093},
	abstract = {Due to the growing complexity and rapid changes of software systems, the assurance of their quality becomes increasingly difficult. Model-based testing in agile development is a way to overcome these difficulties. However, major effort is still required to create specification models from a large set of functional requirements provided in natural language. This paper presents an approach for a machine-aided requirements formalization technique based on Natural Language Processing (NLP) to be used for an automatic test case generation. The goal of the presented method is to automate the process of model creation from requirements in natural language by utilizing appropriate algorithms, thus reducing cost and effort. The application of our procedure will be demonstrated using an industry example from the e-mobility domain. In this example, requirement models are generated for a charging approval system within a larger vehicle battery charging application. Additionally, existing tools for automated model synthesis and test case generation are applied to our models to evaluate whether valid test cases can be generated. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Gröpler, Robin and Sudhi, Viju and García, Emilio José Calleja and Bergmann, Andre},
	editor = {H, Schlingloff and T, Vogel},
	year = {2021},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Natural languages, Model checking, Requirements formalizations, Specification models, Requirement analysis, Agile development, Software-systems, Functional requirement, Test generations, Model based testing, Automatic testcase generation, Charging (batteries)},
	pages = {18 -- 30},
	annote = {Cited by: 3; Conference name: 29th International Workshop on Concurrency, Specification and Programming, CS and P 2021; Conference date: 27 September 2021 through 28 September 2021; Conference code: 171844},
	annote = {Cited by: 3; Conference name: 29th International Workshop on Concurrency, Specification and Programming, CS and P 2021; Conference date: 27 September 2021 through 28 September 2021; Conference code: 171844},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{wu_requirement_2021,
	title = {Requirement {Consistency} and {Integrity} {Verification} {Method} based on {Natural} {Language} {Processing}},
	volume = {1756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102400027&doi=10.1088%2f1742-6596%2f1756%2f1%2f012002&partnerID=40&md5=8a043c84bbd16ba015c284b184e675f5},
	doi = {10.1088/1742-6596/1756/1/012002},
	abstract = {In the iterative process of the update of the information service system, the continuous improvement of the system is restricted due to problems such as non-standard, incomplete, and strong ambiguity in the description of requirements. It makes it difficult to verify the consistency and integrity of requirements. In this paper, we focus on the huge requirements of complex information service system, and propose research on requirement itemized extraction and structured description technology based on natural language processing and requirement item keyword extraction and standardized expression technology. The library management system is used as the verification object to verify the effectiveness of the method proposed in this paper. © Published under licence by IOP Publishing Ltd.},
	language = {English},
	booktitle = {Journal of {Physics}: {Conference} {Series}},
	publisher = {IOP Publishing Ltd},
	author = {Wu, Chao and Huang, Zhong Hua and Yang, Yu Ting and Liu, Yue},
	year = {2021},
	note = {ISSN: 17426588
Issue: 1
Type: Conference paper},
	keywords = {Natural language processing systems, Extraction, Artificial intelligence, NAtural language processing, Big data, Iterative methods, Information services, Integrity verifications, Complex information, Continuous improvements, Information service systems, Iterative process, Keyword extraction, Library management},
	annote = {Cited by: 1; Conference name: 2020 International Conference on Industrial Applications of Big Data and Artificial Intelligence, BDAI 2020; Conference date: 26 November 2020 through 29 November 2020; Conference code: 167463; All Open Access, Bronze Open Access},
	annote = {Cited by: 2; Conference name: 2020 International Conference on Industrial Applications of Big Data and Artificial Intelligence, BDAI 2020; Conference date: 26 November 2020 through 29 November 2020; Conference code: 167463; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{wang_learning_2020,
	title = {Learning a natural-language to {LTL} executable semantic parser for grounded robotics},
	volume = {155},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168241969&partnerID=40&md5=6c3e5cd9fe6da29032fae93808c78a09},
	abstract = {Children acquire their native language with apparent ease by observing how language is used in context and attempting to use it themselves. They do so without laborious annotations, negative examples, or even direct corrections. We take a step toward robots that can do the same by training a grounded semantic parser, which discovers latent linguistic representations that can be used for the execution of natural-language commands. In particular, we focus on the difficult domain of commands with a temporal aspect, whose semantics we capture with Linear Temporal Logic, LTL. Our parser is trained with pairs of sentences and executions as well as an executor. At training time, the parser hypothesizes a meaning representation for the input as a formula in LTL. Three competing pressures allow the parser to discover meaning from language. First, any hypothesized meaning for a sentence must be permissive enough to reflect all the annotated execution trajectories. Second, the executor - a pretrained end-to-end LTL planner - must find that the observed trajectories are likely executions of the meaning. Finally, a generator, which reconstructs the original input, encourages the model to find representations that conserve knowledge about the command. Together these ensure that the meaning is neither too general nor too specific. Our model generalizes well, being able to parse and execute both machine-generated and human-generated commands, with near-equal accuracy, despite the fact that the human-generated sentences are much more varied and complex with an open lexicon. The approach presented here is not specific to LTL: it can be applied to any domain where sentence meanings can be hypothesized and an executor can verify these meanings, thus opening the door to many applications for robotic agents. © 2020 Proceedings of Machine Learning Research. All rights reserved.},
	language = {English},
	booktitle = {Proceedings of {Machine} {Learning} {Research}},
	publisher = {ML Research Press},
	author = {Wang, Christopher and Ross, Candace and Kuo, Yen-Ling and Katz, Boris and Barbu, Andrei},
	editor = {J, Kober and F, Ramos and C, Tomlin},
	year = {2020},
	note = {ISSN: 26403498
Type: Conference paper},
	keywords = {Natural languages, Semantics, Syntactics, Machine learning, Robotics, Semantic parsing, LTL, In contexts, Executable semantics, Linguistic representations, Native language, Negative examples, Temporal aspects, Weak supervision},
	pages = {1706 -- 1718},
	annote = {Cited by: 9; Conference name: 4th Conference on Robot Learning, CoRL 2020; Conference date: 16 November 2020 through 18 November 2020; Conference code: 193480},
	annote = {Cited by: 9; Conference name: 4th Conference on Robot Learning, CoRL 2020; Conference date: 16 November 2020 through 18 November 2020; Conference code: 193480},
	annote = {ISSN: 26403498 Type: Conference paper},
}


@inproceedings{rabinia_towards_2019,
	title = {Towards integrating the {FLG} framework with the {NLP} combinatory framework},
	volume = {2335},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063256698&partnerID=40&md5=d5d2e6f53281e0996c6a8ebbbc497af6},
	abstract = {Automatic modeling of privacy regulations is a highly demanded goal in requirements engineering. The FOL-based Legal-GRL (FLG) is a semi-automated goal-oriented modeling framework for extracting and representing the legal requirements of IT systems. One limitation of the FLG framework, however, is its manual requirements extraction process. Manual extraction of legal requirements is cumbersome, error-prone, and time-consuming. To overcome this shortcoming, we integrate this requirements modeling framework with another framework that combines several natural language processing (NLP) approaches. This Combinatory framework specifically exploits NLP techniques, such as Part-Of-Speech tagging and syntactic parsing, along with NLP tools, such as C\&C and Boxer, to propose an automated approach for extraction of rules from legal texts. This approach enables us to fully automate the FLG framework in order to propose a comprehensive framework for modeling privacy regulations and other legal requirements. This paper outlines the two frameworks and their integration process. Copyright © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Rabinia, Amin and Dragoni, Mauro and Ghanavati, Sepideh},
	editor = {N, Sadeh and K, Ghazinour and S, Wilson and S, Ghanavati},
	year = {2019},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Extraction, Artificial intelligence, NAtural language processing, Modeling languages, Automation, Syntactics, Requirements Models, Computational linguistics, Laws and legislation, Extraction process, Goal oriented modeling, Integration process, Legal requirements, Part of speech tagging, Privacy regulation},
	pages = {80 -- 82},
	annote = {Cited by: 0; Conference name: 2019 PAL: Privacy-Enhancing Artificial Intelligence and Language Technologies, PAL 2019; Conference date: 25 March 2019 through 27 March 2019; Conference code: 146046},
	annote = {Cited by: 0; Conference name: 2019 PAL: Privacy-Enhancing Artificial Intelligence and Language Technologies, PAL 2019; Conference date: 25 March 2019 through 27 March 2019; Conference code: 146046},
	annote = {RELEVANCE: HIGH - try to find a good version
},
}


@inproceedings{blasi_translating_2018,
	title = {Translating code comments to procedure specifications},
	isbn = {978-1-4503-5699-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051519685&doi=10.1145%2f3213846.3213872&partnerID=40&md5=173b5413dd042ae2139b2d4f3f31544c},
	doi = {10.1145/3213846.3213872},
	abstract = {Procedure specifications are useful in many software development tasks. As one example, in automatic test case generation they can guide testing, act as test oracles able to reveal bugs, and identify illegal inputs. Whereas formal specifications are seldom available in practice, it is standard practice for developers to document their code with semi-structured comments. These comments express the procedure specification with a mix of predefined tags and natural language. This paper presents Jdoctor, an approach that combines pattern, lexical, and semantic matching to translate Javadoc comments into executable procedure specifications written as Java expressions. In an empirical evaluation, Jdoctor achieved precision of 92\% and recall of 83\% in translating Javadoc into procedure specifications. We also supplied the Jdoctor-derived specifications to an automated test case generation tool, Randoop. The specifications enabled Randoop to generate test cases that produce fewer false alarms and reveal more defects. © 2018 Association for Computing Machinery.},
	language = {English},
	booktitle = {{ISSTA} 2018 - {Proceedings} of the 27th {ACM} {SIGSOFT} {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {Association for Computing Machinery, Inc},
	author = {Blasi, Arianna and Goffi, Alberto and Kuznetsov, Konstantin and Gorla, Alessandra and Ernst, Michael D. and Pezze, Mauro and Castellanos, Sergio Delgado},
	editor = {E, Bodden and F, Tip},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Software design, Semantics, Software testing, Translation (languages), Automated test case generation, Automatic test-case generations, Empirical evaluations, Semantic matching, Specification inferences, Standard practices, Test oracles},
	pages = {242 -- 253},
	annote = {Cited by: 57; Conference name: 27th ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2018; Conference date: 16 July 2018 through 21 July 2018; Conference code: 138042},
	annote = {Cited by: 66; Conference name: 27th ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2018; Conference date: 16 July 2018 through 21 July 2018; Conference code: 138042},
	annote = {RELEVANCE: NULL but interesting

https://homes.cs.washington.edu/{\textasciitilde}mernst/pubs/comments-specs-issta2018.pdf
},
}


@inproceedings{kadebu_security_2018,
	title = {Security requirements extraction and classification: {A} survey},
	isbn = {978-1-5386-6894-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081129130&doi=10.1109%2fIC3I44769.2018.9007263&partnerID=40&md5=f6a3adba24eda0416ac7378623e87796},
	doi = {10.1109/IC3I44769.2018.9007263},
	abstract = {Security Requirements Engineering is a very important process in the Software Development Life Cycle (SDLC) with Security Engineering being given profound attention in the development of software. It is imperative to build security within a software product. This ensures that software that is deployed is secure and can withstand attack. The research work explores Security Requirements extraction and classification techniques and application of Machine to the process. Techniques such as Naïve Bayes Classifier, K-NN, Support Vector Machine (SVM), ANN among others have been applied to the various tasks embedded in the process. This research will pave a way to techniques that can aid in the process of Security Requirements extraction and classification. © 2018 IEEE.},
	language = {English},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Contemporary} {Computing} and {Informatics}, {IC3I} 2018},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Kadebu, Prudence and Thada, Vikas and Chiurunge, Panashe},
	editor = {P.B, Sharma and A, Rana and P, Singh and S.K, Khatri and A.K, Bhatnagar},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Software design, Extraction, NAtural language processing, Cryptography, Security requirements, Computer software, Learning algorithms, Engineering research, Life cycle, Support vector machines, Classification technique, Security engineering, Security requirements engineering, Software development life cycle, Software products, Software security},
	pages = {129 -- 134},
	annote = {Cited by: 0; Conference name: 3rd International Conference on Contemporary Computing and Informatics, IC3I 2018; Conference date: 10 October 2018 through 12 October 2018; Conference code: 158025},
	annote = {Cited by: 0; Conference name: 3rd International Conference on Contemporary Computing and Informatics, IC3I 2018; Conference date: 10 October 2018 through 12 October 2018; Conference code: 158025},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{kushiro_logic_2020,
	title = {Logic visualization algorithm in system specifications as companion tool for system designing and testing},
	volume = {176},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093361878&doi=10.1016%2fj.procs.2020.09.227&partnerID=40&md5=82ed20779053c2d1f7e1637a50103d74},
	doi = {10.1016/j.procs.2020.09.227},
	abstract = {Formal methods are introduced into system designing and testing for realizing high-reliability system. However, the use of these techniques still remain restrictive, due to their redundancies. Most engineers fulfill their activities with natural languages, the specifications described in a natural language are indispensable. For applying the formal method, the specifications in natural language should be translated into a formal language expressly. While, the specifications in the formal language should be re-translated once again in the natural language for execution tests using actual software and/or product. Those redundancies are reasons why the formal methods cannot penetrate into actual industries. To solve these redundancies, algorithms for converting sentences in specification documents into semi-formal descriptions automatically, and visualizing logical relations among semiformal descriptions are proposed in the paper. © 2020 The Authors. Published by Elsevier B.V.},
	language = {English},
	booktitle = {Procedia {Computer} {Science}},
	publisher = {Elsevier B.V.},
	author = {Kushiro, Noriyuki and Aoyama, Yusuke},
	editor = {M, Cristani and C, Toro and C, Zanni-Merk and R.J, Howlett and L.C, Jain and L.C, Jain},
	year = {2020},
	note = {ISSN: 18770509
Type: Conference paper},
	keywords = {Formal specification, Natural languages, Formal languages, Software testing, Translation (languages), Knowledge based systems, Formal Description, Redundancy, Systems analysis, System specification, High-reliability systems, Logical relations, System designing, Visualization algorithms},
	pages = {1873 -- 1882},
	annote = {Cited by: 3; Conference name: 24th KES International Conference on Knowledge-Based and Intelligent Information and Engineering Systems, KES 2020; Conference date: 16 September 2020 through 18 September 2020; Conference code: 163593; All Open Access, Gold Open Access},
	annote = {Cited by: 3; Conference name: 24th KES International Conference on Knowledge-Based and Intelligent Information and Engineering Systems, KES 2020; Conference date: 16 September 2020 through 18 September 2020; Conference code: 163593; All Open Access, Gold Open Access},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{brunello_synthesis_2019,
	title = {Synthesis of {LTL} formulas from natural language texts: {State} of the art and research directions},
	volume = {147},
	isbn = {978-3-95977-127-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073529846&doi=10.4230%2fLIPIcs.TIME.2019.17&partnerID=40&md5=2a38c99621d79fcfd669488113caba70},
	doi = {10.4230/LIPIcs.TIME.2019.17},
	abstract = {Linear temporal logic (LTL) is commonly used in model checking tasks; moreover, it is well-suited for the formalization of technical requirements. However, the correct specification and interpretation of temporal logic formulas require a strong mathematical background and can hardly be done by domain experts, who, instead, tend to rely on a natural language description of the intended system behaviour. In such situations, a system that is able to automatically translate English sentences into LTL formulas, and vice versa, would be of great help. While the task of rendering an LTL formula into a more readable English sentence may be carried out in a relatively easy way by properly parsing the formula, the converse is still an open problem, due to the inherent difficulty of interpreting free, natural language texts. Although several partial solutions have been proposed in the past, the literature still lacks a critical assessment of the work done. We address such a shortcoming, presenting the current state of the art for what concerns the English-to-LTL translation problem, and outlining some possible research directions. © Michael H. Böhlen and Muhammad Saad;},
	language = {English},
	booktitle = {Leibniz {International} {Proceedings} in {Informatics}, {LIPIcs}},
	publisher = {Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing},
	author = {Brunello, Andrea and Montanari, Angelo and Reynolds, Mark},
	editor = {J, Gamper and S, Pinchinat and G, Sciavicco},
	year = {2019},
	note = {ISSN: 18688969
Type: Conference paper},
	keywords = {Evolutionary algorithms, Natural language processing systems, Natural language text, Semantics, Temporal logic, NAtural language processing, Linear temporal logic, Model checking, Computer circuits, Syntactics, Translation (languages), Machine learning, Learning algorithms, Context free grammars, Temporal logic formula, Technical requirement, Learning systems, Semantic parsing, Critical assessment, English sentences},
	pages = {171 -- 1719},
	annote = {Cited by: 29; Conference name: 26th International Symposium on Temporal Representation and Reasoning, TIME 2019; Conference date: 16 October 2019 through 19 October 2019; Conference code: 152384},
	annote = {Cited by: 34; Conference name: 26th International Symposium on Temporal Representation and Reasoning, TIME 2019; Conference date: 16 October 2019 through 19 October 2019; Conference code: 152384},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{gnesi_research_2018,
	title = {Research on {NLP} for {RE} at {CNR}-{ISTI}: {A} report},
	volume = {2075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045466444&partnerID=40&md5=0ff3222d0dafa5a0c6b52d93746d247c},
	abstract = {[Team Overview] The Formal Methods \& Tools (FMT) group of CNR-ISTI focuses on the study and development of formal methods and tools to support software development processes. [Past Research] FMT started working on requirements formalisation through natural language processing (NLP) at the end of the nineties. This stream of research evolved into requirements analysis and defect detection by means of NLP, with a focus on ambiguity, and resulted in the development and application of the QuARS tool for requirements analysis. More recently, the group started working on the analysis of requirements elicitation interviews, in which ambiguity in spoken natural language and other communication defects are studied. [Research Plan] In the upcoming years, FMT will devote its effort to the diffusion of a dataset for requirements analysis, to the usage of NLP in product line engineering, and to research in NLP techniques applied to the analysis of interviews. Copyright c 2018 by the paper's authors.},
	language = {English},
	booktitle = {{CEUR} {Workshop} {Proceedings}},
	publisher = {CEUR-WS},
	author = {Gnesi, Stefania and Ferrari, Alessio},
	editor = {F, Dalpiaz and X, Franch and M, Kirikova and J, Ralyte and P, Spoletini and Y, Chisik and A, Ferrari and N, Madhavji and C, Palomares and M, Sabetzadeh and D, van der Linden and K, Schmid and E.B, Charrada and P, Sawyer and P, Forbrig and A, Zamansky},
	year = {2018},
	note = {ISSN: 16130073
Type: Conference paper},
	keywords = {Natural language processing systems, Computer software selection and evaluation, Defects, Natural languages, Requirements engineering, Software design, Requirements elicitation, Defect detection, Development and applications, Formal methods, Product line engineering, Requirements analysis, Research plans, Software development process},
	annote = {Cited by: 0; Conference name: 24th Joint International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, REFSQ-JP 2018; Conference date: 19 March 2018; Conference code: 135277},
	annote = {Cited by: 0; Conference name: 24th Joint International Conference on Requirements Engineering: Foundation for Software Quality Workshops, Doctoral Symposium, REFSQ-JP 2018; Conference date: 19 March 2018; Conference code: 135277},
	annote = {RELEVANCE: MEDIUM
},
}


@inproceedings{gopalan_sequence--sequence_2018,
	title = {Sequence-to-{Sequence} {Language} {Grounding} of {Non}-{Markovian} {Task} {Specifications}},
	isbn = {978-0-9923747-4-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071436152&doi=10.15607%2fRSS.2018.XIV.067&partnerID=40&md5=3835730af7a0620e7c74571dfc62694c},
	doi = {10.15607/RSS.2018.XIV.067},
	abstract = {Often times, natural language commands issued to robots not only specify a particular target configuration or goal state but also outline constraints on how the robot goes about its execution. That is, the path taken to achieving some goal state is given equal importance to the goal state itself. One example of this could be instructing a wheeled robot to “go to the living room but avoid the kitchen,” in order to avoid scuffing the floor. This class of behaviors poses a serious obstacle to existing language understanding for robotics approaches that map to either action sequences or goal state representations. Due to the non-Markovian nature of the objective, approaches in the former category must map to potentially unbounded action sequences whereas approaches in the latter category would require folding the entirety of a robot’s trajectory into a (traditionally Markovian) state representation, resulting in an intractable decision-making problem. To resolve this challenge, we use a recently introduced probabilistic variant of Linear Temporal Logic (LTL) as a goal specification language for a Markov Decision Process (MDP). While demonstrating that standard neural sequence-to-sequence learning models can successfully ground language to this semantic representation, we also provide analysis that highlights generalization to novel, unseen logical forms as an open problem for this class of model. We evaluate our system within two simulated robot domains as well as on a physical robot, demonstrating accurate language grounding alongside a significant expansion in the space of interpretable robot behaviors. © 2018, MIT Press Journals. All rights reserved.},
	language = {English},
	booktitle = {Robotics: {Science} and {Systems}},
	publisher = {MIT Press Journals},
	author = {Gopalan, Nakul and Arumugam, Dilip and Wong, Lawson L.S. and Tellex, Stefanie},
	editor = {H, Kress-Gazit and S.S, Srinivasa and T, Howard and N, Atanasov},
	year = {2018},
	note = {ISSN: 2330765X
Type: Conference paper},
	keywords = {Decision making, Natural languages, Semantics, Temporal logic, Action sequences, Behavioral research, Language grounding, Living room, Markov processes, Non-Markovian, Robots, Scuffings, Specification languages, Specifications, State representation, Target configurations, Task specifications, Wheeled robot},
	annote = {Cited by: 26; Conference name: 14th Robotics: Science and Systems, RSS 2018; Conference date: 26 June 2018 through 30 June 2018; Conference code: 275109; All Open Access, Bronze Open Access},
	annote = {Cited by: 31; Conference name: 14th Robotics: Science and Systems, RSS 2018; Conference date: 26 June 2018 through 30 June 2018; Conference code: 275109; All Open Access, Bronze Open Access},
	annote = {RELEVANCE: MEDIUM

They introduce geometric LTL (GLTL)
},
}


@inproceedings{leeuwenberg_temporal_2018,
	title = {Temporal information extraction by predicting relative time-lines},
	isbn = {978-1-948087-84-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075460380&partnerID=40&md5=c7e9603e07c24a80b7665bc549c4ad14},
	abstract = {The current leading paradigm for temporal information extraction from text consists of three phases: (1) recognition of events and temporal expressions, (2) recognition of temporal relations among them, and (3) time-line construction from the temporal relations. In contrast to the first two phases, the last phase, time-line construction, received little attention and is the focus of this work. In this paper, we propose a new method to construct a linear time-line from a set of (extracted) temporal relations. But more importantly, we propose a novel paradigm in which we directly predict start and end-points for events from the text, constituting a time-line without going through the intermediate step of prediction of temporal relations as in earlier work. Within this paradigm, we propose two models that predict in linear complexity, and a new training loss using TimeML-style annotations, yielding promising results. © 2018 Association for Computational Linguistics},
	language = {English},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}, {EMNLP} 2018},
	publisher = {Association for Computational Linguistics},
	author = {Leeuwenberg, Artuur and Moens, Marie-Francine},
	editor = {E, Riloff and D, Chiang and J, Hockenmaier and J, Tsujii},
	year = {2018},
	note = {Type: Conference paper},
	keywords = {Natural language processing systems, Forecasting, Temporal logic, Information retrieval, Temporal expressions, Temporal relation, Character recognition, End points, Linear complexity, Linear time, Relative time, Temporal information extraction, Three phasis},
	pages = {1237 -- 1246},
	annote = {Cited by: 25; Conference name: 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018; Conference date: 31 October 2018 through 4 November 2018; Conference code: 158085},
	annote = {Cited by: 28; Conference name: 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018; Conference date: 31 October 2018 through 4 November 2018; Conference code: 158085},
	annote = {RELEVANCE: HIGHFrom TLinks to Time-lines (TL2RTL)
},
}


@inproceedings{fuggitti_nl2ltl_2023,
	title = {{NL2LTL} - {A} {Python} {Package} for {Converting} {Natural} {Language} ({NL}) {Instructions} to {Linear} {Temporal} {Logic} ({LTL}) {Formulas}},
	volume = {37},
	isbn = {978-1-57735-880-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162164607&partnerID=40&md5=e447cb9c369935ba15401c6d54471d1d},
	abstract = {This is a demonstration of our newly released Python package NL2LTL which leverages the latest in natural language understanding (NLU) and large language models (LLMs) to translate natural language instructions to linear temporal logic (LTL) formulas. This allows direct translation to formal languages that a reasoning system can use, while at the same time, allowing the end-user to provide inputs in natural language without having to understand any details of an underlying formal language. The package comes with support for a set of default LTL patterns, corresponding to popular DECLARE templates, but is also fully extensible to new formulas and user inputs. The package is open-source and is free to use for the AI community under the MIT license. Open Source: https://github.com/IBM/nl2ltl. Video Link: https://bit.ly/3dHW5b1. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	language = {English},
	booktitle = {Proceedings of the 37th {AAAI} {Conference} on {Artificial} {Intelligence}, {AAAI} 2023},
	publisher = {AAAI Press},
	author = {Fuggitti, Francesco and Chakraborti, Tathagata},
	editor = {B, Williams and Y, Chen and J, Neville},
	year = {2023},
	keywords = {Natural languages, Temporal logic, Artificial intelligence, Formal languages, Linear temporal logic, Computer circuits, Translation (languages), Temporal logic formula, Language model, Natural language understanding, End-users, High level languages, HTTP, Logic patterns, Open-source, Python, Reasoning system, User input},
	pages = {16428 -- 16430},
	annote = {Cited by: 1},
	annote = {Cited by: 1; Conference name: 37th AAAI Conference on Artificial Intelligence, AAAI 2023; Conference date: 7 February 2023 through 14 February 2023; Conference code: 190493},
	annote = {Cited by: 5; Conference name: 37th AAAI Conference on Artificial Intelligence, AAAI 2023; Conference date: 7 February 2023 through 14 February 2023; Conference code: 190493},
	annote = {Cited by: 5; Conference name: 37th AAAI Conference on Artificial Intelligence, AAAI 2023; Conference date: 7 February 2023 through 14 February 2023; Conference code: 190493},
	annote = {RELEVANCE: HIGH

https://bit.ly/3dHW5b1 -{\textgreater} video demo

it has industry appication

},
	annote = {Type: Conference paper},
}


@article{li_formalization_2023,
	title = {Formalization of {Natural} {Language} into {PPTL} {Specification} via {Neural} {Machine} {Translation}},
	volume = {13854 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152527374&doi=10.1007%2f978-3-031-29476-1_7&partnerID=40&md5=801df6dcc2dd3b26e89d7c3b762731a7},
	doi = {10.1007/978-3-031-29476-1_7},
	abstract = {Propositional Projection Temporal Logic (PPTL) has been widely used in formal verification, and its expressiveness is suitable for the description of security requirements. However, the expression and application of temporal logic formulas rely on a strong mathematical background, which is difficult for non-domain experts, thus bridging the chasm between natural language descriptions and formal languages is urgently needed. This paper proposes an innovative architecture for neural machine automatic translation named NL2PPTL, which transforms natural language into PPTL specification via utilizing data preprocessing, encoder-decoder network and stack sequentially. To evaluate the performance of our method, the experimental verification is realized on real datasets. The experiment conducted shows that our method has effectiveness on temporal logic specification generation. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Li, Chunyi and Chang, Jiajun and Wang, Xiaobing and Zhao, Liang and Mao, Wenjie},
	editor = {S, Liu and A, Liu and Z, Duan},
	year = {2023},
	keywords = {Natural language processing systems, Formal specification, Natural languages, Temporal logic, Formal languages, Formal verification, Computer circuits, Security requirements, Automatic translation, Formalisation, Domain experts, Temporal logic formula, Temporal logic specifications, Neural machine translation, Propositional projection temporal logic, Computational linguistics, Computer aided language translation, Data preprocessing, Language description},
	pages = {79 -- 92},
	annote = {Cited by: 0; Conference name: 11th International Workshop on Structured Object-Oriented Formal Language and Method, SOFL+MSVL 2022; Conference date: 24 October 2022 through 27 October 2022; Conference code: 292559},
	annote = {ISBN: 978-303129475-4 Publisher: Springer Science and Business Media Deutschland GmbH Type: Conference paper},
}


@article{manas_semantic_2023,
	title = {Semantic {Role} {Assisted} {Natural} {Language} {Rule} {Formalization} for {Intelligent} {Vehicle}},
	volume = {14244 LNCS},
	issn = {03029743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176010676&doi=10.1007%2f978-3-031-45072-3_13&partnerID=40&md5=3dc265e287ae8eced83eaded10712efa},
	doi = {10.1007/978-3-031-45072-3_13},
	abstract = {This paper proposes a novel pipeline to translate natural language rules and instructions for intelligent vehicles into temporal logic. The pipeline uses semantic role labeling (SRL), soft rule-based selection restrictions, and large language models (LLMs) to extract predicates, arguments, and temporal aspects from natural language rules and instruction. We then use the language understanding capability of LLMs to generate temporal logic rules from unstructured natural language text and additional information provided by SRL. We envision our model as a human-in-the-loop system that can facilitate the automated rule formalization for planning and verification systems in automated driving and drone planning. We demonstrate that our method can generate semantically correct temporal logic formulas from natural language text and provide implicit explanations of the output by showing the intermediate reasoning steps involved. This paper illustrates the integration of additional semantic knowledge and LLM and its application for the intelligent system domain of automated driving and drone planning. Our generalizable pipeline can easily extend to new logic formalization types, traffic rules, drone planning instructions, and application domains. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Manas, Kumar and Paschke, Adrian},
	editor = {A, Fensel and A, Ozaki and D, Roman and A, Soylu},
	year = {2023},
	keywords = {Natural language processing systems, Natural languages, Semantics, Temporal logic, Computer circuits, Automation, Formalisation, Intelligent systems, Language processing, Language model, Knowledge representation, Pipelines, Natural languages texts, Automated driving, Semantic role labeling, Drones, Intelligent vehicle highway systems, Knowledge-representation, Rule formalization, Semantic natural language processing},
	pages = {175 -- 189},
	annote = {Cited by: 0; Conference name: 7th International Joint Conference on Rules and Reasoning, RuleML+RR 2023; Conference date: 18 September 2023 through 20 September 2023; Conference code: 303029},
	annote = {ISBN: 978-303145071-6 Publisher: Springer Science and Business Media Deutschland GmbH Type: Conference paper},
}


@article{wan_semantic_2024,
	title = {Semantic {Consistency} and {Correctness} {Verification} of {Digital} {Traffic} {Rules}},
	issn = {20958099},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184618357&doi=10.1016%2fj.eng.2023.04.016&partnerID=40&md5=be85d90243d8b2c254b7d5991d76abfa},
	doi = {10.1016/j.eng.2023.04.016},
	abstract = {The consensus of the automotive industry and traffic management authorities is that autonomous vehicles must follow the same traffic laws as human drivers. Using formal or digital methods, natural language traffic rules can be translated into machine language and used by autonomous vehicles. In this paper, a translation flow is designed. Beyond the translation, a deeper examination is required, because the semantics of natural languages are rich and complex, and frequently contain hidden assumptions. The issue of how to ensure that digital rules are accurate and consistent with the original intent of the traffic rules they represent is both significant and unresolved. In response, we propose a method of formal verification that combines equivalence verification with model checking. Reasonable and reassuring digital traffic rules can be obtained by utilizing the proposed traffic rule digitization flow and verification method. In addition, we offer a number of simulation applications that employ digital traffic rules to assess vehicle violations. The experimental findings indicate that our digital rules utilizing metric temporal logic (MTL) can be easily incorporated into simulation platforms and autonomous driving systems (ADS). © 2023},
	language = {English},
	journal = {Engineering},
	author = {Wan, Lei and Wang, Changjun and Luo, Daxin and Liu, Hang and Ma, Sha and Hu, Weichao},
	year = {2024},
	keywords = {Semantics, Model checking, Formal verification, Translation (languages), Formalisation, Accident prevention, Autonomous vehicles, Traffic laws, Traffic rules, Simulation platform, Consistency verifications, Autonomous Vehicles, Autonomous driving, Automotive industry, Correctness verifications, Digitisation, Semantic consistency, Traffic management},
	annote = {All Open Access, Gold Open Access},
	annote = {All Open Access, Gold Open Access},
	annote = {All Open Access, Gold Open Access},
	annote = {Publisher: Elsevier Ltd Type: Article},
}


@inproceedings{bharadwaj_transforming_2023,
	title = {Transforming {Natural} {Language} {Requirements} into {Petri} {Nets} - {A} {Semi}-{Automated} {Approach}},
	volume = {2023-June},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174415416&partnerID=40&md5=88c458332485b32dd085cd36be25b116},
	abstract = {Software requirements are mostly specified in natural language (say English) and may contain errors. To prevent such errors, the requirements need to be transformed using formal methods, as analysis, identification and subsequent removal of errors are easier. But expression of requirements using formal methods is laborious. We propose a simple, semi-automated methodology that transforms natural language requirements into Petri nets. Petri nets allow better modeling and analysis of the requirements and hence have been chosen as the target method. A practical example of Automated Teller Machine has been used to demonstrate our approach. A tool NLTOPNGEN to implement this approach has been developed. © Grenze Scientific Society, 2023.},
	language = {English},
	booktitle = {14th {International} {Conference} on {Advances} in {Computing}, {Control}, and {Telecommunication} {Technologies}, {ACT} 2023},
	publisher = {Grenze Scientific Society},
	author = {Bharadwaj, A. Keshav and Agrawal, V.K. and Jayashree, R.},
	editor = {J, Stephen and P, Sharma and Y, Chaba and K.U, Abraham and P.K, Anooj and N, Mohammad and Universiti Kebangsaan Malaysia, 43600 UKM, Bangi Selangor and G, Thomas and S, Srikiran},
	year = {2023},
	keywords = {Petri nets, Natural language processing systems, Formal specification, Natural languages, Natural language requirements, Software requirements, Modeling languages, Automation, Requirements specifications, Language processing, Natural language processing, Errors, Modeling, Automated approach, Simple++, Consistency},
	pages = {2176 -- 2188},
	annote = {Cited by: 0; Conference name: 14th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2023; Conference date: 15 June 2023 through 16 June 2023; Conference code: 192282},
	annote = {Cited by: 0; Conference name: 14th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2023; Conference date: 15 June 2023 through 16 June 2023; Conference code: 192282},
	annote = {Type: Conference paper},
}


@inproceedings{zaki-ismail_rcm-extractor_2021,
	title = {{RCM}-{Extractor}: {Automated} {Extraction} of a {Semi} {Formal} {Representation} {Model} from {Natural} {Language} {Requirements}},
	isbn = {978-989-758-487-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173980705&doi=10.5220%2f0010270602700277&partnerID=40&md5=d56fd81ad96d9bb7cbd9a35f2abb4991},
	doi = {10.5220/0010270602700277},
	abstract = {Formal verification requires system requirements to be specified in formal notations. Formalisation of system requirements manually is a time-consuming and error-prone process, and requires engineers to have strong mathematical and domain expertise. Most existing requirements formalisation techniques assume requirements to be specified in pre-defined templates and these techniques employ pre-defined transformation rules to transform requirements specified in the predefined templates to formal notations. These techniques tend to have limited expressiveness and more importantly require system engineers to re-write their system requirements following these templates. In this paper, we introduces an automated extraction technique (RCMExtractor) to extract the key constructs of a comprehensive and formalisable semi-formal representation model from textual requirements. We have evaluated our RCM-Extractor on a dataset of 162 requirements curated from the literature. RCM-Extractor achieved 95\% precision, 79\% recall, 86\% F-measure and 75\% accuracy. © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	language = {English},
	booktitle = {International {Conference} on {Model}-{Driven} {Engineering} and {Software} {Development}},
	publisher = {Science and Technology Publications, Lda},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {E, Seidewitz and L, Ferreira Pires and S, Hammoudi},
	year = {2021},
	pages = {270 -- 277},
	annote = {Cited by: 0; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 300849; All Open Access, Hybrid Gold Open Access},
	annote = {ISSN: 21844348 Type: Conference paper},
}


@inproceedings{zaki-ismail_rcm-extractor_2021-1,
	title = {{RCM}-{Extractor}: {Automated} extraction of a semi formal representation model from natural language requirements},
	isbn = {978-989-758-487-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103016713&partnerID=40&md5=51343518983358f6d7356bee885f811d},
	abstract = {Formal verification requires system requirements to be specified in formal notations. Formalisation of system requirements manually is a time-consuming and error-prone process, and requires engineers to have strong mathematical and domain expertise. Most existing requirements formalisation techniques assume requirements to be specified in pre-defined templates and these techniques employ pre-defined transformation rules to transform requirements specified in the predefined templates to formal notations. These techniques tend to have limited expressiveness and more importantly require system engineers to re-write their system requirements following these templates. In this paper, we introduces an automated extraction technique (RCM-Extractor) to extract the key constructs of a comprehensive and formalisable semi-formal representation model from textual requirements. We have evaluated our RCM-Extractor on a dataset of 162 requirements curated from the literature. RCM-Extractor achieved 95\% precision, 79\% recall, 86\% F-measure and 75\% accuracy. Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	language = {English},
	booktitle = {{MODELSWARD} 2021 - {Proceedings} of the 9th {International} {Conference} on {Model}-{Driven} {Engineering} and {Software} {Development}},
	publisher = {SciTePress},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	editor = {S, Hammoudi and L.F, Pires and E, Seidewitz and R, Soley},
	year = {2021},
	keywords = {Natural language processing systems, Requirements engineering, Software design, Extraction, Natural language requirements, System requirements, Formal notations, Semi-formal representations, Transformation rules, Automated extraction, Domain expertise, Error-prone process},
	pages = {270 -- 277},
	annote = {Cited by: 6; Conference name: 9th International Conference on Model-Driven Engineering and Software Development, MODELSWARD 2021; Conference date: 8 February 2021 through 10 February 2021; Conference code: 167487},
	annote = {Type: Conference paper},
}


@article{ye_probabilistic_2022,
	title = {Probabilistic modelling and verification using {RoboChart} and {PRISM}},
	volume = {21},
	issn = {1619-1366},
	url = {https://doi.org/10.1007/s10270-021-00916-8},
	doi = {10.1007/s10270-021-00916-8},
	abstract = {RoboChart is a timed domain-specific language for robotics, distinctive in its support for automated verification by model checking and theorem proving. Since uncertainty is an essential part of robotic systems, we present here an extension to RoboChart to model uncertainty using probabilism. The extension enriches RoboChart state machines with probability through a new construct: probabilistic junctions as the source of transitions with a probability value. RoboChart has an accompanying tool, called RoboTool, for modelling and verification of functional and real-time behaviour. We present here also an automatic technique, implemented in RoboTool, to transform a RoboChart model into a PRISM model for verification. We have extended the property language of RoboTool so that probabilistic properties expressed in temporal logic can be written using controlled natural language.},
	number = {2},
	journal = {Softw. Syst. Model.},
	author = {Ye, Kangfeng and Cavalcanti, Ana and Foster, Simon and Miyazawa, Alvaro and Woodcock, Jim},
	month = apr,
	year = {2022},
	note = {Place: Berlin, Heidelberg
Publisher: Springer-Verlag},
	keywords = {Semantics, Formal Semantics, Model checking, Formal methods, Modeling languages, Problem oriented languages, Automated verification, Domain-specific language for robotic, Domain-specific language for robotics, Formal semantics, Model transformation, Modeling and verifications, PRISM, Prisms, Probabilistic model checking, Probabilistic model-checking, Probabilistic models, Probabilistic verification, Robotics, State machines, State-machine, Uncertainty analysis},
	pages = {667--716},
	annote = {Cited by: 8; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {Cited by: 12; All Open Access, Green Open Access, Hybrid Gold Open Access},
	annote = {RELEVANCE: MEDIUM - just for the idea

Since uncertainty is an essential part of robotic systems, we present here an extension to RoboChart to model uncertainty using probabilistic.
},
}


@inproceedings{lin_road_2022,
	title = {Road {Traffic} {Law} {Adaptive} {Decision}-making for {Self}-{Driving} {Vehicles}},
	url = {https://doi.org/10.1109/ITSC55140.2022.9922208},
	doi = {10.1109/ITSC55140.2022.9922208},
	abstract = {Self-driving vehicles have their own intelligence to drive on open roads. However, vehicle managers, e.g., government or industrial companies, still need a way to tell these self-driving vehicles what behaviors are encouraged or forbidden. Unlike human drivers, current self-driving vehicles cannot understand the traffic laws, and thus rely on the programmers manually writing the corresponding principles into the driving systems. It would be less efficient and hard to adapt some temporary traffic laws, especially when the vehicles use data-driven decision-making algorithms. Besides, current self-driving vehicle systems rarely take traffic law modification into consideration. This work aims to design a road traffic law adaptive decision-making method. The decision-making algorithm is designed based on reinforcement learning, in which the traffic rules are usually implicitly coded in deep neural networks. The main idea is to supply the adaptability to traffic laws of self-driving vehicles by a law-adaptive backup policy. In this work, the natural language-based traffic laws are first translated into a logical expression by the Linear Temporal Logic method. Then, the system will try to monitor in advance whether the self-driving vehicle may break the traffic laws by designing a long-term RL action space. Finally, a sample-based planning method will re-plan the trajectory when the vehicle may break the traffic rules. The method is validated in a Beijing Winter Olympic Lane scenario and an overtaking case, built in CARLA simulator. The results show that by adopting this method, self-driving vehicles can comply with new issued or updated traffic laws effectively. This method helps self-driving vehicles governed by digital traffic laws, which is necessary for the wide adoption of autonomous driving.},
	booktitle = {2022 {IEEE} 25th {International} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC})},
	publisher = {IEEE Press},
	author = {Lin, Jiaxin and Zhou, Wenhui and Wang, Hong and Cao, Zhong and Yu, Wenhao and Zhao, Chengxiang and Zhao, Ding and Yang, Diange and Li, Jun},
	year = {2022},
	note = {Place: Macau, China},
	keywords = {Decision making, 'current, Roads and streets, Reinforcement learning, Adaptive decision making, Autonomous vehicles, Decision-making algorithms, Decisions makings, Deep neural networks, Digital storage, Highway planning, Reinforcement learnings, Road traffic, Road vehicles, Self drivings, Self-driving vehicle, Traffic laws, Traffic rules},
	pages = {2034--2041},
	annote = {Cited by: 1; Conference name: 25th IEEE International Conference on Intelligent Transportation Systems, ITSC 2022; Conference date: 8 October 2022 through 12 October 2022; Conference code: 183941; All Open Access, Green Open Access},
	annote = {Cited by: 7; Conference name: 25th IEEE International Conference on Intelligent Transportation Systems, ITSC 2022; Conference date: 8 October 2022 through 12 October 2022; Conference code: 183941; All Open Access, Green Open Access},
	annote = {RELEVANCE: MEDIUM

How can self driving vehicles automatically comply with the temporary road traffic laws, e.g. exclusive winter olympic lane?


Road Traffic Law-Adaptive Decision Making



Traffic Law Digitization using Linear Temporal Logic

aw-violence Forecaster

if max speed of road is 40 km hora y ha recorrido 100km en 1 hora, ha violado temporal constraint?

CARLA simulation

compliance vs violation place


},
}


@inproceedings{wiecher_scenarios_2020,
	address = {New York, NY, USA},
	series = {{MODELS} '20},
	title = {Scenarios in the {Loop}: {Integrated} {Requirements} {Analysis} and {Automotive} {System} {Validation}},
	isbn = {978-1-4503-8135-2},
	url = {https://doi.org/10.1145/3417990.3421264},
	doi = {10.1145/3417990.3421264},
	abstract = {The development of safety-relevant systems in the automotive industry requires the definition of high-quality requirements and tests for the coordination and monitoring of development activities in an agile development environment. In this paper we describe a Scenarios in the Loop (SCIL) approach. SCIL combines (1) natural language requirements specification based on Behavior-Driven Development (BDD) with (2) formal and test-driven requirements modeling and analysis, and (3) integrates discipline-specific tools for software and system validation during development. A central element of SCIL is a flexible and executable scenario-based modeling language, the Scenario Modeling Language for Kotlin (SMLK). SMLK allows for an intuitive requirements formalization, and supports engineers to move iteratively, and continuously aided by automated checks, from stakeholder requirements to the validation of the implemented system. We evaluated the approach using a real example from the field of e-mobility.},
	booktitle = {Proceedings of the 23rd {ACM}/{IEEE} {International} {Conference} on {Model} {Driven} {Engineering} {Languages} and {Systems}: {Companion} {Proceedings}},
	publisher = {Association for Computing Machinery},
	author = {Wiecher, Carsten and Japs, Sergej and Kaiser, Lydia and Greenyer, Joel and Dumitrescu, Roman and Wolff, Carsten},
	year = {2020},
	keywords = {Natural language processing systems, Requirements engineering, Natural language requirements, Formal methods, Software testing, Modeling languages, Requirements formalizations, Requirements Models, Accident prevention, Agile development environments, automotive systems engineering, BizDevOps, Development activity, Integrated requirements, requirements analysis, Safety relevant systems, Scenario-based modeling, system validation},
	annote = {Cited by: 12; Conference name: 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020; Conference date: 16 October 2020 through 23 October 2020; Conference code: 164397},
	annote = {Cited by: 12; Conference name: 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020; Conference date: 16 October 2020 through 23 October 2020; Conference code: 164397},
	annote = {Cited by: 12; Conference name: 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020; Conference date: 16 October 2020 through 23 October 2020; Conference code: 164397},
	annote = {Cited by: 12; Conference name: 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020; Conference date: 16 October 2020 through 23 October 2020; Conference code: 164397},
	annote = {Cited by: 12; Conference name: 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS-C 2020; Conference date: 16 October 2020 through 23 October 2020; Conference code: 164397},
	annote = {event-place: Virtual Event, Canada},
	annote = {event-place: Virtual Event, Canada},
	annote = {event-place: Virtual Event, Canada},
	annote = {RELEVANCE: LOW - but nice ideas….

Scenarios in the Loop (SCIL) SCIL combines 
(1) natural language requirements specification based on Behavior-DrivenDevelopment (BDD) with 
(2) formal and test-driven requirements modeling and analysis, and 
(3) integrates discipline-specific tools for software and system validation during development

automotive systems engineering : The basisfor the development of often safety-critical systems are differentstandards (e.g. ISO26262 [ 20 ], ISO/SAE 21434 [ 32 ]). These must betaken into account by the stakeholders involved in the development,which leads to extensive process implementations in the companiesparticipating.

Vague requirements: At the start of the software imple-mentation, requirements were available in an under-specifiedform. In the course of the implementation it turned out thata number of constraints, error cases, etc. were not takeninto account and were only further elaborated during theimplementation phase

Manual requirements analysis: Scenarios were also usedhere to further concretise the behavior. There is currently alarge number of scenarios and there are still contradictionsbetween requirements that were not noticed during the doc-umentation and manual analysis of the requirements andonly became clear in the implementation phase
},
}


@article{zaki-ismail_rcm-extractor_2022,
	title = {{RCM}-{Extractor}: {An} {Automated} {NLP}-{Based} {Approach} for {Extracting} a {Semi} {Formal} {Representation} {Model} from {Natural} {Language} {Requirements}},
	volume = {29},
	issn = {0928-8910},
	url = {https://doi.org/10.1007/s10515-021-00312-y},
	doi = {10.1007/s10515-021-00312-y},
	abstract = {Most existing (semi-)automated requirements formalisation techniques assume requirements to be specified in predefined templates. They also employ template-specific transformation rules to provide the corresponding formal representation. Hence, such techniques have limited expressiveness and more importantly require system engineers to re-write their system requirements following defined templates for maintenance and evolution. In this paper, we introduce an automated requirements extraction technique (RCM-Extractor) to automatically extract the key constructs of a comprehensive and formalisable semi-formal representation model from textual requirements. This avoids the expressiveness issues affecting the existing requirement specification templates, and eliminates the need to rewriting the requirements to match the structure of such templates. We evaluated RCM-Extractor on a dataset of 162 requirements curated from several papers in the literature. RCM-Extractor achieved 87\% precision, 98\% recall, 92\% F-measure, and 86\% accuracy. In addition, we evaluated the capabilities of RCM-Extractor to extract requirements on a dataset of 15,000 automatically synthesised requirements that are constructed specifically to evaluate our approach. This dataset has a complete coverage of the possible structures and arrangements of the properties that can exist in system requirements. Our approach achieved 57\%, 92\% and 100\% accuracy for un-corrected, partially-corrected and fully-corrected Stanford typed-dependencies representations of the synthesised requirements, respectively.},
	number = {1},
	journal = {Automated Software Engg.},
	author = {Zaki-Ismail, Aya and Osama, Mohamed and Abdelrazek, Mohamed and Grundy, John and Ibrahim, Amani},
	month = may,
	year = {2022},
	keywords = {Natural language processing systems, Natural languages, Requirements engineering, Extraction, Natural language requirements, Requirements formalizations, Automation, System requirements, Requirement extraction, Requirements formalization, Natural-language extraction, Representation model, Requirements extraction, Semi-formal representations, Synthesised, Transformation rules},
	annote = {Cited by: 4},
	annote = {Cited by: 4},
	annote = {Cited by: 4},
	annote = {Cited by: 4},
	annote = {Cited by: 5},
	annote = {Place: USA Publisher: Kluwer Academic Publishers},
	annote = {Place: USA Publisher: Kluwer Academic Publishers},
	annote = {Place: USA Publisher: Kluwer Academic Publishers},
	annote = {RELEVANCE: HIGH


"Can a semi-formal representation be sufficient?"


"Should NLT be reformatted to a version that can be formalized?"



intro pana y figure

The introduce the concept of valid time to quantify the time constraints, also pre elapsed time and in between time


First, they add an overhead burden on the system engineers to re-write their requirements to con-form to the used template(s) even if the requirements are well written (i.e., haveno quality issues). Second, the user needs guidance to phrase the requirements incompliance with the defined format(s). Third, they reduce the expressiveness powerof the writing. Finally, the format might be so restricted that it becomes irritating touse.

which other semiformal representation exists?

what to do when you consider documents from different domains?
Zaki-Ismail et al. (2021b), we introduced an automated requirements extrac-tion technique (RCM-Extractor)

Additionally, we also utilised a new dataset of 15,000 automatically synthesised requirements covering all the possible structures of the requirement properties to assess the robustness of the developed approaches.

TODO: check out their dataset

ARSENAL first reduces the complexity of the input sentence through term replacement
},
}


@inproceedings{leong_translating_2023,
	title = {Translating {Natural} {Language} {Requirements} to {Formal} {Specifications}: {A} {Study} on {GPT} and {Symbolic} {NLP}},
	doi = {10.1109/DSN-W58399.2023.00065},
	abstract = {Software verification is essential to ensure dependability and that a system or component fulfils its specified requirements. Natural language is the most common way of specifying requirements, although many verification techniques such as theorem proving depend upon requirements being written in formal specification languages. Automatically translating requirements into a formal specification language is a relevant and challenging research question, because developers often lack the necessary expertise. In our work we consider the application of natural language processing (NLP) to address that research question. This paper considers two distinct approaches to formalise natural language requirements: a symbolic method and a GPT-based method. The two methods are evaluated with respect to their ability to generate accurate Java Modeling Language (JML) from textual requirements, and the results show good promise for automatic formalisation of requirements.},
	booktitle = {2023 53rd {Annual} {IEEE}/{IFIP} {International} {Conference} on {Dependable} {Systems} and {Networks} {Workshops} ({DSN}-{W})},
	author = {Leong, Iat Tou and Barbosa, Raul},
	month = jun,
	year = {2023},
	note = {ISSN: 2325-6664},
	keywords = {Conferences, Natural language processing systems, Formal specification, Natural languages, Natural language requirements, Modeling languages, Verification, Translation (languages), Formalisation, Verification techniques, Software engineering, Formal specification language, Java Modeling Language, Java programming language, Language processing, Research questions, Software verification, Symbolic methods, Natural language processing, Formal specifications, Software, Organizations, Costs, Java},
	pages = {259--262},
	annote = {Cited by: 0; Conference name: 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops Volume, DSN-W 2023; Conference date: 27 June 2023 through 30 June 2023; Conference code: 191633},
	annote = {Cited by: 0; Conference name: 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops Volume, DSN-W 2023; Conference date: 27 June 2023 through 30 June 2023; Conference code: 191633},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{gnezdilova_towards_2023,
	title = {Towards {Controlled} {Natural} {Language} for {Event}-{Driven} {Temporal} {Requirements}},
	doi = {10.1109/EDM58354.2023.10225047},
	abstract = {Currently, requirements for control software written in natural language are often formulated ambiguously and incompletely. Controlled natural languages (CNLs) can solve this problem, at the same time maintaining flexibility for writing and conveying requirements in an intuitive and common way. The creation of domain-specific controlled natural languages nowadays is under active development. In this paper, we suggest CNL which is based on event-driven semantics. This language is intended for describing the temporal properties of cyber-physical systems. We develop our CNL using a number of natural language patterns build for classes of requirements expressed in Event-Driven Temporal Logic formalism (EDTL). Due to formal semantics of EDTL, the suggested CNL is also unambiguous and can be translated into logic formulas. As a result, the proposed CNL provides an auxiliary tool to improve communication quality between different participants in the industrial system development process: customers, requirements engineers, developers, and others. Therefore, the solution helps to reduce the number of errors in the formulation of requirements at earlier stages of development.},
	booktitle = {2023 {IEEE} 24th {International} {Conference} of {Young} {Professionals} in {Electron} {Devices} and {Materials} ({EDM})},
	author = {Gnezdilova, Anna V. and Garanina, Natalia O. and Staroletov, Sergey M. and Zyubin, Vladimir E.},
	month = jun,
	year = {2023},
	note = {ISSN: 2325-419X},
	keywords = {Natural languages, Semantics, Software systems, Temporal logic, Linear temporal logic, Formal methods, Computer circuits, Cyber Physical System, Embedded systems, Control systems, Control software, Event-driven, Requirement, Controlled natural language, Cybe-physical systems, Cyber-physical systems, Event-driven temporal logic, Logic formalism, cyber-physical system, Planning, requirements, Prototypes, linear temporal logic, controlled natural language, event-driven temporal logic},
	pages = {1860--1865},
	annote = {Cited by: 0; Conference name: 24th IEEE International Conference of Young Professionals in Electron Devices and Materials, EDM 2023; Conference date: 29 June 2023 through 3 July 2023; Conference code: 192147},
	annote = {Cited by: 0; Conference name: 24th IEEE International Conference of Young Professionals in Electron Devices and Materials, EDM 2023; Conference date: 29 June 2023 through 3 July 2023; Conference code: 192147},
	annote = {RELEVANCE: HIGH - but i dont like it
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=\&arnumber=10225047
},
}


@inproceedings{irvine_structured_2023,
	title = {Structured {Natural} {Language} for expressing {Rules} of the {Road} for {Automated} {Driving} {Systems}},
	doi = {10.1109/IV55152.2023.10186664},
	abstract = {Automated Driving Systems (ADSs), like human drivers, must be compliant with the rules of the road. However, current rules of the road are not well defined. They use inconsistent and ambiguous language. As a result, they are not sufficiently formal for machine interpretability, a necessity for applications of verification and validation (V\&V) of ADSs. Rules must be defined in a way that make them usable to a variety of stakeholders. While first-order and temporal logic forms of rules of the road are needed for monitoring and verification during simulation and testing, a structured natural language for these rules is necessary for consistent definition. They must also adhering to standard vocabulary taxonomies of Operational Design Domain (ODD) and behaviour. This paper contributes a structured natural language based on formal logic, that allows rules of the road to be defined in a natural, yet precise manner, using concepts of ODD and behaviour, making them usable in the V\&V of ADSs. We evaluate the effectiveness of the language on a selection of rules from the Vienna Convention on Road Traffic and the UK Highway Code.},
	booktitle = {2023 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Irvine, Patrick and Da Costa, Antonio A. Bruto and Zhang, Xizhe and Khastgir, Siddartha and Jennings, Paul},
	month = jun,
	year = {2023},
	note = {ISSN: 2642-7214},
	keywords = {Natural languages, Computer circuits, Automation, Automated driving systems, Computer simulation languages, Design behaviours, Design domains, Formal logic, Human drivers, Logic, Operational design, Roads and streets, Rule of the road, Scenario, Verification-and-validation, Road traffic, Roads, Taxonomy, Safety, Vocabulary, natural language, Codes, logic, scenarios, automated driving systems, rules of the road},
	pages = {1--8},
	annote = {Cited by: 0; Conference name: 34th IEEE Intelligent Vehicles Symposium, IV 2023; Conference date: 4 June 2023 through 7 June 2023; Conference code: 191161},
	annote = {Cited by: 0; Conference name: 34th IEEE Intelligent Vehicles Symposium, IV 2023; Conference date: 4 June 2023 through 7 June 2023; Conference code: 191161; All Open Access, Green Open Access},
	annote = {RELEVANCE: HIGH
},
}


@inproceedings{ferro_simplifying_2023,
	title = {Simplifying {Requirements} {Formalization} for {Resource}-{Constrained} {Mission}-{Critical} {Software}},
	doi = {10.1109/DSN-W58399.2023.00066},
	abstract = {Developing critical software requires adherence to rigorous software development practices, such as formal requirement specification and verification. Despite their importance, such practices are often considered as complex and challenging tasks that require a strong formal methods background. In this paper, we present our work on simplifying the formal requirements specification experience for resource-constrained mission critical software through the use of structured natural language. To this end, we connect NASA’s FRET, a formal requirement elicitation and authoring tool with the Shelley model checking framework for MicroPython code. We report our experience on using these tools to specify requirements and analyze code from the NASA Ames PHALANX exploration concept.},
	booktitle = {2023 53rd {Annual} {IEEE}/{IFIP} {International} {Conference} on {Dependable} {Systems} and {Networks} {Workshops} ({DSN}-{W})},
	author = {Ferro, Carlos Mão de and Mavridou, Anastasia and Dille, Michael and Martins, Francisco},
	month = jun,
	year = {2023},
	note = {ISSN: 2325-6664},
	keywords = {Conferences, Formal specification, Natural languages, Requirements engineering, Software design, Model checking, Formal verification, Requirements formalizations, NASA, Software development practices, Codes (symbols), Requirement, Critical codes, Critical software, Formal requirement specifications, Mission critical, Mission critical softwares, Mission-critical code, Requirement verifications, requirements, Codes, verification, Authoring systems, Mission critical systems, mission-critical code},
	pages = {263--266},
	annote = {Cited by: 0; Conference name: 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops Volume, DSN-W 2023; Conference date: 27 June 2023 through 30 June 2023; Conference code: 191633},
	annote = {Cited by: 0; Conference name: 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops Volume, DSN-W 2023; Conference date: 27 June 2023 through 30 June 2023; Conference code: 191633},
	annote = {RELEVANCE: HIGH
},
}


